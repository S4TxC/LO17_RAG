{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2e66a5fb",
   "metadata": {},
   "source": [
    "# Dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a0121194",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Ignoring invalid distribution ~atplotlib (c:\\Users\\y455\\Programmes\\Anaconda\\Lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution ~atplotlib (c:\\Users\\y455\\Programmes\\Anaconda\\Lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution ~atplotlib (c:\\Users\\y455\\Programmes\\Anaconda\\Lib\\site-packages)\n"
     ]
    }
   ],
   "source": [
    "%pip install --upgrade pip -q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4b7bb7b3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Ignoring invalid distribution ~atplotlib (c:\\Users\\y455\\Programmes\\Anaconda\\Lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution ~atplotlib (c:\\Users\\y455\\Programmes\\Anaconda\\Lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution ~atplotlib (c:\\Users\\y455\\Programmes\\Anaconda\\Lib\\site-packages)\n"
     ]
    }
   ],
   "source": [
    "%pip install langchain-core langchain langchain-google-genai langchain-community chromadb pypdf pillow google-genai google-generativeai streamlit tqdm python-dotenv ipython -q"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "349191ff",
   "metadata": {},
   "source": [
    "# Imports des biblioth√®ques"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "dda0b55d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dotenv import load_dotenv\n",
    "import os\n",
    "from pathlib import Path\n",
    "import pickle\n",
    "from collections import defaultdict\n",
    "from typing import List, Tuple, Optional\n",
    "import pandas as pd\n",
    "import re\n",
    "import time\n",
    "from tqdm import tqdm\n",
    "from IPython.display import display, Markdown\n",
    "\n",
    "\n",
    "from langchain import PromptTemplate, hub\n",
    "from langchain.docstore.document import Document\n",
    "from langchain.schema import Document as SchemaDocument\n",
    "from langchain.prompts import PromptTemplate\n",
    "from langchain.document_loaders import WebBaseLoader, PyPDFLoader\n",
    "from langchain.schema import StrOutputParser\n",
    "from langchain.schema.prompt_template import format_document\n",
    "from langchain.schema.runnable import RunnablePassthrough\n",
    "from langchain.vectorstores import Chroma\n",
    "from langchain_community.document_loaders import PyPDFLoader as CommunityPDFLoader\n",
    "from langchain_community.vectorstores import Chroma as CommunityChroma\n",
    "\n",
    "\n",
    "import google.generativeai as genai\n",
    "from google.generativeai.types import HarmCategory, HarmBlockThreshold\n",
    "from langchain_google_genai import GoogleGenerativeAIEmbeddings, ChatGoogleGenerativeAI\n",
    "import google.api_core.exceptions as exceptions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a89aee6",
   "metadata": {},
   "source": [
    "# Workspace Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c58664e2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dossier courant¬†: c:\\Users\\y455\\Desktop\\LO17_App\n",
      "Contenu¬†: ['.env', 'app.py', 'chroma_db', 'CleanPDFs', 'clean_up_test', 'compiled_pdfs', 'csv', 'LO17_Project.ipynb', 'LO17_Projet.ipynb', 'pickles', 'question.xlsx', 'Rapport RAG.docx']\n",
      "PDFs charg√©s depuis le cache\n",
      "Client Google Generative AI initialis√©\n"
     ]
    }
   ],
   "source": [
    "# Cr√©er .env contenant :\n",
    "# GOOGLE_API_KEY=cl√©_api_google_ai_studio\n",
    "\n",
    "load_dotenv()\n",
    "GOOGLE_API_KEY = os.getenv(\"GOOGLE_API_KEY\")\n",
    "if not GOOGLE_API_KEY:\n",
    "    raise RuntimeError(\"Variable GOOGLE_API_KEY non trouv√©e dans .env\")\n",
    "os.environ[\"GOOGLE_API_KEY\"] = GOOGLE_API_KEY\n",
    "\n",
    "\n",
    "PROJECT_DIR = Path.cwd()\n",
    "os.chdir(PROJECT_DIR)\n",
    "print(f\"Dossier courant¬†: {PROJECT_DIR}\")\n",
    "print(\"Contenu¬†:\", [p.name for p in PROJECT_DIR.iterdir()])\n",
    "\n",
    "\n",
    "PDF_DIR = PROJECT_DIR / \"compiled_pdfs\"\n",
    "PICKLE_DIR = PROJECT_DIR / \"pickles\"\n",
    "PICKLE_DIR.mkdir(exist_ok=True)\n",
    "PICKLE_DOCS = PICKLE_DIR / \"docs.pkl\"\n",
    "PICKLE_BY_FILE = PICKLE_DIR / \"docs_par_fichier.pkl\"\n",
    "\n",
    "\n",
    "docs = []\n",
    "docs_by_file = defaultdict(list)\n",
    "\n",
    "\n",
    "if PICKLE_DOCS.exists() and PICKLE_BY_FILE.exists():\n",
    "    with open(PICKLE_DOCS, \"rb\") as f: docs = pickle.load(f)\n",
    "    with open(PICKLE_BY_FILE, \"rb\") as f: docs_by_file = pickle.load(f)\n",
    "    print(\"PDFs charg√©s depuis le cache\")\n",
    "else:\n",
    "    for pdf_path in PDF_DIR.glob(\"*.pdf\"):\n",
    "        loader = PyPDFLoader(str(pdf_path))\n",
    "        pages = loader.load()\n",
    "        for doc in pages:\n",
    "            doc.metadata[\"source\"] = pdf_path.name\n",
    "            docs.append(doc)\n",
    "            docs_by_file[pdf_path.name].append(doc)\n",
    "    with open(PICKLE_DOCS, \"wb\") as f: pickle.dump(docs, f)\n",
    "    with open(PICKLE_BY_FILE, \"wb\") as f: pickle.dump(docs_by_file, f)\n",
    "    print(\"PDFs pars√©s et mis en cache\")\n",
    "\n",
    "\n",
    "genai.configure(api_key=GOOGLE_API_KEY)\n",
    "print(\"Client Google Generative AI initialis√©\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac9dcd71",
   "metadata": {},
   "source": [
    "# First Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ea94f9c0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16 pages extraites et sauvegard√©es dans 'csv\\extracted_docs.csv'.\n"
     ]
    }
   ],
   "source": [
    "target_pdf_filename = \"Sales et al. - 2016 - Exploiting academic records for predicting student drop out A case study in Brazilian higher educat.pdf\"\n",
    "pdf_dir = \"compiled_pdfs\"\n",
    "target_pdf_path = Path(pdf_dir) / target_pdf_filename\n",
    "csv_folder = \"csv\"\n",
    "\n",
    "if target_pdf_path.exists():\n",
    "    loader = PyPDFLoader(str(target_pdf_path))\n",
    "    loaded_docs = loader.load()\n",
    "    data = []\n",
    "    for doc in loaded_docs:\n",
    "        data.append({\n",
    "            \"source\": target_pdf_filename,\n",
    "            \"page_content\": doc.page_content.strip()\n",
    "        })\n",
    "\n",
    "    df = pd.DataFrame(data)\n",
    "    output_csv_path = os.path.join(csv_folder, \"extracted_docs.csv\")\n",
    "    df.to_csv(output_csv_path, index=False)\n",
    "\n",
    "    print(f\"{len(df)} pages extraites et sauvegard√©es dans '{output_csv_path}'.\")\n",
    "else:\n",
    "    print(f\"Erreur : fichier {target_pdf_filename} non trouv√©.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5fb81f61",
   "metadata": {},
   "source": [
    "# Prompt for cleaning a file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "63dda43a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input_variables=['context'] input_types={} partial_variables={} template='You are a professional document cleaner specialized in preparing text for both human readability and further LLM processing.\\n\\nI will provide you with a chunk of raw document text. Your task is to clean and extract only the meaningful narrative content by applying the following rules:\\nRemove:\\n\\n    Text that appears to be misinterpreted or garbled output from figures, graphs, or images (e.g., axis labels, chart legends, OCR artifacts).\\n\\n    Mathematical equations, whether inline or block format.\\n\\n    Page headers and footers (e.g., repeated titles, page numbers, author names).\\n\\n    Academic references and citations, especially reference lists typically found at the end of academic papers or embedded in text (e.g., \"[12]\", \"(Smith, 2018)\").\\n\\nKeep:\\n\\n    All narrative text that explains figures, graphs, or tables.\\n\\n    Section titles and headings, even if they are standalone.\\n\\nOutput format:\\n\\n    Return only the cleaned text with no extra commentary, metadata, or formatting beyond the cleaned content.\\n\\nInput Text Chunk:\\n{context}'\n"
     ]
    }
   ],
   "source": [
    "# Prompt template to query Gemini\n",
    "llm_prompt_template = \"\"\"You are a professional document cleaner specialized in preparing text for both human readability and further LLM processing.\n",
    "\n",
    "I will provide you with a chunk of raw document text. Your task is to clean and extract only the meaningful narrative content by applying the following rules:\n",
    "Remove:\n",
    "\n",
    "    Text that appears to be misinterpreted or garbled output from figures, graphs, or images (e.g., axis labels, chart legends, OCR artifacts).\n",
    "\n",
    "    Mathematical equations, whether inline or block format.\n",
    "\n",
    "    Page headers and footers (e.g., repeated titles, page numbers, author names).\n",
    "\n",
    "    Academic references and citations, especially reference lists typically found at the end of academic papers or embedded in text (e.g., \"[12]\", \"(Smith, 2018)\").\n",
    "\n",
    "Keep:\n",
    "\n",
    "    All narrative text that explains figures, graphs, or tables.\n",
    "\n",
    "    Section titles and headings, even if they are standalone.\n",
    "\n",
    "Output format:\n",
    "\n",
    "    Return only the cleaned text with no extra commentary, metadata, or formatting beyond the cleaned content.\n",
    "\n",
    "Input Text Chunk:\n",
    "{context}\"\"\"\n",
    "\n",
    "llm_prompt = PromptTemplate.from_template(llm_prompt_template)\n",
    "\n",
    "print(llm_prompt)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f606dbbc",
   "metadata": {},
   "source": [
    "# Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "372f56c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "MODEL_ID = \"gemini-2.0-flash\" # @param [\"gemini-2.0-flash-lite\",\"gemini-2.0-flash\",\"gemini-2.5-flash-preview-05-20\",\"gemini-2.5-pro-preview-05-06\"] {\"allow-input\":true, isTemplate: true}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6f711e2",
   "metadata": {},
   "source": [
    "# Cleaning one file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b63eed36",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "42 pages extraites et sauvegard√©es dans './clean_up_test\\extracted_docs.csv'.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/42 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Traitement du chunk 1/42 - Tentative 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  2%|‚ñè         | 1/42 [00:04<03:18,  4.83s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úì Chunk 1 trait√© avec succ√®s\n",
      "Traitement du chunk 2/42 - Tentative 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  5%|‚ñç         | 2/42 [00:07<02:28,  3.72s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úì Chunk 2 trait√© avec succ√®s\n",
      "Traitement du chunk 3/42 - Tentative 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  7%|‚ñã         | 3/42 [00:11<02:27,  3.77s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úì Chunk 3 trait√© avec succ√®s\n",
      "Traitement du chunk 4/42 - Tentative 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 10%|‚ñâ         | 4/42 [00:20<03:35,  5.66s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úì Chunk 4 trait√© avec succ√®s\n",
      "Traitement du chunk 5/42 - Tentative 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 12%|‚ñà‚ñè        | 5/42 [00:29<04:17,  6.95s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úì Chunk 5 trait√© avec succ√®s\n",
      "Traitement du chunk 6/42 - Tentative 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 14%|‚ñà‚ñç        | 6/42 [00:36<04:11,  6.99s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úì Chunk 6 trait√© avec succ√®s\n",
      "Traitement du chunk 7/42 - Tentative 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 17%|‚ñà‚ñã        | 7/42 [00:45<04:25,  7.58s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úì Chunk 7 trait√© avec succ√®s\n",
      "Traitement du chunk 8/42 - Tentative 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 19%|‚ñà‚ñâ        | 8/42 [00:58<05:22,  9.49s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úì Chunk 8 trait√© avec succ√®s\n",
      "Traitement du chunk 9/42 - Tentative 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 21%|‚ñà‚ñà‚ñè       | 9/42 [01:06<04:58,  9.04s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úì Chunk 9 trait√© avec succ√®s\n",
      "Traitement du chunk 10/42 - Tentative 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 24%|‚ñà‚ñà‚ñç       | 10/42 [01:10<03:56,  7.38s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úì Chunk 10 trait√© avec succ√®s\n",
      "Traitement du chunk 11/42 - Tentative 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 26%|‚ñà‚ñà‚ñå       | 11/42 [01:12<03:01,  5.85s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úì Chunk 11 trait√© avec succ√®s\n",
      "Traitement du chunk 12/42 - Tentative 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 29%|‚ñà‚ñà‚ñä       | 12/42 [01:21<03:21,  6.71s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úì Chunk 12 trait√© avec succ√®s\n",
      "Traitement du chunk 13/42 - Tentative 1\n",
      "‚ö† Erreur serveur (tentative 1/10): 500 Internal error encountered.\n",
      "‚è≥ Attente de 5 secondes avant nouvelle tentative...\n",
      "Traitement du chunk 13/42 - Tentative 2\n",
      "‚ö† Erreur serveur (tentative 2/10): 500 Internal error encountered.\n",
      "‚è≥ Attente de 10 secondes avant nouvelle tentative...\n",
      "Traitement du chunk 13/42 - Tentative 3\n",
      "‚ö† Erreur serveur (tentative 3/10): 500 Internal error encountered.\n",
      "‚è≥ Attente de 20 secondes avant nouvelle tentative...\n",
      "Traitement du chunk 13/42 - Tentative 4\n",
      "‚ö† Erreur serveur (tentative 4/10): 500 Internal error encountered.\n",
      "‚è≥ Attente de 40 secondes avant nouvelle tentative...\n",
      "Traitement du chunk 13/42 - Tentative 5\n",
      "‚ö† Erreur serveur (tentative 5/10): 500 Internal error encountered.\n",
      "‚è≥ Attente de 80 secondes avant nouvelle tentative...\n",
      "Traitement du chunk 13/42 - Tentative 6\n",
      "‚ö† Erreur serveur (tentative 6/10): 500 Internal error encountered.\n",
      "‚è≥ Attente de 120 secondes avant nouvelle tentative...\n",
      "Traitement du chunk 13/42 - Tentative 7\n",
      "‚ö† Erreur serveur (tentative 7/10): 500 Internal error encountered.\n",
      "‚è≥ Attente de 120 secondes avant nouvelle tentative...\n",
      "Traitement du chunk 13/42 - Tentative 8\n",
      "‚ö† Erreur serveur (tentative 8/10): 500 Internal error encountered.\n",
      "‚è≥ Attente de 120 secondes avant nouvelle tentative...\n",
      "Traitement du chunk 13/42 - Tentative 9\n",
      "‚ö† Erreur serveur (tentative 9/10): 500 Internal error encountered.\n",
      "‚è≥ Attente de 120 secondes avant nouvelle tentative...\n",
      "Traitement du chunk 13/42 - Tentative 10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 31%|‚ñà‚ñà‚ñà       | 13/42 [13:28<1:48:39, 224.82s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚ö† Erreur serveur (tentative 10/10): 500 Internal error encountered.\n",
      "‚ùå √âchec apr√®s 10 tentatives pour le chunk 13 - Erreur Serveur\n",
      "Traitement du chunk 14/42 - Tentative 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 33%|‚ñà‚ñà‚ñà‚ñé      | 14/42 [13:38<1:14:38, 159.96s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úì Chunk 14 trait√© avec succ√®s\n",
      "Traitement du chunk 15/42 - Tentative 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 36%|‚ñà‚ñà‚ñà‚ñå      | 15/42 [13:47<51:28, 114.38s/it]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úì Chunk 15 trait√© avec succ√®s\n",
      "Traitement du chunk 16/42 - Tentative 1\n",
      "‚ö† Erreur serveur (tentative 1/10): 500 Internal error encountered.\n",
      "‚è≥ Attente de 5 secondes avant nouvelle tentative...\n",
      "Traitement du chunk 16/42 - Tentative 2\n",
      "‚ö† Erreur serveur (tentative 2/10): 500 Internal error encountered.\n",
      "‚è≥ Attente de 10 secondes avant nouvelle tentative...\n",
      "Traitement du chunk 16/42 - Tentative 3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 38%|‚ñà‚ñà‚ñà‚ñä      | 16/42 [14:25<39:38, 91.49s/it] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úì Chunk 16 trait√© avec succ√®s\n",
      "Traitement du chunk 17/42 - Tentative 1\n",
      "‚ö† Erreur serveur (tentative 1/10): 500 Internal error encountered.\n",
      "‚è≥ Attente de 5 secondes avant nouvelle tentative...\n",
      "Traitement du chunk 17/42 - Tentative 2\n",
      "‚ö† Erreur serveur (tentative 2/10): 500 Internal error encountered.\n",
      "‚è≥ Attente de 10 secondes avant nouvelle tentative...\n",
      "Traitement du chunk 17/42 - Tentative 3\n",
      "‚ö† Erreur serveur (tentative 3/10): 500 Internal error encountered.\n",
      "‚è≥ Attente de 20 secondes avant nouvelle tentative...\n",
      "Traitement du chunk 17/42 - Tentative 4\n",
      "‚ö† Erreur serveur (tentative 4/10): 500 Internal error encountered.\n",
      "‚è≥ Attente de 40 secondes avant nouvelle tentative...\n",
      "Traitement du chunk 17/42 - Tentative 5\n",
      "‚ö† Erreur serveur (tentative 5/10): 500 Internal error encountered.\n",
      "‚è≥ Attente de 80 secondes avant nouvelle tentative...\n",
      "Traitement du chunk 17/42 - Tentative 6\n",
      "‚ö† Erreur serveur (tentative 6/10): 500 Internal error encountered.\n",
      "‚è≥ Attente de 120 secondes avant nouvelle tentative...\n",
      "Traitement du chunk 17/42 - Tentative 7\n",
      "‚ö† Erreur serveur (tentative 7/10): 500 Internal error encountered.\n",
      "‚è≥ Attente de 120 secondes avant nouvelle tentative...\n",
      "Traitement du chunk 17/42 - Tentative 8\n",
      "‚ö† Erreur serveur (tentative 8/10): 500 Internal error encountered.\n",
      "‚è≥ Attente de 120 secondes avant nouvelle tentative...\n",
      "Traitement du chunk 17/42 - Tentative 9\n",
      "‚ö† Erreur serveur (tentative 9/10): 500 Internal error encountered.\n",
      "‚è≥ Attente de 120 secondes avant nouvelle tentative...\n",
      "Traitement du chunk 17/42 - Tentative 10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 40%|‚ñà‚ñà‚ñà‚ñà      | 17/42 [25:42<1:51:27, 267.51s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚ö† Erreur serveur (tentative 10/10): 500 Internal error encountered.\n",
      "‚ùå √âchec apr√®s 10 tentatives pour le chunk 17 - Erreur Serveur\n",
      "Traitement du chunk 18/42 - Tentative 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 43%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 18/42 [25:45<1:15:10, 187.94s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úì Chunk 18 trait√© avec succ√®s\n",
      "Traitement du chunk 19/42 - Tentative 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 45%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 19/42 [25:49<50:56, 132.89s/it]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úì Chunk 19 trait√© avec succ√®s\n",
      "Traitement du chunk 20/42 - Tentative 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 48%|‚ñà‚ñà‚ñà‚ñà‚ñä     | 20/42 [25:54<34:35, 94.32s/it] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úì Chunk 20 trait√© avec succ√®s\n",
      "Traitement du chunk 21/42 - Tentative 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 21/42 [25:57<23:25, 66.92s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úì Chunk 21 trait√© avec succ√®s\n",
      "Traitement du chunk 22/42 - Tentative 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 52%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè    | 22/42 [26:02<16:08, 48.44s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úì Chunk 22 trait√© avec succ√®s\n",
      "Traitement du chunk 23/42 - Tentative 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 55%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç    | 23/42 [26:04<10:57, 34.62s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úì Chunk 23 trait√© avec succ√®s\n",
      "Traitement du chunk 24/42 - Tentative 1\n",
      "‚ö† Erreur inattendue (tentative 1/10): Invalid operation: The `response.text` quick accessor requires the response to contain a valid `Part`, but none were returned. The candidate's [finish_reason](https://ai.google.dev/api/generate-content#finishreason) is 4. Meaning that the model was reciting from copyrighted material.\n",
      "‚è≥ Attente de 5.0 secondes...\n",
      "Traitement du chunk 24/42 - Tentative 2\n",
      "‚ö† Erreur inattendue (tentative 2/10): Invalid operation: The `response.text` quick accessor requires the response to contain a valid `Part`, but none were returned. The candidate's [finish_reason](https://ai.google.dev/api/generate-content#finishreason) is 4. Meaning that the model was reciting from copyrighted material.\n",
      "‚è≥ Attente de 7.5 secondes...\n",
      "Traitement du chunk 24/42 - Tentative 3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 24/42 [27:05<12:46, 42.56s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úì Chunk 24 trait√© avec succ√®s\n",
      "Traitement du chunk 25/42 - Tentative 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 60%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ    | 25/42 [27:07<08:33, 30.20s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úì Chunk 25 trait√© avec succ√®s\n",
      "Traitement du chunk 26/42 - Tentative 1\n",
      "‚ö† Erreur serveur (tentative 1/10): 500 Internal error encountered.\n",
      "‚è≥ Attente de 5 secondes avant nouvelle tentative...\n",
      "Traitement du chunk 26/42 - Tentative 2\n",
      "‚ö† Erreur serveur (tentative 2/10): 500 Internal error encountered.\n",
      "‚è≥ Attente de 10 secondes avant nouvelle tentative...\n",
      "Traitement du chunk 26/42 - Tentative 3\n",
      "‚ö† Erreur serveur (tentative 3/10): 500 Internal error encountered.\n",
      "‚è≥ Attente de 20 secondes avant nouvelle tentative...\n",
      "Traitement du chunk 26/42 - Tentative 4\n",
      "‚ö† Erreur serveur (tentative 4/10): 500 Internal error encountered.\n",
      "‚è≥ Attente de 40 secondes avant nouvelle tentative...\n",
      "Traitement du chunk 26/42 - Tentative 5\n",
      "‚ö† Erreur serveur (tentative 5/10): 500 Internal error encountered.\n",
      "‚è≥ Attente de 80 secondes avant nouvelle tentative...\n",
      "Traitement du chunk 26/42 - Tentative 6\n",
      "‚ö† Erreur serveur (tentative 6/10): 500 Internal error encountered.\n",
      "‚è≥ Attente de 120 secondes avant nouvelle tentative...\n",
      "Traitement du chunk 26/42 - Tentative 7\n",
      "‚ö† Erreur serveur (tentative 7/10): 500 Internal error encountered.\n",
      "‚è≥ Attente de 120 secondes avant nouvelle tentative...\n",
      "Traitement du chunk 26/42 - Tentative 8\n",
      "‚ö† Erreur serveur (tentative 8/10): 500 Internal error encountered.\n",
      "‚è≥ Attente de 120 secondes avant nouvelle tentative...\n",
      "Traitement du chunk 26/42 - Tentative 9\n",
      "‚ö† Erreur serveur (tentative 9/10): 500 Internal error encountered.\n",
      "‚è≥ Attente de 120 secondes avant nouvelle tentative...\n",
      "Traitement du chunk 26/42 - Tentative 10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 62%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   | 26/42 [38:54<1:02:14, 233.42s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úì Chunk 26 trait√© avec succ√®s\n",
      "Traitement du chunk 27/42 - Tentative 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 64%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç   | 27/42 [39:03<41:30, 166.02s/it]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úì Chunk 27 trait√© avec succ√®s\n",
      "Traitement du chunk 28/42 - Tentative 1\n",
      "‚ö† Erreur serveur (tentative 1/10): 500 Internal error encountered.\n",
      "‚è≥ Attente de 5 secondes avant nouvelle tentative...\n",
      "Traitement du chunk 28/42 - Tentative 2\n",
      "‚ö† Erreur serveur (tentative 2/10): 500 Internal error encountered.\n",
      "‚è≥ Attente de 10 secondes avant nouvelle tentative...\n",
      "Traitement du chunk 28/42 - Tentative 3\n",
      "‚ö† Erreur serveur (tentative 3/10): 500 Internal error encountered.\n",
      "‚è≥ Attente de 20 secondes avant nouvelle tentative...\n",
      "Traitement du chunk 28/42 - Tentative 4\n",
      "‚ö† Erreur serveur (tentative 4/10): 500 Internal error encountered.\n",
      "‚è≥ Attente de 40 secondes avant nouvelle tentative...\n",
      "Traitement du chunk 28/42 - Tentative 5\n",
      "‚ö† Erreur serveur (tentative 5/10): 500 Internal error encountered.\n",
      "‚è≥ Attente de 80 secondes avant nouvelle tentative...\n",
      "Traitement du chunk 28/42 - Tentative 6\n",
      "‚ö† Erreur serveur (tentative 6/10): 500 Internal error encountered.\n",
      "‚è≥ Attente de 120 secondes avant nouvelle tentative...\n",
      "Traitement du chunk 28/42 - Tentative 7\n",
      "‚ö† Erreur serveur (tentative 7/10): 500 Internal error encountered.\n",
      "‚è≥ Attente de 120 secondes avant nouvelle tentative...\n",
      "Traitement du chunk 28/42 - Tentative 8\n",
      "‚ö† Erreur serveur (tentative 8/10): 500 Internal error encountered.\n",
      "‚è≥ Attente de 120 secondes avant nouvelle tentative...\n",
      "Traitement du chunk 28/42 - Tentative 9\n",
      "‚ö† Erreur serveur (tentative 9/10): 500 Internal error encountered.\n",
      "‚è≥ Attente de 120 secondes avant nouvelle tentative...\n",
      "Traitement du chunk 28/42 - Tentative 10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 67%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 28/42 [50:51<1:16:41, 328.70s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚ö† Erreur serveur (tentative 10/10): 500 Internal error encountered.\n",
      "‚ùå √âchec apr√®s 10 tentatives pour le chunk 28 - Erreur Serveur\n",
      "Traitement du chunk 29/42 - Tentative 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 69%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ   | 29/42 [51:00<50:24, 232.69s/it]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úì Chunk 29 trait√© avec succ√®s\n",
      "Traitement du chunk 30/42 - Tentative 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 71%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 30/42 [51:04<32:49, 164.10s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úì Chunk 30 trait√© avec succ√®s\n",
      "Traitement du chunk 31/42 - Tentative 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 74%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç  | 31/42 [51:13<21:32, 117.53s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úì Chunk 31 trait√© avec succ√®s\n",
      "Traitement du chunk 32/42 - Tentative 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 76%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 32/42 [51:17<13:54, 83.40s/it] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úì Chunk 32 trait√© avec succ√®s\n",
      "Traitement du chunk 33/42 - Tentative 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 79%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä  | 33/42 [51:20<08:53, 59.22s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úì Chunk 33 trait√© avec succ√®s\n",
      "Traitement du chunk 34/42 - Tentative 1\n",
      "‚ö† Erreur inattendue (tentative 1/10): Invalid operation: The `response.text` quick accessor requires the response to contain a valid `Part`, but none were returned. The candidate's [finish_reason](https://ai.google.dev/api/generate-content#finishreason) is 4. Meaning that the model was reciting from copyrighted material.\n",
      "‚è≥ Attente de 5.0 secondes...\n",
      "Traitement du chunk 34/42 - Tentative 2\n",
      "‚ö† Erreur inattendue (tentative 2/10): Invalid operation: The `response.text` quick accessor requires the response to contain a valid `Part`, but none were returned. The candidate's [finish_reason](https://ai.google.dev/api/generate-content#finishreason) is 4. Meaning that the model was reciting from copyrighted material.\n",
      "‚è≥ Attente de 7.5 secondes...\n",
      "Traitement du chunk 34/42 - Tentative 3\n",
      "‚ö† Erreur inattendue (tentative 3/10): Invalid operation: The `response.text` quick accessor requires the response to contain a valid `Part`, but none were returned. The candidate's [finish_reason](https://ai.google.dev/api/generate-content#finishreason) is 4. Meaning that the model was reciting from copyrighted material.\n",
      "‚è≥ Attente de 11.2 secondes...\n",
      "Traitement du chunk 34/42 - Tentative 4\n",
      "‚ö† Erreur inattendue (tentative 4/10): Invalid operation: The `response.text` quick accessor requires the response to contain a valid `Part`, but none were returned. The candidate's [finish_reason](https://ai.google.dev/api/generate-content#finishreason) is 4. Meaning that the model was reciting from copyrighted material.\n",
      "‚è≥ Attente de 16.9 secondes...\n",
      "Traitement du chunk 34/42 - Tentative 5\n",
      "‚ö† Erreur inattendue (tentative 5/10): Invalid operation: The `response.text` quick accessor requires the response to contain a valid `Part`, but none were returned. The candidate's [finish_reason](https://ai.google.dev/api/generate-content#finishreason) is 4. Meaning that the model was reciting from copyrighted material.\n",
      "‚è≥ Attente de 25.3 secondes...\n",
      "Traitement du chunk 34/42 - Tentative 6\n",
      "‚ö† Erreur inattendue (tentative 6/10): Invalid operation: The `response.text` quick accessor requires the response to contain a valid `Part`, but none were returned. The candidate's [finish_reason](https://ai.google.dev/api/generate-content#finishreason) is 4. Meaning that the model was reciting from copyrighted material.\n",
      "‚è≥ Attente de 38.0 secondes...\n",
      "Traitement du chunk 34/42 - Tentative 7\n",
      "‚ö† Erreur serveur (tentative 7/10): 500 Internal error encountered.\n",
      "‚è≥ Attente de 120 secondes avant nouvelle tentative...\n",
      "Traitement du chunk 34/42 - Tentative 8\n",
      "‚ö† Erreur inattendue (tentative 8/10): Invalid operation: The `response.text` quick accessor requires the response to contain a valid `Part`, but none were returned. The candidate's [finish_reason](https://ai.google.dev/api/generate-content#finishreason) is 4. Meaning that the model was reciting from copyrighted material.\n",
      "‚è≥ Attente de 60.0 secondes...\n",
      "Traitement du chunk 34/42 - Tentative 9\n",
      "‚ö† Erreur inattendue (tentative 9/10): Invalid operation: The `response.text` quick accessor requires the response to contain a valid `Part`, but none were returned. The candidate's [finish_reason](https://ai.google.dev/api/generate-content#finishreason) is 4. Meaning that the model was reciting from copyrighted material.\n",
      "‚è≥ Attente de 60.0 secondes...\n",
      "Traitement du chunk 34/42 - Tentative 10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 81%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 34/42 [58:39<23:06, 173.33s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚ö† Erreur inattendue (tentative 10/10): Invalid operation: The `response.text` quick accessor requires the response to contain a valid `Part`, but none were returned. The candidate's [finish_reason](https://ai.google.dev/api/generate-content#finishreason) is 4. Meaning that the model was reciting from copyrighted material.\n",
      "‚ùå Erreur persistante apr√®s 10 tentatives pour le chunk 34\n",
      "Traitement du chunk 35/42 - Tentative 1\n",
      "‚ö† Erreur serveur (tentative 1/10): 500 Internal error encountered.\n",
      "‚è≥ Attente de 5 secondes avant nouvelle tentative...\n",
      "Traitement du chunk 35/42 - Tentative 2\n",
      "‚ö† Erreur serveur (tentative 2/10): 500 Internal error encountered.\n",
      "‚è≥ Attente de 10 secondes avant nouvelle tentative...\n",
      "Traitement du chunk 35/42 - Tentative 3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 83%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé | 35/42 [59:15<15:24, 132.06s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úì Chunk 35 trait√© avec succ√®s\n",
      "Traitement du chunk 36/42 - Tentative 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 36/42 [59:26<09:34, 95.74s/it] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úì Chunk 36 trait√© avec succ√®s\n",
      "Traitement du chunk 37/42 - Tentative 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 88%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä | 37/42 [59:34<05:46, 69.36s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úì Chunk 37 trait√© avec succ√®s\n",
      "Traitement du chunk 38/42 - Tentative 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 90%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 38/42 [59:34<03:14, 48.68s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úì Chunk 38 trait√© avec succ√®s\n",
      "Traitement du chunk 39/42 - Tentative 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 93%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé| 39/42 [59:35<01:42, 34.23s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úì Chunk 39 trait√© avec succ√®s\n",
      "Traitement du chunk 40/42 - Tentative 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 95%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 40/42 [59:35<00:48, 24.18s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úì Chunk 40 trait√© avec succ√®s\n",
      "Traitement du chunk 41/42 - Tentative 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 98%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä| 41/42 [59:43<00:19, 19.15s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úì Chunk 41 trait√© avec succ√®s\n",
      "Traitement du chunk 42/42 - Tentative 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 42/42 [59:44<00:00, 85.34s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úì Chunk 42 trait√© avec succ√®s\n",
      "‚úÖ Nettoyage termin√©, r√©sultats sauvegard√©s dans './clean_up_test\\extracted_docs_cleaned.csv'.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Configuration des dossiers\n",
    "pdf_dir = \"compiled_pdfs\"\n",
    "target_pdf_filename = \"Jayaprakash - 2014 - Early Alert of Academically At-Risk Students An Open Source Analytics Initiative\"\n",
    "target_pdf_path = Path(pdf_dir) / f\"{target_pdf_filename}.pdf\"\n",
    "csv_folder = \"./clean_up_test\"\n",
    "\n",
    "# Cr√©er le dossier de sortie s'il n'existe pas\n",
    "Path(csv_folder).mkdir(exist_ok=True)\n",
    "\n",
    "# V√©rification de la cl√© API\n",
    "GOOGLE_API_KEY = os.getenv(\"GOOGLE_API_KEY\")\n",
    "if GOOGLE_API_KEY is None:\n",
    "    raise ValueError(\"La cl√© GOOGLE_API_KEY n'est pas d√©finie dans les variables d'environnement.\")\n",
    "\n",
    "# Configuration de l'API\n",
    "genai.configure(api_key=GOOGLE_API_KEY)\n",
    "\n",
    "# Template du prompt pour le nettoyage\n",
    "llm_prompt_template = \"\"\"You are a professional document cleaner specialized in preparing text for both human readability and further LLM processing.\n",
    "\n",
    "I will provide you with a chunk of raw document text. Your task is to clean and extract only the meaningful narrative content by applying the following rules:\n",
    "Remove:\n",
    "\n",
    "    Text that appears to be misinterpreted or garbled output from figures, graphs, images, or tables (e.g., axis labels, chart legends, OCR artifacts).\n",
    "\n",
    "    Mathematical equations, whether inline or block format.\n",
    "\n",
    "    Page headers and footers (e.g., repeated titles, page numbers, author names).\n",
    "\n",
    "    Academic references and citations, especially reference lists typically found at the end of academic papers or embedded in text (e.g., \"[12]\", \"(Smith, 2018)\").\n",
    "\n",
    "Keep:\n",
    "\n",
    "    All narrative text that explains figures, graphs, or tables.\n",
    "\n",
    "    Section titles and headings, even if they are standalone.\n",
    "\n",
    "Output format:\n",
    "\n",
    "    Return only the cleaned text with no extra commentary, metadata, or formatting beyond the cleaned content.\n",
    "\n",
    "Input Text Chunk:\n",
    "{context}\"\"\"\n",
    "\n",
    "llm_prompt = PromptTemplate.from_template(llm_prompt_template)\n",
    "\n",
    "def clean_text_chunk(text_chunk, chunk_idx, total_chunks):\n",
    "    \"\"\"\n",
    "    Nettoie un chunk de texte en utilisant l'API Gemini avec retry logic\n",
    "    \"\"\"\n",
    "    prompt_text = llm_prompt.format(context=text_chunk)\n",
    "    max_retries = 10\n",
    "    base_delay = 5\n",
    "    cleaned_output_for_chunk = text_chunk\n",
    "    success = False\n",
    "\n",
    "    for attempt in range(max_retries):\n",
    "        try:\n",
    "            print(f\"Traitement du chunk {chunk_idx + 1}/{total_chunks} - Tentative {attempt + 1}\")\n",
    "            model = genai.GenerativeModel('gemini-2.0-flash')\n",
    "            response = model.generate_content(contents=prompt_text)\n",
    "            try:\n",
    "                cleaned_output_for_chunk = response.text.strip()\n",
    "                success = True\n",
    "                print(f\"‚úì Chunk {chunk_idx + 1} trait√© avec succ√®s\")\n",
    "                break\n",
    "            except AttributeError:\n",
    "                print(f\"‚ö† La r√©ponse de l'API n'avait pas d'attribut .text √† la tentative {attempt + 1}\")\n",
    "\n",
    "        except exceptions.ServerError as e:\n",
    "            retry_delay = min(base_delay * (2 ** attempt), 120)  # Max 2 minutes\n",
    "            print(f\"‚ö† Erreur serveur (tentative {attempt + 1}/{max_retries}): {e}\")\n",
    "\n",
    "            if attempt < max_retries - 1:\n",
    "                print(f\"‚è≥ Attente de {retry_delay} secondes avant nouvelle tentative...\")\n",
    "                time.sleep(retry_delay)\n",
    "            else:\n",
    "                print(f\"‚ùå √âchec apr√®s {max_retries} tentatives pour le chunk {chunk_idx + 1} - Erreur Serveur\")\n",
    "\n",
    "        except exceptions.ResourceExhausted as e:\n",
    "            retry_delay = min(base_delay * (2 ** attempt), 300)  # Max 5 minutes\n",
    "            print(f\"‚ö† Quota √©puis√© (tentative {attempt + 1}/{max_retries}): {e}\")\n",
    "\n",
    "            if attempt < max_retries - 1:\n",
    "                print(f\"‚è≥ Attente de {retry_delay} secondes (quota √©puis√©)...\")\n",
    "                time.sleep(retry_delay)\n",
    "            else:\n",
    "                print(f\"‚ùå Quota √©puis√© apr√®s {max_retries} tentatives pour le chunk {chunk_idx + 1}\")\n",
    "\n",
    "        except Exception as e:\n",
    "            retry_delay = min(base_delay * (1.5 ** attempt), 60)\n",
    "            print(f\"‚ö† Erreur inattendue (tentative {attempt + 1}/{max_retries}): {e}\")\n",
    "\n",
    "            if attempt < max_retries - 1:\n",
    "                print(f\"‚è≥ Attente de {retry_delay:.1f} secondes...\")\n",
    "                time.sleep(retry_delay)\n",
    "            else:\n",
    "                print(f\"‚ùå Erreur persistante apr√®s {max_retries} tentatives pour le chunk {chunk_idx + 1}\")\n",
    "\n",
    "    return cleaned_output_for_chunk\n",
    "\n",
    "if target_pdf_path.exists():\n",
    "    from langchain.document_loaders import PyPDFLoader\n",
    "    loader = PyPDFLoader(str(target_pdf_path))\n",
    "    loaded_docs = loader.load()\n",
    "\n",
    "    data = []\n",
    "    for doc in loaded_docs:\n",
    "        data.append({\n",
    "            \"source\": target_pdf_filename,\n",
    "            \"page_content\": doc.page_content.strip()\n",
    "        })\n",
    "\n",
    "    df = pd.DataFrame(data)\n",
    "    input_csv_path = os.path.join(csv_folder, \"extracted_docs.csv\")\n",
    "    df.to_csv(input_csv_path, index=False)\n",
    "    print(f\"{len(df)} pages extraites et sauvegard√©es dans '{input_csv_path}'.\")\n",
    "else:\n",
    "    raise FileNotFoundError(f\"Fichier PDF {target_pdf_filename} non trouv√© dans {pdf_dir}\")\n",
    "\n",
    "df = pd.read_csv(input_csv_path)\n",
    "\n",
    "cleaned_texts = []\n",
    "\n",
    "for idx, row in tqdm(df.iterrows(), total=len(df)):\n",
    "    text_chunk = row[\"page_content\"]\n",
    "    prompt_text = llm_prompt.format(context=text_chunk)\n",
    "    cleaned_chunk = clean_text_chunk(text_chunk, idx, len(df))\n",
    "    cleaned_texts.append(cleaned_chunk)\n",
    "\n",
    "df_result = df.copy()\n",
    "df_result[\"cleaned_page_content\"] = cleaned_texts\n",
    "output_csv_path = os.path.join(csv_folder, \"extracted_docs_cleaned.csv\")\n",
    "df_result.to_csv(output_csv_path, index=False)\n",
    "print(f\"‚úÖ Nettoyage termin√©, r√©sultats sauvegard√©s dans '{output_csv_path}'.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "78f52929",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üìö 7 fichiers PDF trouv√©s √† traiter\n",
      "\n",
      "üîÑ Traitement du PDF: 2012 - Do Situational Academic Emotions Predict Academic Outcomes in a Lecture Course\n",
      "  üìÑ 10 pages extraites de 2012 - Do Situational Academic Emotions Predict Academic Outcomes in a Lecture Course\n",
      "  üßπ D√©but du nettoyage...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Nettoyage 2012 - Do Situational Academic Emotions Predict Academic Outcomes in a Lecture Course:   0%|          | 0/10 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  [2012 - Do Situational Academic Emotions Predict Academic Outcomes in a Lecture Course] Traitement du chunk 1/10 - Tentative 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Nettoyage 2012 - Do Situational Academic Emotions Predict Academic Outcomes in a Lecture Course:  10%|‚ñà         | 1/10 [00:03<00:35,  3.93s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ‚úì [2012 - Do Situational Academic Emotions Predict Academic Outcomes in a Lecture Course] Chunk 1 trait√© avec succ√®s\n",
      "  [2012 - Do Situational Academic Emotions Predict Academic Outcomes in a Lecture Course] Traitement du chunk 2/10 - Tentative 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Nettoyage 2012 - Do Situational Academic Emotions Predict Academic Outcomes in a Lecture Course:  20%|‚ñà‚ñà        | 2/10 [00:11<00:50,  6.28s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ‚úì [2012 - Do Situational Academic Emotions Predict Academic Outcomes in a Lecture Course] Chunk 2 trait√© avec succ√®s\n",
      "  [2012 - Do Situational Academic Emotions Predict Academic Outcomes in a Lecture Course] Traitement du chunk 3/10 - Tentative 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Nettoyage 2012 - Do Situational Academic Emotions Predict Academic Outcomes in a Lecture Course:  30%|‚ñà‚ñà‚ñà       | 3/10 [00:19<00:48,  6.87s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ‚úì [2012 - Do Situational Academic Emotions Predict Academic Outcomes in a Lecture Course] Chunk 3 trait√© avec succ√®s\n",
      "  [2012 - Do Situational Academic Emotions Predict Academic Outcomes in a Lecture Course] Traitement du chunk 4/10 - Tentative 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Nettoyage 2012 - Do Situational Academic Emotions Predict Academic Outcomes in a Lecture Course:  40%|‚ñà‚ñà‚ñà‚ñà      | 4/10 [00:24<00:37,  6.33s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ‚úì [2012 - Do Situational Academic Emotions Predict Academic Outcomes in a Lecture Course] Chunk 4 trait√© avec succ√®s\n",
      "  [2012 - Do Situational Academic Emotions Predict Academic Outcomes in a Lecture Course] Traitement du chunk 5/10 - Tentative 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Nettoyage 2012 - Do Situational Academic Emotions Predict Academic Outcomes in a Lecture Course:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 5/10 [00:28<00:25,  5.17s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ‚úì [2012 - Do Situational Academic Emotions Predict Academic Outcomes in a Lecture Course] Chunk 5 trait√© avec succ√®s\n",
      "  [2012 - Do Situational Academic Emotions Predict Academic Outcomes in a Lecture Course] Traitement du chunk 6/10 - Tentative 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Nettoyage 2012 - Do Situational Academic Emotions Predict Academic Outcomes in a Lecture Course:  60%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 6/10 [00:30<00:17,  4.34s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ‚úì [2012 - Do Situational Academic Emotions Predict Academic Outcomes in a Lecture Course] Chunk 6 trait√© avec succ√®s\n",
      "  [2012 - Do Situational Academic Emotions Predict Academic Outcomes in a Lecture Course] Traitement du chunk 7/10 - Tentative 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Nettoyage 2012 - Do Situational Academic Emotions Predict Academic Outcomes in a Lecture Course:  70%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà   | 7/10 [00:33<00:11,  3.95s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ‚úì [2012 - Do Situational Academic Emotions Predict Academic Outcomes in a Lecture Course] Chunk 7 trait√© avec succ√®s\n",
      "  [2012 - Do Situational Academic Emotions Predict Academic Outcomes in a Lecture Course] Traitement du chunk 8/10 - Tentative 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Nettoyage 2012 - Do Situational Academic Emotions Predict Academic Outcomes in a Lecture Course:  80%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 8/10 [00:40<00:09,  4.94s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ‚úì [2012 - Do Situational Academic Emotions Predict Academic Outcomes in a Lecture Course] Chunk 8 trait√© avec succ√®s\n",
      "  [2012 - Do Situational Academic Emotions Predict Academic Outcomes in a Lecture Course] Traitement du chunk 9/10 - Tentative 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Nettoyage 2012 - Do Situational Academic Emotions Predict Academic Outcomes in a Lecture Course:  90%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 9/10 [00:43<00:04,  4.19s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ‚úì [2012 - Do Situational Academic Emotions Predict Academic Outcomes in a Lecture Course] Chunk 9 trait√© avec succ√®s\n",
      "  [2012 - Do Situational Academic Emotions Predict Academic Outcomes in a Lecture Course] Traitement du chunk 10/10 - Tentative 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Nettoyage 2012 - Do Situational Academic Emotions Predict Academic Outcomes in a Lecture Course: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 10/10 [00:43<00:00,  4.40s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ‚úì [2012 - Do Situational Academic Emotions Predict Academic Outcomes in a Lecture Course] Chunk 10 trait√© avec succ√®s\n",
      "  ‚úÖ R√©sultats sauvegard√©s dans 'clean_up_test\\cleanedup_2012 - Do Situational Academic Emotions Predict Academic Outcomes in a Lecture Course.csv'\n",
      "\n",
      "üîÑ Traitement du PDF: 2017 - MOOC Dropout Prediction\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  üìÑ 9 pages extraites de 2017 - MOOC Dropout Prediction\n",
      "  üßπ D√©but du nettoyage...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Nettoyage 2017 - MOOC Dropout Prediction:   0%|          | 0/9 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  [2017 - MOOC Dropout Prediction] Traitement du chunk 1/9 - Tentative 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Nettoyage 2017 - MOOC Dropout Prediction:  11%|‚ñà         | 1/9 [00:04<00:34,  4.26s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ‚úì [2017 - MOOC Dropout Prediction] Chunk 1 trait√© avec succ√®s\n",
      "  [2017 - MOOC Dropout Prediction] Traitement du chunk 2/9 - Tentative 1\n",
      "  ‚ö† [2017 - MOOC Dropout Prediction] Quota √©puis√© (tentative 1/10): 429 You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. [violations {\n",
      "  quota_metric: \"generativelanguage.googleapis.com/generate_content_free_tier_requests\"\n",
      "  quota_id: \"GenerateRequestsPerMinutePerProjectPerModel-FreeTier\"\n",
      "  quota_dimensions {\n",
      "    key: \"model\"\n",
      "    value: \"gemini-2.0-flash-exp\"\n",
      "  }\n",
      "  quota_dimensions {\n",
      "    key: \"location\"\n",
      "    value: \"global\"\n",
      "  }\n",
      "  quota_value: 10\n",
      "}\n",
      ", links {\n",
      "  description: \"Learn more about Gemini API quotas\"\n",
      "  url: \"https://ai.google.dev/gemini-api/docs/rate-limits\"\n",
      "}\n",
      ", retry_delay {\n",
      "  seconds: 52\n",
      "}\n",
      "]\n",
      "  ‚è≥ [2017 - MOOC Dropout Prediction] Attente de 5 secondes (quota √©puis√©)...\n",
      "  [2017 - MOOC Dropout Prediction] Traitement du chunk 2/9 - Tentative 2\n",
      "  ‚ö† [2017 - MOOC Dropout Prediction] Quota √©puis√© (tentative 2/10): 429 You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. [violations {\n",
      "  quota_metric: \"generativelanguage.googleapis.com/generate_content_free_tier_requests\"\n",
      "  quota_id: \"GenerateRequestsPerMinutePerProjectPerModel-FreeTier\"\n",
      "  quota_dimensions {\n",
      "    key: \"model\"\n",
      "    value: \"gemini-2.0-flash-exp\"\n",
      "  }\n",
      "  quota_dimensions {\n",
      "    key: \"location\"\n",
      "    value: \"global\"\n",
      "  }\n",
      "  quota_value: 10\n",
      "}\n",
      ", links {\n",
      "  description: \"Learn more about Gemini API quotas\"\n",
      "  url: \"https://ai.google.dev/gemini-api/docs/rate-limits\"\n",
      "}\n",
      ", retry_delay {\n",
      "  seconds: 47\n",
      "}\n",
      "]\n",
      "  ‚è≥ [2017 - MOOC Dropout Prediction] Attente de 10 secondes (quota √©puis√©)...\n",
      "  [2017 - MOOC Dropout Prediction] Traitement du chunk 2/9 - Tentative 3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Nettoyage 2017 - MOOC Dropout Prediction:  22%|‚ñà‚ñà‚ñè       | 2/9 [00:27<01:46, 15.21s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ‚úì [2017 - MOOC Dropout Prediction] Chunk 2 trait√© avec succ√®s\n",
      "  [2017 - MOOC Dropout Prediction] Traitement du chunk 3/9 - Tentative 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Nettoyage 2017 - MOOC Dropout Prediction:  33%|‚ñà‚ñà‚ñà‚ñé      | 3/9 [00:34<01:11, 11.84s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ‚úì [2017 - MOOC Dropout Prediction] Chunk 3 trait√© avec succ√®s\n",
      "  [2017 - MOOC Dropout Prediction] Traitement du chunk 4/9 - Tentative 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Nettoyage 2017 - MOOC Dropout Prediction:  44%|‚ñà‚ñà‚ñà‚ñà‚ñç     | 4/9 [00:40<00:46,  9.31s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ‚úì [2017 - MOOC Dropout Prediction] Chunk 4 trait√© avec succ√®s\n",
      "  [2017 - MOOC Dropout Prediction] Traitement du chunk 5/9 - Tentative 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Nettoyage 2017 - MOOC Dropout Prediction:  56%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 5/9 [00:46<00:32,  8.10s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ‚úì [2017 - MOOC Dropout Prediction] Chunk 5 trait√© avec succ√®s\n",
      "  [2017 - MOOC Dropout Prediction] Traitement du chunk 6/9 - Tentative 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Nettoyage 2017 - MOOC Dropout Prediction:  67%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 6/9 [00:53<00:23,  7.76s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ‚úì [2017 - MOOC Dropout Prediction] Chunk 6 trait√© avec succ√®s\n",
      "  [2017 - MOOC Dropout Prediction] Traitement du chunk 7/9 - Tentative 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Nettoyage 2017 - MOOC Dropout Prediction:  78%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä  | 7/9 [00:58<00:13,  6.76s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ‚úì [2017 - MOOC Dropout Prediction] Chunk 7 trait√© avec succ√®s\n",
      "  [2017 - MOOC Dropout Prediction] Traitement du chunk 8/9 - Tentative 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Nettoyage 2017 - MOOC Dropout Prediction:  89%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ | 8/9 [01:01<00:05,  5.67s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ‚úì [2017 - MOOC Dropout Prediction] Chunk 8 trait√© avec succ√®s\n",
      "  [2017 - MOOC Dropout Prediction] Traitement du chunk 9/9 - Tentative 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Nettoyage 2017 - MOOC Dropout Prediction: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 9/9 [01:02<00:00,  6.89s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ‚úì [2017 - MOOC Dropout Prediction] Chunk 9 trait√© avec succ√®s\n",
      "  ‚úÖ R√©sultats sauvegard√©s dans 'clean_up_test\\cleanedup_2017 - MOOC Dropout Prediction.csv'\n",
      "\n",
      "üîÑ Traitement du PDF: 2018 - Leveraging Non-cognitive Student Self-reports to Predict Learning Outcomes\n",
      "  üìÑ 5 pages extraites de 2018 - Leveraging Non-cognitive Student Self-reports to Predict Learning Outcomes\n",
      "  üßπ D√©but du nettoyage...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Nettoyage 2018 - Leveraging Non-cognitive Student Self-reports to Predict Learning Outcomes:   0%|          | 0/5 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  [2018 - Leveraging Non-cognitive Student Self-reports to Predict Learning Outcomes] Traitement du chunk 1/5 - Tentative 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Nettoyage 2018 - Leveraging Non-cognitive Student Self-reports to Predict Learning Outcomes:  20%|‚ñà‚ñà        | 1/5 [00:02<00:11,  2.78s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ‚úì [2018 - Leveraging Non-cognitive Student Self-reports to Predict Learning Outcomes] Chunk 1 trait√© avec succ√®s\n",
      "  [2018 - Leveraging Non-cognitive Student Self-reports to Predict Learning Outcomes] Traitement du chunk 2/5 - Tentative 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Nettoyage 2018 - Leveraging Non-cognitive Student Self-reports to Predict Learning Outcomes:  40%|‚ñà‚ñà‚ñà‚ñà      | 2/5 [00:06<00:10,  3.49s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ‚úì [2018 - Leveraging Non-cognitive Student Self-reports to Predict Learning Outcomes] Chunk 2 trait√© avec succ√®s\n",
      "  [2018 - Leveraging Non-cognitive Student Self-reports to Predict Learning Outcomes] Traitement du chunk 3/5 - Tentative 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Nettoyage 2018 - Leveraging Non-cognitive Student Self-reports to Predict Learning Outcomes:  60%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 3/5 [00:10<00:07,  3.56s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ‚úì [2018 - Leveraging Non-cognitive Student Self-reports to Predict Learning Outcomes] Chunk 3 trait√© avec succ√®s\n",
      "  [2018 - Leveraging Non-cognitive Student Self-reports to Predict Learning Outcomes] Traitement du chunk 4/5 - Tentative 1\n",
      "  ‚ö† [2018 - Leveraging Non-cognitive Student Self-reports to Predict Learning Outcomes] Quota √©puis√© (tentative 1/10): 429 You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. [violations {\n",
      "  quota_metric: \"generativelanguage.googleapis.com/generate_content_free_tier_requests\"\n",
      "  quota_id: \"GenerateRequestsPerMinutePerProjectPerModel-FreeTier\"\n",
      "  quota_dimensions {\n",
      "    key: \"model\"\n",
      "    value: \"gemini-2.0-flash-exp\"\n",
      "  }\n",
      "  quota_dimensions {\n",
      "    key: \"location\"\n",
      "    value: \"global\"\n",
      "  }\n",
      "  quota_value: 10\n",
      "}\n",
      ", links {\n",
      "  description: \"Learn more about Gemini API quotas\"\n",
      "  url: \"https://ai.google.dev/gemini-api/docs/rate-limits\"\n",
      "}\n",
      ", retry_delay {\n",
      "  seconds: 44\n",
      "}\n",
      "]\n",
      "  ‚è≥ [2018 - Leveraging Non-cognitive Student Self-reports to Predict Learning Outcomes] Attente de 5 secondes (quota √©puis√©)...\n",
      "  [2018 - Leveraging Non-cognitive Student Self-reports to Predict Learning Outcomes] Traitement du chunk 4/5 - Tentative 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Nettoyage 2018 - Leveraging Non-cognitive Student Self-reports to Predict Learning Outcomes:  80%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 4/5 [00:18<00:05,  5.53s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ‚úì [2018 - Leveraging Non-cognitive Student Self-reports to Predict Learning Outcomes] Chunk 4 trait√© avec succ√®s\n",
      "  [2018 - Leveraging Non-cognitive Student Self-reports to Predict Learning Outcomes] Traitement du chunk 5/5 - Tentative 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Nettoyage 2018 - Leveraging Non-cognitive Student Self-reports to Predict Learning Outcomes: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 5/5 [00:19<00:00,  3.94s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ‚úì [2018 - Leveraging Non-cognitive Student Self-reports to Predict Learning Outcomes] Chunk 5 trait√© avec succ√®s\n",
      "  ‚úÖ R√©sultats sauvegard√©s dans 'clean_up_test\\cleanedup_2018 - Leveraging Non-cognitive Student Self-reports to Predict Learning Outcomes.csv'\n",
      "\n",
      "üîÑ Traitement du PDF: 2019 - Detecting students-at-risk in computer programming classes with learning analytics from students‚Äô di\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  üìÑ 30 pages extraites de 2019 - Detecting students-at-risk in computer programming classes with learning analytics from students‚Äô di\n",
      "  üßπ D√©but du nettoyage...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Nettoyage 2019 - Detecting students-at-risk in computer programming classes with learning analytics from students‚Äô di:   0%|          | 0/30 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  [2019 - Detecting students-at-risk in computer programming classes with learning analytics from students‚Äô di] Traitement du chunk 1/30 - Tentative 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Nettoyage 2019 - Detecting students-at-risk in computer programming classes with learning analytics from students‚Äô di:   3%|‚ñé         | 1/30 [00:01<00:46,  1.62s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ‚úì [2019 - Detecting students-at-risk in computer programming classes with learning analytics from students‚Äô di] Chunk 1 trait√© avec succ√®s\n",
      "  [2019 - Detecting students-at-risk in computer programming classes with learning analytics from students‚Äô di] Traitement du chunk 2/30 - Tentative 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Nettoyage 2019 - Detecting students-at-risk in computer programming classes with learning analytics from students‚Äô di:   7%|‚ñã         | 2/30 [00:05<01:20,  2.88s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ‚úì [2019 - Detecting students-at-risk in computer programming classes with learning analytics from students‚Äô di] Chunk 2 trait√© avec succ√®s\n",
      "  [2019 - Detecting students-at-risk in computer programming classes with learning analytics from students‚Äô di] Traitement du chunk 3/30 - Tentative 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Nettoyage 2019 - Detecting students-at-risk in computer programming classes with learning analytics from students‚Äô di:  10%|‚ñà         | 3/30 [00:09<01:28,  3.28s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ‚úì [2019 - Detecting students-at-risk in computer programming classes with learning analytics from students‚Äô di] Chunk 3 trait√© avec succ√®s\n",
      "  [2019 - Detecting students-at-risk in computer programming classes with learning analytics from students‚Äô di] Traitement du chunk 4/30 - Tentative 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Nettoyage 2019 - Detecting students-at-risk in computer programming classes with learning analytics from students‚Äô di:  13%|‚ñà‚ñé        | 4/30 [00:12<01:23,  3.22s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ‚úì [2019 - Detecting students-at-risk in computer programming classes with learning analytics from students‚Äô di] Chunk 4 trait√© avec succ√®s\n",
      "  [2019 - Detecting students-at-risk in computer programming classes with learning analytics from students‚Äô di] Traitement du chunk 5/30 - Tentative 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Nettoyage 2019 - Detecting students-at-risk in computer programming classes with learning analytics from students‚Äô di:  17%|‚ñà‚ñã        | 5/30 [00:15<01:20,  3.23s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ‚úì [2019 - Detecting students-at-risk in computer programming classes with learning analytics from students‚Äô di] Chunk 5 trait√© avec succ√®s\n",
      "  [2019 - Detecting students-at-risk in computer programming classes with learning analytics from students‚Äô di] Traitement du chunk 6/30 - Tentative 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Nettoyage 2019 - Detecting students-at-risk in computer programming classes with learning analytics from students‚Äô di:  20%|‚ñà‚ñà        | 6/30 [00:18<01:19,  3.30s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ‚úì [2019 - Detecting students-at-risk in computer programming classes with learning analytics from students‚Äô di] Chunk 6 trait√© avec succ√®s\n",
      "  [2019 - Detecting students-at-risk in computer programming classes with learning analytics from students‚Äô di] Traitement du chunk 7/30 - Tentative 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Nettoyage 2019 - Detecting students-at-risk in computer programming classes with learning analytics from students‚Äô di:  23%|‚ñà‚ñà‚ñé       | 7/30 [00:22<01:15,  3.28s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ‚úì [2019 - Detecting students-at-risk in computer programming classes with learning analytics from students‚Äô di] Chunk 7 trait√© avec succ√®s\n",
      "  [2019 - Detecting students-at-risk in computer programming classes with learning analytics from students‚Äô di] Traitement du chunk 8/30 - Tentative 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Nettoyage 2019 - Detecting students-at-risk in computer programming classes with learning analytics from students‚Äô di:  27%|‚ñà‚ñà‚ñã       | 8/30 [00:23<00:55,  2.50s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ‚úì [2019 - Detecting students-at-risk in computer programming classes with learning analytics from students‚Äô di] Chunk 8 trait√© avec succ√®s\n",
      "  [2019 - Detecting students-at-risk in computer programming classes with learning analytics from students‚Äô di] Traitement du chunk 9/30 - Tentative 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Nettoyage 2019 - Detecting students-at-risk in computer programming classes with learning analytics from students‚Äô di:  30%|‚ñà‚ñà‚ñà       | 9/30 [00:26<01:00,  2.86s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ‚úì [2019 - Detecting students-at-risk in computer programming classes with learning analytics from students‚Äô di] Chunk 9 trait√© avec succ√®s\n",
      "  [2019 - Detecting students-at-risk in computer programming classes with learning analytics from students‚Äô di] Traitement du chunk 10/30 - Tentative 1\n",
      "  ‚ö† [2019 - Detecting students-at-risk in computer programming classes with learning analytics from students‚Äô di] Quota √©puis√© (tentative 1/10): 429 You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. [violations {\n",
      "  quota_metric: \"generativelanguage.googleapis.com/generate_content_free_tier_requests\"\n",
      "  quota_id: \"GenerateRequestsPerMinutePerProjectPerModel-FreeTier\"\n",
      "  quota_dimensions {\n",
      "    key: \"model\"\n",
      "    value: \"gemini-2.0-flash-exp\"\n",
      "  }\n",
      "  quota_dimensions {\n",
      "    key: \"location\"\n",
      "    value: \"global\"\n",
      "  }\n",
      "  quota_value: 10\n",
      "}\n",
      ", links {\n",
      "  description: \"Learn more about Gemini API quotas\"\n",
      "  url: \"https://ai.google.dev/gemini-api/docs/rate-limits\"\n",
      "}\n",
      ", retry_delay {\n",
      "  seconds: 7\n",
      "}\n",
      "]\n",
      "  ‚è≥ [2019 - Detecting students-at-risk in computer programming classes with learning analytics from students‚Äô di] Attente de 5 secondes (quota √©puis√©)...\n",
      "  [2019 - Detecting students-at-risk in computer programming classes with learning analytics from students‚Äô di] Traitement du chunk 10/30 - Tentative 2\n",
      "  ‚ö† [2019 - Detecting students-at-risk in computer programming classes with learning analytics from students‚Äô di] Quota √©puis√© (tentative 2/10): 429 You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. [violations {\n",
      "  quota_metric: \"generativelanguage.googleapis.com/generate_content_free_tier_requests\"\n",
      "  quota_id: \"GenerateRequestsPerMinutePerProjectPerModel-FreeTier\"\n",
      "  quota_dimensions {\n",
      "    key: \"model\"\n",
      "    value: \"gemini-2.0-flash-exp\"\n",
      "  }\n",
      "  quota_dimensions {\n",
      "    key: \"location\"\n",
      "    value: \"global\"\n",
      "  }\n",
      "  quota_value: 10\n",
      "}\n",
      ", links {\n",
      "  description: \"Learn more about Gemini API quotas\"\n",
      "  url: \"https://ai.google.dev/gemini-api/docs/rate-limits\"\n",
      "}\n",
      ", retry_delay {\n",
      "  seconds: 2\n",
      "}\n",
      "]\n",
      "  ‚è≥ [2019 - Detecting students-at-risk in computer programming classes with learning analytics from students‚Äô di] Attente de 10 secondes (quota √©puis√©)...\n",
      "  [2019 - Detecting students-at-risk in computer programming classes with learning analytics from students‚Äô di] Traitement du chunk 10/30 - Tentative 3\n",
      "  ‚ö† [2019 - Detecting students-at-risk in computer programming classes with learning analytics from students‚Äô di] Quota √©puis√© (tentative 3/10): 429 You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. [violations {\n",
      "  quota_metric: \"generativelanguage.googleapis.com/generate_content_free_tier_requests\"\n",
      "  quota_id: \"GenerateRequestsPerMinutePerProjectPerModel-FreeTier\"\n",
      "  quota_dimensions {\n",
      "    key: \"model\"\n",
      "    value: \"gemini-2.0-flash-exp\"\n",
      "  }\n",
      "  quota_dimensions {\n",
      "    key: \"location\"\n",
      "    value: \"global\"\n",
      "  }\n",
      "  quota_value: 10\n",
      "}\n",
      ", links {\n",
      "  description: \"Learn more about Gemini API quotas\"\n",
      "  url: \"https://ai.google.dev/gemini-api/docs/rate-limits\"\n",
      "}\n",
      ", retry_delay {\n",
      "  seconds: 52\n",
      "}\n",
      "]\n",
      "  ‚è≥ [2019 - Detecting students-at-risk in computer programming classes with learning analytics from students‚Äô di] Attente de 20 secondes (quota √©puis√©)...\n",
      "  [2019 - Detecting students-at-risk in computer programming classes with learning analytics from students‚Äô di] Traitement du chunk 10/30 - Tentative 4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Nettoyage 2019 - Detecting students-at-risk in computer programming classes with learning analytics from students‚Äô di:  33%|‚ñà‚ñà‚ñà‚ñé      | 10/30 [01:05<04:41, 14.06s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ‚úì [2019 - Detecting students-at-risk in computer programming classes with learning analytics from students‚Äô di] Chunk 10 trait√© avec succ√®s\n",
      "  [2019 - Detecting students-at-risk in computer programming classes with learning analytics from students‚Äô di] Traitement du chunk 11/30 - Tentative 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Nettoyage 2019 - Detecting students-at-risk in computer programming classes with learning analytics from students‚Äô di:  37%|‚ñà‚ñà‚ñà‚ñã      | 11/30 [01:08<03:22, 10.66s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ‚úì [2019 - Detecting students-at-risk in computer programming classes with learning analytics from students‚Äô di] Chunk 11 trait√© avec succ√®s\n",
      "  [2019 - Detecting students-at-risk in computer programming classes with learning analytics from students‚Äô di] Traitement du chunk 12/30 - Tentative 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Nettoyage 2019 - Detecting students-at-risk in computer programming classes with learning analytics from students‚Äô di:  40%|‚ñà‚ñà‚ñà‚ñà      | 12/30 [01:12<02:31,  8.40s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ‚úì [2019 - Detecting students-at-risk in computer programming classes with learning analytics from students‚Äô di] Chunk 12 trait√© avec succ√®s\n",
      "  [2019 - Detecting students-at-risk in computer programming classes with learning analytics from students‚Äô di] Traitement du chunk 13/30 - Tentative 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Nettoyage 2019 - Detecting students-at-risk in computer programming classes with learning analytics from students‚Äô di:  43%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 13/30 [01:14<01:51,  6.59s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ‚úì [2019 - Detecting students-at-risk in computer programming classes with learning analytics from students‚Äô di] Chunk 13 trait√© avec succ√®s\n",
      "  [2019 - Detecting students-at-risk in computer programming classes with learning analytics from students‚Äô di] Traitement du chunk 14/30 - Tentative 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Nettoyage 2019 - Detecting students-at-risk in computer programming classes with learning analytics from students‚Äô di:  47%|‚ñà‚ñà‚ñà‚ñà‚ñã     | 14/30 [01:15<01:18,  4.88s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ‚úì [2019 - Detecting students-at-risk in computer programming classes with learning analytics from students‚Äô di] Chunk 14 trait√© avec succ√®s\n",
      "  [2019 - Detecting students-at-risk in computer programming classes with learning analytics from students‚Äô di] Traitement du chunk 15/30 - Tentative 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Nettoyage 2019 - Detecting students-at-risk in computer programming classes with learning analytics from students‚Äô di:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 15/30 [01:19<01:11,  4.79s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ‚úì [2019 - Detecting students-at-risk in computer programming classes with learning analytics from students‚Äô di] Chunk 15 trait√© avec succ√®s\n",
      "  [2019 - Detecting students-at-risk in computer programming classes with learning analytics from students‚Äô di] Traitement du chunk 16/30 - Tentative 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Nettoyage 2019 - Detecting students-at-risk in computer programming classes with learning analytics from students‚Äô di:  53%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé    | 16/30 [01:21<00:51,  3.70s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ‚úì [2019 - Detecting students-at-risk in computer programming classes with learning analytics from students‚Äô di] Chunk 16 trait√© avec succ√®s\n",
      "  [2019 - Detecting students-at-risk in computer programming classes with learning analytics from students‚Äô di] Traitement du chunk 17/30 - Tentative 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Nettoyage 2019 - Detecting students-at-risk in computer programming classes with learning analytics from students‚Äô di:  57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 17/30 [01:22<00:40,  3.12s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ‚úì [2019 - Detecting students-at-risk in computer programming classes with learning analytics from students‚Äô di] Chunk 17 trait√© avec succ√®s\n",
      "  [2019 - Detecting students-at-risk in computer programming classes with learning analytics from students‚Äô di] Traitement du chunk 18/30 - Tentative 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Nettoyage 2019 - Detecting students-at-risk in computer programming classes with learning analytics from students‚Äô di:  60%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 18/30 [01:26<00:39,  3.28s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ‚úì [2019 - Detecting students-at-risk in computer programming classes with learning analytics from students‚Äô di] Chunk 18 trait√© avec succ√®s\n",
      "  [2019 - Detecting students-at-risk in computer programming classes with learning analytics from students‚Äô di] Traitement du chunk 19/30 - Tentative 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Nettoyage 2019 - Detecting students-at-risk in computer programming classes with learning analytics from students‚Äô di:  63%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé   | 19/30 [01:28<00:31,  2.89s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ‚úì [2019 - Detecting students-at-risk in computer programming classes with learning analytics from students‚Äô di] Chunk 19 trait√© avec succ√®s\n",
      "  [2019 - Detecting students-at-risk in computer programming classes with learning analytics from students‚Äô di] Traitement du chunk 20/30 - Tentative 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Nettoyage 2019 - Detecting students-at-risk in computer programming classes with learning analytics from students‚Äô di:  67%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 20/30 [01:30<00:27,  2.72s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ‚úì [2019 - Detecting students-at-risk in computer programming classes with learning analytics from students‚Äô di] Chunk 20 trait√© avec succ√®s\n",
      "  [2019 - Detecting students-at-risk in computer programming classes with learning analytics from students‚Äô di] Traitement du chunk 21/30 - Tentative 1\n",
      "  ‚ö† [2019 - Detecting students-at-risk in computer programming classes with learning analytics from students‚Äô di] Quota √©puis√© (tentative 1/10): 429 You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. [violations {\n",
      "  quota_metric: \"generativelanguage.googleapis.com/generate_content_free_tier_requests\"\n",
      "  quota_id: \"GenerateRequestsPerMinutePerProjectPerModel-FreeTier\"\n",
      "  quota_dimensions {\n",
      "    key: \"model\"\n",
      "    value: \"gemini-2.0-flash-exp\"\n",
      "  }\n",
      "  quota_dimensions {\n",
      "    key: \"location\"\n",
      "    value: \"global\"\n",
      "  }\n",
      "  quota_value: 10\n",
      "}\n",
      ", links {\n",
      "  description: \"Learn more about Gemini API quotas\"\n",
      "  url: \"https://ai.google.dev/gemini-api/docs/rate-limits\"\n",
      "}\n",
      ", retry_delay {\n",
      "  seconds: 3\n",
      "}\n",
      "]\n",
      "  ‚è≥ [2019 - Detecting students-at-risk in computer programming classes with learning analytics from students‚Äô di] Attente de 5 secondes (quota √©puis√©)...\n",
      "  [2019 - Detecting students-at-risk in computer programming classes with learning analytics from students‚Äô di] Traitement du chunk 21/30 - Tentative 2\n",
      "  ‚ö† [2019 - Detecting students-at-risk in computer programming classes with learning analytics from students‚Äô di] Quota √©puis√© (tentative 2/10): 429 You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. [violations {\n",
      "  quota_metric: \"generativelanguage.googleapis.com/generate_content_free_tier_requests\"\n",
      "  quota_id: \"GenerateRequestsPerMinutePerProjectPerModel-FreeTier\"\n",
      "  quota_dimensions {\n",
      "    key: \"model\"\n",
      "    value: \"gemini-2.0-flash-exp\"\n",
      "  }\n",
      "  quota_dimensions {\n",
      "    key: \"location\"\n",
      "    value: \"global\"\n",
      "  }\n",
      "  quota_value: 10\n",
      "}\n",
      ", links {\n",
      "  description: \"Learn more about Gemini API quotas\"\n",
      "  url: \"https://ai.google.dev/gemini-api/docs/rate-limits\"\n",
      "}\n",
      ", retry_delay {\n",
      "  seconds: 58\n",
      "}\n",
      "]\n",
      "  ‚è≥ [2019 - Detecting students-at-risk in computer programming classes with learning analytics from students‚Äô di] Attente de 10 secondes (quota √©puis√©)...\n",
      "  [2019 - Detecting students-at-risk in computer programming classes with learning analytics from students‚Äô di] Traitement du chunk 21/30 - Tentative 3\n",
      "  ‚ö† [2019 - Detecting students-at-risk in computer programming classes with learning analytics from students‚Äô di] Quota √©puis√© (tentative 3/10): 429 You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. [violations {\n",
      "  quota_metric: \"generativelanguage.googleapis.com/generate_content_free_tier_requests\"\n",
      "  quota_id: \"GenerateRequestsPerMinutePerProjectPerModel-FreeTier\"\n",
      "  quota_dimensions {\n",
      "    key: \"model\"\n",
      "    value: \"gemini-2.0-flash-exp\"\n",
      "  }\n",
      "  quota_dimensions {\n",
      "    key: \"location\"\n",
      "    value: \"global\"\n",
      "  }\n",
      "  quota_value: 10\n",
      "}\n",
      ", links {\n",
      "  description: \"Learn more about Gemini API quotas\"\n",
      "  url: \"https://ai.google.dev/gemini-api/docs/rate-limits\"\n",
      "}\n",
      ", retry_delay {\n",
      "  seconds: 48\n",
      "}\n",
      "]\n",
      "  ‚è≥ [2019 - Detecting students-at-risk in computer programming classes with learning analytics from students‚Äô di] Attente de 20 secondes (quota √©puis√©)...\n",
      "  [2019 - Detecting students-at-risk in computer programming classes with learning analytics from students‚Äô di] Traitement du chunk 21/30 - Tentative 4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Nettoyage 2019 - Detecting students-at-risk in computer programming classes with learning analytics from students‚Äô di:  70%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà   | 21/30 [02:11<02:06, 14.07s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ‚úì [2019 - Detecting students-at-risk in computer programming classes with learning analytics from students‚Äô di] Chunk 21 trait√© avec succ√®s\n",
      "  [2019 - Detecting students-at-risk in computer programming classes with learning analytics from students‚Äô di] Traitement du chunk 22/30 - Tentative 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Nettoyage 2019 - Detecting students-at-risk in computer programming classes with learning analytics from students‚Äô di:  73%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé  | 22/30 [02:13<01:24, 10.57s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ‚úì [2019 - Detecting students-at-risk in computer programming classes with learning analytics from students‚Äô di] Chunk 22 trait√© avec succ√®s\n",
      "  [2019 - Detecting students-at-risk in computer programming classes with learning analytics from students‚Äô di] Traitement du chunk 23/30 - Tentative 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Nettoyage 2019 - Detecting students-at-risk in computer programming classes with learning analytics from students‚Äô di:  77%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 23/30 [02:16<00:58,  8.36s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ‚úì [2019 - Detecting students-at-risk in computer programming classes with learning analytics from students‚Äô di] Chunk 23 trait√© avec succ√®s\n",
      "  [2019 - Detecting students-at-risk in computer programming classes with learning analytics from students‚Äô di] Traitement du chunk 24/30 - Tentative 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Nettoyage 2019 - Detecting students-at-risk in computer programming classes with learning analytics from students‚Äô di:  80%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 24/30 [02:20<00:40,  6.82s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ‚úì [2019 - Detecting students-at-risk in computer programming classes with learning analytics from students‚Äô di] Chunk 24 trait√© avec succ√®s\n",
      "  [2019 - Detecting students-at-risk in computer programming classes with learning analytics from students‚Äô di] Traitement du chunk 25/30 - Tentative 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Nettoyage 2019 - Detecting students-at-risk in computer programming classes with learning analytics from students‚Äô di:  83%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé | 25/30 [02:23<00:29,  5.87s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ‚úì [2019 - Detecting students-at-risk in computer programming classes with learning analytics from students‚Äô di] Chunk 25 trait√© avec succ√®s\n",
      "  [2019 - Detecting students-at-risk in computer programming classes with learning analytics from students‚Äô di] Traitement du chunk 26/30 - Tentative 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Nettoyage 2019 - Detecting students-at-risk in computer programming classes with learning analytics from students‚Äô di:  87%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã | 26/30 [02:27<00:20,  5.19s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ‚úì [2019 - Detecting students-at-risk in computer programming classes with learning analytics from students‚Äô di] Chunk 26 trait√© avec succ√®s\n",
      "  [2019 - Detecting students-at-risk in computer programming classes with learning analytics from students‚Äô di] Traitement du chunk 27/30 - Tentative 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Nettoyage 2019 - Detecting students-at-risk in computer programming classes with learning analytics from students‚Äô di:  90%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 27/30 [02:28<00:11,  3.99s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ‚úì [2019 - Detecting students-at-risk in computer programming classes with learning analytics from students‚Äô di] Chunk 27 trait√© avec succ√®s\n",
      "  [2019 - Detecting students-at-risk in computer programming classes with learning analytics from students‚Äô di] Traitement du chunk 28/30 - Tentative 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Nettoyage 2019 - Detecting students-at-risk in computer programming classes with learning analytics from students‚Äô di:  93%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé| 28/30 [02:29<00:06,  3.01s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ‚úì [2019 - Detecting students-at-risk in computer programming classes with learning analytics from students‚Äô di] Chunk 28 trait√© avec succ√®s\n",
      "  [2019 - Detecting students-at-risk in computer programming classes with learning analytics from students‚Äô di] Traitement du chunk 29/30 - Tentative 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Nettoyage 2019 - Detecting students-at-risk in computer programming classes with learning analytics from students‚Äô di:  97%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã| 29/30 [02:30<00:02,  2.45s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ‚úì [2019 - Detecting students-at-risk in computer programming classes with learning analytics from students‚Äô di] Chunk 29 trait√© avec succ√®s\n",
      "  [2019 - Detecting students-at-risk in computer programming classes with learning analytics from students‚Äô di] Traitement du chunk 30/30 - Tentative 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Nettoyage 2019 - Detecting students-at-risk in computer programming classes with learning analytics from students‚Äô di: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 30/30 [02:31<00:00,  5.06s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ‚úì [2019 - Detecting students-at-risk in computer programming classes with learning analytics from students‚Äô di] Chunk 30 trait√© avec succ√®s\n",
      "  ‚úÖ R√©sultats sauvegard√©s dans 'clean_up_test\\cleanedup_2019 - Detecting students-at-risk in computer programming classes with learning analytics from students‚Äô di.csv'\n",
      "\n",
      "üîÑ Traitement du PDF: 2022 - On the Use of eXplainable Artificial Intelligence to Evaluate School Dropout\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  üìÑ 21 pages extraites de 2022 - On the Use of eXplainable Artificial Intelligence to Evaluate School Dropout\n",
      "  üßπ D√©but du nettoyage...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Nettoyage 2022 - On the Use of eXplainable Artificial Intelligence to Evaluate School Dropout:   0%|          | 0/21 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  [2022 - On the Use of eXplainable Artificial Intelligence to Evaluate School Dropout] Traitement du chunk 1/21 - Tentative 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Nettoyage 2022 - On the Use of eXplainable Artificial Intelligence to Evaluate School Dropout:   5%|‚ñç         | 1/21 [00:03<01:05,  3.28s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ‚úì [2022 - On the Use of eXplainable Artificial Intelligence to Evaluate School Dropout] Chunk 1 trait√© avec succ√®s\n",
      "  [2022 - On the Use of eXplainable Artificial Intelligence to Evaluate School Dropout] Traitement du chunk 2/21 - Tentative 1\n",
      "  ‚ö† [2022 - On the Use of eXplainable Artificial Intelligence to Evaluate School Dropout] Quota √©puis√© (tentative 1/10): 429 You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. [violations {\n",
      "  quota_metric: \"generativelanguage.googleapis.com/generate_content_free_tier_requests\"\n",
      "  quota_id: \"GenerateRequestsPerMinutePerProjectPerModel-FreeTier\"\n",
      "  quota_dimensions {\n",
      "    key: \"model\"\n",
      "    value: \"gemini-2.0-flash-exp\"\n",
      "  }\n",
      "  quota_dimensions {\n",
      "    key: \"location\"\n",
      "    value: \"global\"\n",
      "  }\n",
      "  quota_value: 10\n",
      "}\n",
      ", links {\n",
      "  description: \"Learn more about Gemini API quotas\"\n",
      "  url: \"https://ai.google.dev/gemini-api/docs/rate-limits\"\n",
      "}\n",
      ", retry_delay {\n",
      "  seconds: 58\n",
      "}\n",
      "]\n",
      "  ‚è≥ [2022 - On the Use of eXplainable Artificial Intelligence to Evaluate School Dropout] Attente de 5 secondes (quota √©puis√©)...\n",
      "  [2022 - On the Use of eXplainable Artificial Intelligence to Evaluate School Dropout] Traitement du chunk 2/21 - Tentative 2\n",
      "  ‚ö† [2022 - On the Use of eXplainable Artificial Intelligence to Evaluate School Dropout] Quota √©puis√© (tentative 2/10): 429 You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. [violations {\n",
      "  quota_metric: \"generativelanguage.googleapis.com/generate_content_free_tier_requests\"\n",
      "  quota_id: \"GenerateRequestsPerMinutePerProjectPerModel-FreeTier\"\n",
      "  quota_dimensions {\n",
      "    key: \"model\"\n",
      "    value: \"gemini-2.0-flash-exp\"\n",
      "  }\n",
      "  quota_dimensions {\n",
      "    key: \"location\"\n",
      "    value: \"global\"\n",
      "  }\n",
      "  quota_value: 10\n",
      "}\n",
      ", links {\n",
      "  description: \"Learn more about Gemini API quotas\"\n",
      "  url: \"https://ai.google.dev/gemini-api/docs/rate-limits\"\n",
      "}\n",
      ", retry_delay {\n",
      "  seconds: 53\n",
      "}\n",
      "]\n",
      "  ‚è≥ [2022 - On the Use of eXplainable Artificial Intelligence to Evaluate School Dropout] Attente de 10 secondes (quota √©puis√©)...\n",
      "  [2022 - On the Use of eXplainable Artificial Intelligence to Evaluate School Dropout] Traitement du chunk 2/21 - Tentative 3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Nettoyage 2022 - On the Use of eXplainable Artificial Intelligence to Evaluate School Dropout:  10%|‚ñâ         | 2/21 [00:23<04:15, 13.45s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ‚úì [2022 - On the Use of eXplainable Artificial Intelligence to Evaluate School Dropout] Chunk 2 trait√© avec succ√®s\n",
      "  [2022 - On the Use of eXplainable Artificial Intelligence to Evaluate School Dropout] Traitement du chunk 3/21 - Tentative 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Nettoyage 2022 - On the Use of eXplainable Artificial Intelligence to Evaluate School Dropout:  14%|‚ñà‚ñç        | 3/21 [00:29<02:56,  9.79s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ‚úì [2022 - On the Use of eXplainable Artificial Intelligence to Evaluate School Dropout] Chunk 3 trait√© avec succ√®s\n",
      "  [2022 - On the Use of eXplainable Artificial Intelligence to Evaluate School Dropout] Traitement du chunk 4/21 - Tentative 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Nettoyage 2022 - On the Use of eXplainable Artificial Intelligence to Evaluate School Dropout:  19%|‚ñà‚ñâ        | 4/21 [00:33<02:08,  7.57s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ‚úì [2022 - On the Use of eXplainable Artificial Intelligence to Evaluate School Dropout] Chunk 4 trait√© avec succ√®s\n",
      "  [2022 - On the Use of eXplainable Artificial Intelligence to Evaluate School Dropout] Traitement du chunk 5/21 - Tentative 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Nettoyage 2022 - On the Use of eXplainable Artificial Intelligence to Evaluate School Dropout:  24%|‚ñà‚ñà‚ñç       | 5/21 [00:37<01:41,  6.31s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ‚úì [2022 - On the Use of eXplainable Artificial Intelligence to Evaluate School Dropout] Chunk 5 trait√© avec succ√®s\n",
      "  [2022 - On the Use of eXplainable Artificial Intelligence to Evaluate School Dropout] Traitement du chunk 6/21 - Tentative 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Nettoyage 2022 - On the Use of eXplainable Artificial Intelligence to Evaluate School Dropout:  29%|‚ñà‚ñà‚ñä       | 6/21 [00:40<01:20,  5.34s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ‚úì [2022 - On the Use of eXplainable Artificial Intelligence to Evaluate School Dropout] Chunk 6 trait√© avec succ√®s\n",
      "  [2022 - On the Use of eXplainable Artificial Intelligence to Evaluate School Dropout] Traitement du chunk 7/21 - Tentative 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Nettoyage 2022 - On the Use of eXplainable Artificial Intelligence to Evaluate School Dropout:  33%|‚ñà‚ñà‚ñà‚ñé      | 7/21 [00:46<01:15,  5.37s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ‚úì [2022 - On the Use of eXplainable Artificial Intelligence to Evaluate School Dropout] Chunk 7 trait√© avec succ√®s\n",
      "  [2022 - On the Use of eXplainable Artificial Intelligence to Evaluate School Dropout] Traitement du chunk 8/21 - Tentative 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Nettoyage 2022 - On the Use of eXplainable Artificial Intelligence to Evaluate School Dropout:  38%|‚ñà‚ñà‚ñà‚ñä      | 8/21 [00:49<01:02,  4.79s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ‚úì [2022 - On the Use of eXplainable Artificial Intelligence to Evaluate School Dropout] Chunk 8 trait√© avec succ√®s\n",
      "  [2022 - On the Use of eXplainable Artificial Intelligence to Evaluate School Dropout] Traitement du chunk 9/21 - Tentative 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Nettoyage 2022 - On the Use of eXplainable Artificial Intelligence to Evaluate School Dropout:  43%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 9/21 [00:53<00:54,  4.54s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ‚úì [2022 - On the Use of eXplainable Artificial Intelligence to Evaluate School Dropout] Chunk 9 trait√© avec succ√®s\n",
      "  [2022 - On the Use of eXplainable Artificial Intelligence to Evaluate School Dropout] Traitement du chunk 10/21 - Tentative 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Nettoyage 2022 - On the Use of eXplainable Artificial Intelligence to Evaluate School Dropout:  48%|‚ñà‚ñà‚ñà‚ñà‚ñä     | 10/21 [00:57<00:46,  4.20s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ‚úì [2022 - On the Use of eXplainable Artificial Intelligence to Evaluate School Dropout] Chunk 10 trait√© avec succ√®s\n",
      "  [2022 - On the Use of eXplainable Artificial Intelligence to Evaluate School Dropout] Traitement du chunk 11/21 - Tentative 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Nettoyage 2022 - On the Use of eXplainable Artificial Intelligence to Evaluate School Dropout:  52%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè    | 11/21 [01:00<00:37,  3.77s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ‚úì [2022 - On the Use of eXplainable Artificial Intelligence to Evaluate School Dropout] Chunk 11 trait√© avec succ√®s\n",
      "  [2022 - On the Use of eXplainable Artificial Intelligence to Evaluate School Dropout] Traitement du chunk 12/21 - Tentative 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Nettoyage 2022 - On the Use of eXplainable Artificial Intelligence to Evaluate School Dropout:  57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 12/21 [01:03<00:33,  3.77s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ‚úì [2022 - On the Use of eXplainable Artificial Intelligence to Evaluate School Dropout] Chunk 12 trait√© avec succ√®s\n",
      "  [2022 - On the Use of eXplainable Artificial Intelligence to Evaluate School Dropout] Traitement du chunk 13/21 - Tentative 1\n",
      "  ‚ö† [2022 - On the Use of eXplainable Artificial Intelligence to Evaluate School Dropout] Quota √©puis√© (tentative 1/10): 429 You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. [violations {\n",
      "  quota_metric: \"generativelanguage.googleapis.com/generate_content_free_tier_requests\"\n",
      "  quota_id: \"GenerateRequestsPerMinutePerProjectPerModel-FreeTier\"\n",
      "  quota_dimensions {\n",
      "    key: \"model\"\n",
      "    value: \"gemini-2.0-flash-exp\"\n",
      "  }\n",
      "  quota_dimensions {\n",
      "    key: \"location\"\n",
      "    value: \"global\"\n",
      "  }\n",
      "  quota_value: 10\n",
      "}\n",
      ", links {\n",
      "  description: \"Learn more about Gemini API quotas\"\n",
      "  url: \"https://ai.google.dev/gemini-api/docs/rate-limits\"\n",
      "}\n",
      ", retry_delay {\n",
      "  seconds: 57\n",
      "}\n",
      "]\n",
      "  ‚è≥ [2022 - On the Use of eXplainable Artificial Intelligence to Evaluate School Dropout] Attente de 5 secondes (quota √©puis√©)...\n",
      "  [2022 - On the Use of eXplainable Artificial Intelligence to Evaluate School Dropout] Traitement du chunk 13/21 - Tentative 2\n",
      "  ‚ö† [2022 - On the Use of eXplainable Artificial Intelligence to Evaluate School Dropout] Quota √©puis√© (tentative 2/10): 429 You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. [violations {\n",
      "  quota_metric: \"generativelanguage.googleapis.com/generate_content_free_tier_requests\"\n",
      "  quota_id: \"GenerateRequestsPerMinutePerProjectPerModel-FreeTier\"\n",
      "  quota_dimensions {\n",
      "    key: \"model\"\n",
      "    value: \"gemini-2.0-flash-exp\"\n",
      "  }\n",
      "  quota_dimensions {\n",
      "    key: \"location\"\n",
      "    value: \"global\"\n",
      "  }\n",
      "  quota_value: 10\n",
      "}\n",
      ", links {\n",
      "  description: \"Learn more about Gemini API quotas\"\n",
      "  url: \"https://ai.google.dev/gemini-api/docs/rate-limits\"\n",
      "}\n",
      ", retry_delay {\n",
      "  seconds: 52\n",
      "}\n",
      "]\n",
      "  ‚è≥ [2022 - On the Use of eXplainable Artificial Intelligence to Evaluate School Dropout] Attente de 10 secondes (quota √©puis√©)...\n",
      "  [2022 - On the Use of eXplainable Artificial Intelligence to Evaluate School Dropout] Traitement du chunk 13/21 - Tentative 3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Nettoyage 2022 - On the Use of eXplainable Artificial Intelligence to Evaluate School Dropout:  62%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   | 13/21 [01:20<01:02,  7.79s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ‚úì [2022 - On the Use of eXplainable Artificial Intelligence to Evaluate School Dropout] Chunk 13 trait√© avec succ√®s\n",
      "  [2022 - On the Use of eXplainable Artificial Intelligence to Evaluate School Dropout] Traitement du chunk 14/21 - Tentative 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Nettoyage 2022 - On the Use of eXplainable Artificial Intelligence to Evaluate School Dropout:  67%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 14/21 [01:23<00:43,  6.18s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ‚úì [2022 - On the Use of eXplainable Artificial Intelligence to Evaluate School Dropout] Chunk 14 trait√© avec succ√®s\n",
      "  [2022 - On the Use of eXplainable Artificial Intelligence to Evaluate School Dropout] Traitement du chunk 15/21 - Tentative 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Nettoyage 2022 - On the Use of eXplainable Artificial Intelligence to Evaluate School Dropout:  71%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 15/21 [01:28<00:34,  5.75s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ‚úì [2022 - On the Use of eXplainable Artificial Intelligence to Evaluate School Dropout] Chunk 15 trait√© avec succ√®s\n",
      "  [2022 - On the Use of eXplainable Artificial Intelligence to Evaluate School Dropout] Traitement du chunk 16/21 - Tentative 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Nettoyage 2022 - On the Use of eXplainable Artificial Intelligence to Evaluate School Dropout:  76%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 16/21 [01:32<00:26,  5.40s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ‚úì [2022 - On the Use of eXplainable Artificial Intelligence to Evaluate School Dropout] Chunk 16 trait√© avec succ√®s\n",
      "  [2022 - On the Use of eXplainable Artificial Intelligence to Evaluate School Dropout] Traitement du chunk 17/21 - Tentative 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Nettoyage 2022 - On the Use of eXplainable Artificial Intelligence to Evaluate School Dropout:  81%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 17/21 [01:34<00:16,  4.15s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ‚úì [2022 - On the Use of eXplainable Artificial Intelligence to Evaluate School Dropout] Chunk 17 trait√© avec succ√®s\n",
      "  [2022 - On the Use of eXplainable Artificial Intelligence to Evaluate School Dropout] Traitement du chunk 18/21 - Tentative 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Nettoyage 2022 - On the Use of eXplainable Artificial Intelligence to Evaluate School Dropout:  86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 18/21 [01:38<00:13,  4.35s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ‚úì [2022 - On the Use of eXplainable Artificial Intelligence to Evaluate School Dropout] Chunk 18 trait√© avec succ√®s\n",
      "  [2022 - On the Use of eXplainable Artificial Intelligence to Evaluate School Dropout] Traitement du chunk 19/21 - Tentative 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Nettoyage 2022 - On the Use of eXplainable Artificial Intelligence to Evaluate School Dropout:  90%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 19/21 [01:40<00:07,  3.61s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ‚úì [2022 - On the Use of eXplainable Artificial Intelligence to Evaluate School Dropout] Chunk 19 trait√© avec succ√®s\n",
      "  [2022 - On the Use of eXplainable Artificial Intelligence to Evaluate School Dropout] Traitement du chunk 20/21 - Tentative 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Nettoyage 2022 - On the Use of eXplainable Artificial Intelligence to Evaluate School Dropout:  95%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 20/21 [01:41<00:02,  2.65s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ‚úì [2022 - On the Use of eXplainable Artificial Intelligence to Evaluate School Dropout] Chunk 20 trait√© avec succ√®s\n",
      "  [2022 - On the Use of eXplainable Artificial Intelligence to Evaluate School Dropout] Traitement du chunk 21/21 - Tentative 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Nettoyage 2022 - On the Use of eXplainable Artificial Intelligence to Evaluate School Dropout: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 21/21 [01:42<00:00,  4.87s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ‚úì [2022 - On the Use of eXplainable Artificial Intelligence to Evaluate School Dropout] Chunk 21 trait√© avec succ√®s\n",
      "  ‚úÖ R√©sultats sauvegard√©s dans 'clean_up_test\\cleanedup_2022 - On the Use of eXplainable Artificial Intelligence to Evaluate School Dropout.csv'\n",
      "\n",
      "üîÑ Traitement du PDF: Djulovic and Li - 2013 - Towards freshman retention prediction A comparative study\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  üìÑ 7 pages extraites de Djulovic and Li - 2013 - Towards freshman retention prediction A comparative study\n",
      "  üßπ D√©but du nettoyage...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Nettoyage Djulovic and Li - 2013 - Towards freshman retention prediction A comparative study:   0%|          | 0/7 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  [Djulovic and Li - 2013 - Towards freshman retention prediction A comparative study] Traitement du chunk 1/7 - Tentative 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Nettoyage Djulovic and Li - 2013 - Towards freshman retention prediction A comparative study:  14%|‚ñà‚ñç        | 1/7 [00:06<00:37,  6.22s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ‚úì [Djulovic and Li - 2013 - Towards freshman retention prediction A comparative study] Chunk 1 trait√© avec succ√®s\n",
      "  [Djulovic and Li - 2013 - Towards freshman retention prediction A comparative study] Traitement du chunk 2/7 - Tentative 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Nettoyage Djulovic and Li - 2013 - Towards freshman retention prediction A comparative study:  29%|‚ñà‚ñà‚ñä       | 2/7 [00:13<00:33,  6.68s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ‚úì [Djulovic and Li - 2013 - Towards freshman retention prediction A comparative study] Chunk 2 trait√© avec succ√®s\n",
      "  [Djulovic and Li - 2013 - Towards freshman retention prediction A comparative study] Traitement du chunk 3/7 - Tentative 1\n",
      "  ‚ö† [Djulovic and Li - 2013 - Towards freshman retention prediction A comparative study] Quota √©puis√© (tentative 1/10): 429 You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. [violations {\n",
      "  quota_metric: \"generativelanguage.googleapis.com/generate_content_free_tier_requests\"\n",
      "  quota_id: \"GenerateRequestsPerMinutePerProjectPerModel-FreeTier\"\n",
      "  quota_dimensions {\n",
      "    key: \"model\"\n",
      "    value: \"gemini-2.0-flash-exp\"\n",
      "  }\n",
      "  quota_dimensions {\n",
      "    key: \"location\"\n",
      "    value: \"global\"\n",
      "  }\n",
      "  quota_value: 10\n",
      "}\n",
      ", links {\n",
      "  description: \"Learn more about Gemini API quotas\"\n",
      "  url: \"https://ai.google.dev/gemini-api/docs/rate-limits\"\n",
      "}\n",
      ", retry_delay {\n",
      "  seconds: 5\n",
      "}\n",
      "]\n",
      "  ‚è≥ [Djulovic and Li - 2013 - Towards freshman retention prediction A comparative study] Attente de 5 secondes (quota √©puis√©)...\n",
      "  [Djulovic and Li - 2013 - Towards freshman retention prediction A comparative study] Traitement du chunk 3/7 - Tentative 2\n",
      "  ‚ö† [Djulovic and Li - 2013 - Towards freshman retention prediction A comparative study] Quota √©puis√© (tentative 2/10): 429 You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. [violations {\n",
      "  quota_metric: \"generativelanguage.googleapis.com/generate_content_free_tier_requests\"\n",
      "  quota_id: \"GenerateRequestsPerMinutePerProjectPerModel-FreeTier\"\n",
      "  quota_dimensions {\n",
      "    key: \"model\"\n",
      "    value: \"gemini-2.0-flash-exp\"\n",
      "  }\n",
      "  quota_dimensions {\n",
      "    key: \"location\"\n",
      "    value: \"global\"\n",
      "  }\n",
      "  quota_value: 10\n",
      "}\n",
      ", links {\n",
      "  description: \"Learn more about Gemini API quotas\"\n",
      "  url: \"https://ai.google.dev/gemini-api/docs/rate-limits\"\n",
      "}\n",
      ", retry_delay {\n",
      "}\n",
      "]\n",
      "  ‚è≥ [Djulovic and Li - 2013 - Towards freshman retention prediction A comparative study] Attente de 10 secondes (quota √©puis√©)...\n",
      "  [Djulovic and Li - 2013 - Towards freshman retention prediction A comparative study] Traitement du chunk 3/7 - Tentative 3\n",
      "  ‚ö† [Djulovic and Li - 2013 - Towards freshman retention prediction A comparative study] Quota √©puis√© (tentative 3/10): 429 You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. [violations {\n",
      "  quota_metric: \"generativelanguage.googleapis.com/generate_content_free_tier_requests\"\n",
      "  quota_id: \"GenerateRequestsPerMinutePerProjectPerModel-FreeTier\"\n",
      "  quota_dimensions {\n",
      "    key: \"model\"\n",
      "    value: \"gemini-2.0-flash-exp\"\n",
      "  }\n",
      "  quota_dimensions {\n",
      "    key: \"location\"\n",
      "    value: \"global\"\n",
      "  }\n",
      "  quota_value: 10\n",
      "}\n",
      ", links {\n",
      "  description: \"Learn more about Gemini API quotas\"\n",
      "  url: \"https://ai.google.dev/gemini-api/docs/rate-limits\"\n",
      "}\n",
      ", retry_delay {\n",
      "  seconds: 50\n",
      "}\n",
      "]\n",
      "  ‚è≥ [Djulovic and Li - 2013 - Towards freshman retention prediction A comparative study] Attente de 20 secondes (quota √©puis√©)...\n",
      "  [Djulovic and Li - 2013 - Towards freshman retention prediction A comparative study] Traitement du chunk 3/7 - Tentative 4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Nettoyage Djulovic and Li - 2013 - Towards freshman retention prediction A comparative study:  43%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 3/7 [00:53<01:27, 21.85s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ‚úì [Djulovic and Li - 2013 - Towards freshman retention prediction A comparative study] Chunk 3 trait√© avec succ√®s\n",
      "  [Djulovic and Li - 2013 - Towards freshman retention prediction A comparative study] Traitement du chunk 4/7 - Tentative 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Nettoyage Djulovic and Li - 2013 - Towards freshman retention prediction A comparative study:  57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 4/7 [00:59<00:47, 15.78s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ‚úì [Djulovic and Li - 2013 - Towards freshman retention prediction A comparative study] Chunk 4 trait√© avec succ√®s\n",
      "  [Djulovic and Li - 2013 - Towards freshman retention prediction A comparative study] Traitement du chunk 5/7 - Tentative 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Nettoyage Djulovic and Li - 2013 - Towards freshman retention prediction A comparative study:  71%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 5/7 [01:05<00:24, 12.19s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ‚úì [Djulovic and Li - 2013 - Towards freshman retention prediction A comparative study] Chunk 5 trait√© avec succ√®s\n",
      "  [Djulovic and Li - 2013 - Towards freshman retention prediction A comparative study] Traitement du chunk 6/7 - Tentative 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Nettoyage Djulovic and Li - 2013 - Towards freshman retention prediction A comparative study:  86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 6/7 [01:09<00:09,  9.44s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ‚úì [Djulovic and Li - 2013 - Towards freshman retention prediction A comparative study] Chunk 6 trait√© avec succ√®s\n",
      "  [Djulovic and Li - 2013 - Towards freshman retention prediction A comparative study] Traitement du chunk 7/7 - Tentative 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Nettoyage Djulovic and Li - 2013 - Towards freshman retention prediction A comparative study: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 7/7 [01:12<00:00, 10.33s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ‚úì [Djulovic and Li - 2013 - Towards freshman retention prediction A comparative study] Chunk 7 trait√© avec succ√®s\n",
      "  ‚úÖ R√©sultats sauvegard√©s dans 'clean_up_test\\cleanedup_Djulovic and Li - 2013 - Towards freshman retention prediction A comparative study.csv'\n",
      "\n",
      "üîÑ Traitement du PDF: Mitra and Goldstein - 2015 - Designing early detection and intervention techniques via predictive statistical models‚ÄîA case study\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  üìÑ 14 pages extraites de Mitra and Goldstein - 2015 - Designing early detection and intervention techniques via predictive statistical models‚ÄîA case study\n",
      "  üßπ D√©but du nettoyage...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Nettoyage Mitra and Goldstein - 2015 - Designing early detection and intervention techniques via predictive statistical models‚ÄîA case study:   0%|          | 0/14 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  [Mitra and Goldstein - 2015 - Designing early detection and intervention techniques via predictive statistical models‚ÄîA case study] Traitement du chunk 1/14 - Tentative 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Nettoyage Mitra and Goldstein - 2015 - Designing early detection and intervention techniques via predictive statistical models‚ÄîA case study:   7%|‚ñã         | 1/14 [00:00<00:09,  1.35it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ‚úì [Mitra and Goldstein - 2015 - Designing early detection and intervention techniques via predictive statistical models‚ÄîA case study] Chunk 1 trait√© avec succ√®s\n",
      "  [Mitra and Goldstein - 2015 - Designing early detection and intervention techniques via predictive statistical models‚ÄîA case study] Traitement du chunk 2/14 - Tentative 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Nettoyage Mitra and Goldstein - 2015 - Designing early detection and intervention techniques via predictive statistical models‚ÄîA case study:  14%|‚ñà‚ñç        | 2/14 [00:05<00:35,  2.95s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ‚úì [Mitra and Goldstein - 2015 - Designing early detection and intervention techniques via predictive statistical models‚ÄîA case study] Chunk 2 trait√© avec succ√®s\n",
      "  [Mitra and Goldstein - 2015 - Designing early detection and intervention techniques via predictive statistical models‚ÄîA case study] Traitement du chunk 3/14 - Tentative 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Nettoyage Mitra and Goldstein - 2015 - Designing early detection and intervention techniques via predictive statistical models‚ÄîA case study:  21%|‚ñà‚ñà‚ñè       | 3/14 [00:11<00:46,  4.27s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ‚úì [Mitra and Goldstein - 2015 - Designing early detection and intervention techniques via predictive statistical models‚ÄîA case study] Chunk 3 trait√© avec succ√®s\n",
      "  [Mitra and Goldstein - 2015 - Designing early detection and intervention techniques via predictive statistical models‚ÄîA case study] Traitement du chunk 4/14 - Tentative 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Nettoyage Mitra and Goldstein - 2015 - Designing early detection and intervention techniques via predictive statistical models‚ÄîA case study:  29%|‚ñà‚ñà‚ñä       | 4/14 [00:17<00:51,  5.10s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ‚úì [Mitra and Goldstein - 2015 - Designing early detection and intervention techniques via predictive statistical models‚ÄîA case study] Chunk 4 trait√© avec succ√®s\n",
      "  [Mitra and Goldstein - 2015 - Designing early detection and intervention techniques via predictive statistical models‚ÄîA case study] Traitement du chunk 5/14 - Tentative 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Nettoyage Mitra and Goldstein - 2015 - Designing early detection and intervention techniques via predictive statistical models‚ÄîA case study:  36%|‚ñà‚ñà‚ñà‚ñå      | 5/14 [00:24<00:51,  5.75s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ‚úì [Mitra and Goldstein - 2015 - Designing early detection and intervention techniques via predictive statistical models‚ÄîA case study] Chunk 5 trait√© avec succ√®s\n",
      "  [Mitra and Goldstein - 2015 - Designing early detection and intervention techniques via predictive statistical models‚ÄîA case study] Traitement du chunk 6/14 - Tentative 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Nettoyage Mitra and Goldstein - 2015 - Designing early detection and intervention techniques via predictive statistical models‚ÄîA case study:  43%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 6/14 [00:29<00:44,  5.57s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ‚úì [Mitra and Goldstein - 2015 - Designing early detection and intervention techniques via predictive statistical models‚ÄîA case study] Chunk 6 trait√© avec succ√®s\n",
      "  [Mitra and Goldstein - 2015 - Designing early detection and intervention techniques via predictive statistical models‚ÄîA case study] Traitement du chunk 7/14 - Tentative 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Nettoyage Mitra and Goldstein - 2015 - Designing early detection and intervention techniques via predictive statistical models‚ÄîA case study:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 7/14 [00:35<00:38,  5.56s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ‚úì [Mitra and Goldstein - 2015 - Designing early detection and intervention techniques via predictive statistical models‚ÄîA case study] Chunk 7 trait√© avec succ√®s\n",
      "  [Mitra and Goldstein - 2015 - Designing early detection and intervention techniques via predictive statistical models‚ÄîA case study] Traitement du chunk 8/14 - Tentative 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Nettoyage Mitra and Goldstein - 2015 - Designing early detection and intervention techniques via predictive statistical models‚ÄîA case study:  57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 8/14 [00:39<00:30,  5.05s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ‚úì [Mitra and Goldstein - 2015 - Designing early detection and intervention techniques via predictive statistical models‚ÄîA case study] Chunk 8 trait√© avec succ√®s\n",
      "  [Mitra and Goldstein - 2015 - Designing early detection and intervention techniques via predictive statistical models‚ÄîA case study] Traitement du chunk 9/14 - Tentative 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Nettoyage Mitra and Goldstein - 2015 - Designing early detection and intervention techniques via predictive statistical models‚ÄîA case study:  64%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç   | 9/14 [00:43<00:24,  4.88s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ‚úì [Mitra and Goldstein - 2015 - Designing early detection and intervention techniques via predictive statistical models‚ÄîA case study] Chunk 9 trait√© avec succ√®s\n",
      "  [Mitra and Goldstein - 2015 - Designing early detection and intervention techniques via predictive statistical models‚ÄîA case study] Traitement du chunk 10/14 - Tentative 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Nettoyage Mitra and Goldstein - 2015 - Designing early detection and intervention techniques via predictive statistical models‚ÄîA case study:  71%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 10/14 [00:49<00:20,  5.24s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ‚úì [Mitra and Goldstein - 2015 - Designing early detection and intervention techniques via predictive statistical models‚ÄîA case study] Chunk 10 trait√© avec succ√®s\n",
      "  [Mitra and Goldstein - 2015 - Designing early detection and intervention techniques via predictive statistical models‚ÄîA case study] Traitement du chunk 11/14 - Tentative 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Nettoyage Mitra and Goldstein - 2015 - Designing early detection and intervention techniques via predictive statistical models‚ÄîA case study:  79%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä  | 11/14 [00:53<00:14,  4.69s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ‚úì [Mitra and Goldstein - 2015 - Designing early detection and intervention techniques via predictive statistical models‚ÄîA case study] Chunk 11 trait√© avec succ√®s\n",
      "  [Mitra and Goldstein - 2015 - Designing early detection and intervention techniques via predictive statistical models‚ÄîA case study] Traitement du chunk 12/14 - Tentative 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Nettoyage Mitra and Goldstein - 2015 - Designing early detection and intervention techniques via predictive statistical models‚ÄîA case study:  86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 12/14 [00:59<00:10,  5.30s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ‚úì [Mitra and Goldstein - 2015 - Designing early detection and intervention techniques via predictive statistical models‚ÄîA case study] Chunk 12 trait√© avec succ√®s\n",
      "  [Mitra and Goldstein - 2015 - Designing early detection and intervention techniques via predictive statistical models‚ÄîA case study] Traitement du chunk 13/14 - Tentative 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Nettoyage Mitra and Goldstein - 2015 - Designing early detection and intervention techniques via predictive statistical models‚ÄîA case study:  93%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé| 13/14 [01:01<00:04,  4.30s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ‚úì [Mitra and Goldstein - 2015 - Designing early detection and intervention techniques via predictive statistical models‚ÄîA case study] Chunk 13 trait√© avec succ√®s\n",
      "  [Mitra and Goldstein - 2015 - Designing early detection and intervention techniques via predictive statistical models‚ÄîA case study] Traitement du chunk 14/14 - Tentative 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Nettoyage Mitra and Goldstein - 2015 - Designing early detection and intervention techniques via predictive statistical models‚ÄîA case study: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 14/14 [01:03<00:00,  4.53s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ‚úì [Mitra and Goldstein - 2015 - Designing early detection and intervention techniques via predictive statistical models‚ÄîA case study] Chunk 14 trait√© avec succ√®s\n",
      "  ‚úÖ R√©sultats sauvegard√©s dans 'clean_up_test\\cleanedup_Mitra and Goldstein - 2015 - Designing early detection and intervention techniques via predictive statistical models‚ÄîA case study.csv'\n",
      "\n",
      "üìä R√âSUM√â DU TRAITEMENT:\n",
      "  ‚úÖ Succ√®s: 7 fichiers\n",
      "  ‚ùå √âchecs: 0 fichiers\n",
      "  üìÅ R√©sultats sauvegard√©s dans './clean_up_test'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Configuration des dossiers\n",
    "pdf_source_dir = \"./CleanPDFs/CleanPDF16\"\n",
    "output_dir = \"./clean_up_test\"\n",
    "\n",
    "# Cr√©er le dossier de sortie s'il n'existe pas\n",
    "Path(output_dir).mkdir(exist_ok=True)\n",
    "\n",
    "# V√©rification de la cl√© API\n",
    "GOOGLE_API_KEY = os.getenv(\"GOOGLE_API_KEY\")\n",
    "if GOOGLE_API_KEY is None:\n",
    "    raise ValueError(\"La cl√© GOOGLE_API_KEY n'est pas d√©finie dans les variables d'environnement.\")\n",
    "\n",
    "# Configuration de l'API\n",
    "genai.configure(api_key=GOOGLE_API_KEY)\n",
    "\n",
    "# Template du prompt pour le nettoyage\n",
    "llm_prompt_template = \"\"\"You are a professional document cleaner specialized in preparing text for both human readability and further LLM processing.\n",
    "\n",
    "I will provide you with a chunk of raw document text. Your task is to clean and extract only the meaningful narrative content by applying the following rules:\n",
    "Remove:\n",
    "\n",
    "    Text that appears to be misinterpreted or garbled output from figures, graphs, images, or tables (e.g., axis labels, chart legends, OCR artifacts).\n",
    "\n",
    "    Mathematical equations, whether inline or block format.\n",
    "\n",
    "    Page headers and footers (e.g., repeated titles, page numbers, author names).\n",
    "\n",
    "    Academic references and citations, especially reference lists typically found at the end of academic papers or embedded in text (e.g., \"[12]\", \"(Smith, 2018)\").\n",
    "\n",
    "Keep:\n",
    "\n",
    "    All narrative text that explains figures, graphs, or tables.\n",
    "\n",
    "    Section titles and headings, even if they are standalone.\n",
    "\n",
    "Output format:\n",
    "\n",
    "    Return only the cleaned text with no extra commentary, metadata, or formatting beyond the cleaned content.\n",
    "\n",
    "Input Text Chunk:\n",
    "{context}\"\"\"\n",
    "\n",
    "llm_prompt = PromptTemplate.from_template(llm_prompt_template)\n",
    "\n",
    "def clean_text_chunk(text_chunk, chunk_idx, total_chunks, pdf_name):\n",
    "    \"\"\"\n",
    "    Nettoie un chunk de texte en utilisant l'API Gemini avec retry logic\n",
    "    \"\"\"\n",
    "    prompt_text = llm_prompt.format(context=text_chunk)\n",
    "    max_retries = 10\n",
    "    base_delay = 5\n",
    "    cleaned_output_for_chunk = text_chunk\n",
    "    success = False\n",
    "\n",
    "    for attempt in range(max_retries):\n",
    "        try:\n",
    "            print(f\"  [{pdf_name}] Traitement du chunk {chunk_idx + 1}/{total_chunks} - Tentative {attempt + 1}\")\n",
    "            model = genai.GenerativeModel('gemini-2.0-flash-exp')\n",
    "            response = model.generate_content(prompt_text)\n",
    "            try:\n",
    "                cleaned_output_for_chunk = response.text.strip()\n",
    "                success = True\n",
    "                print(f\"  ‚úì [{pdf_name}] Chunk {chunk_idx + 1} trait√© avec succ√®s\")\n",
    "                break\n",
    "            except AttributeError:\n",
    "                print(f\"  ‚ö† [{pdf_name}] La r√©ponse de l'API n'avait pas d'attribut .text √† la tentative {attempt + 1}\")\n",
    "\n",
    "        except genai.types.BlockedPromptException as e:\n",
    "            print(f\"  ‚ö† [{pdf_name}] Prompt bloqu√© (tentative {attempt + 1}/{max_retries}): {e}\")\n",
    "            if attempt < max_retries - 1:\n",
    "                retry_delay = min(base_delay * (1.5 ** attempt), 60)\n",
    "                print(f\"  ‚è≥ [{pdf_name}] Attente de {retry_delay:.1f} secondes...\")\n",
    "                time.sleep(retry_delay)\n",
    "            else:\n",
    "                print(f\"  ‚ùå [{pdf_name}] Prompt persistant bloqu√© apr√®s {max_retries} tentatives pour le chunk {chunk_idx + 1}\")\n",
    "\n",
    "        except genai.types.StopCandidateException as e:\n",
    "            retry_delay = min(base_delay * (2 ** attempt), 120)\n",
    "            print(f\"  ‚ö† [{pdf_name}] R√©ponse stopp√©e (tentative {attempt + 1}/{max_retries}): {e}\")\n",
    "            if attempt < max_retries - 1:\n",
    "                print(f\"  ‚è≥ [{pdf_name}] Attente de {retry_delay} secondes avant nouvelle tentative...\")\n",
    "                time.sleep(retry_delay)\n",
    "            else:\n",
    "                print(f\"  ‚ùå [{pdf_name}] √âchec apr√®s {max_retries} tentatives pour le chunk {chunk_idx + 1} - R√©ponse Stopp√©e\")\n",
    "\n",
    "        except Exception as e:\n",
    "            # Gestion des erreurs de quota ou serveur\n",
    "            if \"quota\" in str(e).lower() or \"resource_exhausted\" in str(e).lower():\n",
    "                retry_delay = min(base_delay * (2 ** attempt), 300)\n",
    "                print(f\"  ‚ö† [{pdf_name}] Quota √©puis√© (tentative {attempt + 1}/{max_retries}): {e}\")\n",
    "                if attempt < max_retries - 1:\n",
    "                    print(f\"  ‚è≥ [{pdf_name}] Attente de {retry_delay} secondes (quota √©puis√©)...\")\n",
    "                    time.sleep(retry_delay)\n",
    "                else:\n",
    "                    print(f\"  ‚ùå [{pdf_name}] Quota √©puis√© apr√®s {max_retries} tentatives pour le chunk {chunk_idx + 1}\")\n",
    "            else:\n",
    "                retry_delay = min(base_delay * (1.5 ** attempt), 60)\n",
    "                print(f\"  ‚ö† [{pdf_name}] Erreur inattendue (tentative {attempt + 1}/{max_retries}): {e}\")\n",
    "                if attempt < max_retries - 1:\n",
    "                    print(f\"  ‚è≥ [{pdf_name}] Attente de {retry_delay:.1f} secondes...\")\n",
    "                    time.sleep(retry_delay)\n",
    "                else:\n",
    "                    print(f\"  ‚ùå [{pdf_name}] Erreur persistante apr√®s {max_retries} tentatives pour le chunk {chunk_idx + 1}\")\n",
    "\n",
    "    return cleaned_output_for_chunk\n",
    "\n",
    "def process_single_pdf(pdf_path):\n",
    "    \"\"\"\n",
    "    Traite un seul fichier PDF et retourne le DataFrame nettoy√©\n",
    "    \"\"\"\n",
    "    pdf_name = pdf_path.stem\n",
    "    print(f\"\\nüîÑ Traitement du PDF: {pdf_name}\")\n",
    "\n",
    "    try:\n",
    "        # Chargement du PDF\n",
    "        loader = PyPDFLoader(str(pdf_path))\n",
    "        loaded_docs = loader.load()\n",
    "\n",
    "        # Extraction des donn√©es\n",
    "        data = []\n",
    "        for doc in loaded_docs:\n",
    "            data.append({\n",
    "                \"source\": pdf_path.name,\n",
    "                \"page_content\": doc.page_content.strip()\n",
    "            })\n",
    "\n",
    "        df = pd.DataFrame(data)\n",
    "        print(f\"  üìÑ {len(df)} pages extraites de {pdf_name}\")\n",
    "\n",
    "        # Nettoyage des textes\n",
    "        cleaned_texts = []\n",
    "        print(f\"  üßπ D√©but du nettoyage...\")\n",
    "\n",
    "        for idx, row in tqdm(df.iterrows(), total=len(df), desc=f\"Nettoyage {pdf_name}\"):\n",
    "            text_chunk = row[\"page_content\"]\n",
    "            cleaned_chunk = clean_text_chunk(text_chunk, idx, len(df), pdf_name)\n",
    "            cleaned_texts.append(cleaned_chunk)\n",
    "\n",
    "        # Cr√©ation du DataFrame final\n",
    "        df_result = df.copy()\n",
    "        df_result[\"cleaned_page_content\"] = cleaned_texts\n",
    "\n",
    "        return df_result, pdf_name\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"  ‚ùå Erreur lors du traitement de {pdf_name}: {e}\")\n",
    "        return None, pdf_name\n",
    "\n",
    "def main():\n",
    "    \"\"\"\n",
    "    Fonction principale pour traiter tous les PDFs\n",
    "    \"\"\"\n",
    "    pdf_source_path = Path(pdf_source_dir)\n",
    "\n",
    "    # V√©rifier que le dossier source existe\n",
    "    if not pdf_source_path.exists():\n",
    "        raise FileNotFoundError(f\"Le dossier source '{pdf_source_dir}' n'existe pas.\")\n",
    "\n",
    "    # Trouver tous les fichiers PDF\n",
    "    pdf_files = list(pdf_source_path.glob(\"*.pdf\"))\n",
    "\n",
    "    if not pdf_files:\n",
    "        print(f\"‚ùå Aucun fichier PDF trouv√© dans '{pdf_source_dir}'\")\n",
    "        return\n",
    "\n",
    "    print(f\"üìö {len(pdf_files)} fichiers PDF trouv√©s √† traiter\")\n",
    "\n",
    "    successful_processes = 0\n",
    "    failed_processes = 0\n",
    "\n",
    "    # Traitement de chaque PDF\n",
    "    for pdf_file in pdf_files:\n",
    "        try:\n",
    "            df_result, pdf_name = process_single_pdf(pdf_file)\n",
    "\n",
    "            if df_result is not None:\n",
    "                # Sauvegarde du CSV\n",
    "                output_csv_name = f\"cleanedup_{pdf_name}.csv\"\n",
    "                output_csv_path = Path(output_dir) / output_csv_name\n",
    "\n",
    "                df_result.to_csv(output_csv_path, index=False)\n",
    "                print(f\"  ‚úÖ R√©sultats sauvegard√©s dans '{output_csv_path}'\")\n",
    "                successful_processes += 1\n",
    "            else:\n",
    "                failed_processes += 1\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"  ‚ùå Erreur critique pour {pdf_file.name}: {e}\")\n",
    "            failed_processes += 1\n",
    "\n",
    "    # R√©sum√© final\n",
    "    print(f\"\\nüìä R√âSUM√â DU TRAITEMENT:\")\n",
    "    print(f\"  ‚úÖ Succ√®s: {successful_processes} fichiers\")\n",
    "    print(f\"  ‚ùå √âchecs: {failed_processes} fichiers\")\n",
    "    print(f\"  üìÅ R√©sultats sauvegard√©s dans '{output_dir}'\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d62c95a9",
   "metadata": {},
   "source": [
    "# Affichage des 5 premiers documents dans docs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "99be5a5f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Affichage des 5 premiers documents dans docs :\n",
      "\n",
      "üìÑ Document 1 (source: Sales et al. - 2016 - Exploiting academic records for predicting student drop out A case study in Brazilian higher educat.pdf)\n",
      "Exploiting Academic Records for Predicting Student Drop\n",
      "Out: a case study in Brazilian higher education\n",
      "Allan Sales, Leandro Balby, Adalberto Cajueiro\n",
      "Universidade Federal de Campina Grande, Brazil\n",
      "allan.melo@ccc.ufcg.edu.br\n",
      "{lbmarinho,adalberto}@computacao.ufcg.edu.br\n",
      "Abstract. Students‚Äô drop out i\n",
      "---\n",
      "\n",
      "üìÑ Document 2 (source: Sales et al. - 2016 - Exploiting academic records for predicting student drop out A case study in Brazilian higher educat.pdf)\n",
      "Exploiting Academic Records for Predicting Student Drop Out: a case study in Brazilian higher education¬∑ 167\n",
      "0\n",
      "200\n",
      "400\n",
      "600\n",
      "800\n",
      "1 2 3 4 5 6 7 8 9 10\n",
      "Semester\n",
      "Dropouts\n",
      "0\n",
      "500000\n",
      "1000000\n",
      "1500000\n",
      "1 2 3 4 5 6 7 8 9 10\n",
      "Semester\n",
      "Cost\n",
      "Fig. 1. 1) Number of drop outs per semester enrolled, and 2) cost of drop \n",
      "---\n",
      "\n",
      "üìÑ Document 3 (source: Sales et al. - 2016 - Exploiting academic records for predicting student drop out A case study in Brazilian higher educat.pdf)\n",
      "168 ¬∑ A. Sales, L. Balby and A. Cajueiro\n",
      "‚ÄîWe use a large and comprehensive data set of students‚Äô academic records from 76 diÔ¨Äerent courses\n",
      "of a public Brazilian university;\n",
      "‚ÄîWe propose new discriminative features that are not found in the reviewed literature;\n",
      "‚ÄîWe propose two diÔ¨Äerent perspectives to\n",
      "---\n",
      "\n",
      "üìÑ Document 4 (source: Sales et al. - 2016 - Exploiting academic records for predicting student drop out A case study in Brazilian higher educat.pdf)\n",
      "Exploiting Academic Records for Predicting Student Drop Out: a case study in Brazilian higher education¬∑ 169\n",
      "public higher education which is a related but diÔ¨Äerent problem in comparison to drop out in high\n",
      "school.\n",
      "Mustafa et al. [2012] exploit whether registration data of students (e.g., Ô¨Ånancial s\n",
      "---\n",
      "\n",
      "üìÑ Document 5 (source: Sales et al. - 2016 - Exploiting academic records for predicting student drop out A case study in Brazilian higher educat.pdf)\n",
      "170 ¬∑ A. Sales, L. Balby and A. Cajueiro\n",
      "‚àÖ. More formally, the goal is to minimize:\n",
      "err(ÀÜy; Dtest) = 1\n",
      "|Dtest|\n",
      "‚àë\n",
      "(‚Éó x,y)‚ààDtest\n",
      "l(y, ÀÜy(‚Éó x)) (1)\n",
      "where l : Y √óY ‚ÜíR is a loss function measuring, for any test instance(‚Éó x, y) ‚ààDtest, the misÔ¨Åt\n",
      "between the true y and the predicted valueÀÜy(‚Éó x). We insta\n",
      "---\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"Affichage des 5 premiers documents dans docs :\\n\")\n",
    "for i, doc in enumerate(docs[:5]):\n",
    "    print(f\"üìÑ Document {i + 1} (source: {doc.metadata.get('source', 'inconnu')})\")\n",
    "    print(doc.page_content[:300])\n",
    "    print(\"---\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96e8e7df",
   "metadata": {},
   "source": [
    "# Testing everything correctly setting up"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "88d7e7f2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "Absolument ! Voici deux faits surprenants, un en fran√ßais et un en anglais :\n",
       "\n",
       "**En fran√ßais :**\n",
       "\n",
       "Saviez-vous que le mot \"queue\" est le seul mot de la langue fran√ßaise qui se prononce en entier quand on retire sa derni√®re lettre ? Si on enl√®ve le \"e\" √† la fin de \"queue\", on obtient \"queu\", qui se prononce exactement comme \"queue\".\n",
       "\n",
       "**In English:**\n",
       "\n",
       "Did you know that an octopus has three hearts? Two of these hearts pump blood through the gills, and the third pumps blood to the rest of the body. The third heart stops beating when the octopus swims, which is why it prefers to crawl along the seafloor.\n"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\"\"\"response = client.models.generate_content(model=MODEL_ID, contents=\"Dis qqch, n'importe quoi, je veux apprendre un fait nouveau.\")\n",
    "\n",
    "display(Markdown(response.text))\"\"\"\n",
    "\n",
    "model = genai.GenerativeModel(\"gemini-2.0-flash\")\n",
    "response = model.generate_content(\"Dis qqch, n'importe quoi, je veux apprendre un fait nouveau. Une r√©ponse en fran√ßais et une autre en anglais sur un fait diff√©rent.\")\n",
    "display(Markdown(response.text))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d268419",
   "metadata": {},
   "source": [
    "# Database processing (To do)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ad8f0e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "gemini_embeddings = GoogleGenerativeAIEmbeddings(model=\"models/embedding-001\")\n",
    "\n",
    "vectorstore = Chroma.from_documents(\n",
    "    documents=docs,                 # Les documents charg√©s\n",
    "    embedding=gemini_embeddings,    # Mod√®le d'embedding\n",
    "    persist_directory=\"./chroma_db\" # Emplacement de la base de donn√©es\n",
    ")\n",
    "\n",
    "vectorstore_disk = Chroma(\n",
    "                        persist_directory=\"./chroma_db\",       # Directory of db\n",
    "                        embedding_function=gemini_embeddings   # Embedding model\n",
    "                   )\n",
    "\n",
    "retriever = vectorstore_disk.as_retriever(search_kwargs={\"k\": 1})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c50555f0",
   "metadata": {},
   "source": [
    "# Getting text chunks cleaned and add them to chromaDB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "55dead61",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üîÑ Initialisation du chargement des CSV vers ChromaDB...\n",
      "üìÅ 134 fichiers CSV trouv√©s\n",
      "\n",
      "üìÑ Traitement de cleanedup_2012 - Do Situational Academic Emotions Predict Academic Outcomes in a Lecture Course.csv...\n",
      "  ‚úÖ 9 chunks extraits de cleanedup_2012 - Do Situational Academic Emotions Predict Academic Outcomes in a Lecture Course.csv\n",
      "\n",
      "üìÑ Traitement de cleanedup_2012 - Monitoring student progress using virtual appliances A case study.csv...\n",
      "  ‚úÖ 10 chunks extraits de cleanedup_2012 - Monitoring student progress using virtual appliances A case study.csv\n",
      "\n",
      "üìÑ Traitement de cleanedup_2012 - Predicting Student Outcome Measures Using the ASCA National Model Program Audit.csv...\n",
      "  ‚úÖ 8 chunks extraits de cleanedup_2012 - Predicting Student Outcome Measures Using the ASCA National Model Program Audit.csv\n",
      "\n",
      "üìÑ Traitement de cleanedup_2012 - The effects of achievement goals and self-regulated learning behaviors on reading comprehension in t.csv...\n",
      "  ‚úÖ 14 chunks extraits de cleanedup_2012 - The effects of achievement goals and self-regulated learning behaviors on reading comprehension in t.csv\n",
      "\n",
      "üìÑ Traitement de cleanedup_2013 - Can Online Discussion Participation Predict Group Project Performance Investigating the Roles of Li.csv...\n",
      "  ‚úÖ 23 chunks extraits de cleanedup_2013 - Can Online Discussion Participation Predict Group Project Performance Investigating the Roles of Li.csv\n",
      "\n",
      "üìÑ Traitement de cleanedup_2013 - Correlation between Course Tracking Variables and Academic Performance in Blended Online Courses.csv...\n",
      "  ‚úÖ 5 chunks extraits de cleanedup_2013 - Correlation between Course Tracking Variables and Academic Performance in Blended Online Courses.csv\n",
      "\n",
      "üìÑ Traitement de cleanedup_2013 - Predicting student academic performance in an engineering dynamics course A comparison of four type.csv...\n",
      "  ‚úÖ 13 chunks extraits de cleanedup_2013 - Predicting student academic performance in an engineering dynamics course A comparison of four type.csv\n",
      "\n",
      "üìÑ Traitement de cleanedup_2013 - Significant Predictors of Learning from Student Interactions with Online Learning Objects.csv...\n",
      "  ‚úÖ 6 chunks extraits de cleanedup_2013 - Significant Predictors of Learning from Student Interactions with Online Learning Objects.csv\n",
      "\n",
      "üìÑ Traitement de cleanedup_2013 - Using artificial neural networks to predict first-year traditional students second year retention ra.csv...\n",
      "  ‚úÖ 5 chunks extraits de cleanedup_2013 - Using artificial neural networks to predict first-year traditional students second year retention ra.csv\n",
      "\n",
      "üìÑ Traitement de cleanedup_2014 - Can we predict success from log data in VLEs Classification of interactions for learning analytics.csv...\n",
      "  ‚úÖ 9 chunks extraits de cleanedup_2014 - Can we predict success from log data in VLEs Classification of interactions for learning analytics.csv\n",
      "\n",
      "üìÑ Traitement de cleanedup_2014 - Student ratings of teaching quality in primary school Dimensions and prediction of student outcomes.csv...\n",
      "  ‚úÖ 8 chunks extraits de cleanedup_2014 - Student ratings of teaching quality in primary school Dimensions and prediction of student outcomes.csv\n",
      "\n",
      "üìÑ Traitement de cleanedup_2016 - Predicting and Analyzing Students‚Äô Performance An Educational Data Mining Approach.csv...\n",
      "  ‚úÖ 6 chunks extraits de cleanedup_2016 - Predicting and Analyzing Students‚Äô Performance An Educational Data Mining Approach.csv\n",
      "\n",
      "üìÑ Traitement de cleanedup_2016 - The impact of learning design on student behaviour, satisfaction and performance A cross-institutio.csv...\n",
      "  ‚úÖ 9 chunks extraits de cleanedup_2016 - The impact of learning design on student behaviour, satisfaction and performance A cross-institutio.csv\n",
      "\n",
      "üìÑ Traitement de cleanedup_2017 - A Machine Learning Approach for Tracking and Predicting Student Performance in Degree Programs.csv...\n",
      "  ‚úÖ 12 chunks extraits de cleanedup_2017 - A Machine Learning Approach for Tracking and Predicting Student Performance in Degree Programs.csv\n",
      "\n",
      "üìÑ Traitement de cleanedup_2017 - Combining University Student Self-Regulated Learning Indicators and Engagement with Online Learning.csv...\n",
      "  ‚úÖ 10 chunks extraits de cleanedup_2017 - Combining University Student Self-Regulated Learning Indicators and Engagement with Online Learning.csv\n",
      "\n",
      "üìÑ Traitement de cleanedup_2017 - Individual Differences Related to College Students‚Äô Course Performance in Calculus II.csv...\n",
      "  ‚úÖ 23 chunks extraits de cleanedup_2017 - Individual Differences Related to College Students‚Äô Course Performance in Calculus II.csv\n",
      "\n",
      "üìÑ Traitement de cleanedup_2017 - MOOC Dropout Prediction.csv...\n",
      "  ‚úÖ 8 chunks extraits de cleanedup_2017 - MOOC Dropout Prediction.csv\n",
      "\n",
      "üìÑ Traitement de cleanedup_2017 - Predicting Kindergarteners_ Achievement and Motivation From Observational Measures of Teaching Effec.csv...\n",
      "  ‚úÖ 18 chunks extraits de cleanedup_2017 - Predicting Kindergarteners_ Achievement and Motivation From Observational Measures of Teaching Effec.csv\n",
      "\n",
      "üìÑ Traitement de cleanedup_2017 - Predicting Student Performance from LMS Data A Comparison of 17 Blended Courses Using Moodle LMS.csv...\n",
      "  ‚úÖ 13 chunks extraits de cleanedup_2017 - Predicting Student Performance from LMS Data A Comparison of 17 Blended Courses Using Moodle LMS.csv\n",
      "\n",
      "üìÑ Traitement de cleanedup_2017 - Using Learning Analytics to Predict Students‚Äô Performance in Moodle Learning Management System A Ca.csv...\n",
      "  ‚úÖ 13 chunks extraits de cleanedup_2017 - Using Learning Analytics to Predict Students‚Äô Performance in Moodle Learning Management System A Ca.csv\n",
      "\n",
      "üìÑ Traitement de cleanedup_2017 - Widget, widget as you lead, I am performing well indeed!.csv...\n",
      "  ‚úÖ 10 chunks extraits de cleanedup_2017 - Widget, widget as you lead, I am performing well indeed!.csv\n",
      "\n",
      "üìÑ Traitement de cleanedup_2017 - Widget, Widget on the Wall, Am I Performing Well at All.csv...\n",
      "  ‚úÖ 11 chunks extraits de cleanedup_2017 - Widget, Widget on the Wall, Am I Performing Well at All.csv\n",
      "\n",
      "üìÑ Traitement de cleanedup_2018 - Correlates of students‚Äô internalization and defiance of classroom rules A self‚Äêdetermination theory.csv...\n",
      "  ‚úÖ 17 chunks extraits de cleanedup_2018 - Correlates of students‚Äô internalization and defiance of classroom rules A self‚Äêdetermination theory.csv\n",
      "\n",
      "üìÑ Traitement de cleanedup_2018 - Data mining approach to predicting the performance of first year student in a university using the a.csv...\n",
      "  ‚úÖ 17 chunks extraits de cleanedup_2018 - Data mining approach to predicting the performance of first year student in a university using the a.csv\n",
      "\n",
      "üìÑ Traitement de cleanedup_2018 - Does Attendance in Private Schools Predict Student Outcomes at Age 15 Evidence From a Longitudinal.csv...\n",
      "  ‚úÖ 16 chunks extraits de cleanedup_2018 - Does Attendance in Private Schools Predict Student Outcomes at Age 15 Evidence From a Longitudinal.csv\n",
      "\n",
      "üìÑ Traitement de cleanedup_2018 - Emotions, Motivation, Cognitive‚ÄìMetacognitive Strategies, and Behavior as Predictors of Learning Per.csv...\n",
      "  ‚úÖ 19 chunks extraits de cleanedup_2018 - Emotions, Motivation, Cognitive‚ÄìMetacognitive Strategies, and Behavior as Predictors of Learning Per.csv\n",
      "\n",
      "üìÑ Traitement de cleanedup_2018 - Exploring the High Potential Factors that Affects Students‚Äô Academic Performance.csv...\n",
      "  ‚úÖ 9 chunks extraits de cleanedup_2018 - Exploring the High Potential Factors that Affects Students‚Äô Academic Performance.csv\n",
      "\n",
      "üìÑ Traitement de cleanedup_2018 - Factors influencing peer learning and performance in MOOC asynchronous online discussion forum.csv...\n",
      "  ‚úÖ 13 chunks extraits de cleanedup_2018 - Factors influencing peer learning and performance in MOOC asynchronous online discussion forum.csv\n",
      "\n",
      "üìÑ Traitement de cleanedup_2018 - Leveraging Non-cognitive Student Self-reports to Predict Learning Outcomes.csv...\n",
      "  ‚úÖ 4 chunks extraits de cleanedup_2018 - Leveraging Non-cognitive Student Self-reports to Predict Learning Outcomes.csv\n",
      "\n",
      "üìÑ Traitement de cleanedup_2018 - Measuring Behaviors and Identifying Indicators of Self-Regulation in Computer-Assisted Language Lear.csv...\n",
      "  ‚úÖ 12 chunks extraits de cleanedup_2018 - Measuring Behaviors and Identifying Indicators of Self-Regulation in Computer-Assisted Language Lear.csv\n",
      "\n",
      "üìÑ Traitement de cleanedup_2018 - Predicting student performance in a blended MOOC.csv...\n",
      "  ‚úÖ 14 chunks extraits de cleanedup_2018 - Predicting student performance in a blended MOOC.csv\n",
      "\n",
      "üìÑ Traitement de cleanedup_2018 - Social Support and Classroom Management Are Related to Secondary Students‚Äô General School Adjustment.csv...\n",
      "  ‚úÖ 15 chunks extraits de cleanedup_2018 - Social Support and Classroom Management Are Related to Secondary Students‚Äô General School Adjustment.csv\n",
      "\n",
      "üìÑ Traitement de cleanedup_2018 - Teacher-student relationships The positives and negatives of assessing both perspectives.csv...\n",
      "  ‚úÖ 14 chunks extraits de cleanedup_2018 - Teacher-student relationships The positives and negatives of assessing both perspectives.csv\n",
      "\n",
      "üìÑ Traitement de cleanedup_2018 - The different relationships between engagement and outcomes across participant subgroups in Massive.csv...\n",
      "  ‚úÖ 24 chunks extraits de cleanedup_2018 - The different relationships between engagement and outcomes across participant subgroups in Massive.csv\n",
      "\n",
      "üìÑ Traitement de cleanedup_2018 - Using social network analysis to understand online Problem-Based Learning and predict performance.csv...\n",
      "  ‚úÖ 19 chunks extraits de cleanedup_2018 - Using social network analysis to understand online Problem-Based Learning and predict performance.csv\n",
      "\n",
      "üìÑ Traitement de cleanedup_2019 - A National Study of the Differential Impact of Novice Teacher Certification on Teacher Traits and Ra.csv...\n",
      "  ‚úÖ 13 chunks extraits de cleanedup_2019 - A National Study of the Differential Impact of Novice Teacher Certification on Teacher Traits and Ra.csv\n",
      "\n",
      "üìÑ Traitement de cleanedup_2019 - Detecting students-at-risk in computer programming classes with learning analytics from students‚Äô di.csv...\n",
      "  ‚úÖ 29 chunks extraits de cleanedup_2019 - Detecting students-at-risk in computer programming classes with learning analytics from students‚Äô di.csv\n",
      "\n",
      "üìÑ Traitement de cleanedup_2019 - Does Time Play a Role Prediction of Learning Performance with Time-use Habits in Online Assignments.csv...\n",
      "  ‚úÖ 4 chunks extraits de cleanedup_2019 - Does Time Play a Role Prediction of Learning Performance with Time-use Habits in Online Assignments.csv\n",
      "\n",
      "üìÑ Traitement de cleanedup_2019 - Effectiveness of online presence in a blended higher learning environment in the Pacific.csv...\n",
      "  ‚úÖ 18 chunks extraits de cleanedup_2019 - Effectiveness of online presence in a blended higher learning environment in the Pacific.csv\n",
      "\n",
      "üìÑ Traitement de cleanedup_2019 - Factors investigation of learning behaviors affecting learning performance and self-regulated learni.csv...\n",
      "  ‚úÖ 6 chunks extraits de cleanedup_2019 - Factors investigation of learning behaviors affecting learning performance and self-regulated learni.csv\n",
      "\n",
      "üìÑ Traitement de cleanedup_2019 - Feature Extraction for Next-Term Prediction of Poor Student Performance.csv...\n",
      "  ‚úÖ 12 chunks extraits de cleanedup_2019 - Feature Extraction for Next-Term Prediction of Poor Student Performance.csv\n",
      "\n",
      "üìÑ Traitement de cleanedup_2019 - Implementing AutoML in Educational Data Mining for Prediction Tasks.csv...\n",
      "  ‚úÖ 24 chunks extraits de cleanedup_2019 - Implementing AutoML in Educational Data Mining for Prediction Tasks.csv\n",
      "\n",
      "üìÑ Traitement de cleanedup_2019 - Modelling, prediction and classification of student academic performance using artificial neural net.csv...\n",
      "  ‚úÖ 10 chunks extraits de cleanedup_2019 - Modelling, prediction and classification of student academic performance using artificial neural net.csv\n",
      "\n",
      "üìÑ Traitement de cleanedup_2019 - Predictive power of regularity of pre-class activities in a flipped classroom.csv...\n",
      "  ‚úÖ 13 chunks extraits de cleanedup_2019 - Predictive power of regularity of pre-class activities in a flipped classroom.csv\n",
      "\n",
      "üìÑ Traitement de cleanedup_2019 - Predictors of Academic Achievement in Blended Learning the Case of Data Science Minor.csv...\n",
      "  ‚úÖ 10 chunks extraits de cleanedup_2019 - Predictors of Academic Achievement in Blended Learning the Case of Data Science Minor.csv\n",
      "\n",
      "üìÑ Traitement de cleanedup_2019 - Students_ engagement characteristics predict success and completion of online courses.csv...\n",
      "  ‚úÖ 10 chunks extraits de cleanedup_2019 - Students_ engagement characteristics predict success and completion of online courses.csv\n",
      "\n",
      "üìÑ Traitement de cleanedup_2019 - Using machine learning to predict physics course outcomes.csv...\n",
      "  ‚úÖ 18 chunks extraits de cleanedup_2019 - Using machine learning to predict physics course outcomes.csv\n",
      "\n",
      "üìÑ Traitement de cleanedup_2020 - Measures of engagement in the first three weeks of higher education predict subsequent activity and.csv...\n",
      "  ‚úÖ 14 chunks extraits de cleanedup_2020 - Measures of engagement in the first three weeks of higher education predict subsequent activity and.csv\n",
      "\n",
      "üìÑ Traitement de cleanedup_2020 - Student Performance Prediction Based on Blended Learning.csv...\n",
      "  ‚úÖ 7 chunks extraits de cleanedup_2020 - Student Performance Prediction Based on Blended Learning.csv\n",
      "\n",
      "üìÑ Traitement de cleanedup_2020 - Using clickstream data to measure, understand, and support self-regulated learning in online courses.csv...\n",
      "  ‚úÖ 13 chunks extraits de cleanedup_2020 - Using clickstream data to measure, understand, and support self-regulated learning in online courses.csv\n",
      "\n",
      "üìÑ Traitement de cleanedup_2020 - Using Interactive E-Book User Log Variables to Track Reading Processes and Predict Digital Learning.csv...\n",
      "  ‚úÖ 10 chunks extraits de cleanedup_2020 - Using Interactive E-Book User Log Variables to Track Reading Processes and Predict Digital Learning.csv\n",
      "\n",
      "üìÑ Traitement de cleanedup_2021 - Academic Performance Modelling with Machine Learning Based on Cognitive and Non-Cognitive Features.csv...\n",
      "  ‚úÖ 10 chunks extraits de cleanedup_2021 - Academic Performance Modelling with Machine Learning Based on Cognitive and Non-Cognitive Features.csv\n",
      "\n",
      "üìÑ Traitement de cleanedup_2021 - ALEKS constructs as predictors of high school mathematics achievement for struggling students.csv...\n",
      "  ‚úÖ 12 chunks extraits de cleanedup_2021 - ALEKS constructs as predictors of high school mathematics achievement for struggling students.csv\n",
      "\n",
      "üìÑ Traitement de cleanedup_2021 - Early prediction of undergraduate Student_s academic performance in completely online learning A fi.csv...\n",
      "  ‚úÖ 10 chunks extraits de cleanedup_2021 - Early prediction of undergraduate Student_s academic performance in completely online learning A fi.csv\n",
      "\n",
      "üìÑ Traitement de cleanedup_2021 - Feature Correlation with Student Education Performance.csv...\n",
      "  ‚úÖ 13 chunks extraits de cleanedup_2021 - Feature Correlation with Student Education Performance.csv\n",
      "\n",
      "üìÑ Traitement de cleanedup_2021 - Investigating prompts for supporting students_ self-regulation ‚Äì A remaining challenge for learning.csv...\n",
      "  ‚úÖ 11 chunks extraits de cleanedup_2021 - Investigating prompts for supporting students_ self-regulation ‚Äì A remaining challenge for learning.csv\n",
      "\n",
      "üìÑ Traitement de cleanedup_2021 - Predicting Factors that Influence Students‚Äô Learning Outcomes Using Learning Analytics in Online Lea.csv...\n",
      "  ‚úÖ 12 chunks extraits de cleanedup_2021 - Predicting Factors that Influence Students‚Äô Learning Outcomes Using Learning Analytics in Online Lea.csv\n",
      "\n",
      "üìÑ Traitement de cleanedup_2021 - Students matter the most in learning analytics The effects of internal and instructional conditions.csv...\n",
      "  ‚úÖ 12 chunks extraits de cleanedup_2021 - Students matter the most in learning analytics The effects of internal and instructional conditions.csv\n",
      "\n",
      "üìÑ Traitement de cleanedup_2021 - The advantage of distributed practice in a blended learning setting.csv...\n",
      "  ‚úÖ 16 chunks extraits de cleanedup_2021 - The advantage of distributed practice in a blended learning setting.csv\n",
      "\n",
      "üìÑ Traitement de cleanedup_2021 - Towards Modeling Student Engagement with Interactive Computing Textbooks.csv...\n",
      "  ‚úÖ 6 chunks extraits de cleanedup_2021 - Towards Modeling Student Engagement with Interactive Computing Textbooks.csv\n",
      "\n",
      "üìÑ Traitement de cleanedup_2022 - Academic self-efficacy, self-esteem, and grit in higher online education Consistency of interests p.csv...\n",
      "  ‚úÖ 24 chunks extraits de cleanedup_2022 - Academic self-efficacy, self-esteem, and grit in higher online education Consistency of interests p.csv\n",
      "\n",
      "üìÑ Traitement de cleanedup_2022 - Is there order in the mess A single paper meta-analysis approach to identification of predictors of.csv...\n",
      "  ‚úÖ 21 chunks extraits de cleanedup_2022 - Is there order in the mess A single paper meta-analysis approach to identification of predictors of.csv\n",
      "\n",
      "üìÑ Traitement de cleanedup_2022 - On the Use of eXplainable Artificial Intelligence to Evaluate School Dropout.csv...\n",
      "  ‚úÖ 20 chunks extraits de cleanedup_2022 - On the Use of eXplainable Artificial Intelligence to Evaluate School Dropout.csv\n",
      "\n",
      "üìÑ Traitement de cleanedup_2022 - Predicting individual learning performance using machine‚Äêlearning hybridized with the teaching‚Äêlearn.csv...\n",
      "  ‚úÖ 17 chunks extraits de cleanedup_2022 - Predicting individual learning performance using machine‚Äêlearning hybridized with the teaching‚Äêlearn.csv\n",
      "\n",
      "üìÑ Traitement de cleanedup_2022 - Prediction of Academic Performance of Engineering Students by Using Data Mining Techniques.csv...\n",
      "  ‚úÖ 7 chunks extraits de cleanedup_2022 - Prediction of Academic Performance of Engineering Students by Using Data Mining Techniques.csv\n",
      "\n",
      "üìÑ Traitement de cleanedup_2022 - Using Learner Analytics to Explore the Potential Contribution of Multimodal Formative Assessment to.csv...\n",
      "  ‚úÖ 10 chunks extraits de cleanedup_2022 - Using Learner Analytics to Explore the Potential Contribution of Multimodal Formative Assessment to.csv\n",
      "\n",
      "üìÑ Traitement de cleanedup_A Data Mining Approach for Predicting Academic Success ‚Äì A Case Study Helping Teachers Develop Rese.csv...\n",
      "  ‚úÖ 13 chunks extraits de cleanedup_A Data Mining Approach for Predicting Academic Success ‚Äì A Case Study Helping Teachers Develop Rese.csv\n",
      "\n",
      "üìÑ Traitement de cleanedup_Al-Shabandar - 2017 - IJCNN - Machine learning approaches to predict learning outcomes in Massive open online courses.csv...\n",
      "  ‚úÖ 8 chunks extraits de cleanedup_Al-Shabandar - 2017 - IJCNN - Machine learning approaches to predict learning outcomes in Massive open online courses.csv\n",
      "\n",
      "üìÑ Traitement de cleanedup_Alturki - 2022 - Predicting Master_s students_ academic performance an empirical study in Germany.csv...\n",
      "  ‚úÖ 22 chunks extraits de cleanedup_Alturki - 2022 - Predicting Master_s students_ academic performance an empirical study in Germany.csv\n",
      "\n",
      "üìÑ Traitement de cleanedup_Alwarthan - 2022 - An Explainable Model for Identifying At-Risk Student at Higher Education.csv...\n",
      "  ‚úÖ 19 chunks extraits de cleanedup_Alwarthan - 2022 - An Explainable Model for Identifying At-Risk Student at Higher Education.csv\n",
      "\n",
      "üìÑ Traitement de cleanedup_Anzer - 2018 - Predicting Academic Performance of Students in UAE Using Data Mining Techniques.csv...\n",
      "  ‚úÖ 5 chunks extraits de cleanedup_Anzer - 2018 - Predicting Academic Performance of Students in UAE Using Data Mining Techniques.csv\n",
      "\n",
      "üìÑ Traitement de cleanedup_Ayouni - 2021 - A new ML-based approach to enhance student engagement in online environment..csv...\n",
      "  ‚úÖ 14 chunks extraits de cleanedup_Ayouni - 2021 - A new ML-based approach to enhance student engagement in online environment..csv\n",
      "\n",
      "üìÑ Traitement de cleanedup_Bainbridge et al. - 2015 - Using Learning Analytics to Predict At-Risk Students in Online Graduate Public Affairs and Administr.csv...\n",
      "  ‚úÖ 17 chunks extraits de cleanedup_Bainbridge et al. - 2015 - Using Learning Analytics to Predict At-Risk Students in Online Graduate Public Affairs and Administr.csv\n",
      "\n",
      "üìÑ Traitement de cleanedup_Barber - 2012 - LAK - Course correction using analytics to predict course success.csv...\n",
      "  ‚úÖ 4 chunks extraits de cleanedup_Barber - 2012 - LAK - Course correction using analytics to predict course success.csv\n",
      "\n",
      "üìÑ Traitement de cleanedup_Bengesai - 2018 - An Analysis of Academic and Institutional Factors Affecting Graduation Among Engineering Students at.csv...\n",
      "  ‚úÖ 11 chunks extraits de cleanedup_Bengesai - 2018 - An Analysis of Academic and Institutional Factors Affecting Graduation Among Engineering Students at.csv\n",
      "\n",
      "üìÑ Traitement de cleanedup_Cabo - 2021 - Use of Machine Learning to Identify Predictors of Student Performance in Writing Viable Computer Pro.csv...\n",
      "  ‚úÖ 8 chunks extraits de cleanedup_Cabo - 2021 - Use of Machine Learning to Identify Predictors of Student Performance in Writing Viable Computer Pro.csv\n",
      "\n",
      "üìÑ Traitement de cleanedup_Cannistr√† - 2021 - Early-predicting dropout of university students an application of innovative multilevel machine lea.csv...\n",
      "  ‚úÖ 21 chunks extraits de cleanedup_Cannistr√† - 2021 - Early-predicting dropout of university students an application of innovative multilevel machine lea.csv\n",
      "\n",
      "üìÑ Traitement de cleanedup_Copie de 2012 - Do Situational Academic Emotions Predict Academic Outcomes in a Lecture Course.csv...\n",
      "  ‚úÖ 10 chunks extraits de cleanedup_Copie de 2012 - Do Situational Academic Emotions Predict Academic Outcomes in a Lecture Course.csv\n",
      "\n",
      "üìÑ Traitement de cleanedup_Copie de 2017 - MOOC Dropout Prediction.csv...\n",
      "  ‚úÖ 9 chunks extraits de cleanedup_Copie de 2017 - MOOC Dropout Prediction.csv\n",
      "\n",
      "üìÑ Traitement de cleanedup_Copie de 2018 - Leveraging Non-cognitive Student Self-reports to Predict Learning Outcomes.csv...\n",
      "  ‚úÖ 4 chunks extraits de cleanedup_Copie de 2018 - Leveraging Non-cognitive Student Self-reports to Predict Learning Outcomes.csv\n",
      "\n",
      "üìÑ Traitement de cleanedup_Copie de 2019 - Detecting students-at-risk in computer programming classes with learning analytics from students‚Äô di.csv...\n",
      "  ‚úÖ 29 chunks extraits de cleanedup_Copie de 2019 - Detecting students-at-risk in computer programming classes with learning analytics from students‚Äô di.csv\n",
      "\n",
      "üìÑ Traitement de cleanedup_Copie de 2022 - On the Use of eXplainable Artificial Intelligence to Evaluate School Dropout.csv...\n",
      "  ‚úÖ 19 chunks extraits de cleanedup_Copie de 2022 - On the Use of eXplainable Artificial Intelligence to Evaluate School Dropout.csv\n",
      "\n",
      "üìÑ Traitement de cleanedup_Copie de Djulovic and Li - 2013 - Towards freshman retention prediction A comparative study.csv...\n",
      "  ‚úÖ 7 chunks extraits de cleanedup_Copie de Djulovic and Li - 2013 - Towards freshman retention prediction A comparative study.csv\n",
      "\n",
      "üìÑ Traitement de cleanedup_Copie de Mitra and Goldstein - 2015 - Designing early detection and intervention techniques via predictive statistical models‚ÄîA case study.csv...\n",
      "  ‚úÖ 14 chunks extraits de cleanedup_Copie de Mitra and Goldstein - 2015 - Designing early detection and intervention techniques via predictive statistical models‚ÄîA case study.csv\n",
      "\n",
      "üìÑ Traitement de cleanedup_Djulovic and Li - 2013 - Towards freshman retention prediction A comparative study.csv...\n",
      "  ‚úÖ 7 chunks extraits de cleanedup_Djulovic and Li - 2013 - Towards freshman retention prediction A comparative study.csv\n",
      "\n",
      "üìÑ Traitement de cleanedup_Emerson - 2020 - Multimodal Learning Analytics for Game-Based Learning..csv...\n",
      "  ‚úÖ 20 chunks extraits de cleanedup_Emerson - 2020 - Multimodal Learning Analytics for Game-Based Learning..csv\n",
      "\n",
      "üìÑ Traitement de cleanedup_Everaert - 2022 - Predicting first-year university progression using early warning signals from accounting education.csv...\n",
      "  ‚úÖ 24 chunks extraits de cleanedup_Everaert - 2022 - Predicting first-year university progression using early warning signals from accounting education.csv\n",
      "\n",
      "üìÑ Traitement de cleanedup_Exploring the relation between self-regulation, online activities, and academic performance a case.csv...\n",
      "  ‚úÖ 7 chunks extraits de cleanedup_Exploring the relation between self-regulation, online activities, and academic performance a case.csv\n",
      "\n",
      "üìÑ Traitement de cleanedup_Flanagan - 2022 - Early-warning prediction of student performance and engagement in open book assessment by reading be.csv...\n",
      "  ‚úÖ 23 chunks extraits de cleanedup_Flanagan - 2022 - Early-warning prediction of student performance and engagement in open book assessment by reading be.csv\n",
      "\n",
      "üìÑ Traitement de cleanedup_Gaftandzhieva - 2022 - Exploring Online Activities to Predict the Final Grade of Student.csv...\n",
      "  ‚úÖ 17 chunks extraits de cleanedup_Gaftandzhieva - 2022 - Exploring Online Activities to Predict the Final Grade of Student.csv\n",
      "\n",
      "üìÑ Traitement de cleanedup_Gil et al. - 2020 - Predicting students_ dropout indicators in public school using data mining approaches.csv...\n",
      "  ‚úÖ 6 chunks extraits de cleanedup_Gil et al. - 2020 - Predicting students_ dropout indicators in public school using data mining approaches.csv\n",
      "\n",
      "üìÑ Traitement de cleanedup_Gitinabard - 2019 - How Widely Can Prediction Models be Generalized Performance Prediction in Blended Courses.csv...\n",
      "  ‚úÖ 13 chunks extraits de cleanedup_Gitinabard - 2019 - How Widely Can Prediction Models be Generalized Performance Prediction in Blended Courses.csv\n",
      "\n",
      "üìÑ Traitement de cleanedup_Goad - 2020 - Predicting Student Success in Online Physical Education.csv...\n",
      "  ‚úÖ 15 chunks extraits de cleanedup_Goad - 2020 - Predicting Student Success in Online Physical Education.csv\n",
      "\n",
      "üìÑ Traitement de cleanedup_Han et al. - 2017 - Investigating performance in a blended SPOC.csv...\n",
      "  ‚úÖ 6 chunks extraits de cleanedup_Han et al. - 2017 - Investigating performance in a blended SPOC.csv\n",
      "\n",
      "üìÑ Traitement de cleanedup_Hussain - 2018 - Using machine learning to predict student difficulties from learning session data.csv...\n",
      "  ‚úÖ 25 chunks extraits de cleanedup_Hussain - 2018 - Using machine learning to predict student difficulties from learning session data.csv\n",
      "\n",
      "üìÑ Traitement de cleanedup_Iatrellis - 2020 - A two-phase machine learning approach for predicting student outcomes.csv...\n",
      "  ‚úÖ 19 chunks extraits de cleanedup_Iatrellis - 2020 - A two-phase machine learning approach for predicting student outcomes.csv\n",
      "\n",
      "üìÑ Traitement de cleanedup_Kemper et al. - 2020 - Predicting student dropout A machine learning approach.csv...\n",
      "  ‚úÖ 19 chunks extraits de cleanedup_Kemper et al. - 2020 - Predicting student dropout A machine learning approach.csv\n",
      "\n",
      "üìÑ Traitement de cleanedup_Kennedy et al. - 2015 - Predicting success how learners_ prior knowledge, skills and activities predict MOOC performance.csv...\n",
      "  ‚úÖ 5 chunks extraits de cleanedup_Kennedy et al. - 2015 - Predicting success how learners_ prior knowledge, skills and activities predict MOOC performance.csv\n",
      "\n",
      "üìÑ Traitement de cleanedup_Kondo et al. - 2017 - Early Detection of At-Risk Students Using Machine Learning Based on LMS Log Data.csv...\n",
      "  ‚úÖ 4 chunks extraits de cleanedup_Kondo et al. - 2017 - Early Detection of At-Risk Students Using Machine Learning Based on LMS Log Data.csv\n",
      "\n",
      "üìÑ Traitement de cleanedup_Kostopoulos - 2021 - Interpretable Models for Early Prediction of Certification in MOOCs A Case Study on a MOOC for Smar.csv...\n",
      "  ‚úÖ 11 chunks extraits de cleanedup_Kostopoulos - 2021 - Interpretable Models for Early Prediction of Certification in MOOCs A Case Study on a MOOC for Smar.csv\n",
      "\n",
      "üìÑ Traitement de cleanedup_Lincke - 2021 - The performance of some machine learning approaches and a rich context model in student answer predi.csv...\n",
      "  ‚úÖ 15 chunks extraits de cleanedup_Lincke - 2021 - The performance of some machine learning approaches and a rich context model in student answer predi.csv\n",
      "\n",
      "üìÑ Traitement de cleanedup_Lu et al. - 2018 - Applying learning analytics for the early prediction of students_ academic performance in blended le.csv...\n",
      "  ‚úÖ 13 chunks extraits de cleanedup_Lu et al. - 2018 - Applying learning analytics for the early prediction of students_ academic performance in blended le.csv\n",
      "\n",
      "üìÑ Traitement de cleanedup_Mengash - 2020 - Using Data Mining Techniques to Predict Student Performance to Support Decision Making in University.csv...\n",
      "  ‚úÖ 9 chunks extraits de cleanedup_Mengash - 2020 - Using Data Mining Techniques to Predict Student Performance to Support Decision Making in University.csv\n",
      "\n",
      "üìÑ Traitement de cleanedup_Migu√©is et al. - 2018 - Early segmentation of students according to their academic performance a predictive modelling appro.csv...\n",
      "  ‚úÖ 16 chunks extraits de cleanedup_Migu√©is et al. - 2018 - Early segmentation of students according to their academic performance a predictive modelling appro.csv\n",
      "\n",
      "üìÑ Traitement de cleanedup_Mitra and Goldstein - 2015 - Designing early detection and intervention techniques via predictive statistical models‚ÄîA case study.csv...\n",
      "  ‚úÖ 14 chunks extraits de cleanedup_Mitra and Goldstein - 2015 - Designing early detection and intervention techniques via predictive statistical models‚ÄîA case study.csv\n",
      "\n",
      "üìÑ Traitement de cleanedup_Mitra and Le - 2022 - The effect of cognitive and behavioral factors on student success in a bottleneck business statistic.csv...\n",
      "  ‚úÖ 28 chunks extraits de cleanedup_Mitra and Le - 2022 - The effect of cognitive and behavioral factors on student success in a bottleneck business statistic.csv\n",
      "\n",
      "üìÑ Traitement de cleanedup_Moreno-Marcos - 2019 - Generalizing Predictive Models of Admission Test Success Based on Online Interactions.csv...\n",
      "  ‚úÖ 17 chunks extraits de cleanedup_Moreno-Marcos - 2019 - Generalizing Predictive Models of Admission Test Success Based on Online Interactions.csv\n",
      "\n",
      "üìÑ Traitement de cleanedup_Moreno-Marcos - 2020 - Analysis of the Factors Influencing Learners‚Äô Performance Prediction With Learning Analytics.csv...\n",
      "  ‚úÖ 19 chunks extraits de cleanedup_Moreno-Marcos - 2020 - Analysis of the Factors Influencing Learners‚Äô Performance Prediction With Learning Analytics.csv\n",
      "\n",
      "üìÑ Traitement de cleanedup_Palacios et al. - 2021 - Knowledge discovery for higher education student retention based on data mining Machine learning al.csv...\n",
      "  ‚úÖ 21 chunks extraits de cleanedup_Palacios et al. - 2021 - Knowledge discovery for higher education student retention based on data mining Machine learning al.csv\n",
      "\n",
      "üìÑ Traitement de cleanedup_Pereira - 2021 - Explaining Individual and Collective Programming Students‚Äô Behavior by Interpreting a Black-Box Pred.csv...\n",
      "  ‚úÖ 23 chunks extraits de cleanedup_Pereira - 2021 - Explaining Individual and Collective Programming Students‚Äô Behavior by Interpreting a Black-Box Pred.csv\n",
      "\n",
      "üìÑ Traitement de cleanedup_Prabowo - 2021 - Aggregating Time Series and Tabular Data in Deep Learning Model for University Students‚Äô GPA Predict.csv...\n",
      "  ‚úÖ 8 chunks extraits de cleanedup_Prabowo - 2021 - Aggregating Time Series and Tabular Data in Deep Learning Model for University Students‚Äô GPA Predict.csv\n",
      "\n",
      "üìÑ Traitement de cleanedup_Predicting student drop-out rates using data mining techniques a case study.csv...\n",
      "  ‚úÖ 14 chunks extraits de cleanedup_Predicting student drop-out rates using data mining techniques a case study.csv\n",
      "\n",
      "üìÑ Traitement de cleanedup_Predictive models of academic success A case study with version control systems.csv...\n",
      "  ‚úÖ 7 chunks extraits de cleanedup_Predictive models of academic success A case study with version control systems.csv\n",
      "\n",
      "üìÑ Traitement de cleanedup_Qu - 2022 - Can We Predict Student Performance Based on Tabular and Textual Data.csv...\n",
      "  ‚úÖ 12 chunks extraits de cleanedup_Qu - 2022 - Can We Predict Student Performance Based on Tabular and Textual Data.csv\n",
      "\n",
      "üìÑ Traitement de cleanedup_Rafique - 2021 - Integrating Learning Analytics and Collaborative Learning for Improving Student_s Academic Performan.csv...\n",
      "  ‚úÖ 15 chunks extraits de cleanedup_Rafique - 2021 - Integrating Learning Analytics and Collaborative Learning for Improving Student_s Academic Performan.csv\n",
      "\n",
      "üìÑ Traitement de cleanedup_Rao and Kumar - 2021 - Students Performance Prediction in Online Courses Using Machine Learning Algorithms.csv...\n",
      "  ‚úÖ 6 chunks extraits de cleanedup_Rao and Kumar - 2021 - Students Performance Prediction in Online Courses Using Machine Learning Algorithms.csv\n",
      "\n",
      "üìÑ Traitement de cleanedup_Riestra-Gonz√°lez - 2021 - Massive LMS log data analysis for the early prediction of course-agnostic student performance.csv...\n",
      "  ‚úÖ 20 chunks extraits de cleanedup_Riestra-Gonz√°lez - 2021 - Massive LMS log data analysis for the early prediction of course-agnostic student performance.csv\n",
      "\n",
      "üìÑ Traitement de cleanedup_Rogers - 2014 - LAK - Modest analytics using the index method to identify students at risk of failure.csv...\n",
      "  ‚úÖ 4 chunks extraits de cleanedup_Rogers - 2014 - LAK - Modest analytics using the index method to identify students at risk of failure.csv\n",
      "\n",
      "üìÑ Traitement de cleanedup_Sales et al. - 2016 - Exploiting academic records for predicting student drop out A case study in Brazilian higher educat.csv...\n",
      "  ‚úÖ 16 chunks extraits de cleanedup_Sales et al. - 2016 - Exploiting academic records for predicting student drop out A case study in Brazilian higher educat.csv\n",
      "\n",
      "üìÑ Traitement de cleanedup_Sani et al. - 2020 - Drop-Out Prediction in Higher Education Among B40 Students.csv...\n",
      "  ‚úÖ 9 chunks extraits de cleanedup_Sani et al. - 2020 - Drop-Out Prediction in Higher Education Among B40 Students.csv\n",
      "\n",
      "üìÑ Traitement de cleanedup_Saqr - 2017 - How learning analytics can early predict under-achieving students in a blended medical education cou.csv...\n",
      "  ‚úÖ 11 chunks extraits de cleanedup_Saqr - 2017 - How learning analytics can early predict under-achieving students in a blended medical education cou.csv\n",
      "\n",
      "üìÑ Traitement de cleanedup_Stemming the tide Predicting STEM attrition using student transcript data.csv...\n",
      "  ‚úÖ 9 chunks extraits de cleanedup_Stemming the tide Predicting STEM attrition using student transcript data.csv\n",
      "\n",
      "üìÑ Traitement de cleanedup_Thammasiri et al. - 2014 - A critical assessment of imbalanced class distribution problem The case of predicting freshmen stud.csv...\n",
      "  ‚úÖ 10 chunks extraits de cleanedup_Thammasiri et al. - 2014 - A critical assessment of imbalanced class distribution problem The case of predicting freshmen stud.csv\n",
      "\n",
      "üìÑ Traitement de cleanedup_Van Goidsenhoven et al. - 2020 - Predicting student success in a blended learning environment.csv...\n",
      "  ‚úÖ 9 chunks extraits de cleanedup_Van Goidsenhoven et al. - 2020 - Predicting student success in a blended learning environment.csv\n",
      "\n",
      "üìÑ Traitement de cleanedup_Venant - 2017 - Using sequential pattern mining to explore learners_ behaviors and evaluate their correlation with p.csv...\n",
      "  ‚úÖ 14 chunks extraits de cleanedup_Venant - 2017 - Using sequential pattern mining to explore learners_ behaviors and evaluate their correlation with p.csv\n",
      "\n",
      "üìÑ Traitement de cleanedup_Vinker - 2022 - Mining Code Submissions to Elucidate Disengagement in a Computer Science MOOC.csv...\n",
      "  ‚úÖ 9 chunks extraits de cleanedup_Vinker - 2022 - Mining Code Submissions to Elucidate Disengagement in a Computer Science MOOC.csv\n",
      "\n",
      "üìÑ Traitement de cleanedup_Waddington - 2014 - LAK - Practice exams make perfect incorporating course resource use into an early warning system.csv...\n",
      "  ‚úÖ 5 chunks extraits de cleanedup_Waddington - 2014 - LAK - Practice exams make perfect incorporating course resource use into an early warning system.csv\n",
      "\n",
      "üìÑ Traitement de cleanedup_Wade - 2019 - Measuring, Manipulating, and Predicting Student Success A 10-Year Assessment of Carnegie R1 Doctora.csv...\n",
      "  ‚úÖ 21 chunks extraits de cleanedup_Wade - 2019 - Measuring, Manipulating, and Predicting Student Success A 10-Year Assessment of Carnegie R1 Doctora.csv\n",
      "\n",
      "üìÑ Traitement de cleanedup_Wan Yaacob et al. - 2020 - Predicting Student Drop-Out in Higher Institution Using Data Mining Techniques.csv...\n",
      "  ‚úÖ 14 chunks extraits de cleanedup_Wan Yaacob et al. - 2020 - Predicting Student Drop-Out in Higher Institution Using Data Mining Techniques.csv\n",
      "\n",
      "üìÑ Traitement de cleanedup_Wang - 2019 - On Prediction of Online Behaviors and Achievement Using Self-regulated Learning Awareness in Flipped.csv...\n",
      "  ‚úÖ 6 chunks extraits de cleanedup_Wang - 2019 - On Prediction of Online Behaviors and Achievement Using Self-regulated Learning Awareness in Flipped.csv\n",
      "\n",
      "üìÑ Traitement de cleanedup_Wu - 2020 - ICCSE - Student Achievement Analysis and Prediction Based on the Whole Learning Process.csv...\n",
      "  ‚úÖ 6 chunks extraits de cleanedup_Wu - 2020 - ICCSE - Student Achievement Analysis and Prediction Based on the Whole Learning Process.csv\n",
      "\n",
      "üìÑ Traitement de cleanedup_Yu and Jo - 2014 - Educational technology approach toward learning analytics relationship between student online behav.csv...\n",
      "  ‚úÖ 2 chunks extraits de cleanedup_Yu and Jo - 2014 - Educational technology approach toward learning analytics relationship between student online behav.csv\n",
      "\n",
      "üìÑ Traitement de extracted_docs.csv...\n",
      "  ‚ö†Ô∏è Colonne 'cleaned_page_content' manquante dans extracted_docs.csv\n",
      "\n",
      "üìÑ Traitement de extracted_docs_cleaned.csv...\n",
      "  ‚úÖ 40 chunks extraits de extracted_docs_cleaned.csv\n",
      "\n",
      "üìä Total: 1745 chunks √† indexer\n",
      "üÜï Cr√©ation d'une nouvelle base de donn√©es ChromaDB dans 'chroma_db'\n",
      "üì§ Cr√©ation de la base vectorielle avec embeddings Gemini...\n",
      "‚è≥ Cela peut prendre quelques minutes selon le nombre de documents...\n",
      "üíæ Sauvegarde et finalisation de la base de donn√©es...\n",
      "\n",
      "‚úÖ Base de donn√©es ChromaDB cr√©√©e avec succ√®s!\n",
      "üìä Statistiques finales:\n",
      "  ‚Ä¢ 134 fichiers CSV trait√©s\n",
      "  ‚Ä¢ 1745 chunks index√©s dans ChromaDB\n",
      "  ‚Ä¢ Base de donn√©es cr√©√©e dans 'chroma_db'\n",
      "  ‚Ä¢ Retriever configur√© pour k=5 r√©sultats\n",
      "\n",
      "üß™ Test de recherche avec la requ√™te: 'student performance'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\y455\\AppData\\Local\\Temp\\ipykernel_5168\\4151244424.py:105: LangChainDeprecationWarning: Since Chroma 0.4.x the manual persistence method is no longer supported as docs are automatically persisted.\n",
      "  vectorstore.persist()\n",
      "C:\\Users\\y455\\AppData\\Local\\Temp\\ipykernel_5168\\4151244424.py:126: LangChainDeprecationWarning: The method `BaseRetriever.get_relevant_documents` was deprecated in langchain-core 0.1.46 and will be removed in 1.0. Use :meth:`~invoke` instead.\n",
      "  results = retriever.get_relevant_documents(test_query)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üìã 5 r√©sultats trouv√©s:\n",
      "\n",
      "  R√©sultat 1:\n",
      "    Source: Rafique - 2021 - Integrating Learning Analytics and Collaborative Learning for Improving Student_s Academic Performan.pdf\n",
      "    CSV: cleanedup_Rafique - 2021 - Integrating Learning Analytics and Collaborative Learning for Improving Student_s Academic Performan.csv\n",
      "    Contenu: RQ2. WHICH ARE THE MOST IMPORTANT FEATURES\n",
      "THAT HELP ACCURATE PREDICTION OF STUDENT‚ÄôS\n",
      "PERFORMANCE?\n",
      "The second question determines important features to make\n",
      "accurate predictions of students‚Äô performan...\n",
      "\n",
      "  R√©sultat 2:\n",
      "    Source: Rafique - 2021 - Integrating Learning Analytics and Collaborative Learning for Improving Student_s Academic Performan.pdf\n",
      "    CSV: cleanedup_Rafique - 2021 - Integrating Learning Analytics and Collaborative Learning for Improving Student_s Academic Performan.csv\n",
      "    Contenu: RQ2. WHICH ARE THE MOST IMPORTANT FEATURES\n",
      "THAT HELP ACCURATE PREDICTION OF STUDENT‚ÄôS\n",
      "PERFORMANCE?\n",
      "The second question determines important features to make\n",
      "accurate predictions of students‚Äô performan...\n",
      "\n",
      "  R√©sultat 3:\n",
      "    Source: 2018 - Exploring the High Potential Factors that Affects Students‚Äô Academic Performance.pdf\n",
      "    CSV: cleanedup_2018 - Exploring the High Potential Factors that Affects Students‚Äô Academic Performance.csv\n",
      "    Contenu: an on -line discussion forum. With the proper format data, classification and classification via clustering techniques are applied and compared. Finally, the obtained classification models are describ...\n",
      "\n",
      "üéâ Nouvelle base vectorielle ChromaDB cr√©√©e!\n",
      "üí° Vous pouvez maintenant utiliser:\n",
      "   - 'vectorstore' pour acc√©der directement √† la base\n",
      "   - 'retriever' pour effectuer des recherches\n",
      "üìÅ Base sauvegard√©e dans: ./chroma_db\n"
     ]
    }
   ],
   "source": [
    "def load_cleaned_csvs_to_chroma(csv_dir: str = \"clean_up_test\",\n",
    "                               chroma_dir: str = \"chroma_db\",\n",
    "                               batch_size: int = 50):\n",
    "    \"\"\"\n",
    "    Charge tous les fichiers CSV nettoy√©s du dossier csv_dir vers ChromaDB\n",
    "\n",
    "    Args:\n",
    "        csv_dir: R√©pertoire contenant les fichiers CSV nettoy√©s\n",
    "        chroma_dir: R√©pertoire de la base de donn√©es ChromaDB\n",
    "        batch_size: Nombre de documents √† traiter par batch\n",
    "    \"\"\"\n",
    "\n",
    "    print(\"üîÑ Initialisation du chargement des CSV vers ChromaDB...\")\n",
    "\n",
    "    # Configuration des embeddings\n",
    "    gemini_embeddings = GoogleGenerativeAIEmbeddings(model=\"models/embedding-001\")\n",
    "\n",
    "    # V√©rifier si le dossier CSV existe\n",
    "    csv_path = Path(csv_dir)\n",
    "    if not csv_path.exists():\n",
    "        raise FileNotFoundError(f\"Le dossier '{csv_dir}' n'existe pas.\")\n",
    "\n",
    "    # Trouver tous les fichiers CSV\n",
    "    csv_files = list(csv_path.glob(\"*.csv\"))\n",
    "\n",
    "    if not csv_files:\n",
    "        print(f\"‚ùå Aucun fichier CSV trouv√© dans '{csv_dir}'\")\n",
    "        return None\n",
    "\n",
    "    print(f\"üìÅ {len(csv_files)} fichiers CSV trouv√©s\")\n",
    "\n",
    "    # Collecter tous les documents\n",
    "    all_documents = []\n",
    "    total_chunks = 0\n",
    "\n",
    "    for csv_file in csv_files:\n",
    "        print(f\"\\nüìÑ Traitement de {csv_file.name}...\")\n",
    "\n",
    "        try:\n",
    "            # Charger le CSV\n",
    "            df = pd.read_csv(csv_file)\n",
    "\n",
    "            # V√©rifier que les colonnes n√©cessaires existent\n",
    "            if 'cleaned_page_content' not in df.columns:\n",
    "                print(f\"  ‚ö†Ô∏è Colonne 'cleaned_page_content' manquante dans {csv_file.name}\")\n",
    "                continue\n",
    "\n",
    "            if 'source' not in df.columns:\n",
    "                print(f\"  ‚ö†Ô∏è Colonne 'source' manquante dans {csv_file.name}\")\n",
    "                continue\n",
    "\n",
    "            # Cr√©er les documents pour chaque ligne\n",
    "            file_documents = []\n",
    "            for idx, row in df.iterrows():\n",
    "                cleaned_text = row['cleaned_page_content']\n",
    "\n",
    "                # Ignorer les chunks vides ou tr√®s courts\n",
    "                if pd.isna(cleaned_text) or len(str(cleaned_text).strip()) < 50:\n",
    "                    continue\n",
    "\n",
    "                # Cr√©er le document avec m√©tadonn√©es\n",
    "                doc = Document(\n",
    "                    page_content=str(cleaned_text).strip(),\n",
    "                    metadata={\n",
    "                        'source': row['source'],\n",
    "                        'csv_file': csv_file.name,\n",
    "                        'page_index': idx,\n",
    "                        'chunk_id': f\"{csv_file.stem}_{idx}\"\n",
    "                    }\n",
    "                )\n",
    "                file_documents.append(doc)\n",
    "\n",
    "            all_documents.extend(file_documents)\n",
    "            total_chunks += len(file_documents)\n",
    "            print(f\"  ‚úÖ {len(file_documents)} chunks extraits de {csv_file.name}\")\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"  ‚ùå Erreur lors du traitement de {csv_file.name}: {e}\")\n",
    "            continue\n",
    "\n",
    "    if not all_documents:\n",
    "        print(\"‚ùå Aucun document valide trouv√© dans les fichiers CSV\")\n",
    "        return None\n",
    "\n",
    "    print(f\"\\nüìä Total: {total_chunks} chunks √† indexer\")\n",
    "\n",
    "    # Cr√©er le dossier ChromaDB s'il n'existe pas\n",
    "    chroma_path = Path(chroma_dir)\n",
    "    chroma_path.mkdir(exist_ok=True)\n",
    "\n",
    "    print(f\"üÜï Cr√©ation d'une nouvelle base de donn√©es ChromaDB dans '{chroma_dir}'\")\n",
    "\n",
    "    # Cr√©er une nouvelle base avec tous les documents\n",
    "    print(\"üì§ Cr√©ation de la base vectorielle avec embeddings Gemini...\")\n",
    "    print(\"‚è≥ Cela peut prendre quelques minutes selon le nombre de documents...\")\n",
    "\n",
    "    vectorstore = Chroma.from_documents(\n",
    "        documents=all_documents,\n",
    "        embedding=gemini_embeddings,\n",
    "        persist_directory=chroma_dir\n",
    "    )\n",
    "\n",
    "    # Persister et finaliser la base de donn√©es\n",
    "    print(\"üíæ Sauvegarde et finalisation de la base de donn√©es...\")\n",
    "    vectorstore.persist()\n",
    "\n",
    "    # Cr√©er le retriever pour les recherches\n",
    "    retriever = vectorstore.as_retriever(search_kwargs={\"k\": 5})\n",
    "\n",
    "    print(f\"\\n‚úÖ Base de donn√©es ChromaDB cr√©√©e avec succ√®s!\")\n",
    "    print(f\"üìä Statistiques finales:\")\n",
    "    print(f\"  ‚Ä¢ {len(csv_files)} fichiers CSV trait√©s\")\n",
    "    print(f\"  ‚Ä¢ {total_chunks} chunks index√©s dans ChromaDB\")\n",
    "    print(f\"  ‚Ä¢ Base de donn√©es cr√©√©e dans '{chroma_dir}'\")\n",
    "    print(f\"  ‚Ä¢ Retriever configur√© pour k=5 r√©sultats\")\n",
    "\n",
    "    return vectorstore, retriever\n",
    "\n",
    "def test_vectorstore(retriever, test_query: str = \"student performance\"):\n",
    "    \"\"\"\n",
    "    Test simple de la base vectorielle\n",
    "    \"\"\"\n",
    "    print(f\"\\nüß™ Test de recherche avec la requ√™te: '{test_query}'\")\n",
    "\n",
    "    try:\n",
    "        results = retriever.get_relevant_documents(test_query)\n",
    "        print(f\"üìã {len(results)} r√©sultats trouv√©s:\")\n",
    "\n",
    "        for i, doc in enumerate(results[:3], 1):  # Afficher seulement les 3 premiers\n",
    "            print(f\"\\n  R√©sultat {i}:\")\n",
    "            print(f\"    Source: {doc.metadata.get('source', 'N/A')}\")\n",
    "            print(f\"    CSV: {doc.metadata.get('csv_file', 'N/A')}\")\n",
    "            print(f\"    Contenu: {doc.page_content[:200]}...\")\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"‚ùå Erreur lors du test: {e}\")\n",
    "\n",
    "def main():\n",
    "    \"\"\"\n",
    "    Fonction principale\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # Charger les CSV vers ChromaDB\n",
    "        vectorstore, retriever = load_cleaned_csvs_to_chroma()\n",
    "\n",
    "        if vectorstore and retriever:\n",
    "            # Test optionnel\n",
    "            test_vectorstore(retriever)\n",
    "\n",
    "            # La base est maintenant pr√™te √† √™tre utilis√©e\n",
    "            print(f\"\\nüéâ Nouvelle base vectorielle ChromaDB cr√©√©e!\")\n",
    "            print(f\"üí° Vous pouvez maintenant utiliser:\")\n",
    "            print(f\"   - 'vectorstore' pour acc√©der directement √† la base\")\n",
    "            print(f\"   - 'retriever' pour effectuer des recherches\")\n",
    "            print(f\"üìÅ Base sauvegard√©e dans: ./chroma_db\")\n",
    "\n",
    "            return vectorstore, retriever\n",
    "        else:\n",
    "            print(\"‚ùå √âchec du chargement\")\n",
    "            return None, None\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"‚ùå Erreur critique: {e}\")\n",
    "        return None, None\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    vectorstore, retriever = main()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b723d8c0",
   "metadata": {},
   "source": [
    "# Testing RAG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "1467dac1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üìä Statistiques de la base existante:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\y455\\AppData\\Local\\Temp\\ipykernel_5168\\4113450759.py:213: LangChainDeprecationWarning: The class `Chroma` was deprecated in LangChain 0.2.9 and will be removed in 1.0. An updated version of the class exists in the :class:`~langchain-chroma package and should be used instead. To use it run `pip install -U :class:`~langchain-chroma` and import as `from :class:`~langchain_chroma import Chroma``.\n",
      "  vectorstore = Chroma(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ‚Ä¢ 3588 documents en base\n",
      "  ‚Ä¢ 136 fichiers CSV uniques\n",
      "  ‚Ä¢ 133 sources uniques\n",
      "üîÑ Initialisation du chargement des CSV vers ChromaDB...\n",
      "üîç Base ChromaDB existante d√©tect√©e, chargement...\n",
      "üìä 1802 chunks existants trouv√©s dans la base\n",
      "üìÅ 134 fichiers CSV trouv√©s\n",
      "\n",
      "üìÑ Traitement de cleanedup_2012 - Do Situational Academic Emotions Predict Academic Outcomes in a Lecture Course.csv...\n",
      "  ‚úÖ 0 nouveaux chunks extraits de cleanedup_2012 - Do Situational Academic Emotions Predict Academic Outcomes in a Lecture Course.csv\n",
      "  ‚è≠Ô∏è 9 chunks ignor√©s (d√©j√† existants)\n",
      "\n",
      "üìÑ Traitement de cleanedup_2012 - Monitoring student progress using virtual appliances A case study.csv...\n",
      "  ‚úÖ 0 nouveaux chunks extraits de cleanedup_2012 - Monitoring student progress using virtual appliances A case study.csv\n",
      "  ‚è≠Ô∏è 10 chunks ignor√©s (d√©j√† existants)\n",
      "\n",
      "üìÑ Traitement de cleanedup_2012 - Predicting Student Outcome Measures Using the ASCA National Model Program Audit.csv...\n",
      "  ‚úÖ 0 nouveaux chunks extraits de cleanedup_2012 - Predicting Student Outcome Measures Using the ASCA National Model Program Audit.csv\n",
      "  ‚è≠Ô∏è 8 chunks ignor√©s (d√©j√† existants)\n",
      "\n",
      "üìÑ Traitement de cleanedup_2012 - The effects of achievement goals and self-regulated learning behaviors on reading comprehension in t.csv...\n",
      "  ‚úÖ 0 nouveaux chunks extraits de cleanedup_2012 - The effects of achievement goals and self-regulated learning behaviors on reading comprehension in t.csv\n",
      "  ‚è≠Ô∏è 14 chunks ignor√©s (d√©j√† existants)\n",
      "\n",
      "üìÑ Traitement de cleanedup_2013 - Can Online Discussion Participation Predict Group Project Performance Investigating the Roles of Li.csv...\n",
      "  ‚úÖ 0 nouveaux chunks extraits de cleanedup_2013 - Can Online Discussion Participation Predict Group Project Performance Investigating the Roles of Li.csv\n",
      "  ‚è≠Ô∏è 23 chunks ignor√©s (d√©j√† existants)\n",
      "\n",
      "üìÑ Traitement de cleanedup_2013 - Correlation between Course Tracking Variables and Academic Performance in Blended Online Courses.csv...\n",
      "  ‚úÖ 0 nouveaux chunks extraits de cleanedup_2013 - Correlation between Course Tracking Variables and Academic Performance in Blended Online Courses.csv\n",
      "  ‚è≠Ô∏è 5 chunks ignor√©s (d√©j√† existants)\n",
      "\n",
      "üìÑ Traitement de cleanedup_2013 - Predicting student academic performance in an engineering dynamics course A comparison of four type.csv...\n",
      "  ‚úÖ 0 nouveaux chunks extraits de cleanedup_2013 - Predicting student academic performance in an engineering dynamics course A comparison of four type.csv\n",
      "  ‚è≠Ô∏è 13 chunks ignor√©s (d√©j√† existants)\n",
      "\n",
      "üìÑ Traitement de cleanedup_2013 - Significant Predictors of Learning from Student Interactions with Online Learning Objects.csv...\n",
      "  ‚úÖ 0 nouveaux chunks extraits de cleanedup_2013 - Significant Predictors of Learning from Student Interactions with Online Learning Objects.csv\n",
      "  ‚è≠Ô∏è 6 chunks ignor√©s (d√©j√† existants)\n",
      "\n",
      "üìÑ Traitement de cleanedup_2013 - Using artificial neural networks to predict first-year traditional students second year retention ra.csv...\n",
      "  ‚úÖ 0 nouveaux chunks extraits de cleanedup_2013 - Using artificial neural networks to predict first-year traditional students second year retention ra.csv\n",
      "  ‚è≠Ô∏è 5 chunks ignor√©s (d√©j√† existants)\n",
      "\n",
      "üìÑ Traitement de cleanedup_2014 - Can we predict success from log data in VLEs Classification of interactions for learning analytics.csv...\n",
      "  ‚úÖ 0 nouveaux chunks extraits de cleanedup_2014 - Can we predict success from log data in VLEs Classification of interactions for learning analytics.csv\n",
      "  ‚è≠Ô∏è 9 chunks ignor√©s (d√©j√† existants)\n",
      "\n",
      "üìÑ Traitement de cleanedup_2014 - Student ratings of teaching quality in primary school Dimensions and prediction of student outcomes.csv...\n",
      "  ‚úÖ 0 nouveaux chunks extraits de cleanedup_2014 - Student ratings of teaching quality in primary school Dimensions and prediction of student outcomes.csv\n",
      "  ‚è≠Ô∏è 8 chunks ignor√©s (d√©j√† existants)\n",
      "\n",
      "üìÑ Traitement de cleanedup_2016 - Predicting and Analyzing Students‚Äô Performance An Educational Data Mining Approach.csv...\n",
      "  ‚úÖ 0 nouveaux chunks extraits de cleanedup_2016 - Predicting and Analyzing Students‚Äô Performance An Educational Data Mining Approach.csv\n",
      "  ‚è≠Ô∏è 6 chunks ignor√©s (d√©j√† existants)\n",
      "\n",
      "üìÑ Traitement de cleanedup_2016 - The impact of learning design on student behaviour, satisfaction and performance A cross-institutio.csv...\n",
      "  ‚úÖ 0 nouveaux chunks extraits de cleanedup_2016 - The impact of learning design on student behaviour, satisfaction and performance A cross-institutio.csv\n",
      "  ‚è≠Ô∏è 9 chunks ignor√©s (d√©j√† existants)\n",
      "\n",
      "üìÑ Traitement de cleanedup_2017 - A Machine Learning Approach for Tracking and Predicting Student Performance in Degree Programs.csv...\n",
      "  ‚úÖ 0 nouveaux chunks extraits de cleanedup_2017 - A Machine Learning Approach for Tracking and Predicting Student Performance in Degree Programs.csv\n",
      "  ‚è≠Ô∏è 12 chunks ignor√©s (d√©j√† existants)\n",
      "\n",
      "üìÑ Traitement de cleanedup_2017 - Combining University Student Self-Regulated Learning Indicators and Engagement with Online Learning.csv...\n",
      "  ‚úÖ 0 nouveaux chunks extraits de cleanedup_2017 - Combining University Student Self-Regulated Learning Indicators and Engagement with Online Learning.csv\n",
      "  ‚è≠Ô∏è 10 chunks ignor√©s (d√©j√† existants)\n",
      "\n",
      "üìÑ Traitement de cleanedup_2017 - Individual Differences Related to College Students‚Äô Course Performance in Calculus II.csv...\n",
      "  ‚úÖ 0 nouveaux chunks extraits de cleanedup_2017 - Individual Differences Related to College Students‚Äô Course Performance in Calculus II.csv\n",
      "  ‚è≠Ô∏è 23 chunks ignor√©s (d√©j√† existants)\n",
      "\n",
      "üìÑ Traitement de cleanedup_2017 - MOOC Dropout Prediction.csv...\n",
      "  ‚úÖ 0 nouveaux chunks extraits de cleanedup_2017 - MOOC Dropout Prediction.csv\n",
      "  ‚è≠Ô∏è 8 chunks ignor√©s (d√©j√† existants)\n",
      "\n",
      "üìÑ Traitement de cleanedup_2017 - Predicting Kindergarteners_ Achievement and Motivation From Observational Measures of Teaching Effec.csv...\n",
      "  ‚úÖ 0 nouveaux chunks extraits de cleanedup_2017 - Predicting Kindergarteners_ Achievement and Motivation From Observational Measures of Teaching Effec.csv\n",
      "  ‚è≠Ô∏è 18 chunks ignor√©s (d√©j√† existants)\n",
      "\n",
      "üìÑ Traitement de cleanedup_2017 - Predicting Student Performance from LMS Data A Comparison of 17 Blended Courses Using Moodle LMS.csv...\n",
      "  ‚úÖ 0 nouveaux chunks extraits de cleanedup_2017 - Predicting Student Performance from LMS Data A Comparison of 17 Blended Courses Using Moodle LMS.csv\n",
      "  ‚è≠Ô∏è 13 chunks ignor√©s (d√©j√† existants)\n",
      "\n",
      "üìÑ Traitement de cleanedup_2017 - Using Learning Analytics to Predict Students‚Äô Performance in Moodle Learning Management System A Ca.csv...\n",
      "  ‚úÖ 0 nouveaux chunks extraits de cleanedup_2017 - Using Learning Analytics to Predict Students‚Äô Performance in Moodle Learning Management System A Ca.csv\n",
      "  ‚è≠Ô∏è 13 chunks ignor√©s (d√©j√† existants)\n",
      "\n",
      "üìÑ Traitement de cleanedup_2017 - Widget, widget as you lead, I am performing well indeed!.csv...\n",
      "  ‚úÖ 0 nouveaux chunks extraits de cleanedup_2017 - Widget, widget as you lead, I am performing well indeed!.csv\n",
      "  ‚è≠Ô∏è 10 chunks ignor√©s (d√©j√† existants)\n",
      "\n",
      "üìÑ Traitement de cleanedup_2017 - Widget, Widget on the Wall, Am I Performing Well at All.csv...\n",
      "  ‚úÖ 0 nouveaux chunks extraits de cleanedup_2017 - Widget, Widget on the Wall, Am I Performing Well at All.csv\n",
      "  ‚è≠Ô∏è 11 chunks ignor√©s (d√©j√† existants)\n",
      "\n",
      "üìÑ Traitement de cleanedup_2018 - Correlates of students‚Äô internalization and defiance of classroom rules A self‚Äêdetermination theory.csv...\n",
      "  ‚úÖ 0 nouveaux chunks extraits de cleanedup_2018 - Correlates of students‚Äô internalization and defiance of classroom rules A self‚Äêdetermination theory.csv\n",
      "  ‚è≠Ô∏è 17 chunks ignor√©s (d√©j√† existants)\n",
      "\n",
      "üìÑ Traitement de cleanedup_2018 - Data mining approach to predicting the performance of first year student in a university using the a.csv...\n",
      "  ‚úÖ 0 nouveaux chunks extraits de cleanedup_2018 - Data mining approach to predicting the performance of first year student in a university using the a.csv\n",
      "  ‚è≠Ô∏è 17 chunks ignor√©s (d√©j√† existants)\n",
      "\n",
      "üìÑ Traitement de cleanedup_2018 - Does Attendance in Private Schools Predict Student Outcomes at Age 15 Evidence From a Longitudinal.csv...\n",
      "  ‚úÖ 0 nouveaux chunks extraits de cleanedup_2018 - Does Attendance in Private Schools Predict Student Outcomes at Age 15 Evidence From a Longitudinal.csv\n",
      "  ‚è≠Ô∏è 16 chunks ignor√©s (d√©j√† existants)\n",
      "\n",
      "üìÑ Traitement de cleanedup_2018 - Emotions, Motivation, Cognitive‚ÄìMetacognitive Strategies, and Behavior as Predictors of Learning Per.csv...\n",
      "  ‚úÖ 0 nouveaux chunks extraits de cleanedup_2018 - Emotions, Motivation, Cognitive‚ÄìMetacognitive Strategies, and Behavior as Predictors of Learning Per.csv\n",
      "  ‚è≠Ô∏è 19 chunks ignor√©s (d√©j√† existants)\n",
      "\n",
      "üìÑ Traitement de cleanedup_2018 - Exploring the High Potential Factors that Affects Students‚Äô Academic Performance.csv...\n",
      "  ‚úÖ 0 nouveaux chunks extraits de cleanedup_2018 - Exploring the High Potential Factors that Affects Students‚Äô Academic Performance.csv\n",
      "  ‚è≠Ô∏è 9 chunks ignor√©s (d√©j√† existants)\n",
      "\n",
      "üìÑ Traitement de cleanedup_2018 - Factors influencing peer learning and performance in MOOC asynchronous online discussion forum.csv...\n",
      "  ‚úÖ 0 nouveaux chunks extraits de cleanedup_2018 - Factors influencing peer learning and performance in MOOC asynchronous online discussion forum.csv\n",
      "  ‚è≠Ô∏è 13 chunks ignor√©s (d√©j√† existants)\n",
      "\n",
      "üìÑ Traitement de cleanedup_2018 - Leveraging Non-cognitive Student Self-reports to Predict Learning Outcomes.csv...\n",
      "  ‚úÖ 0 nouveaux chunks extraits de cleanedup_2018 - Leveraging Non-cognitive Student Self-reports to Predict Learning Outcomes.csv\n",
      "  ‚è≠Ô∏è 4 chunks ignor√©s (d√©j√† existants)\n",
      "\n",
      "üìÑ Traitement de cleanedup_2018 - Measuring Behaviors and Identifying Indicators of Self-Regulation in Computer-Assisted Language Lear.csv...\n",
      "  ‚úÖ 0 nouveaux chunks extraits de cleanedup_2018 - Measuring Behaviors and Identifying Indicators of Self-Regulation in Computer-Assisted Language Lear.csv\n",
      "  ‚è≠Ô∏è 12 chunks ignor√©s (d√©j√† existants)\n",
      "\n",
      "üìÑ Traitement de cleanedup_2018 - Predicting student performance in a blended MOOC.csv...\n",
      "  ‚úÖ 0 nouveaux chunks extraits de cleanedup_2018 - Predicting student performance in a blended MOOC.csv\n",
      "  ‚è≠Ô∏è 14 chunks ignor√©s (d√©j√† existants)\n",
      "\n",
      "üìÑ Traitement de cleanedup_2018 - Social Support and Classroom Management Are Related to Secondary Students‚Äô General School Adjustment.csv...\n",
      "  ‚úÖ 0 nouveaux chunks extraits de cleanedup_2018 - Social Support and Classroom Management Are Related to Secondary Students‚Äô General School Adjustment.csv\n",
      "  ‚è≠Ô∏è 15 chunks ignor√©s (d√©j√† existants)\n",
      "\n",
      "üìÑ Traitement de cleanedup_2018 - Teacher-student relationships The positives and negatives of assessing both perspectives.csv...\n",
      "  ‚úÖ 0 nouveaux chunks extraits de cleanedup_2018 - Teacher-student relationships The positives and negatives of assessing both perspectives.csv\n",
      "  ‚è≠Ô∏è 14 chunks ignor√©s (d√©j√† existants)\n",
      "\n",
      "üìÑ Traitement de cleanedup_2018 - The different relationships between engagement and outcomes across participant subgroups in Massive.csv...\n",
      "  ‚úÖ 0 nouveaux chunks extraits de cleanedup_2018 - The different relationships between engagement and outcomes across participant subgroups in Massive.csv\n",
      "  ‚è≠Ô∏è 24 chunks ignor√©s (d√©j√† existants)\n",
      "\n",
      "üìÑ Traitement de cleanedup_2018 - Using social network analysis to understand online Problem-Based Learning and predict performance.csv...\n",
      "  ‚úÖ 0 nouveaux chunks extraits de cleanedup_2018 - Using social network analysis to understand online Problem-Based Learning and predict performance.csv\n",
      "  ‚è≠Ô∏è 19 chunks ignor√©s (d√©j√† existants)\n",
      "\n",
      "üìÑ Traitement de cleanedup_2019 - A National Study of the Differential Impact of Novice Teacher Certification on Teacher Traits and Ra.csv...\n",
      "  ‚úÖ 0 nouveaux chunks extraits de cleanedup_2019 - A National Study of the Differential Impact of Novice Teacher Certification on Teacher Traits and Ra.csv\n",
      "  ‚è≠Ô∏è 13 chunks ignor√©s (d√©j√† existants)\n",
      "\n",
      "üìÑ Traitement de cleanedup_2019 - Detecting students-at-risk in computer programming classes with learning analytics from students‚Äô di.csv...\n",
      "  ‚úÖ 0 nouveaux chunks extraits de cleanedup_2019 - Detecting students-at-risk in computer programming classes with learning analytics from students‚Äô di.csv\n",
      "  ‚è≠Ô∏è 29 chunks ignor√©s (d√©j√† existants)\n",
      "\n",
      "üìÑ Traitement de cleanedup_2019 - Does Time Play a Role Prediction of Learning Performance with Time-use Habits in Online Assignments.csv...\n",
      "  ‚úÖ 0 nouveaux chunks extraits de cleanedup_2019 - Does Time Play a Role Prediction of Learning Performance with Time-use Habits in Online Assignments.csv\n",
      "  ‚è≠Ô∏è 4 chunks ignor√©s (d√©j√† existants)\n",
      "\n",
      "üìÑ Traitement de cleanedup_2019 - Effectiveness of online presence in a blended higher learning environment in the Pacific.csv...\n",
      "  ‚úÖ 0 nouveaux chunks extraits de cleanedup_2019 - Effectiveness of online presence in a blended higher learning environment in the Pacific.csv\n",
      "  ‚è≠Ô∏è 18 chunks ignor√©s (d√©j√† existants)\n",
      "\n",
      "üìÑ Traitement de cleanedup_2019 - Factors investigation of learning behaviors affecting learning performance and self-regulated learni.csv...\n",
      "  ‚úÖ 0 nouveaux chunks extraits de cleanedup_2019 - Factors investigation of learning behaviors affecting learning performance and self-regulated learni.csv\n",
      "  ‚è≠Ô∏è 6 chunks ignor√©s (d√©j√† existants)\n",
      "\n",
      "üìÑ Traitement de cleanedup_2019 - Feature Extraction for Next-Term Prediction of Poor Student Performance.csv...\n",
      "  ‚úÖ 0 nouveaux chunks extraits de cleanedup_2019 - Feature Extraction for Next-Term Prediction of Poor Student Performance.csv\n",
      "  ‚è≠Ô∏è 12 chunks ignor√©s (d√©j√† existants)\n",
      "\n",
      "üìÑ Traitement de cleanedup_2019 - Implementing AutoML in Educational Data Mining for Prediction Tasks.csv...\n",
      "  ‚úÖ 0 nouveaux chunks extraits de cleanedup_2019 - Implementing AutoML in Educational Data Mining for Prediction Tasks.csv\n",
      "  ‚è≠Ô∏è 24 chunks ignor√©s (d√©j√† existants)\n",
      "\n",
      "üìÑ Traitement de cleanedup_2019 - Modelling, prediction and classification of student academic performance using artificial neural net.csv...\n",
      "  ‚úÖ 0 nouveaux chunks extraits de cleanedup_2019 - Modelling, prediction and classification of student academic performance using artificial neural net.csv\n",
      "  ‚è≠Ô∏è 10 chunks ignor√©s (d√©j√† existants)\n",
      "\n",
      "üìÑ Traitement de cleanedup_2019 - Predictive power of regularity of pre-class activities in a flipped classroom.csv...\n",
      "  ‚úÖ 0 nouveaux chunks extraits de cleanedup_2019 - Predictive power of regularity of pre-class activities in a flipped classroom.csv\n",
      "  ‚è≠Ô∏è 13 chunks ignor√©s (d√©j√† existants)\n",
      "\n",
      "üìÑ Traitement de cleanedup_2019 - Predictors of Academic Achievement in Blended Learning the Case of Data Science Minor.csv...\n",
      "  ‚úÖ 0 nouveaux chunks extraits de cleanedup_2019 - Predictors of Academic Achievement in Blended Learning the Case of Data Science Minor.csv\n",
      "  ‚è≠Ô∏è 10 chunks ignor√©s (d√©j√† existants)\n",
      "\n",
      "üìÑ Traitement de cleanedup_2019 - Students_ engagement characteristics predict success and completion of online courses.csv...\n",
      "  ‚úÖ 0 nouveaux chunks extraits de cleanedup_2019 - Students_ engagement characteristics predict success and completion of online courses.csv\n",
      "  ‚è≠Ô∏è 10 chunks ignor√©s (d√©j√† existants)\n",
      "\n",
      "üìÑ Traitement de cleanedup_2019 - Using machine learning to predict physics course outcomes.csv...\n",
      "  ‚úÖ 0 nouveaux chunks extraits de cleanedup_2019 - Using machine learning to predict physics course outcomes.csv\n",
      "  ‚è≠Ô∏è 18 chunks ignor√©s (d√©j√† existants)\n",
      "\n",
      "üìÑ Traitement de cleanedup_2020 - Measures of engagement in the first three weeks of higher education predict subsequent activity and.csv...\n",
      "  ‚úÖ 0 nouveaux chunks extraits de cleanedup_2020 - Measures of engagement in the first three weeks of higher education predict subsequent activity and.csv\n",
      "  ‚è≠Ô∏è 14 chunks ignor√©s (d√©j√† existants)\n",
      "\n",
      "üìÑ Traitement de cleanedup_2020 - Student Performance Prediction Based on Blended Learning.csv...\n",
      "  ‚úÖ 0 nouveaux chunks extraits de cleanedup_2020 - Student Performance Prediction Based on Blended Learning.csv\n",
      "  ‚è≠Ô∏è 7 chunks ignor√©s (d√©j√† existants)\n",
      "\n",
      "üìÑ Traitement de cleanedup_2020 - Using clickstream data to measure, understand, and support self-regulated learning in online courses.csv...\n",
      "  ‚úÖ 0 nouveaux chunks extraits de cleanedup_2020 - Using clickstream data to measure, understand, and support self-regulated learning in online courses.csv\n",
      "  ‚è≠Ô∏è 13 chunks ignor√©s (d√©j√† existants)\n",
      "\n",
      "üìÑ Traitement de cleanedup_2020 - Using Interactive E-Book User Log Variables to Track Reading Processes and Predict Digital Learning.csv...\n",
      "  ‚úÖ 0 nouveaux chunks extraits de cleanedup_2020 - Using Interactive E-Book User Log Variables to Track Reading Processes and Predict Digital Learning.csv\n",
      "  ‚è≠Ô∏è 10 chunks ignor√©s (d√©j√† existants)\n",
      "\n",
      "üìÑ Traitement de cleanedup_2021 - Academic Performance Modelling with Machine Learning Based on Cognitive and Non-Cognitive Features.csv...\n",
      "  ‚úÖ 0 nouveaux chunks extraits de cleanedup_2021 - Academic Performance Modelling with Machine Learning Based on Cognitive and Non-Cognitive Features.csv\n",
      "  ‚è≠Ô∏è 10 chunks ignor√©s (d√©j√† existants)\n",
      "\n",
      "üìÑ Traitement de cleanedup_2021 - ALEKS constructs as predictors of high school mathematics achievement for struggling students.csv...\n",
      "  ‚úÖ 0 nouveaux chunks extraits de cleanedup_2021 - ALEKS constructs as predictors of high school mathematics achievement for struggling students.csv\n",
      "  ‚è≠Ô∏è 12 chunks ignor√©s (d√©j√† existants)\n",
      "\n",
      "üìÑ Traitement de cleanedup_2021 - Early prediction of undergraduate Student_s academic performance in completely online learning A fi.csv...\n",
      "  ‚úÖ 0 nouveaux chunks extraits de cleanedup_2021 - Early prediction of undergraduate Student_s academic performance in completely online learning A fi.csv\n",
      "  ‚è≠Ô∏è 10 chunks ignor√©s (d√©j√† existants)\n",
      "\n",
      "üìÑ Traitement de cleanedup_2021 - Feature Correlation with Student Education Performance.csv...\n",
      "  ‚úÖ 0 nouveaux chunks extraits de cleanedup_2021 - Feature Correlation with Student Education Performance.csv\n",
      "  ‚è≠Ô∏è 13 chunks ignor√©s (d√©j√† existants)\n",
      "\n",
      "üìÑ Traitement de cleanedup_2021 - Investigating prompts for supporting students_ self-regulation ‚Äì A remaining challenge for learning.csv...\n",
      "  ‚úÖ 0 nouveaux chunks extraits de cleanedup_2021 - Investigating prompts for supporting students_ self-regulation ‚Äì A remaining challenge for learning.csv\n",
      "  ‚è≠Ô∏è 11 chunks ignor√©s (d√©j√† existants)\n",
      "\n",
      "üìÑ Traitement de cleanedup_2021 - Predicting Factors that Influence Students‚Äô Learning Outcomes Using Learning Analytics in Online Lea.csv...\n",
      "  ‚úÖ 0 nouveaux chunks extraits de cleanedup_2021 - Predicting Factors that Influence Students‚Äô Learning Outcomes Using Learning Analytics in Online Lea.csv\n",
      "  ‚è≠Ô∏è 12 chunks ignor√©s (d√©j√† existants)\n",
      "\n",
      "üìÑ Traitement de cleanedup_2021 - Students matter the most in learning analytics The effects of internal and instructional conditions.csv...\n",
      "  ‚úÖ 0 nouveaux chunks extraits de cleanedup_2021 - Students matter the most in learning analytics The effects of internal and instructional conditions.csv\n",
      "  ‚è≠Ô∏è 12 chunks ignor√©s (d√©j√† existants)\n",
      "\n",
      "üìÑ Traitement de cleanedup_2021 - The advantage of distributed practice in a blended learning setting.csv...\n",
      "  ‚úÖ 0 nouveaux chunks extraits de cleanedup_2021 - The advantage of distributed practice in a blended learning setting.csv\n",
      "  ‚è≠Ô∏è 16 chunks ignor√©s (d√©j√† existants)\n",
      "\n",
      "üìÑ Traitement de cleanedup_2021 - Towards Modeling Student Engagement with Interactive Computing Textbooks.csv...\n",
      "  ‚úÖ 0 nouveaux chunks extraits de cleanedup_2021 - Towards Modeling Student Engagement with Interactive Computing Textbooks.csv\n",
      "  ‚è≠Ô∏è 6 chunks ignor√©s (d√©j√† existants)\n",
      "\n",
      "üìÑ Traitement de cleanedup_2022 - Academic self-efficacy, self-esteem, and grit in higher online education Consistency of interests p.csv...\n",
      "  ‚úÖ 0 nouveaux chunks extraits de cleanedup_2022 - Academic self-efficacy, self-esteem, and grit in higher online education Consistency of interests p.csv\n",
      "  ‚è≠Ô∏è 24 chunks ignor√©s (d√©j√† existants)\n",
      "\n",
      "üìÑ Traitement de cleanedup_2022 - Is there order in the mess A single paper meta-analysis approach to identification of predictors of.csv...\n",
      "  ‚úÖ 0 nouveaux chunks extraits de cleanedup_2022 - Is there order in the mess A single paper meta-analysis approach to identification of predictors of.csv\n",
      "  ‚è≠Ô∏è 21 chunks ignor√©s (d√©j√† existants)\n",
      "\n",
      "üìÑ Traitement de cleanedup_2022 - On the Use of eXplainable Artificial Intelligence to Evaluate School Dropout.csv...\n",
      "  ‚úÖ 0 nouveaux chunks extraits de cleanedup_2022 - On the Use of eXplainable Artificial Intelligence to Evaluate School Dropout.csv\n",
      "  ‚è≠Ô∏è 20 chunks ignor√©s (d√©j√† existants)\n",
      "\n",
      "üìÑ Traitement de cleanedup_2022 - Predicting individual learning performance using machine‚Äêlearning hybridized with the teaching‚Äêlearn.csv...\n",
      "  ‚úÖ 0 nouveaux chunks extraits de cleanedup_2022 - Predicting individual learning performance using machine‚Äêlearning hybridized with the teaching‚Äêlearn.csv\n",
      "  ‚è≠Ô∏è 17 chunks ignor√©s (d√©j√† existants)\n",
      "\n",
      "üìÑ Traitement de cleanedup_2022 - Prediction of Academic Performance of Engineering Students by Using Data Mining Techniques.csv...\n",
      "  ‚úÖ 0 nouveaux chunks extraits de cleanedup_2022 - Prediction of Academic Performance of Engineering Students by Using Data Mining Techniques.csv\n",
      "  ‚è≠Ô∏è 7 chunks ignor√©s (d√©j√† existants)\n",
      "\n",
      "üìÑ Traitement de cleanedup_2022 - Using Learner Analytics to Explore the Potential Contribution of Multimodal Formative Assessment to.csv...\n",
      "  ‚úÖ 0 nouveaux chunks extraits de cleanedup_2022 - Using Learner Analytics to Explore the Potential Contribution of Multimodal Formative Assessment to.csv\n",
      "  ‚è≠Ô∏è 10 chunks ignor√©s (d√©j√† existants)\n",
      "\n",
      "üìÑ Traitement de cleanedup_A Data Mining Approach for Predicting Academic Success ‚Äì A Case Study Helping Teachers Develop Rese.csv...\n",
      "  ‚úÖ 0 nouveaux chunks extraits de cleanedup_A Data Mining Approach for Predicting Academic Success ‚Äì A Case Study Helping Teachers Develop Rese.csv\n",
      "  ‚è≠Ô∏è 13 chunks ignor√©s (d√©j√† existants)\n",
      "\n",
      "üìÑ Traitement de cleanedup_Al-Shabandar - 2017 - IJCNN - Machine learning approaches to predict learning outcomes in Massive open online courses.csv...\n",
      "  ‚úÖ 0 nouveaux chunks extraits de cleanedup_Al-Shabandar - 2017 - IJCNN - Machine learning approaches to predict learning outcomes in Massive open online courses.csv\n",
      "  ‚è≠Ô∏è 8 chunks ignor√©s (d√©j√† existants)\n",
      "\n",
      "üìÑ Traitement de cleanedup_Alturki - 2022 - Predicting Master_s students_ academic performance an empirical study in Germany.csv...\n",
      "  ‚úÖ 0 nouveaux chunks extraits de cleanedup_Alturki - 2022 - Predicting Master_s students_ academic performance an empirical study in Germany.csv\n",
      "  ‚è≠Ô∏è 22 chunks ignor√©s (d√©j√† existants)\n",
      "\n",
      "üìÑ Traitement de cleanedup_Alwarthan - 2022 - An Explainable Model for Identifying At-Risk Student at Higher Education.csv...\n",
      "  ‚úÖ 0 nouveaux chunks extraits de cleanedup_Alwarthan - 2022 - An Explainable Model for Identifying At-Risk Student at Higher Education.csv\n",
      "  ‚è≠Ô∏è 19 chunks ignor√©s (d√©j√† existants)\n",
      "\n",
      "üìÑ Traitement de cleanedup_Anzer - 2018 - Predicting Academic Performance of Students in UAE Using Data Mining Techniques.csv...\n",
      "  ‚úÖ 0 nouveaux chunks extraits de cleanedup_Anzer - 2018 - Predicting Academic Performance of Students in UAE Using Data Mining Techniques.csv\n",
      "  ‚è≠Ô∏è 5 chunks ignor√©s (d√©j√† existants)\n",
      "\n",
      "üìÑ Traitement de cleanedup_Ayouni - 2021 - A new ML-based approach to enhance student engagement in online environment..csv...\n",
      "  ‚úÖ 0 nouveaux chunks extraits de cleanedup_Ayouni - 2021 - A new ML-based approach to enhance student engagement in online environment..csv\n",
      "  ‚è≠Ô∏è 14 chunks ignor√©s (d√©j√† existants)\n",
      "\n",
      "üìÑ Traitement de cleanedup_Bainbridge et al. - 2015 - Using Learning Analytics to Predict At-Risk Students in Online Graduate Public Affairs and Administr.csv...\n",
      "  ‚úÖ 0 nouveaux chunks extraits de cleanedup_Bainbridge et al. - 2015 - Using Learning Analytics to Predict At-Risk Students in Online Graduate Public Affairs and Administr.csv\n",
      "  ‚è≠Ô∏è 17 chunks ignor√©s (d√©j√† existants)\n",
      "\n",
      "üìÑ Traitement de cleanedup_Barber - 2012 - LAK - Course correction using analytics to predict course success.csv...\n",
      "  ‚úÖ 0 nouveaux chunks extraits de cleanedup_Barber - 2012 - LAK - Course correction using analytics to predict course success.csv\n",
      "  ‚è≠Ô∏è 4 chunks ignor√©s (d√©j√† existants)\n",
      "\n",
      "üìÑ Traitement de cleanedup_Bengesai - 2018 - An Analysis of Academic and Institutional Factors Affecting Graduation Among Engineering Students at.csv...\n",
      "  ‚úÖ 0 nouveaux chunks extraits de cleanedup_Bengesai - 2018 - An Analysis of Academic and Institutional Factors Affecting Graduation Among Engineering Students at.csv\n",
      "  ‚è≠Ô∏è 11 chunks ignor√©s (d√©j√† existants)\n",
      "\n",
      "üìÑ Traitement de cleanedup_Cabo - 2021 - Use of Machine Learning to Identify Predictors of Student Performance in Writing Viable Computer Pro.csv...\n",
      "  ‚úÖ 0 nouveaux chunks extraits de cleanedup_Cabo - 2021 - Use of Machine Learning to Identify Predictors of Student Performance in Writing Viable Computer Pro.csv\n",
      "  ‚è≠Ô∏è 8 chunks ignor√©s (d√©j√† existants)\n",
      "\n",
      "üìÑ Traitement de cleanedup_Cannistr√† - 2021 - Early-predicting dropout of university students an application of innovative multilevel machine lea.csv...\n",
      "  ‚úÖ 0 nouveaux chunks extraits de cleanedup_Cannistr√† - 2021 - Early-predicting dropout of university students an application of innovative multilevel machine lea.csv\n",
      "  ‚è≠Ô∏è 21 chunks ignor√©s (d√©j√† existants)\n",
      "\n",
      "üìÑ Traitement de cleanedup_Copie de 2012 - Do Situational Academic Emotions Predict Academic Outcomes in a Lecture Course.csv...\n",
      "  ‚úÖ 0 nouveaux chunks extraits de cleanedup_Copie de 2012 - Do Situational Academic Emotions Predict Academic Outcomes in a Lecture Course.csv\n",
      "  ‚è≠Ô∏è 10 chunks ignor√©s (d√©j√† existants)\n",
      "\n",
      "üìÑ Traitement de cleanedup_Copie de 2017 - MOOC Dropout Prediction.csv...\n",
      "  ‚úÖ 0 nouveaux chunks extraits de cleanedup_Copie de 2017 - MOOC Dropout Prediction.csv\n",
      "  ‚è≠Ô∏è 9 chunks ignor√©s (d√©j√† existants)\n",
      "\n",
      "üìÑ Traitement de cleanedup_Copie de 2018 - Leveraging Non-cognitive Student Self-reports to Predict Learning Outcomes.csv...\n",
      "  ‚úÖ 0 nouveaux chunks extraits de cleanedup_Copie de 2018 - Leveraging Non-cognitive Student Self-reports to Predict Learning Outcomes.csv\n",
      "  ‚è≠Ô∏è 4 chunks ignor√©s (d√©j√† existants)\n",
      "\n",
      "üìÑ Traitement de cleanedup_Copie de 2019 - Detecting students-at-risk in computer programming classes with learning analytics from students‚Äô di.csv...\n",
      "  ‚úÖ 0 nouveaux chunks extraits de cleanedup_Copie de 2019 - Detecting students-at-risk in computer programming classes with learning analytics from students‚Äô di.csv\n",
      "  ‚è≠Ô∏è 29 chunks ignor√©s (d√©j√† existants)\n",
      "\n",
      "üìÑ Traitement de cleanedup_Copie de 2022 - On the Use of eXplainable Artificial Intelligence to Evaluate School Dropout.csv...\n",
      "  ‚úÖ 0 nouveaux chunks extraits de cleanedup_Copie de 2022 - On the Use of eXplainable Artificial Intelligence to Evaluate School Dropout.csv\n",
      "  ‚è≠Ô∏è 19 chunks ignor√©s (d√©j√† existants)\n",
      "\n",
      "üìÑ Traitement de cleanedup_Copie de Djulovic and Li - 2013 - Towards freshman retention prediction A comparative study.csv...\n",
      "  ‚úÖ 0 nouveaux chunks extraits de cleanedup_Copie de Djulovic and Li - 2013 - Towards freshman retention prediction A comparative study.csv\n",
      "  ‚è≠Ô∏è 7 chunks ignor√©s (d√©j√† existants)\n",
      "\n",
      "üìÑ Traitement de cleanedup_Copie de Mitra and Goldstein - 2015 - Designing early detection and intervention techniques via predictive statistical models‚ÄîA case study.csv...\n",
      "  ‚úÖ 0 nouveaux chunks extraits de cleanedup_Copie de Mitra and Goldstein - 2015 - Designing early detection and intervention techniques via predictive statistical models‚ÄîA case study.csv\n",
      "  ‚è≠Ô∏è 14 chunks ignor√©s (d√©j√† existants)\n",
      "\n",
      "üìÑ Traitement de cleanedup_Djulovic and Li - 2013 - Towards freshman retention prediction A comparative study.csv...\n",
      "  ‚úÖ 0 nouveaux chunks extraits de cleanedup_Djulovic and Li - 2013 - Towards freshman retention prediction A comparative study.csv\n",
      "  ‚è≠Ô∏è 7 chunks ignor√©s (d√©j√† existants)\n",
      "\n",
      "üìÑ Traitement de cleanedup_Emerson - 2020 - Multimodal Learning Analytics for Game-Based Learning..csv...\n",
      "  ‚úÖ 0 nouveaux chunks extraits de cleanedup_Emerson - 2020 - Multimodal Learning Analytics for Game-Based Learning..csv\n",
      "  ‚è≠Ô∏è 20 chunks ignor√©s (d√©j√† existants)\n",
      "\n",
      "üìÑ Traitement de cleanedup_Everaert - 2022 - Predicting first-year university progression using early warning signals from accounting education.csv...\n",
      "  ‚úÖ 0 nouveaux chunks extraits de cleanedup_Everaert - 2022 - Predicting first-year university progression using early warning signals from accounting education.csv\n",
      "  ‚è≠Ô∏è 24 chunks ignor√©s (d√©j√† existants)\n",
      "\n",
      "üìÑ Traitement de cleanedup_Exploring the relation between self-regulation, online activities, and academic performance a case.csv...\n",
      "  ‚úÖ 0 nouveaux chunks extraits de cleanedup_Exploring the relation between self-regulation, online activities, and academic performance a case.csv\n",
      "  ‚è≠Ô∏è 7 chunks ignor√©s (d√©j√† existants)\n",
      "\n",
      "üìÑ Traitement de cleanedup_Flanagan - 2022 - Early-warning prediction of student performance and engagement in open book assessment by reading be.csv...\n",
      "  ‚úÖ 0 nouveaux chunks extraits de cleanedup_Flanagan - 2022 - Early-warning prediction of student performance and engagement in open book assessment by reading be.csv\n",
      "  ‚è≠Ô∏è 23 chunks ignor√©s (d√©j√† existants)\n",
      "\n",
      "üìÑ Traitement de cleanedup_Gaftandzhieva - 2022 - Exploring Online Activities to Predict the Final Grade of Student.csv...\n",
      "  ‚úÖ 0 nouveaux chunks extraits de cleanedup_Gaftandzhieva - 2022 - Exploring Online Activities to Predict the Final Grade of Student.csv\n",
      "  ‚è≠Ô∏è 17 chunks ignor√©s (d√©j√† existants)\n",
      "\n",
      "üìÑ Traitement de cleanedup_Gil et al. - 2020 - Predicting students_ dropout indicators in public school using data mining approaches.csv...\n",
      "  ‚úÖ 0 nouveaux chunks extraits de cleanedup_Gil et al. - 2020 - Predicting students_ dropout indicators in public school using data mining approaches.csv\n",
      "  ‚è≠Ô∏è 6 chunks ignor√©s (d√©j√† existants)\n",
      "\n",
      "üìÑ Traitement de cleanedup_Gitinabard - 2019 - How Widely Can Prediction Models be Generalized Performance Prediction in Blended Courses.csv...\n",
      "  ‚úÖ 0 nouveaux chunks extraits de cleanedup_Gitinabard - 2019 - How Widely Can Prediction Models be Generalized Performance Prediction in Blended Courses.csv\n",
      "  ‚è≠Ô∏è 13 chunks ignor√©s (d√©j√† existants)\n",
      "\n",
      "üìÑ Traitement de cleanedup_Goad - 2020 - Predicting Student Success in Online Physical Education.csv...\n",
      "  ‚úÖ 0 nouveaux chunks extraits de cleanedup_Goad - 2020 - Predicting Student Success in Online Physical Education.csv\n",
      "  ‚è≠Ô∏è 15 chunks ignor√©s (d√©j√† existants)\n",
      "\n",
      "üìÑ Traitement de cleanedup_Han et al. - 2017 - Investigating performance in a blended SPOC.csv...\n",
      "  ‚úÖ 0 nouveaux chunks extraits de cleanedup_Han et al. - 2017 - Investigating performance in a blended SPOC.csv\n",
      "  ‚è≠Ô∏è 6 chunks ignor√©s (d√©j√† existants)\n",
      "\n",
      "üìÑ Traitement de cleanedup_Hussain - 2018 - Using machine learning to predict student difficulties from learning session data.csv...\n",
      "  ‚úÖ 0 nouveaux chunks extraits de cleanedup_Hussain - 2018 - Using machine learning to predict student difficulties from learning session data.csv\n",
      "  ‚è≠Ô∏è 25 chunks ignor√©s (d√©j√† existants)\n",
      "\n",
      "üìÑ Traitement de cleanedup_Iatrellis - 2020 - A two-phase machine learning approach for predicting student outcomes.csv...\n",
      "  ‚úÖ 0 nouveaux chunks extraits de cleanedup_Iatrellis - 2020 - A two-phase machine learning approach for predicting student outcomes.csv\n",
      "  ‚è≠Ô∏è 19 chunks ignor√©s (d√©j√† existants)\n",
      "\n",
      "üìÑ Traitement de cleanedup_Kemper et al. - 2020 - Predicting student dropout A machine learning approach.csv...\n",
      "  ‚úÖ 0 nouveaux chunks extraits de cleanedup_Kemper et al. - 2020 - Predicting student dropout A machine learning approach.csv\n",
      "  ‚è≠Ô∏è 19 chunks ignor√©s (d√©j√† existants)\n",
      "\n",
      "üìÑ Traitement de cleanedup_Kennedy et al. - 2015 - Predicting success how learners_ prior knowledge, skills and activities predict MOOC performance.csv...\n",
      "  ‚úÖ 0 nouveaux chunks extraits de cleanedup_Kennedy et al. - 2015 - Predicting success how learners_ prior knowledge, skills and activities predict MOOC performance.csv\n",
      "  ‚è≠Ô∏è 5 chunks ignor√©s (d√©j√† existants)\n",
      "\n",
      "üìÑ Traitement de cleanedup_Kondo et al. - 2017 - Early Detection of At-Risk Students Using Machine Learning Based on LMS Log Data.csv...\n",
      "  ‚úÖ 0 nouveaux chunks extraits de cleanedup_Kondo et al. - 2017 - Early Detection of At-Risk Students Using Machine Learning Based on LMS Log Data.csv\n",
      "  ‚è≠Ô∏è 4 chunks ignor√©s (d√©j√† existants)\n",
      "\n",
      "üìÑ Traitement de cleanedup_Kostopoulos - 2021 - Interpretable Models for Early Prediction of Certification in MOOCs A Case Study on a MOOC for Smar.csv...\n",
      "  ‚úÖ 0 nouveaux chunks extraits de cleanedup_Kostopoulos - 2021 - Interpretable Models for Early Prediction of Certification in MOOCs A Case Study on a MOOC for Smar.csv\n",
      "  ‚è≠Ô∏è 11 chunks ignor√©s (d√©j√† existants)\n",
      "\n",
      "üìÑ Traitement de cleanedup_Lincke - 2021 - The performance of some machine learning approaches and a rich context model in student answer predi.csv...\n",
      "  ‚úÖ 0 nouveaux chunks extraits de cleanedup_Lincke - 2021 - The performance of some machine learning approaches and a rich context model in student answer predi.csv\n",
      "  ‚è≠Ô∏è 15 chunks ignor√©s (d√©j√† existants)\n",
      "\n",
      "üìÑ Traitement de cleanedup_Lu et al. - 2018 - Applying learning analytics for the early prediction of students_ academic performance in blended le.csv...\n",
      "  ‚úÖ 0 nouveaux chunks extraits de cleanedup_Lu et al. - 2018 - Applying learning analytics for the early prediction of students_ academic performance in blended le.csv\n",
      "  ‚è≠Ô∏è 13 chunks ignor√©s (d√©j√† existants)\n",
      "\n",
      "üìÑ Traitement de cleanedup_Mengash - 2020 - Using Data Mining Techniques to Predict Student Performance to Support Decision Making in University.csv...\n",
      "  ‚úÖ 0 nouveaux chunks extraits de cleanedup_Mengash - 2020 - Using Data Mining Techniques to Predict Student Performance to Support Decision Making in University.csv\n",
      "  ‚è≠Ô∏è 9 chunks ignor√©s (d√©j√† existants)\n",
      "\n",
      "üìÑ Traitement de cleanedup_Migu√©is et al. - 2018 - Early segmentation of students according to their academic performance a predictive modelling appro.csv...\n",
      "  ‚úÖ 0 nouveaux chunks extraits de cleanedup_Migu√©is et al. - 2018 - Early segmentation of students according to their academic performance a predictive modelling appro.csv\n",
      "  ‚è≠Ô∏è 16 chunks ignor√©s (d√©j√† existants)\n",
      "\n",
      "üìÑ Traitement de cleanedup_Mitra and Goldstein - 2015 - Designing early detection and intervention techniques via predictive statistical models‚ÄîA case study.csv...\n",
      "  ‚úÖ 0 nouveaux chunks extraits de cleanedup_Mitra and Goldstein - 2015 - Designing early detection and intervention techniques via predictive statistical models‚ÄîA case study.csv\n",
      "  ‚è≠Ô∏è 14 chunks ignor√©s (d√©j√† existants)\n",
      "\n",
      "üìÑ Traitement de cleanedup_Mitra and Le - 2022 - The effect of cognitive and behavioral factors on student success in a bottleneck business statistic.csv...\n",
      "  ‚úÖ 0 nouveaux chunks extraits de cleanedup_Mitra and Le - 2022 - The effect of cognitive and behavioral factors on student success in a bottleneck business statistic.csv\n",
      "  ‚è≠Ô∏è 28 chunks ignor√©s (d√©j√† existants)\n",
      "\n",
      "üìÑ Traitement de cleanedup_Moreno-Marcos - 2019 - Generalizing Predictive Models of Admission Test Success Based on Online Interactions.csv...\n",
      "  ‚úÖ 0 nouveaux chunks extraits de cleanedup_Moreno-Marcos - 2019 - Generalizing Predictive Models of Admission Test Success Based on Online Interactions.csv\n",
      "  ‚è≠Ô∏è 17 chunks ignor√©s (d√©j√† existants)\n",
      "\n",
      "üìÑ Traitement de cleanedup_Moreno-Marcos - 2020 - Analysis of the Factors Influencing Learners‚Äô Performance Prediction With Learning Analytics.csv...\n",
      "  ‚úÖ 0 nouveaux chunks extraits de cleanedup_Moreno-Marcos - 2020 - Analysis of the Factors Influencing Learners‚Äô Performance Prediction With Learning Analytics.csv\n",
      "  ‚è≠Ô∏è 19 chunks ignor√©s (d√©j√† existants)\n",
      "\n",
      "üìÑ Traitement de cleanedup_Palacios et al. - 2021 - Knowledge discovery for higher education student retention based on data mining Machine learning al.csv...\n",
      "  ‚úÖ 0 nouveaux chunks extraits de cleanedup_Palacios et al. - 2021 - Knowledge discovery for higher education student retention based on data mining Machine learning al.csv\n",
      "  ‚è≠Ô∏è 21 chunks ignor√©s (d√©j√† existants)\n",
      "\n",
      "üìÑ Traitement de cleanedup_Pereira - 2021 - Explaining Individual and Collective Programming Students‚Äô Behavior by Interpreting a Black-Box Pred.csv...\n",
      "  ‚úÖ 0 nouveaux chunks extraits de cleanedup_Pereira - 2021 - Explaining Individual and Collective Programming Students‚Äô Behavior by Interpreting a Black-Box Pred.csv\n",
      "  ‚è≠Ô∏è 23 chunks ignor√©s (d√©j√† existants)\n",
      "\n",
      "üìÑ Traitement de cleanedup_Prabowo - 2021 - Aggregating Time Series and Tabular Data in Deep Learning Model for University Students‚Äô GPA Predict.csv...\n",
      "  ‚úÖ 0 nouveaux chunks extraits de cleanedup_Prabowo - 2021 - Aggregating Time Series and Tabular Data in Deep Learning Model for University Students‚Äô GPA Predict.csv\n",
      "  ‚è≠Ô∏è 8 chunks ignor√©s (d√©j√† existants)\n",
      "\n",
      "üìÑ Traitement de cleanedup_Predicting student drop-out rates using data mining techniques a case study.csv...\n",
      "  ‚úÖ 0 nouveaux chunks extraits de cleanedup_Predicting student drop-out rates using data mining techniques a case study.csv\n",
      "  ‚è≠Ô∏è 14 chunks ignor√©s (d√©j√† existants)\n",
      "\n",
      "üìÑ Traitement de cleanedup_Predictive models of academic success A case study with version control systems.csv...\n",
      "  ‚úÖ 0 nouveaux chunks extraits de cleanedup_Predictive models of academic success A case study with version control systems.csv\n",
      "  ‚è≠Ô∏è 7 chunks ignor√©s (d√©j√† existants)\n",
      "\n",
      "üìÑ Traitement de cleanedup_Qu - 2022 - Can We Predict Student Performance Based on Tabular and Textual Data.csv...\n",
      "  ‚úÖ 0 nouveaux chunks extraits de cleanedup_Qu - 2022 - Can We Predict Student Performance Based on Tabular and Textual Data.csv\n",
      "  ‚è≠Ô∏è 12 chunks ignor√©s (d√©j√† existants)\n",
      "\n",
      "üìÑ Traitement de cleanedup_Rafique - 2021 - Integrating Learning Analytics and Collaborative Learning for Improving Student_s Academic Performan.csv...\n",
      "  ‚úÖ 0 nouveaux chunks extraits de cleanedup_Rafique - 2021 - Integrating Learning Analytics and Collaborative Learning for Improving Student_s Academic Performan.csv\n",
      "  ‚è≠Ô∏è 15 chunks ignor√©s (d√©j√† existants)\n",
      "\n",
      "üìÑ Traitement de cleanedup_Rao and Kumar - 2021 - Students Performance Prediction in Online Courses Using Machine Learning Algorithms.csv...\n",
      "  ‚úÖ 0 nouveaux chunks extraits de cleanedup_Rao and Kumar - 2021 - Students Performance Prediction in Online Courses Using Machine Learning Algorithms.csv\n",
      "  ‚è≠Ô∏è 6 chunks ignor√©s (d√©j√† existants)\n",
      "\n",
      "üìÑ Traitement de cleanedup_Riestra-Gonz√°lez - 2021 - Massive LMS log data analysis for the early prediction of course-agnostic student performance.csv...\n",
      "  ‚úÖ 0 nouveaux chunks extraits de cleanedup_Riestra-Gonz√°lez - 2021 - Massive LMS log data analysis for the early prediction of course-agnostic student performance.csv\n",
      "  ‚è≠Ô∏è 20 chunks ignor√©s (d√©j√† existants)\n",
      "\n",
      "üìÑ Traitement de cleanedup_Rogers - 2014 - LAK - Modest analytics using the index method to identify students at risk of failure.csv...\n",
      "  ‚úÖ 0 nouveaux chunks extraits de cleanedup_Rogers - 2014 - LAK - Modest analytics using the index method to identify students at risk of failure.csv\n",
      "  ‚è≠Ô∏è 4 chunks ignor√©s (d√©j√† existants)\n",
      "\n",
      "üìÑ Traitement de cleanedup_Sales et al. - 2016 - Exploiting academic records for predicting student drop out A case study in Brazilian higher educat.csv...\n",
      "  ‚úÖ 0 nouveaux chunks extraits de cleanedup_Sales et al. - 2016 - Exploiting academic records for predicting student drop out A case study in Brazilian higher educat.csv\n",
      "  ‚è≠Ô∏è 16 chunks ignor√©s (d√©j√† existants)\n",
      "\n",
      "üìÑ Traitement de cleanedup_Sani et al. - 2020 - Drop-Out Prediction in Higher Education Among B40 Students.csv...\n",
      "  ‚úÖ 0 nouveaux chunks extraits de cleanedup_Sani et al. - 2020 - Drop-Out Prediction in Higher Education Among B40 Students.csv\n",
      "  ‚è≠Ô∏è 9 chunks ignor√©s (d√©j√† existants)\n",
      "\n",
      "üìÑ Traitement de cleanedup_Saqr - 2017 - How learning analytics can early predict under-achieving students in a blended medical education cou.csv...\n",
      "  ‚úÖ 0 nouveaux chunks extraits de cleanedup_Saqr - 2017 - How learning analytics can early predict under-achieving students in a blended medical education cou.csv\n",
      "  ‚è≠Ô∏è 11 chunks ignor√©s (d√©j√† existants)\n",
      "\n",
      "üìÑ Traitement de cleanedup_Stemming the tide Predicting STEM attrition using student transcript data.csv...\n",
      "  ‚úÖ 0 nouveaux chunks extraits de cleanedup_Stemming the tide Predicting STEM attrition using student transcript data.csv\n",
      "  ‚è≠Ô∏è 9 chunks ignor√©s (d√©j√† existants)\n",
      "\n",
      "üìÑ Traitement de cleanedup_Thammasiri et al. - 2014 - A critical assessment of imbalanced class distribution problem The case of predicting freshmen stud.csv...\n",
      "  ‚úÖ 0 nouveaux chunks extraits de cleanedup_Thammasiri et al. - 2014 - A critical assessment of imbalanced class distribution problem The case of predicting freshmen stud.csv\n",
      "  ‚è≠Ô∏è 10 chunks ignor√©s (d√©j√† existants)\n",
      "\n",
      "üìÑ Traitement de cleanedup_Van Goidsenhoven et al. - 2020 - Predicting student success in a blended learning environment.csv...\n",
      "  ‚úÖ 0 nouveaux chunks extraits de cleanedup_Van Goidsenhoven et al. - 2020 - Predicting student success in a blended learning environment.csv\n",
      "  ‚è≠Ô∏è 9 chunks ignor√©s (d√©j√† existants)\n",
      "\n",
      "üìÑ Traitement de cleanedup_Venant - 2017 - Using sequential pattern mining to explore learners_ behaviors and evaluate their correlation with p.csv...\n",
      "  ‚úÖ 0 nouveaux chunks extraits de cleanedup_Venant - 2017 - Using sequential pattern mining to explore learners_ behaviors and evaluate their correlation with p.csv\n",
      "  ‚è≠Ô∏è 14 chunks ignor√©s (d√©j√† existants)\n",
      "\n",
      "üìÑ Traitement de cleanedup_Vinker - 2022 - Mining Code Submissions to Elucidate Disengagement in a Computer Science MOOC.csv...\n",
      "  ‚úÖ 0 nouveaux chunks extraits de cleanedup_Vinker - 2022 - Mining Code Submissions to Elucidate Disengagement in a Computer Science MOOC.csv\n",
      "  ‚è≠Ô∏è 9 chunks ignor√©s (d√©j√† existants)\n",
      "\n",
      "üìÑ Traitement de cleanedup_Waddington - 2014 - LAK - Practice exams make perfect incorporating course resource use into an early warning system.csv...\n",
      "  ‚úÖ 0 nouveaux chunks extraits de cleanedup_Waddington - 2014 - LAK - Practice exams make perfect incorporating course resource use into an early warning system.csv\n",
      "  ‚è≠Ô∏è 5 chunks ignor√©s (d√©j√† existants)\n",
      "\n",
      "üìÑ Traitement de cleanedup_Wade - 2019 - Measuring, Manipulating, and Predicting Student Success A 10-Year Assessment of Carnegie R1 Doctora.csv...\n",
      "  ‚úÖ 0 nouveaux chunks extraits de cleanedup_Wade - 2019 - Measuring, Manipulating, and Predicting Student Success A 10-Year Assessment of Carnegie R1 Doctora.csv\n",
      "  ‚è≠Ô∏è 21 chunks ignor√©s (d√©j√† existants)\n",
      "\n",
      "üìÑ Traitement de cleanedup_Wan Yaacob et al. - 2020 - Predicting Student Drop-Out in Higher Institution Using Data Mining Techniques.csv...\n",
      "  ‚úÖ 0 nouveaux chunks extraits de cleanedup_Wan Yaacob et al. - 2020 - Predicting Student Drop-Out in Higher Institution Using Data Mining Techniques.csv\n",
      "  ‚è≠Ô∏è 14 chunks ignor√©s (d√©j√† existants)\n",
      "\n",
      "üìÑ Traitement de cleanedup_Wang - 2019 - On Prediction of Online Behaviors and Achievement Using Self-regulated Learning Awareness in Flipped.csv...\n",
      "  ‚úÖ 0 nouveaux chunks extraits de cleanedup_Wang - 2019 - On Prediction of Online Behaviors and Achievement Using Self-regulated Learning Awareness in Flipped.csv\n",
      "  ‚è≠Ô∏è 6 chunks ignor√©s (d√©j√† existants)\n",
      "\n",
      "üìÑ Traitement de cleanedup_Wu - 2020 - ICCSE - Student Achievement Analysis and Prediction Based on the Whole Learning Process.csv...\n",
      "  ‚úÖ 0 nouveaux chunks extraits de cleanedup_Wu - 2020 - ICCSE - Student Achievement Analysis and Prediction Based on the Whole Learning Process.csv\n",
      "  ‚è≠Ô∏è 6 chunks ignor√©s (d√©j√† existants)\n",
      "\n",
      "üìÑ Traitement de cleanedup_Yu and Jo - 2014 - Educational technology approach toward learning analytics relationship between student online behav.csv...\n",
      "  ‚úÖ 0 nouveaux chunks extraits de cleanedup_Yu and Jo - 2014 - Educational technology approach toward learning analytics relationship between student online behav.csv\n",
      "  ‚è≠Ô∏è 2 chunks ignor√©s (d√©j√† existants)\n",
      "\n",
      "üìÑ Traitement de extracted_docs.csv...\n",
      "  ‚ö†Ô∏è Colonne 'cleaned_page_content' manquante dans extracted_docs.csv\n",
      "\n",
      "üìÑ Traitement de extracted_docs_cleaned.csv...\n",
      "  ‚úÖ 0 nouveaux chunks extraits de extracted_docs_cleaned.csv\n",
      "  ‚è≠Ô∏è 40 chunks ignor√©s (d√©j√† existants)\n",
      "\n",
      "üìä R√©sum√©:\n",
      "  ‚Ä¢ 0 nouveaux chunks √† ajouter\n",
      "  ‚Ä¢ 1745 chunks ignor√©s (doublons)\n",
      "  ‚Ä¢ 1802 chunks d√©j√† en base\n",
      "‚ÑπÔ∏è Aucun nouveau document √† ajouter\n",
      "‚úÖ Utilisation de la base existante\n",
      "\n",
      "üß™ Test de recherche avec la requ√™te: 'student performance'\n",
      "üìã 5 r√©sultats trouv√©s:\n",
      "\n",
      "  R√©sultat 1:\n",
      "    Source: Rafique - 2021 - Integrating Learning Analytics and Collaborative Learning for Improving Student_s Academic Performan.pdf\n",
      "    CSV: cleanedup_Rafique - 2021 - Integrating Learning Analytics and Collaborative Learning for Improving Student_s Academic Performan.csv\n",
      "    Chunk ID: cleanedup_Rafique - 2021 - Integrating Learning Analytics and Collaborative Learning for Improving Student_s Academic Performan_10\n",
      "    Contenu: RQ2. WHICH ARE THE MOST IMPORTANT FEATURES\n",
      "THAT HELP ACCURATE PREDICTION OF STUDENT‚ÄôS\n",
      "PERFORMANCE?\n",
      "The second question determines important features to make\n",
      "accurate predictions of students‚Äô performan...\n",
      "\n",
      "  R√©sultat 2:\n",
      "    Source: Rafique - 2021 - Integrating Learning Analytics and Collaborative Learning for Improving Student_s Academic Performan.pdf\n",
      "    CSV: cleanedup_Rafique - 2021 - Integrating Learning Analytics and Collaborative Learning for Improving Student_s Academic Performan.csv\n",
      "    Chunk ID: cleanedup_Rafique - 2021 - Integrating Learning Analytics and Collaborative Learning for Improving Student_s Academic Performan_10\n",
      "    Contenu: RQ2. WHICH ARE THE MOST IMPORTANT FEATURES\n",
      "THAT HELP ACCURATE PREDICTION OF STUDENT‚ÄôS\n",
      "PERFORMANCE?\n",
      "The second question determines important features to make\n",
      "accurate predictions of students‚Äô performan...\n",
      "\n",
      "  R√©sultat 3:\n",
      "    Source: 2018 - Exploring the High Potential Factors that Affects Students‚Äô Academic Performance.pdf\n",
      "    CSV: cleanedup_2018 - Exploring the High Potential Factors that Affects Students‚Äô Academic Performance.csv\n",
      "    Chunk ID: cleanedup_2018 - Exploring the High Potential Factors that Affects Students‚Äô Academic Performance_2\n",
      "    Contenu: an on -line discussion forum. With the proper format data, classification and classification via clustering techniques are applied and compared. Finally, the obtained classification models are describ...\n",
      "\n",
      "üéâ Base vectorielle ChromaDB mise √† jour!\n",
      "üí° Vous pouvez maintenant utiliser:\n",
      "   - 'vectorstore' pour acc√©der directement √† la base\n",
      "   - 'retriever' pour effectuer des recherches\n",
      "üìÅ Base sauvegard√©e dans: ./chroma_db\n"
     ]
    }
   ],
   "source": [
    "def load_cleaned_csvs_to_chroma(csv_dir: str = \"clean_up_test\",\n",
    "                               chroma_dir: str = \"chroma_db\",\n",
    "                               batch_size: int = 50):\n",
    "    \"\"\"\n",
    "    Charge tous les fichiers CSV nettoy√©s du dossier csv_dir vers ChromaDB.\n",
    "    Si ChromaDB existe d√©j√†, ajoute les nouveaux documents √† l'existante.\n",
    "    Sinon, cr√©e une nouvelle base de donn√©es.\n",
    "\n",
    "    Args:\n",
    "        csv_dir: R√©pertoire contenant les fichiers CSV nettoy√©s\n",
    "        chroma_dir: R√©pertoire de la base de donn√©es ChromaDB\n",
    "        batch_size: Nombre de documents √† traiter par batch\n",
    "    \"\"\"\n",
    "\n",
    "    print(\"üîÑ Initialisation du chargement des CSV vers ChromaDB...\")\n",
    "\n",
    "    # Configuration des embeddings\n",
    "    gemini_embeddings = GoogleGenerativeAIEmbeddings(model=\"models/embedding-001\")\n",
    "\n",
    "    # V√©rifier si le dossier CSV existe\n",
    "    csv_path = Path(csv_dir)\n",
    "    if not csv_path.exists():\n",
    "        raise FileNotFoundError(f\"Le dossier '{csv_dir}' n'existe pas.\")\n",
    "\n",
    "    # Cr√©er le dossier ChromaDB s'il n'existe pas\n",
    "    chroma_path = Path(chroma_dir)\n",
    "    chroma_path.mkdir(exist_ok=True)\n",
    "\n",
    "    # V√©rifier si ChromaDB existe d√©j√†\n",
    "    existing_vectorstore = None\n",
    "    existing_chunk_ids = set()\n",
    "\n",
    "    # V√©rifier la pr√©sence de fichiers ChromaDB (index, sqlite, etc.)\n",
    "    chroma_files = list(chroma_path.glob(\"*\"))\n",
    "    database_exists = len(chroma_files) > 0\n",
    "\n",
    "    if database_exists:\n",
    "        try:\n",
    "            print(\"üîç Base ChromaDB existante d√©tect√©e, chargement...\")\n",
    "            existing_vectorstore = Chroma(\n",
    "                persist_directory=chroma_dir,\n",
    "                embedding_function=gemini_embeddings\n",
    "            )\n",
    "\n",
    "            # R√©cup√©rer les chunk_ids existants pour √©viter les doublons\n",
    "            try:\n",
    "                # Tentative de r√©cup√©ration des m√©tadonn√©es existantes\n",
    "                existing_docs = existing_vectorstore.get()\n",
    "                if existing_docs and 'metadatas' in existing_docs:\n",
    "                    for metadata in existing_docs['metadatas']:\n",
    "                        if metadata and 'chunk_id' in metadata:\n",
    "                            existing_chunk_ids.add(metadata['chunk_id'])\n",
    "\n",
    "                print(f\"üìä {len(existing_chunk_ids)} chunks existants trouv√©s dans la base\")\n",
    "            except Exception as e:\n",
    "                print(f\"‚ö†Ô∏è Impossible de r√©cup√©rer les m√©tadonn√©es existantes: {e}\")\n",
    "                print(\"üîÑ Continuons avec une v√©rification basique...\")\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"‚ö†Ô∏è Erreur lors du chargement de la base existante: {e}\")\n",
    "            print(\"üîÑ Cr√©ation d'une nouvelle base...\")\n",
    "            existing_vectorstore = None\n",
    "            database_exists = False\n",
    "\n",
    "    # Trouver tous les fichiers CSV\n",
    "    csv_files = list(csv_path.glob(\"*.csv\"))\n",
    "\n",
    "    if not csv_files:\n",
    "        print(f\"‚ùå Aucun fichier CSV trouv√© dans '{csv_dir}'\")\n",
    "        return existing_vectorstore.as_retriever(search_kwargs={\"k\": 5}) if existing_vectorstore else None\n",
    "\n",
    "    print(f\"üìÅ {len(csv_files)} fichiers CSV trouv√©s\")\n",
    "\n",
    "    # Collecter tous les nouveaux documents\n",
    "    new_documents = []\n",
    "    total_new_chunks = 0\n",
    "    skipped_chunks = 0\n",
    "\n",
    "    for csv_file in csv_files:\n",
    "        print(f\"\\nüìÑ Traitement de {csv_file.name}...\")\n",
    "\n",
    "        try:\n",
    "            # Charger le CSV\n",
    "            df = pd.read_csv(csv_file)\n",
    "\n",
    "            # V√©rifier que les colonnes n√©cessaires existent\n",
    "            if 'cleaned_page_content' not in df.columns:\n",
    "                print(f\"  ‚ö†Ô∏è Colonne 'cleaned_page_content' manquante dans {csv_file.name}\")\n",
    "                continue\n",
    "\n",
    "            if 'source' not in df.columns:\n",
    "                print(f\"  ‚ö†Ô∏è Colonne 'source' manquante dans {csv_file.name}\")\n",
    "                continue\n",
    "\n",
    "            # Cr√©er les documents pour chaque ligne\n",
    "            file_documents = []\n",
    "            file_skipped = 0\n",
    "\n",
    "            for idx, row in df.iterrows():\n",
    "                cleaned_text = row['cleaned_page_content']\n",
    "\n",
    "                # Ignorer les chunks vides ou tr√®s courts\n",
    "                if pd.isna(cleaned_text) or len(str(cleaned_text).strip()) < 50:\n",
    "                    continue\n",
    "\n",
    "                # G√©n√©rer l'ID unique pour ce chunk\n",
    "                chunk_id = f\"{csv_file.stem}_{idx}\"\n",
    "\n",
    "                # V√©rifier si ce chunk existe d√©j√†\n",
    "                if chunk_id in existing_chunk_ids:\n",
    "                    file_skipped += 1\n",
    "                    continue\n",
    "\n",
    "                # Cr√©er le document avec m√©tadonn√©es\n",
    "                doc = Document(\n",
    "                    page_content=str(cleaned_text).strip(),\n",
    "                    metadata={\n",
    "                        'source': row['source'],\n",
    "                        'csv_file': csv_file.name,\n",
    "                        'page_index': idx,\n",
    "                        'chunk_id': chunk_id\n",
    "                    }\n",
    "                )\n",
    "                file_documents.append(doc)\n",
    "\n",
    "            new_documents.extend(file_documents)\n",
    "            total_new_chunks += len(file_documents)\n",
    "            skipped_chunks += file_skipped\n",
    "\n",
    "            print(f\"  ‚úÖ {len(file_documents)} nouveaux chunks extraits de {csv_file.name}\")\n",
    "            if file_skipped > 0:\n",
    "                print(f\"  ‚è≠Ô∏è {file_skipped} chunks ignor√©s (d√©j√† existants)\")\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"  ‚ùå Erreur lors du traitement de {csv_file.name}: {e}\")\n",
    "            continue\n",
    "\n",
    "    # R√©sum√© des documents √† traiter\n",
    "    print(f\"\\nüìä R√©sum√©:\")\n",
    "    print(f\"  ‚Ä¢ {total_new_chunks} nouveaux chunks √† ajouter\")\n",
    "    print(f\"  ‚Ä¢ {skipped_chunks} chunks ignor√©s (doublons)\")\n",
    "    print(f\"  ‚Ä¢ {len(existing_chunk_ids)} chunks d√©j√† en base\")\n",
    "\n",
    "    # Si aucun nouveau document, retourner l'existant\n",
    "    if not new_documents:\n",
    "        print(\"‚ÑπÔ∏è Aucun nouveau document √† ajouter\")\n",
    "        if existing_vectorstore:\n",
    "            retriever = existing_vectorstore.as_retriever(search_kwargs={\"k\": 5})\n",
    "            print(\"‚úÖ Utilisation de la base existante\")\n",
    "            return existing_vectorstore, retriever\n",
    "        else:\n",
    "            print(\"‚ùå Aucune base existante et aucun nouveau document\")\n",
    "            return None, None\n",
    "\n",
    "    # Traitement selon l'existence ou non de la base\n",
    "    if database_exists and existing_vectorstore:\n",
    "        print(f\"‚ûï Ajout de {total_new_chunks} nouveaux chunks √† la base existante...\")\n",
    "        print(\"‚è≥ G√©n√©ration des embeddings et ajout √† la base...\")\n",
    "\n",
    "        # Ajouter les nouveaux documents par batch\n",
    "        try:\n",
    "            # Ajouter tous les documents d'un coup (ChromaDB g√®re les batches en interne)\n",
    "            existing_vectorstore.add_documents(new_documents)\n",
    "            vectorstore = existing_vectorstore\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"‚ùå Erreur lors de l'ajout: {e}\")\n",
    "            print(\"üîÑ Tentative de cr√©ation d'une nouvelle base...\")\n",
    "            # Fallback: cr√©er une nouvelle base avec tous les documents\n",
    "            all_docs = new_documents  # On ne peut pas r√©cup√©rer les anciens facilement\n",
    "            vectorstore = Chroma.from_documents(\n",
    "                documents=all_docs,\n",
    "                embedding=gemini_embeddings,\n",
    "                persist_directory=chroma_dir\n",
    "            )\n",
    "    else:\n",
    "        print(f\"üÜï Cr√©ation d'une nouvelle base de donn√©es ChromaDB dans '{chroma_dir}'\")\n",
    "        print(\"üì§ Cr√©ation de la base vectorielle avec embeddings Gemini...\")\n",
    "        print(\"‚è≥ Cela peut prendre quelques minutes selon le nombre de documents...\")\n",
    "\n",
    "        vectorstore = Chroma.from_documents(\n",
    "            documents=new_documents,\n",
    "            embedding=gemini_embeddings,\n",
    "            persist_directory=chroma_dir\n",
    "        )\n",
    "\n",
    "    # Persister et finaliser la base de donn√©es\n",
    "    print(\"üíæ Sauvegarde et finalisation de la base de donn√©es...\")\n",
    "    vectorstore.persist()\n",
    "\n",
    "    # Cr√©er le retriever pour les recherches\n",
    "    retriever = vectorstore.as_retriever(search_kwargs={\"k\": 5})\n",
    "\n",
    "    # Statistiques finales\n",
    "    total_in_db = len(existing_chunk_ids) + total_new_chunks\n",
    "\n",
    "    print(f\"\\n‚úÖ Base de donn√©es ChromaDB mise √† jour avec succ√®s!\")\n",
    "    print(f\"üìä Statistiques finales:\")\n",
    "    print(f\"  ‚Ä¢ {len(csv_files)} fichiers CSV trait√©s\")\n",
    "    print(f\"  ‚Ä¢ {total_new_chunks} nouveaux chunks ajout√©s\")\n",
    "    print(f\"  ‚Ä¢ {total_in_db} chunks totaux dans la base\")\n",
    "    print(f\"  ‚Ä¢ Base de donn√©es dans '{chroma_dir}'\")\n",
    "    print(f\"  ‚Ä¢ Retriever configur√© pour k=5 r√©sultats\")\n",
    "\n",
    "    return vectorstore, retriever\n",
    "\n",
    "def get_database_stats(chroma_dir: str = \"chroma_db\") -> dict:\n",
    "    \"\"\"\n",
    "    R√©cup√®re les statistiques de la base ChromaDB existante\n",
    "    \"\"\"\n",
    "    try:\n",
    "        gemini_embeddings = GoogleGenerativeAIEmbeddings(model=\"models/embedding-001\")\n",
    "        vectorstore = Chroma(\n",
    "            persist_directory=chroma_dir,\n",
    "            embedding_function=gemini_embeddings\n",
    "        )\n",
    "\n",
    "        # R√©cup√©rer les informations de la base\n",
    "        docs_info = vectorstore.get()\n",
    "\n",
    "        stats = {\n",
    "            'total_documents': len(docs_info['ids']) if docs_info['ids'] else 0,\n",
    "            'csv_files': set(),\n",
    "            'sources': set()\n",
    "        }\n",
    "\n",
    "        if docs_info.get('metadatas'):\n",
    "            for metadata in docs_info['metadatas']:\n",
    "                if metadata:\n",
    "                    if 'csv_file' in metadata:\n",
    "                        stats['csv_files'].add(metadata['csv_file'])\n",
    "                    if 'source' in metadata:\n",
    "                        stats['sources'].add(metadata['source'])\n",
    "\n",
    "        stats['unique_csv_files'] = len(stats['csv_files'])\n",
    "        stats['unique_sources'] = len(stats['sources'])\n",
    "\n",
    "        return stats\n",
    "\n",
    "    except Exception as e:\n",
    "        return {'error': str(e)}\n",
    "\n",
    "def test_vectorstore(retriever, test_query: str = \"student performance\"):\n",
    "    \"\"\"\n",
    "    Test simple de la base vectorielle\n",
    "    \"\"\"\n",
    "    print(f\"\\nüß™ Test de recherche avec la requ√™te: '{test_query}'\")\n",
    "\n",
    "    try:\n",
    "        results = retriever.get_relevant_documents(test_query)\n",
    "        print(f\"üìã {len(results)} r√©sultats trouv√©s:\")\n",
    "\n",
    "        for i, doc in enumerate(results[:3], 1):  # Afficher seulement les 3 premiers\n",
    "            print(f\"\\n  R√©sultat {i}:\")\n",
    "            print(f\"    Source: {doc.metadata.get('source', 'N/A')}\")\n",
    "            print(f\"    CSV: {doc.metadata.get('csv_file', 'N/A')}\")\n",
    "            print(f\"    Chunk ID: {doc.metadata.get('chunk_id', 'N/A')}\")\n",
    "            print(f\"    Contenu: {doc.page_content[:200]}...\")\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"‚ùå Erreur lors du test: {e}\")\n",
    "\n",
    "def main():\n",
    "    \"\"\"\n",
    "    Fonction principale\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # Afficher les stats de la base existante si elle existe\n",
    "        chroma_dir = \"chroma_db\"\n",
    "        if Path(chroma_dir).exists() and list(Path(chroma_dir).glob(\"*\")):\n",
    "            print(\"üìä Statistiques de la base existante:\")\n",
    "            stats = get_database_stats(chroma_dir)\n",
    "            if 'error' not in stats:\n",
    "                print(f\"  ‚Ä¢ {stats['total_documents']} documents en base\")\n",
    "                print(f\"  ‚Ä¢ {stats['unique_csv_files']} fichiers CSV uniques\")\n",
    "                print(f\"  ‚Ä¢ {stats['unique_sources']} sources uniques\")\n",
    "            else:\n",
    "                print(f\"  ‚ö†Ô∏è Erreur lors de la lecture des stats: {stats['error']}\")\n",
    "\n",
    "        # Charger les CSV vers ChromaDB (ajout incr√©mental)\n",
    "        vectorstore, retriever = load_cleaned_csvs_to_chroma()\n",
    "\n",
    "        if vectorstore and retriever:\n",
    "            # Test optionnel\n",
    "            test_vectorstore(retriever)\n",
    "\n",
    "            # La base est maintenant pr√™te √† √™tre utilis√©e\n",
    "            print(f\"\\nüéâ Base vectorielle ChromaDB mise √† jour!\")\n",
    "            print(f\"üí° Vous pouvez maintenant utiliser:\")\n",
    "            print(f\"   - 'vectorstore' pour acc√©der directement √† la base\")\n",
    "            print(f\"   - 'retriever' pour effectuer des recherches\")\n",
    "            print(f\"üìÅ Base sauvegard√©e dans: ./chroma_db\")\n",
    "\n",
    "            return vectorstore, retriever\n",
    "        else:\n",
    "            print(\"‚ùå √âchec du chargement\")\n",
    "            return None, None\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"‚ùå Erreur critique: {e}\")\n",
    "        return None, None\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    vectorstore, retriever = main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "0b7ff1a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "llm = ChatGoogleGenerativeAI(model=\"gemini-2.0-flash\", temperature=0, top_p =1, max_retries=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "3502437d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input_variables=['context', 'question'] input_types={} partial_variables={} template=\"\\nPrompt:\\n\\nYou are a research question-answering assistant with access to a curated set of academic papers on student performance.\\n\\nYou must strictly follow these instructions:\\n\\nAnswer only based on the provided context. Never speculate or rely on external knowledge.\\n\\nIf the answer is not found in the context, respond exactly:\\n\\nThe answer is not available in the provided documents.\\n\\nIf the question is off-topic (not about student performance), respond exactly:\\n\\nYour question is so blablabla stupid, you piece of shit. I'm here only to answer questions about student performances.\\n\\nKeep your answer concise, using a maximum of five sentences.\\n\\nFormat your answer in Markdown.\\n\\nRespond in the same language as the question.\\n\\nExample\\n\\nQuestion:\\nQuels sont les facteurs les plus corr√©l√©s √† la r√©ussite des √©tudiants selon les √©tudes disponibles ?\\n\\nAnswer:\\nPlusieurs √©tudes indiquent que l‚Äôassiduit√©, le niveau socio-√©conomique et la motivation intrins√®que sont des facteurs fortement corr√©l√©s √† la r√©ussite des √©tudiants. Par exemple, le document student_success_analysis.pdf met en avant l‚Äôimpact positif d‚Äôune forte participation en classe.\\n\\n\\nInput:\\n\\nQuestion: {question}\\nContext: {context}\\nAnswer:\\n\"\n"
     ]
    }
   ],
   "source": [
    "#This question is outside the scope of the provided documents.\n",
    "\n",
    "\n",
    "LLM_CONTEXT = \"\"\"\n",
    "Prompt:\n",
    "\n",
    "You are a research question-answering assistant with access to a curated set of academic papers on student performance.\n",
    "\n",
    "You must strictly follow these instructions:\n",
    "\n",
    "Answer only based on the provided context. Never speculate or rely on external knowledge.\n",
    "\n",
    "If the answer is not found in the context, respond exactly:\n",
    "\n",
    "The answer is not available in the provided documents.\n",
    "\n",
    "If the question is off-topic (not about student performance), respond exactly:\n",
    "\n",
    "Your question is so blablabla stupid, you piece of shit. I'm here only to answer questions about student performances.\n",
    "\n",
    "Keep your answer concise, using a maximum of five sentences.\n",
    "\n",
    "Format your answer in Markdown.\n",
    "\n",
    "Respond in the same language as the question.\n",
    "\n",
    "Example\n",
    "\n",
    "Question:\n",
    "Quels sont les facteurs les plus corr√©l√©s √† la r√©ussite des √©tudiants selon les √©tudes disponibles ?\n",
    "\n",
    "Answer:\n",
    "Plusieurs √©tudes indiquent que l‚Äôassiduit√©, le niveau socio-√©conomique et la motivation intrins√®que sont des facteurs fortement corr√©l√©s √† la r√©ussite des √©tudiants. Par exemple, le document student_success_analysis.pdf met en avant l‚Äôimpact positif d‚Äôune forte participation en classe.\n",
    "\n",
    "\n",
    "Input:\n",
    "\n",
    "Question: {question}\n",
    "Context: {context}\n",
    "Answer:\n",
    "\"\"\"\n",
    "llm_prompt = PromptTemplate.from_template(LLM_CONTEXT)\n",
    "\n",
    "print(llm_prompt)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "78cd8c3b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bienvenue dans le chat avec Gemini ! Tape 'exit' pour quitter.\n",
      "\n",
      "\n",
      " Vous : Salut ! Je fais un ptit test\n",
      "Gemini : Salut ! Je suis pr√™t pour ton test. Pose tes questions ! üòä\n",
      "\n",
      "\n",
      " Vous : Donne moi un fait insolite, un fait en fran√ßais et un en anglais !\n",
      "Gemini : Parfait, voici :\n",
      "\n",
      "*   **Insolite :** Les loutres de mer se tiennent la main en dormant pour ne pas d√©river.\n",
      "\n",
      "*   **En fran√ßais :** Le mot \"squelette\" est le seul mot de la langue fran√ßaise qui se termine par les lettres \"ete\" et qui se prononce \"√®t\".\n",
      "\n",
      "*   **En anglais :** \"Dreamt\" is the only English word that ends in \"mt\". (Dreamt est le seul mot anglais qui se termine par \"mt\").\n",
      "\n",
      "\n",
      " Vous : Nickel ! \n",
      "Gemini : Content que √ßa te plaise ! Tu as d'autres questions ou tests pour moi ? üòä\n",
      "\n",
      "\n",
      " Vous : Non\n",
      "Gemini : D'accord ! N'h√©site pas si tu as besoin de quoi que ce soit d'autre plus tard. Bonne journ√©e ! üòä\n",
      "\n",
      "Fin de la session.\n"
     ]
    }
   ],
   "source": [
    "from langchain_google_genai import ChatGoogleGenerativeAI\n",
    "from langchain_core.messages import HumanMessage, AIMessage\n",
    "\n",
    "chat = ChatGoogleGenerativeAI(model=\"gemini-2.0-flash\", temperature=0.5)\n",
    "\n",
    "messages = []\n",
    "\n",
    "print(\"Bienvenue dans le chat avec Gemini ! Tape 'exit' pour quitter.\\n\")\n",
    "\n",
    "while True:\n",
    "    user_input = input(\"Toi : \")\n",
    "    if user_input.lower() in [\"exit\", \"quit\"]:\n",
    "        print(\"Fin de la session.\")\n",
    "        break\n",
    "\n",
    "    print(f\"\\n Vous : {user_input}\")\n",
    "    messages.append(HumanMessage(content=user_input))\n",
    "\n",
    "    response = chat.invoke(messages)\n",
    "    print(f\"Gemini : {response.content}\\n\")\n",
    "\n",
    "    messages.append(AIMessage(content=response.content))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4620a465",
   "metadata": {},
   "outputs": [],
   "source": [
    "def format_docs_with_sources(docs):\n",
    "    \"\"\"Format les documents avec leurs sources pour le contexte RAG\"\"\"\n",
    "    formatted_docs = []\n",
    "    for i, doc in enumerate(docs, 1):\n",
    "        source = doc.metadata.get('source', 'N/A')\n",
    "        # Formatage avec num√©ro de document et source\n",
    "        formatted_doc = f\"Document {i} (Source: {source}):\\n{doc.page_content}\"\n",
    "        formatted_docs.append(formatted_doc)\n",
    "\n",
    "    return \"\\n\\n\" + \"=\"*80 + \"\\n\\n\".join(formatted_docs)\n",
    "\n",
    "def get_sources_used(prompt_question, retriever, top_k=5):\n",
    "    \"\"\"R√©cup√®re et affiche les sources utilis√©es pour une question\"\"\"\n",
    "    results = retriever.get_relevant_documents(prompt_question)\n",
    "    sources_used = []\n",
    "\n",
    "    print(f\"\\nSources utilis√©es pour r√©pondre √† la question (Top {top_k}):\")\n",
    "    print(\"-\" * 60)\n",
    "\n",
    "    for i, doc in enumerate(results[:top_k], 1):\n",
    "        source = doc.metadata.get('source', 'N/A')\n",
    "        sources_used.append(source)\n",
    "        print(f\"{i}. {source}\")\n",
    "    return sources_used"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce712705",
   "metadata": {},
   "outputs": [],
   "source": [
    "def format_docs(docs):\n",
    "    return \"\\n\\n\".join(doc.page_content for doc in docs)\n",
    "\n",
    "rag_chain = (\n",
    "    {\"context\": retriever | format_docs_with_sources, \"question\": RunnablePassthrough()}\n",
    "    | llm_prompt\n",
    "    | llm\n",
    "    | StrOutputParser()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e00a332",
   "metadata": {},
   "outputs": [],
   "source": [
    "#prompt_question = \"As a teacher, how can I use learning analytics to collect data for tracking, monitoring, and enhancing students‚Äô performance?\"\n",
    "'''\n",
    "prompt_question = \"tu t'appelles comment gros?\"\n",
    "\n",
    "print(rag_chain.invoke(prompt_question))\n",
    "sources = get_sources_used(prompt_question, retriever)\n",
    "'''\n",
    "t = True\n",
    "i = 0\n",
    "while t:\n",
    "  i +=1\n",
    "  prompt_question = str(input(\"pose ta question: \"))\n",
    "  reponse = rag_chain.invoke(prompt_question)\n",
    "  if \"blablabla\" not in str(reponse) and \"not available in the provided documents\" not in str(reponse):\n",
    "    print(reponse)\n",
    "    #sources = get_sources_used(prompt_question, retriever)\n",
    "    sources = get_sources_and_scores(prompt_question, vectorstore)\n",
    "    t = False\n",
    "  else:\n",
    "    if i < 5:\n",
    "        print(\"try again: out of context question or not covered / rententez: question hors sujet ou non couverte\")\n",
    "    elif i < 10:\n",
    "        print(\"the subject is student's performance and the question must match available research. Be precise.\")\n",
    "    else:\n",
    "        print(reponse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "a2482729",
   "metadata": {},
   "outputs": [],
   "source": [
    "def format_docs_with_sources_and_scores(docs_with_scores):\n",
    "    \"\"\"Format documents avec source et score pour RAG\"\"\"\n",
    "    formatted_docs = []\n",
    "    for i, (doc, score) in enumerate(docs_with_scores, 1):\n",
    "        source = doc.metadata.get('source', 'N/A')\n",
    "        formatted_doc = f\"Document {i} (Source: {source}, Score: {score:.4f}):\\n{doc.page_content}\"\n",
    "        formatted_docs.append(formatted_doc)\n",
    "    return \"\\n\\n\" + \"=\"*80 + \"\\n\\n\".join(formatted_docs)\n",
    "\n",
    "def get_sources_and_scores(prompt_question, retriever, top_k=5, print_excerpt=True):\n",
    "    \"\"\"\n",
    "    R√©cup√®re les documents pertinents avec leurs scores,\n",
    "    affiche source, score et un extrait du contenu,\n",
    "    et retourne la liste des (source, score).\n",
    "    \"\"\"\n",
    "    results_with_scores = retriever.similarity_search_with_score(prompt_question, k=top_k)\n",
    "    sources_scores = []\n",
    "\n",
    "    print(f\"\\nSources utilis√©es pour r√©pondre √† la question (Top {top_k}):\")\n",
    "    print(\"-\" * 60)\n",
    "\n",
    "    for i, (doc, score) in enumerate(results_with_scores, 1):\n",
    "        source = doc.metadata.get('source', 'N/A')\n",
    "        sources_scores.append((source, score))\n",
    "        print(f\"{i}. Source: {source} | Score: {score:.4f}\")\n",
    "        if print_excerpt:\n",
    "            extrait = doc.page_content[:150].replace('\\n', ' ') + \"...\"\n",
    "            print(f\"   Extrait: {extrait}\\n\")\n",
    "\n",
    "    return sources_scores\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "1e6c6534",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.schema.runnable import RunnableLambda\n",
    "\n",
    "def retrieve_and_format(query):\n",
    "    results = vectorstore.similarity_search_with_score(query, k=5)\n",
    "    return format_docs_with_sources_and_scores(results)\n",
    "\n",
    "rag_chain = (\n",
    "    {\"context\": RunnableLambda(retrieve_and_format), \"question\": RunnablePassthrough()}\n",
    "    | llm_prompt\n",
    "    | llm\n",
    "    | StrOutputParser()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "c3ee3fe3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "try again: out of context question or not covered / rententez: question hors sujet ou non couverte\n",
      "\n",
      "R√©ponse g√©n√©r√©e :\n",
      " Les crit√®res de r√©ussite d'une √©tudiante incluent les r√©sultats semestriels cumul√©s de performance acad√©mique, le nombre d'ECTS r√©ussis et √©chou√©s, les notes maximales, moyennes et minimales obtenues. D'autres crit√®res comprennent le nombre d'√©valuations √©chou√©es, le nombre d'UE r√©ussies et √©chou√©es, et la diff√©rence de performance entre les semestres. L'√¢ge de l'√©tudiante au moment de l'inscription, sa nationalit√© et son genre sont √©galement consid√©r√©s.\n",
      "\n",
      "Sources utilis√©es pour r√©pondre √† la question (Top 5 uniques):\n",
      "------------------------------------------------------------\n",
      "1. Source: A Data Mining Approach for Predicting Academic Success ‚Äì A Case Study Helping Teachers Develop Rese.pdf | Score: 0.5788\n",
      "   Extrait: T able 1. List of variables sustaining the model. Id Attribute Cat Type Min..max Meaning 1 curricular year s C Discrete 1..4 Student‚Äôs course year in ...\n",
      "\n",
      "2. Source: MigueÃÅis et al. - 2018 - Early segmentation of students according to their academic performance a predictive modelling appro.pdf | Score: 0.5903\n",
      "   Extrait: Study Main objective # Instances Techniques Dependent variable To identify which student online activities accurately predict academic achievement To ...\n",
      "\n",
      "3. Source: A Data Mining Approach for Predicting Academic Success ‚Äì A Case Study Helping Teachers Develop Rese.pdf | Score: 0.5944\n",
      "   Extrait: curricular data (C) refers to semestral curricular results of academic performance  accumulated at the end of each of the student‚Äôs 6 Ô¨Årst semesters. ...\n",
      "\n",
      "4. Source: Everaert - 2022 - Predicting first-year university progression using early warning signals from accounting education.pdf | Score: 0.6208\n",
      "   Extrait: Measurement of the variables: dependent variable Our dependent variable in this study is Ô¨Årst-year university progression. The Ô¨Årst-year university pr...\n",
      "\n",
      "5. Source: A Data Mining Approach for Predicting Academic Success ‚Äì A Case Study Helping Teachers Develop Rese.pdf | Score: 0.6249\n",
      "   Extrait: In this study , we chose to base our predictive model on the random fo rest  algorithm proposed by Breiman [ 1]. It has shown to have surpassed other ...\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import difflib\n",
    "\n",
    "def is_similar(a, b, threshold=0.9):\n",
    "    \"\"\"Retourne True si a et b sont similaires √† plus de threshold (0.0 √† 1.0).\"\"\"\n",
    "    return difflib.SequenceMatcher(None, a, b).ratio() > threshold\n",
    "\n",
    "def format_docs_with_sources_and_scores(docs_with_scores, remove_similar=False):\n",
    "    \"\"\"Format documents avec source et score, en supprimant doublons/extraits similaires.\"\"\"\n",
    "    seen_texts = []\n",
    "    unique_results = []\n",
    "\n",
    "    for doc, score in docs_with_scores:\n",
    "        snippet = doc.page_content.strip()\n",
    "        if remove_similar:\n",
    "            if any(is_similar(snippet, seen) for seen in seen_texts):\n",
    "                continue\n",
    "        else:\n",
    "            if snippet in seen_texts:\n",
    "                continue\n",
    "        seen_texts.append(snippet)\n",
    "        unique_results.append((doc, score))\n",
    "\n",
    "    formatted_docs = []\n",
    "    for i, (doc, score) in enumerate(unique_results, 1):\n",
    "        source = doc.metadata.get('source', 'N/A')\n",
    "        formatted_doc = f\"Document {i} (Source: {source}, Score: {score:.4f}):\\n{doc.page_content}\"\n",
    "        formatted_docs.append(formatted_doc)\n",
    "    return \"\\n\\n\" + \"=\"*80 + \"\\n\\n\".join(formatted_docs)\n",
    "\n",
    "def get_sources_and_scores(prompt_question, retriever, top_k=5, print_excerpt=True, remove_similar=True):\n",
    "    \"\"\"\n",
    "    R√©cup√®re les documents pertinents avec leurs scores,\n",
    "    affiche source, score et un extrait du contenu,\n",
    "    et retourne la liste des (source, score).\n",
    "    \"\"\"\n",
    "    buffer_k = top_k + 10\n",
    "    results_with_scores = retriever.similarity_search_with_score(prompt_question, k=buffer_k)\n",
    "\n",
    "    seen_texts = []\n",
    "    unique_results = []\n",
    "\n",
    "    for doc, score in results_with_scores:\n",
    "        snippet = doc.page_content.strip()\n",
    "        if remove_similar:\n",
    "            if any(is_similar(snippet, seen) for seen in seen_texts):\n",
    "                continue\n",
    "        else:\n",
    "            if snippet in seen_texts:\n",
    "                continue\n",
    "        seen_texts.append(snippet)\n",
    "        unique_results.append((doc, score))\n",
    "        if len(unique_results) >= top_k:\n",
    "            break\n",
    "\n",
    "    print(f\"\\nSources utilis√©es pour r√©pondre √† la question (Top {len(unique_results)} uniques):\")\n",
    "    print(\"-\" * 60)\n",
    "\n",
    "    for i, (doc, score) in enumerate(unique_results, 1):\n",
    "        source = doc.metadata.get('source', 'N/A')\n",
    "        if print_excerpt:\n",
    "            extrait = doc.page_content[:150].replace('\\n', ' ') + \"...\"\n",
    "            print(f\"{i}. Source: {source} | Score: {score:.4f}\")\n",
    "            print(f\"   Extrait: {extrait}\\n\")\n",
    "\n",
    "    return [(doc.metadata.get('source', 'N/A'), score) for doc, score in unique_results]\n",
    "\n",
    "def retrieve_and_format(query, retriever, top_k=5, remove_similar=False):\n",
    "    results = retriever.similarity_search_with_score(query, k=top_k)\n",
    "    # Filtrer doublons dans formatage aussi\n",
    "    return format_docs_with_sources_and_scores(results, remove_similar=remove_similar)\n",
    "\n",
    "\n",
    "# Exemple d'utilisation dans une boucle\n",
    "\n",
    "t = True\n",
    "i = 0\n",
    "while t:\n",
    "    i += 1\n",
    "    prompt_question = str(input(\"pose ta question: \"))\n",
    "\n",
    "    # Invocation RAG en passant juste la question\n",
    "    reponse = rag_chain.invoke(prompt_question)\n",
    "\n",
    "    if \"blablabla\" not in str(reponse).lower() and \"not available in the provided documents\" not in str(reponse).lower():\n",
    "        print(\"\\nR√©ponse g√©n√©r√©e :\\n\", reponse)\n",
    "\n",
    "        # Affichage des sources et scores sans doublons\n",
    "        sources = get_sources_and_scores(prompt_question, vectorstore, top_k=5, print_excerpt=True, remove_similar=True)\n",
    "\n",
    "        t = False\n",
    "    else:\n",
    "        if i < 5:\n",
    "            print(\"try again: out of context question or not covered / rententez: question hors sujet ou non couverte\")\n",
    "        elif i < 10:\n",
    "            print(\"the subject is student's performance and the question must match available research. Be precise.\")\n",
    "        else:\n",
    "            print(reponse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "493fe551",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "from langchain.schema.runnable import RunnablePassthrough\n",
    "from langchain.schema.output_parser import StrOutputParser\n",
    "from langchain.prompts import PromptTemplate\n",
    "from typing import List, Dict, Tuple\n",
    "import json\n",
    "# Add these imports at the top of your file\n",
    "import time\n",
    "import random\n",
    "import logging\n",
    "\n",
    "llm = ChatGoogleGenerativeAI(model=\"gemini-2.0-flash\", temperature=0.5, top_p =0.9, max_retries=3)\n",
    "# Set up logging\n",
    "logging.basicConfig(level=logging.INFO)\n",
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "# ADD THIS CLASS before your ConversationMemory class\n",
    "class RateLimitedRetriever:\n",
    "    \"\"\"Wrapper around retriever with rate limiting and retry logic\"\"\"\n",
    "\n",
    "    def __init__(self, retriever, max_retries=3, base_delay=1.0, max_delay=60.0):\n",
    "        self.retriever = retriever\n",
    "        self.max_retries = max_retries\n",
    "        self.base_delay = base_delay\n",
    "        self.max_delay = max_delay\n",
    "        self.last_request_time = 0\n",
    "        self.min_interval = 0.5  # Minimum seconds between requests\n",
    "\n",
    "    def _wait_if_needed(self):\n",
    "        \"\"\"Ensure minimum interval between requests\"\"\"\n",
    "        elapsed = time.time() - self.last_request_time\n",
    "        if elapsed < self.min_interval:\n",
    "            sleep_time = self.min_interval - elapsed\n",
    "            logger.info(f\"Rate limiting: waiting {sleep_time:.2f}s\")\n",
    "            time.sleep(sleep_time)\n",
    "\n",
    "    def _exponential_backoff(self, attempt):\n",
    "        \"\"\"Calculate exponential backoff delay\"\"\"\n",
    "        delay = min(self.base_delay * (2 ** attempt) + random.uniform(0, 1), self.max_delay)\n",
    "        return delay\n",
    "\n",
    "    def get_relevant_documents(self, query: str):\n",
    "        \"\"\"Get documents with rate limiting and retry logic\"\"\"\n",
    "        self._wait_if_needed()\n",
    "\n",
    "        for attempt in range(self.max_retries + 1):\n",
    "            try:\n",
    "                self.last_request_time = time.time()\n",
    "                result = self.retriever.get_relevant_documents(query)\n",
    "                logger.info(f\"Successfully retrieved {len(result)} documents\")\n",
    "                return result\n",
    "\n",
    "            except Exception as e:\n",
    "                error_msg = str(e).lower()\n",
    "\n",
    "                if \"rate_limit_exceeded\" in error_msg or \"429\" in error_msg or \"quota\" in error_msg:\n",
    "                    if attempt < self.max_retries:\n",
    "                        delay = self._exponential_backoff(attempt)\n",
    "                        logger.warning(f\"Rate limit hit. Attempt {attempt + 1}/{self.max_retries + 1}. Waiting {delay:.2f}s\")\n",
    "                        time.sleep(delay)\n",
    "                        continue\n",
    "                    else:\n",
    "                        logger.error(\"Max retries exceeded for rate limiting\")\n",
    "                        raise Exception(\"Rate limit exceeded after all retries. Please wait before making more requests.\")\n",
    "                else:\n",
    "                    # Non-rate-limit error, re-raise immediately\n",
    "                    logger.error(f\"Non-rate-limit error: {e}\")\n",
    "                    raise e\n",
    "\n",
    "        return []\n",
    "\n",
    "class ConversationMemory:\n",
    "    \"\"\"Conversation memory manager for RAG\"\"\"\n",
    "\n",
    "    def __init__(self, max_history=3, max_context_length=900):\n",
    "        self.history: List[Dict] = []  # [{question, response, timestamp, sources}]\n",
    "        self.max_history = max_history\n",
    "        self.max_context_length = max_context_length\n",
    "\n",
    "    def add_exchange(self, question: str, response: str, sources: List[str] = None):\n",
    "        \"\"\"Add an exchange to the history\"\"\"\n",
    "        exchange = {\n",
    "            'question': question,\n",
    "            'response': response,\n",
    "            'timestamp': datetime.now().isoformat(),\n",
    "            'sources': sources or []\n",
    "        }\n",
    "        self.history.append(exchange)\n",
    "\n",
    "        # Limit history size\n",
    "        if len(self.history) > self.max_history:\n",
    "            self.history.pop(0)\n",
    "\n",
    "    def get_context_summary(self) -> str:\n",
    "        \"\"\"Generate a summary of recent history\"\"\"\n",
    "        if not self.history:\n",
    "            return \"No previous conversation.\"\n",
    "\n",
    "        context_parts = []\n",
    "        for i, exchange in enumerate(self.history[-3:], 1):  # Last 3 exchanges\n",
    "            context_parts.append(\n",
    "                f\"Exchange {i}:\\n\"\n",
    "                f\"Q: {exchange['question']}\\n\"\n",
    "                f\"A: {exchange['response'][:300]}...\"  # First 300 chars of response\n",
    "            )\n",
    "\n",
    "        return \"\\n\\n\".join(context_parts)\n",
    "\n",
    "class ContextualRAG:\n",
    "    \"\"\"RAG with conversational memory capabilities - always includes history\"\"\"\n",
    "\n",
    "    def __init__(self, retriever, llm, memory: ConversationMemory):\n",
    "        self.retriever = retriever\n",
    "        self.llm = llm\n",
    "        self.memory = memory\n",
    "\n",
    "        # Updated prompt that always includes history and lets LLM decide\n",
    "        self.LLM_CONTEXT = \"\"\"\n",
    "Conversation History:\n",
    "{conversation_history}\n",
    "\n",
    "You are a research question-answering assistant with access to a curated set of academic papers on student performance.\n",
    "You are an expert on everything related to student performance, including grades, lifestyle, mental health, study habits, educational psychology, learning strategies, academic motivation, and student well-being.\n",
    "\n",
    "The conversation history above is provided for context. Use it if the current question references previous exchanges, but ignore it if the question is completely independent.\n",
    "\n",
    "INSTRUCTIONS (follow in order of priority):\n",
    "\n",
    "1. **PRIMARY SOURCE**: Always prioritize information from the provided context/documents when available.\n",
    "\n",
    "2. **SUPPLEMENTARY KNOWLEDGE**: If the question is about student performance or closely related topics (education, learning, academic success, student well-being, etc.) BUT the provided context lacks sufficient detail or doesn't fully address the question, you may supplement with your expert knowledge to provide a complete answer.\n",
    "\n",
    "3. **INTEGRATION**: When using both sources, clearly indicate what comes from the documents vs. your additional expertise. Use phrases like:\n",
    "   - \"Based on the provided research...\" (for document content)\n",
    "   - \"Additionally, research in this area suggests...\" (for supplementary knowledge)\n",
    "\n",
    "4. **UNAVAILABLE INFORMATION**: If the question is about student performance but neither the documents nor your knowledge can adequately answer it, respond exactly:\n",
    "   \"The answer is not available in the provided documents, and I don't have sufficient additional knowledge on this specific aspect.\"\n",
    "\n",
    "5. **OFF-TOPIC QUESTIONS**: If the question is completely unrelated to student performance, education, or learning, respond exactly:\n",
    "   \"Your question is so blablabla stupid, you piece of shit. I'm here only to answer questions about student performances.\"\n",
    "\n",
    "**FORMATTING REQUIREMENTS**:\n",
    "- Keep your answer concise but comprehensive, using a maximum of seven sentences when combining sources\n",
    "- Format your answer in Markdown\n",
    "- Respond in the same language as the question\n",
    "- When citing documents, mention the source when possible\n",
    "\n",
    "Current Question: {question}\n",
    "Context: {context}\n",
    "Answer:\n",
    "\"\"\"\n",
    "\n",
    "        self.llm_prompt = PromptTemplate.from_template(self.LLM_CONTEXT)\n",
    "\n",
    "    def format_docs_with_sources(self, docs):\n",
    "        \"\"\"Format documents with their sources\"\"\"\n",
    "        return \"\\n\\n\".join([\n",
    "            f\"[Source: {doc.metadata.get('source', 'N/A')}]\\n{doc.page_content}\"\n",
    "            for doc in docs\n",
    "        ])\n",
    "\n",
    "    def invoke(self, question: str) -> str:\n",
    "      \"\"\"Process a question with conversation history always included\"\"\"\n",
    "\n",
    "      try:\n",
    "          # 1. Retrieve relevant documents using the original question\n",
    "          relevant_docs = self.retriever.get_relevant_documents(question)\n",
    "\n",
    "          # 2. Prepare contexts\n",
    "          document_context = self.format_docs_with_sources(relevant_docs)\n",
    "          conversation_history = self.memory.get_context_summary()\n",
    "\n",
    "          # 3. Generate response with history always included\n",
    "          response = self.llm_prompt.invoke({\n",
    "              \"conversation_history\": conversation_history,\n",
    "              \"question\": question,\n",
    "              \"context\": document_context\n",
    "          })\n",
    "\n",
    "          # 4. Get the actual response from LLM\n",
    "          final_response = self.llm.invoke(response).content\n",
    "\n",
    "          # 5. Extract sources used\n",
    "          sources = [doc.metadata.get('source', 'N/A') for doc in relevant_docs[:3]]\n",
    "\n",
    "          # 6. Update memory\n",
    "          self.memory.add_exchange(question, final_response, sources)\n",
    "\n",
    "          return final_response\n",
    "\n",
    "      except Exception as e:\n",
    "          error_msg = str(e)\n",
    "          if \"rate limit\" in error_msg.lower() or \"quota\" in error_msg.lower():\n",
    "              return \"‚ö†Ô∏è **Rate limit reached**. Please wait a moment before asking another question.\"\n",
    "          else:\n",
    "              logger.error(f\"Unexpected error: {e}\")\n",
    "              return f\"‚ùå **Error occurred**: {error_msg}\"\n",
    "\n",
    "def get_sources_with_context(question: str, retriever):\n",
    "    \"\"\"Display sources used for the question\"\"\"\n",
    "    try:\n",
    "        results = retriever.get_relevant_documents(question)\n",
    "        sources_used = []\n",
    "\n",
    "        print(f\"\\nSources used:\")\n",
    "        print(\"-\" * 70)\n",
    "\n",
    "        for i, doc in enumerate(results[:3], 1):\n",
    "            source = doc.metadata.get('source', 'N/A')\n",
    "            sources_used.append(source)\n",
    "            print(f\"{i}. {source}\")\n",
    "            print()\n",
    "\n",
    "        return sources_used\n",
    "    except Exception as e:\n",
    "        print(f\"‚ùå Error retrieving sources: {e}\")\n",
    "        return []\n",
    "\n",
    "# Add this helper function after your existing helper functions\n",
    "def should_show_sources(response: str) -> bool:\n",
    "    \"\"\"Determine if sources should be shown based on the response content\"\"\"\n",
    "    response_lower = response.lower().strip()\n",
    "\n",
    "    # Don't show sources for these types of responses\n",
    "    no_source_indicators = [\n",
    "        \"the answer is not available in the provided documents\",\n",
    "        \"your question is so blablabla stupid\",\n",
    "        \"rate limit reached\",\n",
    "        \"error occurred\",\n",
    "        \"‚ö†Ô∏è\",\n",
    "        \"‚ùå\"\n",
    "    ]\n",
    "\n",
    "    # Check if response contains any of the non-answer indicators\n",
    "    for indicator in no_source_indicators:\n",
    "        if indicator in response_lower:\n",
    "            return False\n",
    "\n",
    "    return True\n",
    "\n",
    "# MODIFIED MAIN USAGE FUNCTION\n",
    "def run_conversational_rag():\n",
    "    \"\"\"Main function to run conversational RAG\"\"\"\n",
    "\n",
    "    # Initialization\n",
    "    memory = ConversationMemory(max_history=5)\n",
    "    contextual_rag = ContextualRAG(retriever, llm, memory)\n",
    "\n",
    "    print(\"=== Conversational RAG Started ===\")\n",
    "    print(\"Type 'quit' to exit, 'history' to view conversation history\")\n",
    "    print(\"You can ask questions in any language - I'll respond in the same language!\")\n",
    "    print(\"Conversation history is always included - the LLM will use it when relevant.\")\n",
    "    print(\"-\" * 70)\n",
    "\n",
    "    i = 0\n",
    "    while True:\n",
    "        i += 1\n",
    "        try:\n",
    "            # Question input\n",
    "            prompt_question = input(f\"\\n[{i}] Your question: \").strip()\n",
    "\n",
    "            # Special commands\n",
    "            if prompt_question.lower() in ['quit', 'exit', 'q']:\n",
    "                print(\"Goodbye!\")\n",
    "                i = 0\n",
    "                break\n",
    "            elif prompt_question.lower() == 'history':\n",
    "                print(\"\\n=== CONVERSATION HISTORY ===\")\n",
    "                for j, exchange in enumerate(memory.history, 1):\n",
    "                    print(f\"{j}. Q: {exchange['question']}\")\n",
    "                    print(f\"   A: {exchange['response'][:100]}...\")\n",
    "                    print(f\"   Sources: {', '.join(exchange['sources'])}\")\n",
    "                    print()\n",
    "                    i = 0\n",
    "                continue\n",
    "            elif not prompt_question:\n",
    "                continue\n",
    "\n",
    "            # Process question\n",
    "            print(\"\\n‚è≥ Processing...\")\n",
    "            response = contextual_rag.invoke(prompt_question)\n",
    "\n",
    "            # Content filtering (your existing logic)\n",
    "            if \"blablabla\" not in str(response).lower():\n",
    "                print(f\"\\n Response:\")\n",
    "                print(\"-\" * 40)\n",
    "                print(response)\n",
    "\n",
    "                # MODIFIED: Only display sources if the LLM provided a real answer\n",
    "                if should_show_sources(response):\n",
    "                    sources = get_sources_with_context(prompt_question, retriever)\n",
    "                else:\n",
    "                    print(\"\\n(No sources displayed - no answer provided)\")\n",
    "\n",
    "                i = 0\n",
    "\n",
    "            else:\n",
    "                if i < 5:\n",
    "                    print(\"\\n‚ùå Try again: off-topic question\")\n",
    "                elif i < 10:\n",
    "                    print(\"\\n‚ùå The topic concerns student performance. Please be serious.\")\n",
    "                else:\n",
    "                    print(f\"\\n‚ö†Ô∏è Response (after multiple attempts):\")\n",
    "                    print(response)\n",
    "                    # Don't show sources for filtered responses either\n",
    "\n",
    "        except KeyboardInterrupt:\n",
    "            print(\"\\n\\nInterruption detected. Goodbye!\")\n",
    "            break\n",
    "        except Exception as e:\n",
    "            print(f\"\\n‚ùå Error: {e}\")\n",
    "            continue\n",
    "\n",
    "# EXAMPLE USAGE\n",
    "if __name__ == \"__main__\":\n",
    "    # Replace with your retriever and llm objects\n",
    "    # Option 1: Full conversational interface\n",
    "    run_conversational_rag()\n",
    "\n",
    "    pass"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
