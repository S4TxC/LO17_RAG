source,page_content,cleaned_page_content
"2020 - Using clickstream data to measure, understand, and support self-regulated learning in online courses.pdf","Contents lists available at ScienceDirect
The Internet and Higher Education
journal homepage: www.elsevier.com/locate/iheduc
Using clickstream data to measure, understand, and support self-regulated
learning in online courses
Qiujie Lia,b,⁎
, Rachel Bakera, Mark Warschauera
a UniversityofCalifornia,Irvine–SchoolofEducation,3000Education,Irvine,CA,92697,UnitedStatesofAmerica
b NYU-LearningAnalytics ResearchNetwork(NYU-LEARN),NewYorkUniversity,NewYork,NY 10003,UnitedStatesofAmerica
ARTICLE INFO
Keywords:
Self-regulated learning
Clickstream data
Self-report questionnaire
Online learning
ABSTRACT
The ability to regulate one's own learning is essential for success in online courses. Recent efforts have used
clickstream data to create timely, fine-grained, and comprehensive measures of self-regulated learning (SRL) in
online courses in an attempt to shed light on the process of SRL and to improve the identification of students who
lack SRL skills and are at risk of low achievement. However, key questions remain: to what extent do these
clickstream measures correspond to traditional self-reported measures about specific SRL constructs? Do these
clickstream measures provide more information than existing self-reported measures in predicting course per-
formance? This study used the clickstream data collected from a learning management system to measure two
aspects of SRL: time management and effort regulation. We found that the clickstream measures were sig-
nificantly associated with students' self-reported time management and effort regulation after the course. In
addition, these clickstream measures significantly improved predictions of students' performance in the current
and subsequent courses over predictions based on self-reported measures alone. These results provide evidence
for the validity of the clickstream measures and guide the use of clickstream data to understand the process of
SRL and identify students who might not be well served by taking classes online.
1. Introduction
As a promising method for increasing the accessibility and de-
creasing the costs of higher education, the rapid expansion of online
learning is an international phenomenon; digitally mediated distance
education has been widely adopted in countries such as China, India,
South Korea, Australia, and United States (Kumar, Kumar, Palvia, &
Verma, 2017; Qayyum & Zawacki-Richter, 2018). For instance, in
Australia, around 27% of college students were enrolled in one or more
online courses in 2014 (Norton, 2016). More than 30% of American
college students were enrolled in at least one online course and around
15% of college students were completing their degree entirely online in
2016 (National Center for Education Statistics, 2018).
Despite the widespread adoption of online learning in higher edu-
cation, current research has found that low course performance is a
consistent issue in online courses (Finnegan, Morris, & Lee, 2008; Fritz,
2011; Macfadyen & Dawson, 2010). Students in online courses tend to
have lower persistence rates and worse course grades as compared to
their counterparts in in-person courses (Bettinger, Fox, Loeb, & Taylor,
2017; Xu & Jaggars, 2011, 2013). The low performance in online
learning is due, in part, to the fact that some students are not well
prepared to study online (Artino Jr & Stephens, 2009; Broadbent &
Poon, 2015; Yukselturk & Bulut, 2007). More so than in in-person
courses, students in online courses must regulate their own learning by
establishing study plans, monitoring and controlling their learning
processes, and constantly reflecting on and adjusting their study plans
(Dabbagh & Kitsantas, 2004; Roll & Winne, 2015).
In light of the critical role that self-regulated learning (SRL) stra-
tegies play in online learning, it is essential to assess student uses of SRL
strategies and to identify students who are likely to struggle in online
courses so that institutions and instructors can provide timely support.
Researchers and practitioners have mainly relied on self-report ques-
tionnaires to identify students with low SRL skills (Broadbent & Poon,
2015; Winne, 2010). However, these self-report questionnaires are
costly and time intensive to administer. Additionally, students' self-re-
ports before or after an online course are not always accurate. They may
not predict or reflect student actual behavior in the course, since self-
reporting is usually based on unrepresentative and abbreviated mem-
ories (Gilbert & Wilson, 2007; Loewenstein, O'Donoghue, & Rabin,
2003; Winne, Jamieson-Noel, & Muis, 2002; Winne & Perry, 2000).
These concerns have given rise to new avenues into research on
measuring SRL in online learning environments. Clickstream data, the
https://doi.org/10.1016/j.iheduc.2020.100727
Received 15 July 2019; Received in revised form 6 January 2020; Accepted 13 January 2020
⁎ Corresponding author.
E-mailaddresses: ql16@nyu.edu (Q. Li), rachelbb@uci.edu (R. Baker), markw@uci.edu (M. Warschauer).
The Internet and Higher Education 45 (2020) 100727
Available online 15 January 2020
1096-7516/ © 2020 Elsevier Inc. All rights reserved.
T","Using clickstream data to measure, understand, and support self-regulated
learning in online courses
ARTICLE INFO
Keywords:
Self-regulated learning
Clickstream data
Self-report questionnaire
Online learning
ABSTRACT
The ability to regulate one's own learning is essential for success in online courses. Recent efforts have used
clickstream data to create timely, fine-grained, and comprehensive measures of self-regulated learning (SRL) in
online courses in an attempt to shed light on the process of SRL and to improve the identification of students who
lack SRL skills and are at risk of low achievement. However, key questions remain: to what extent do these
clickstream measures correspond to traditional self-reported measures about specific SRL constructs? Do these
clickstream measures provide more information than existing self-reported measures in predicting course per-
formance? This study used the clickstream data collected from a learning management system to measure two
aspects of SRL: time management and effort regulation. We found that the clickstream measures were sig-
nificantly associated with students' self-reported time management and effort regulation after the course. In
addition, these clickstream measures significantly improved predictions of students' performance in the current
and subsequent courses over predictions based on self-reported measures alone. These results provide evidence
for the validity of the clickstream measures and guide the use of clickstream data to understand the process of
SRL and identify students who might not be well served by taking classes online.
1. Introduction
As a promising method for increasing the accessibility and de-
creasing the costs of higher education, the rapid expansion of online
learning is an international phenomenon; digitally mediated distance
education has been widely adopted in countries such as China, India,
South Korea, Australia, and United States. For instance, in
Australia, around 27% of college students were enrolled in one or more
online courses in 2014. More than 30% of American
college students were enrolled in at least one online course and around
15% of college students were completing their degree entirely online in
2016.
Despite the widespread adoption of online learning in higher edu-
cation, current research has found that low course performance is a
consistent issue in online courses. Students in online courses tend to
have lower persistence rates and worse course grades as compared to
their counterparts in in-person courses. The low performance in online
learning is due, in part, to the fact that some students are not well
prepared to study online. More so than in in-person
courses, students in online courses must regulate their own learning by
establishing study plans, monitoring and controlling their learning
processes, and constantly reflecting on and adjusting their study plans.
In light of the critical role that self-regulated learning (SRL) stra-
tegies play in online learning, it is essential to assess student uses of SRL
strategies and to identify students who are likely to struggle in online
courses so that institutions and instructors can provide timely support.
Researchers and practitioners have mainly relied on self-report ques-
tionnaires to identify students with low SRL skills. However, these self-report questionnaires are
costly and time intensive to administer. Additionally, students' self-re-
ports before or after an online course are not always accurate. They may
not predict or reflect student actual behavior in the course, since self-
reporting is usually based on unrepresentative and abbreviated mem-
ories.
These concerns have given rise to new avenues into research on
measuring SRL in online learning environments. Clickstream data, the"
"2020 - Using clickstream data to measure, understand, and support self-regulated learning in online courses.pdf","detailed and real-time record of students' observable interactions with
online learning environments, provide new opportunities to measure
SRL (Greene & Azevedo, 2010; Roll & Winne, 2015; Winne, 2010). Past
research has shown that clickstream data can be used to capture SRL
more accurately and to provide a more comprehensive understanding
of students' behaviors than self-reporting (e.g., Cicchinelli et al., 2018;
Winne & Jamieson-Noel, 2002). A growing body of research has used
clickstream data from learning management systems, a type of com-
monly used learning environment, to describe, interpret, and evaluate
student SRL behaviors (Roll & Winne, 2015).
While there is cumulative evidence that some clickstream measures,
such as the number of assignments submitted before deadlines, are
predictive of student achievement (e.g.,Baker, Evans, Li, & Cung, 2018;
Cicchinelli et al., 2018; Crossley, Paquette, Dascalu, McNamara, &
Baker, 2016), these clickstream measures are often not triangulated
with data from other instruments that have been previously evaluated.
Therefore, the extent to which the clickstream measures capture SRL as
intended by researchers remains unclear. Additionally, practitioners,
who are generally familiar with self-reported measures of SRL, may
question the benefits of exerting effort to collect and analyze click-
stream data. Therefore, more direct evidence is needed to determine the
extent to which clickstream measures of SRL can meaningfully improve
the prediction of student performance.
To address these questions, this study used both a self-report
questionnaire and clickstream data to measure two sub-constructs of
SRL in an online course: time management and effort regulation.
Specifically, we investigated 1) the extent to which clickstream mea-
sures could provide valid inferences about the constructs of time
management and effort regulation and 2) whether the clickstream
measures of time management and effort regulation could meaningfully
improve the prediction of student performance.
2. Literature review
2.1. BroadframeworksfordefiningandmeasuringSRL
There is a large body of literature examining how students actively
regulate their learning process. Numerous definitions and models have
been developed over the last two decades, with some models describing
the overall processes of SRL (e.g., Pintrich, 2000; Zimmerman, 2000)
and others focusing on specific sub-components of SRL, such as the sub-
process of goal-setting process (Boekaerts, 2011) and the cognitive as-
pect of SRL (Winne, 1996), or SRL in a specific context, such as colla-
borative learning (Järvelä & Hadwin, 2013). Among them, the model
proposed by Pintrich (2000) is considered to be one of the most com-
prehensive models that classify the main processes of SRL. Importantly,
Pintrich's, 2000 model has been used as a theoretical framework to
validate and classify existing self-report questionnaires of SRL skills,
including measures in the Motivated Strategies for Learning Ques-
tionnaire (MSLQ) – the most widely used instrument of SRL skills in
online learning in higher education (Azevedo, Behnagh, Duffy, Harley,
& Trevors, 2012; Broadbent & Poon, 2015; Pintrich, 2004). Because it
has been used extensively in this context and because it provides clear
guidance for developing clickstream measures that theoretically align
with the MSLQ, we use this model as a starting framework.
Pulling from previous models of SRL,Pintrich (2000) defined SRL as
the process in which students actively and constructively set goals,
constantly adjust those goals, and regulate their cognition, motivation,
and behaviors to achieve their goals in constrained learning environ-
ments. Based on this definition, Pintrich (2000) depicted SRL using a
taxonomy of four processes and four domains that students could apply
the processes to. Specifically, the four processes include forethought,
planning, and activation; monitoring; control; and reaction and reflec-
tion and the four domains are cognition; motivation/affect; behavior;
and context (Pintrich, 2000). Using this taxonomy, Pintrich proposed a
four-by-four matrix as a conceptual framework to validate and
categorize existing measures of SRL. For instance, the time management
strategy of keeping up with the coursework in MSLQ measures students'
propensity to controltheir behaviorof spending time on coursework and
the self-testing strategy in MSLQ measures students' propensity to
monitor their cognition. For a full review of how this model is used to
validate and classify measures of SRL strategies in MSLQ, please see
Pintrich (2004).
2.2. ThemeasurementofSRL
Past research on SRL has focused on measuring students' use of SRL
strategies in an effort to better understand the process, determinants,
and consequences of SRL (Winne, 2010). Practitioners have also relied
on established measures to identify students with low SRL skills so that
they can offer these students academic supports (Schellings & Van
Hout-Wolters, 2011). Most of the previous work in online learning has
relied on either student reports of their SRL behaviors via ques-
tionnaires or time-intensive researcher-oriented methods, such as ob-
servations and think-aloud protocols, to measure SRL (Schellings & Van
Hout-Wolters, 2011; Winne, 2010). A growing number of studies,
however, have suggested that it is possible to better measure SRL using
the detailed clickstream data available in online learning environments.
Below, we provide an overview of previous work on the measurement
of SRL in online learning, focusing on two approaches: self-report
questionnaires and clickstream data.
2.2.1. Self-reportquestionnaire andSRL
2.2.1.1. Using self-report questionnaires to measure SRL. Self-report
questionnaires, such as the MSLQ (Pintrich & De Groot, 1990), the
Learning and Study Strategies Inventory (LASSI; Weinstein, Schulte, &
Palmer, 1987), and the Study Process Questionnaire (SPQ;Biggs, 1987),
have been used to measure students' use of SRL strategies. These
questionnaires usually instruct students to respond to several Likert
scale statements reflecting their learning behavior by either predicting
their behavior in an upcoming course or recalling their behavior in a
course that just ended. Most of the SRL questionnaires are designed for
traditional in-person classroom settings and have high or acceptable
reliability (e.g., Loong, 2012; Taylor, 2012; Yilmaz & Orhan, 2011). A
large body of research has borrowed or adapted measures from
previous questionnaires, mainly MSLQ, to capture student SRL in
online learning and has also reported high reliability (e.g., Artino Jr
& Stephens, 2009; Cho & Shen, 2013; Kizilcec, Pérez-Sanagustín, &
Maldonado, 2017; Lynch & Dembo, 2004; Wang, Shannon, & Ross,
2013).
2.2.1.2. Self-reported measures of SRL predicting online success. Despite
evidence of high psychometric quality of self-reported SRL measures in
online contexts, the evidence concerning the relationships between self-
reported SRL measures and academic outcomes is mixed. Some studies
found significant and positive relationships between self-reported SRL
and online course performance (e.g., Chang, 2007; Cho & Shen, 2013;
Puzziferro, 2008). Broadbent and Poon (2015) conducted a meta-
analysis on twelve studies that examined the relationships between
self-reported measures of SRL and academic achievement in the context
of online higher education and found significant and positive
associations between students' online achievement and both their
overall SRL measures and certain subscales (time management, effort
regulation, and metacognition).
In contrast, some notable studies failed to find significant correla-
tions between academic outcomes and self-reported measures of both
overall SRL (e.g., Cicchinelli et al., 2018;Pardo, Han, & Ellis, 2016) and
subscales such as time management (e.g., Bruso & Stefaniak, 2016;
Cazan, 2014; Klingsieck, Fries, Horz, & Hofer, 2012; Lynch & Dembo,
2004) and effort regulation (e.g., Bruso & Stefaniak, 2016; Dunnigan,
2018). There are at least two potential explanations for these findings of
no relationship between self-reported SRL behaviors and academic
Q.Li,etal. The Internet and Higher Education 45 (2020) 100727
2","detailed and real-time record of students' observable interactions with
online learning environments, provide new opportunities to measure
SRL (Greene & Azevedo, 2010; Roll & Winne, 2015; Winne, 2010). Past
research has shown that clickstream data can be used to capture SRL
more accurately and to provide a more comprehensive understanding
of students' behaviors than self-reporting (e.g., Cicchinelli et al., 2018;
Winne & Jamieson-Noel, 2002). A growing body of research has used
clickstream data from learning management systems, a type of com-
monly used learning environment, to describe, interpret, and evaluate
student SRL behaviors (Roll & Winne, 2015).
While there is cumulative evidence that some clickstream measures,
such as the number of assignments submitted before deadlines, are
predictive of student achievement (e.g.,Baker, Evans, Li, & Cung, 2018;
Cicchinelli et al., 2018; Crossley, Paquette, Dascalu, McNamara, &
Baker, 2016), these clickstream measures are often not triangulated
with data from other instruments that have been previously evaluated.
Therefore, the extent to which the clickstream measures capture SRL as
intended by researchers remains unclear. Additionally, practitioners,
who are generally familiar with self-reported measures of SRL, may
question the benefits of exerting effort to collect and analyze click-
stream data. Therefore, more direct evidence is needed to determine the
extent to which clickstream measures of SRL can meaningfully improve
the prediction of student performance.
To address these questions, this study used both a self-report
questionnaire and clickstream data to measure two sub-constructs of
SRL in an online course: time management and effort regulation.
Specifically, we investigated 1) the extent to which clickstream mea-
sures could provide valid inferences about the constructs of time
management and effort regulation and 2) whether the clickstream
measures of time management and effort regulation could meaningfully
improve the prediction of student performance.
2. Literature review
2.1. BroadframeworksfordefiningandmeasuringSRL
There is a large body of literature examining how students actively
regulate their learning process. Numerous definitions and models have
been developed over the last two decades, with some models describing
the overall processes of SRL (e.g., Pintrich, 2000; Zimmerman, 2000)
and others focusing on specific sub-components of SRL, such as the sub-
process of goal-setting process (Boekaerts, 2011) and the cognitive as-
pect of SRL (Winne, 1996), or SRL in a specific context, such as colla-
borative learning (Järvelä & Hadwin, 2013). Among them, the model
proposed by Pintrich (2000) is considered to be one of the most com-
prehensive models that classify the main processes of SRL. Importantly,
Pintrich's, 2000 model has been used as a theoretical framework to
validate and classify existing self-report questionnaires of SRL skills,
including measures in the Motivated Strategies for Learning Ques-
tionnaire (MSLQ) – the most widely used instrument of SRL skills in
online learning in higher education (Azevedo, Behnagh, Duffy, Harley,
& Trevors, 2012; Broadbent & Poon, 2015; Pintrich, 2004). Because it
has been used extensively in this context and because it provides clear
guidance for developing clickstream measures that theoretically align
with the MSLQ, we use this model as a starting framework.
Pulling from previous models of SRL,Pintrich (2000) defined SRL as
the process in which students actively and constructively set goals,
constantly adjust those goals, and regulate their cognition, motivation,
and behaviors to achieve their goals in constrained learning environ-
ments. Based on this definition, Pintrich (2000) depicted SRL using a
taxonomy of four processes and four domains that students could apply
the processes to. Specifically, the four processes include forethought,
planning, and activation; monitoring; control; and reaction and reflec-
tion and the four domains are cognition; motivation/affect; behavior;
and context (Pintrich, 2000). Using this taxonomy, Pintrich proposed a
four-by-four matrix as a conceptual framework to validate and
categorize existing measures of SRL. For instance, the time management
strategy of keeping up with the coursework in MSLQ measures students'
propensity to controltheir behaviorof spending time on coursework and
the self-testing strategy in MSLQ measures students' propensity to
monitor their cognition. For a full review of how this model is used to
validate and classify measures of SRL strategies in MSLQ, please see
Pintrich (2004).
2.2. ThemeasurementofSRL
Past research on SRL has focused on measuring students' use of SRL
strategies in an effort to better understand the process, determinants,
and consequences of SRL (Winne, 2010). Practitioners have also relied
on established measures to identify students with low SRL skills so that
they can offer these students academic supports (Schellings & Van
Hout-Wolters, 2011). Most of the previous work in online learning has
relied on either student reports of their SRL behaviors via ques-
tionnaires or time-intensive researcher-oriented methods, such as ob-
servations and think-aloud protocols, to measure SRL (Schellings & Van
Hout-Wolters, 2011; Winne, 2010). A growing number of studies,
however, have suggested that it is possible to better measure SRL using
the detailed clickstream data available in online learning environments.
Below, we provide an overview of previous work on the measurement
of SRL in online learning, focusing on two approaches: self-report
questionnaires and clickstream data.
2.2.1. Self-reportquestionnaire andSRL
2.2.1.1. Using self-report questionnaires to measure SRL. Self-report
questionnaires, such as the MSLQ (Pintrich & De Groot, 1990), the
Learning and Study Strategies Inventory (LASSI; Weinstein, Schulte, &
Palmer, 1987), and the Study Process Questionnaire (SPQ;Biggs, 1987),
have been used to measure students' use of SRL strategies. These
questionnaires usually instruct students to respond to several Likert
scale statements reflecting their learning behavior by either predicting
their behavior in an upcoming course or recalling their behavior in a
course that just ended. Most of the SRL questionnaires are designed for
traditional in-person classroom settings and have high or acceptable
reliability (e.g., Loong, 2012; Taylor, 2012; Yilmaz & Orhan, 2011). A
large body of research has borrowed or adapted measures from
previous questionnaires, mainly MSLQ, to capture student SRL in
online learning and has also reported high reliability (e.g., Artino Jr
& Stephens, 2009; Cho & Shen, 2013; Kizilcec, Pérez-Sanagustín, &
Maldonado, 2017; Lynch & Dembo, 2004; Wang, Shannon, & Ross,
2013).
2.2.1.2. Self-reported measures of SRL predicting online success. Despite
evidence of high psychometric quality of self-reported SRL measures in
online contexts, the evidence concerning the relationships between self-
reported SRL measures and academic outcomes is mixed. Some studies
found significant and positive relationships between self-reported SRL
and online course performance (e.g., Chang, 2007; Cho & Shen, 2013;
Puzziferro, 2008). Broadbent and Poon (2015) conducted a meta-
analysis on twelve studies that examined the relationships between
self-reported measures of SRL and academic achievement in the context
of online higher education and found significant and positive
associations between students' online achievement and both their
overall SRL measures and certain subscales (time management, effort
regulation, and metacognition).
In contrast, some notable studies failed to find significant correla-
tions between academic outcomes and self-reported measures of both
overall SRL (e.g., Cicchinelli et al., 2018;Pardo, Han, & Ellis, 2016) and
subscales such as time management (e.g., Bruso & Stefaniak, 2016;
Cazan, 2014; Klingsieck, Fries, Horz, & Hofer, 2012; Lynch & Dembo,
2004) and effort regulation (e.g., Bruso & Stefaniak, 2016; Dunnigan,
2018). There are at least two potential explanations for these findings of
no relationship between self-reported SRL behaviors and academic"
"2020 - Using clickstream data to measure, understand, and support self-regulated learning in online courses.pdf","outcomes: the applicability of specific measures to the online context
and students' ability to accurately report their use of SRL strategies.
The lack of a significant relationship may be partially explained by
the fact that some studies used questionnaires designed for traditional
in-person courses (Lynch & Dembo, 2004; Pardo et al., 2016). Some
researchers argue that since the types of SRL strategies students would
use may vary based on the learning contexts, instruments of SRL that
are valid in traditional in-person courses may not be valid for online
environments (Barnard, Lan, To, Paton, & Lai, 2009). However, this
does not fully account for the null findings, as several studies that used
instruments established for and validated in online learning environ-
ments also failed to identify significant relationships between student
course performance and self-reported SRL measures (e.g., Cazan, 2014;
Dunnigan, 2018).
Another potential explanation for these null findings is that students
are generally unable to accurately report or predict their SRL strategies
(e.g., Bruso & Stefaniak, 2016;Klingsieck et al., 2012). Indeed, there are
substantial barriers to using self-reported data to capture past or predict
future SRL behaviors (Gilbert & Wilson, 2007; Winne et al., 2002;
Winne & Perry, 2000). Self-reporting one's SRL behaviors after a course
involves memory reconstruction that may not accurately capture one's
actual experiences in the course (Bruso & Stefaniak, 2016). These re-
sponses may suffer from issues including response bias and memory
deficiencies (Kahneman, Fredrickson, Schreiber, & Redelmeier, 1993;
Morewedge, Gilbert, & Wilson, 2005). In a study that directly compared
students' perceived use of and actual use of SRL strategies, Winne and
Jamieson-Noel (2002) found that students were positively biased in
reporting their use of SRL strategies.
Perhaps even more problematic is using self-report questionnaires
before a course starts to predict student SRL behaviors later on, which is
often how the early identification of students with low SRL skills is
attempted. Self-reporting the probability of carrying out an SRL beha-
vior, such as planning in advance to finish work on time, requires
students to make predictions based on their memories of similar events
in the past. In addition to the problem of memories being inaccurate,
memories are aggregated over many events and thus may lack sig-
nificant contextual features (Gilbert & Wilson, 2007). Such features
(e.g., the nature of the task or resources available), however, may
profoundly influence students' SRL behaviors. Previous studies have
found that at the beginning of the course, students tend to ignore the
difficulties of carrying out SRL behaviors and overestimate their SRL
skills (e.g., Bernard, Brauer, Abrami, & Surkes, 2004; DiBenedetto &
Bembenutty, 2013; Matuga, 2009).
Predicting one's SRL behaviors in an upcoming online course may be
especially challenging for students who lack prior experience with on-
line learning. As noted above, past experience is necessary, though
insufficient, for predicting future behavior (Gilbert & Wilson, 2007).
For students who have limited or no experience with formal online
learning, their predictions of SRL behaviors in online courses may not
be reliable because such predictions may largely rely on students' past
experience in in-person classrooms, a learning environment that sub-
stantially differs from online courses.
2.2.2. ClickstreamdataandSRL
2.2.2.1. Using clickstream data to measure SRL. A growing body of
literature has used clickstream data collected from online learning
environments to obtain more objective information on students' use SRL
strategies (e.g., Baker et al., 2018; Cicchinelli et al., 2018; Crossley
et al., 2016; Winne & Jamieson-Noel, 2002). Clickstream data are a
class of detailed, frequent, and unobtrusive records of users' click
behavior in online environments. In the context of online learning,
these can include behaviors such as logging into the learning platform,
pressing the pause buttons on video lectures, submitting assignments,
and so on. While they are not direct measures of the underlying mental
processes, they correspond to students' cognition and metacognition
and therefore provide promising opportunities for tracing and
measuring SRL (Winne, 2010).
Researchers argue that clickstream data have several advantages
over self-reported data as measures of SRL (Winne, 2010). First, click-
stream data are collected in authentic learning settings while learning is
happening and therefore can be used to measure student behavior more
objectively, accurately, and comprehensively than self-reported data
that are based on unreliable and decontextualized memories (Winne,
2010). Second, clickstream data are unobtrusive and do not require
attention or effort from students; they can be collected without inter-
rupting the learning process (Greene & Azevedo, 2010;Sha, Looi, Chen,
& Zhang, 2012). In contrast, self-report questionnaires may encourage
students to reflect on their behavior and therefore change students'
behavior. This could bias results in an unpredictable manner (Greene &
Azevedo, 2010). Finally, the automatically collected clickstream data
can provide timely, frequent, and large-scale measures of student be-
havior, which are usually not feasible with self-reports.
An emerging literature has explored the use of clickstream data
from learning management systems (LMS), which are commonly used
in higher education contexts, to measure SRL in online courses. LMS
(e.g., Blackboard and Canvas) provide the basic functions needed for
teaching and learning online, including delivering learning materials
(e.g., lecture video), managing learning activities (e.g., quizzes, as-
signments, and discussion), and supporting assessments (e.g., exams
and essays; Lewis et al., 2005). While most previous studies used
clickstream data from LMS to measure student general engagement
rather than SRL, a few studies have taken a step further to measure time
management, a sub-construct of SRL (e.g.,Baker et al., 2018;Cicchinelli
et al., 2018;Lim, 2016; Park, Denaro, Rodriguez, Smyth, & Warschauer,
2017).
Three types of behaviors related to time management have been
measured: studying on time, studying in advance, and spacing.
Studying on time is defined as viewing course materials or completing
assignments before deadlines. Researchers have used measures such as
the frequency with which students in blended courses view resources
pertaining to the face-to-face meetings before the actual course meet-
ings to capture the amount of course work that students study on time
(Cicchinelli et al., 2018; Park et al., 2017). Studying in advance is de-
fined as studying early instead of postponing studying until it is close to
deadlines (Baker et al., 2018). Researchers have used measures such as
how far in advance students start working on/turn in assignments in
fully online courses to measure to what extent students study in ad-
vance (Crossley et al., 2016;Kazerouni, Edwards, & Shaffer, 2017;Levy
& Ramim, 2013). Spacing is defined as distributing study time over a
long time period instead of finishing a lot of coursework during a short
time period (Baker et al., 2018; Park et al., 2017). For instance, prior
research has used how widely one's work sessions are distributed within
a week to capture the behavior of spacing (e.g.,Baker et al., 2018; Lim,
2016; Park et al., 2017; You, 2016).
2.2.2.2. Clickstreammeasurespredictingsuccessinonlinelearning. There
is emerging evidence showing that clickstream measures of studying on
time, studying in advance, and spacing consistently predict course
performance (Baker et al., 2018; Cicchinelli et al., 2018; Crossley et al.,
2016; Kazerouni et al., 2017; Lim, 2016; Park et al., 2017; You, 2016).
For instance, several studies found consistent evidence that the more
assignments students finished on time and the earlier students
attempted or completed assignments, the better they performed on
quizzes and final exams (e.g., Baker et al., 2018; Crossley et al., 2016;
Park et al., 2017). In an online course where students were required to
watch a number of videos by the end of the week, Baker et al. (2018)
found that the behavior of spacing, measured by the standard deviation
of the watch time for each of the course videos within a week, was
significantly and positively associated with quiz performance and final
course grade.
Q.Li,etal. The Internet and Higher Education 45 (2020) 100727
3","outcomes: the applicability of specific measures to the online context
and students' ability to accurately report their use of SRL strategies.
The lack of a significant relationship may be partially explained by
the fact that some studies used questionnaires designed for traditional
in-person courses. Some
researchers argue that since the types of SRL strategies students would
use may vary based on the learning contexts, instruments of SRL that
are valid in traditional in-person courses may not be valid for online
environments. However, this
does not fully account for the null findings, as several studies that used
instruments established for and validated in online learning environ-
ments also failed to identify significant relationships between student
course performance and self-reported SRL measures.
Another potential explanation for these null findings is that students
are generally unable to accurately report or predict their SRL strategies. Indeed, there are
substantial barriers to using self-reported data to capture past or predict
future SRL behaviors. Self-reporting one's SRL behaviors after a course
involves memory reconstruction that may not accurately capture one's
actual experiences in the course. These re-
sponses may suffer from issues including response bias and memory
deficiencies. In a study that directly compared
students' perceived use of and actual use of SRL strategies, Winne and
Jamieson-Noel (2002) found that students were positively biased in
reporting their use of SRL strategies.
Perhaps even more problematic is using self-report questionnaires
before a course starts to predict student SRL behaviors later on, which is
often how the early identification of students with low SRL skills is
attempted. Self-reporting the probability of carrying out an SRL beha-
vior, such as planning in advance to finish work on time, requires
students to make predictions based on their memories of similar events
in the past. In addition to the problem of memories being inaccurate,
memories are aggregated over many events and thus may lack sig-
nificant contextual features. Such features
(e.g., the nature of the task or resources available), however, may
profoundly influence students' SRL behaviors. Previous studies have
found that at the beginning of the course, students tend to ignore the
difficulties of carrying out SRL behaviors and overestimate their SRL
skills.
Predicting one's SRL behaviors in an upcoming online course may be
especially challenging for students who lack prior experience with on-
line learning. As noted above, past experience is necessary, though
insufficient, for predicting future behavior.
For students who have limited or no experience with formal online
learning, their predictions of SRL behaviors in online courses may not
be reliable because such predictions may largely rely on students' past
experience in in-person classrooms, a learning environment that sub-
stantially differs from online courses.
2.2.2. ClickstreamdataandSRL
2.2.2.1. Using clickstream data to measure SRL. A growing body of
literature has used clickstream data collected from online learning
environments to obtain more objective information on students' use SRL
strategies. Clickstream data are a
class of detailed, frequent, and unobtrusive records of users' click
behavior in online environments. In the context of online learning,
these can include behaviors such as logging into the learning platform,
pressing the pause buttons on video lectures, submitting assignments,
and so on. While they are not direct measures of the underlying mental
processes, they correspond to students' cognition and metacognition
and therefore provide promising opportunities for tracing and
measuring SRL.
Researchers argue that clickstream data have several advantages
over self-reported data as measures of SRL. First, click-
stream data are collected in authentic learning settings while learning is
happening and therefore can be used to measure student behavior more
objectively, accurately, and comprehensively than self-reported data
that are based on unreliable and decontextualized memories. Second, clickstream data are unobtrusive and do not require
attention or effort from students; they can be collected without inter-
rupting the learning process. In contrast, self-report questionnaires may encourage
students to reflect on their behavior and therefore change students'
behavior. This could bias results in an unpredictable manner. Finally, the automatically collected clickstream data
can provide timely, frequent, and large-scale measures of student be-
havior, which are usually not feasible with self-reports.
An emerging literature has explored the use of clickstream data
from learning management systems (LMS), which are commonly used
in higher education contexts, to measure SRL in online courses. LMS
(e.g., Blackboard and Canvas) provide the basic functions needed for
teaching and learning online, including delivering learning materials
(e.g., lecture video), managing learning activities (e.g., quizzes, as-
signments, and discussion), and supporting assessments (e.g., exams
and essays. While most previous studies used
clickstream data from LMS to measure student general engagement
rather than SRL, a few studies have taken a step further to measure time
management, a sub-construct of SRL.
Three types of behaviors related to time management have been
measured: studying on time, studying in advance, and spacing.
Studying on time is defined as viewing course materials or completing
assignments before deadlines. Researchers have used measures such as
the frequency with which students in blended courses view resources
pertaining to the face-to-face meetings before the actual course meet-
ings to capture the amount of course work that students study on time
(Cicchinelli et al., 2018; Park et al., 2017). Studying in advance is de-
fined as studying early instead of postponing studying until it is close to
deadlines. Researchers have used measures such as
how far in advance students start working on/turn in assignments in
fully online courses to measure to what extent students study in ad-
vance. Spacing is defined as distributing study time over a
long time period instead of finishing a lot of coursework during a short
time period. For instance, prior
research has used how widely one's work sessions are distributed within
a week to capture the behavior of spacing (e.g.,Baker et al., 2018; Lim,
2016; Park et al., 2017; You, 2016).
2.2.2.2. Clickstreammeasurespredictingsuccessinonlinelearning. There
is emerging evidence showing that clickstream measures of studying on
time, studying in advance, and spacing consistently predict course
performance.
For instance, several studies found consistent evidence that the more
assignments students finished on time and the earlier students
attempted or completed assignments, the better they performed on
quizzes and final exams. In an online course where students were required to
watch a number of videos by the end of the week, Baker et al. (2018)
found that the behavior of spacing, measured by the standard deviation
of the watch time for each of the course videos within a week, was
significantly and positively associated with quiz performance and final
course grade."
"2020 - Using clickstream data to measure, understand, and support self-regulated learning in online courses.pdf","Moreover, there is evidence that clickstream measures have better
predictive power over self-reported measures collected before the
course (e.g., Cicchinelli et al., 2018). In one study examining student
SRL in a blended course, Cicchinelli et al. (2018) used both self-report
questionnaire and clickstream data to measure SRL and found that self-
reported data collected at the beginning of the course did not predict
course performance. In contrast, they found that a behavioral measure
of delaying study time—the average time until a student returned to the
platform after each in-person class—was significantly and negatively
associated with quiz scores and final exam score.
2.3. Rationaleofthestudyandresearchquestion
Identifying valid measures of SRL is important for researchers and
practitioners in online learning. Although self-reported measures of SRL
are widely used, they are time intensive to administer and may not
accurately predict students' actual behaviors in the course nor their
course performance. Clickstream data collected in online learning en-
vironments provide novel and promising opportunities for timely, ob-
jective, and comprehensive measures of SRL at a large scale (Roll &
Winne, 2015). Prior research has mainly used clickstream data col-
lected from LMS to measure SRL behavior related to time management.
These studies have provided consistent evidence that clickstream
measures of time management are predictive of student online perfor-
mance.
However, despite the promising evidence on the associations be-
tween clickstream measures of time management and performance,
there are three important gaps in knowledge. First, it is not clear the
extent to which these clickstream measures of time management can
provide valid inferences about the constructs of time management
skills. The current interpretations of these clickstream measures as
measuring time management skills are researchers' inferences regarding
observable interactions between students and the learning management
systems. Very few of the prior studies have looked beyond the asso-
ciations between these clickstream measures and student performance
to triangulate clickstream measures with other previously evaluated
instruments (e.g., the MSLQ) to provide support for the validity of the
interpretation of the clickstream measures.
Moreover, although previous studies have found significant re-
lationships between clickstream measures of time management and
student performance, very few studies have examined the extent to
which these clickstream measures could significantly improve the
prediction of achievement outcomes over self-reported time manage-
ment alone. As self-report questionnaires have already been widely
used in higher education to measure SRL, such evidence is needed to
better inform practitioners deciding whether to invest their effort in
understanding and utilizing the clickstream data provided by learning
management systems.
Finally, there are relatively few studies using clickstream data from
LMS to measure sub-constructs of SRL beyond time management. This
is partially due to the types of interactions students can have within the
learning environment. The features of learning management systems
are often not set up to explicitly support or record SRL behaviors, such
as the use of cognitive strategies (e.g., note-taking and highlighting),
and therefore impose challenges in measuring SRL. However, more
studies are needed to explore the potential of innovative approaches for
using clickstream data from learning management systems to measure
other sub-constructs of SRL, such as effort regulation.
To address these gaps, this study examined the following research
questions: (1) to what extent do clickstream measures of time man-
agement and effort regulation correspond with students' self-reported
use of time management and effort regulation strategies from before
and after the course? (2) to what extent do clickstream measures of time
management and effort regulation complement self-reported measures
in predicting student performance in the current and subsequent
courses?
3. Method
3.1. Researchcontext
3.1.1. Course
This study was conducted in the context of a 10-week fully online
Chemistry course at a public university in Fall 2016. The course was
offered through Canvas, a learning management system, and contained
four modules. Each module was comprised of between 9 and 14 small
study units. All the materials were released at the beginning of the
course and were available to students until the end of the course. In
each module, students needed to take a one-hour quiz. The instructor
recommended that students finish one module (i.e., complete all the
study units and the one-hour quiz in a given module) every two to three
weeks. Specifically, the four module quizzes were due on the Sundays of
the second, fourth, seventh, and ninth weeks. Students' course grades
were comprised of the scores from homework assignments (15%), the
module quiz scores (20%), the midterm exam score (20%), and the final
exam score (45%). This course was the first course of a series of general
chemistry courses offered to first year college students, and students
needed to get a grade of C– or better in this course in order to enroll in
the subsequent courses.
3.1.2. Participants
A total of 319 freshmen enrolled in this course. Of these, 238
completed both the pre- and post-course surveys and were used as the
main analytic sample. Using this sample allowed us to compare stu-
dents' self-reported measures with clickstream measures of time man-
agement and effort regulation. As noted above, this course was the first
of a course series. Therefore, we followed the subset of 220 students
who continued to the next course and examined their course grades in
the subsequent course.
3.2. Data
3.2.1. Demographicvariables
The institution provided data on student prior achievement and a
variety of student demographics. Eight of the 238 students who com-
pleted the pre- and post-course surveys had missing data on one or two
demographic variables. Table 1 presents summary statistics on student
demographic characteristics for the 230 students. The sample was
predominantly female (79%). Students were, on average, around
18 years old. The sample was 48% Hispanic, 34% Asian/Pacific Is-
lander, 13% White, and 5% African American. More than half of the
students were first generation students. Around half of the students
were from low-income families. Students' average high school GPA and
SAT total score were 3.96 and 1619 (on a 2400 scale), respectively.
These characteristics are slightly different from the overall
Table 1
Descriptive statistics of student demographic characteristics.
Mean SD
Female 0.79 /
Age 18.37 0.4
Hispanic 0.48 /
Asian/Pacific Islander 0.34 /
White 0.13 /
African American 0.05 /
First generation 0.63 /
Low income 0.56 /
SAT score 1619 130.82
High school GPA 3.96 0.19
N 230
Note. 230 students (97%) in the analytic sample had complete data on demo-
graphic variables.
Q.Li,etal. The Internet and Higher Education 45 (2020) 100727
4","Moreover, there is evidence that clickstream measures have better
predictive power over self-reported measures collected before the
course (e.g., Cicchinelli et al., 2018). In one study examining student
SRL in a blended course, Cicchinelli et al. (2018) used both self-report
questionnaire and clickstream data to measure SRL and found that self-
reported data collected at the beginning of the course did not predict
course performance. In contrast, they found that a behavioral measure
of delaying study time—the average time until a student returned to the
platform after each in-person class—was significantly and negatively
associated with quiz scores and final exam score.
2.3. Rationaleofthestudyandresearchquestion
Identifying valid measures of SRL is important for researchers and
practitioners in online learning. Although self-reported measures of SRL
are widely used, they are time intensive to administer and may not
accurately predict students' actual behaviors in the course nor their
course performance. Clickstream data collected in online learning en-
vironments provide novel and promising opportunities for timely, ob-
jective, and comprehensive measures of SRL at a large scale (Roll &
Winne, 2015). Prior research has mainly used clickstream data col-
lected from LMS to measure SRL behavior related to time management.
These studies have provided consistent evidence that clickstream
measures of time management are predictive of student online perfor-
mance.
However, despite the promising evidence on the associations be-
tween clickstream measures of time management and performance,
there are three important gaps in knowledge. First, it is not clear the
extent to which these clickstream measures of time management can
provide valid inferences about the constructs of time management
skills. The current interpretations of these clickstream measures as
measuring time management skills are researchers' inferences regarding
observable interactions between students and the learning management
systems. Very few of the prior studies have looked beyond the asso-
ciations between these clickstream measures and student performance
to triangulate clickstream measures with other previously evaluated
instruments (e.g., the MSLQ) to provide support for the validity of the
interpretation of the clickstream measures.
Moreover, although previous studies have found significant re-
lationships between clickstream measures of time management and
student performance, very few studies have examined the extent to
which these clickstream measures could significantly improve the
prediction of achievement outcomes over self-reported time manage-
ment alone. As self-report questionnaires have already been widely
used in higher education to measure SRL, such evidence is needed to
better inform practitioners deciding whether to invest their effort in
understanding and utilizing the clickstream data provided by learning
management systems.
Finally, there are relatively few studies using clickstream data from
LMS to measure sub-constructs of SRL beyond time management. This
is partially due to the types of interactions students can have within the
learning environment. The features of learning management systems
are often not set up to explicitly support or record SRL behaviors, such
as the use of cognitive strategies (e.g., note-taking and highlighting),
and therefore impose challenges in measuring SRL. However, more
studies are needed to explore the potential of innovative approaches for
using clickstream data from learning management systems to measure
other sub-constructs of SRL, such as effort regulation.
To address these gaps, this study examined the following research
questions: (1) to what extent do clickstream measures of time man-
agement and effort regulation correspond with students' self-reported
use of time management and effort regulation strategies from before
and after the course? (2) to what extent do clickstream measures of time
management and effort regulation complement self-reported measures
in predicting student performance in the current and subsequent
courses?
3. Method
3.1. Researchcontext
3.1.1. Course
This study was conducted in the context of a 10-week fully online
Chemistry course at a public university in Fall 2016. The course was
offered through Canvas, a learning management system, and contained
four modules. Each module was comprised of between 9 and 14 small
study units. All the materials were released at the beginning of the
course and were available to students until the end of the course. In
each module, students needed to take a one-hour quiz. The instructor
recommended that students finish one module (i.e., complete all the
study units and the one-hour quiz in a given module) every two to three
weeks. Specifically, the four module quizzes were due on the Sundays of
the second, fourth, seventh, and ninth weeks. Students' course grades
were comprised of the scores from homework assignments (15%), the
module quiz scores (20%), the midterm exam score (20%), and the final
exam score (45%). This course was the first course of a series of general
chemistry courses offered to first year college students, and students
needed to get a grade of C– or better in this course in order to enroll in
the subsequent courses.
3.1.2. Participants
A total of 319 freshmen enrolled in this course. Of these, 238
completed both the pre- and post-course surveys and were used as the
main analytic sample. Using this sample allowed us to compare stu-
dents' self-reported measures with clickstream measures of time man-
agement and effort regulation. As noted above, this course was the first
of a course series. Therefore, we followed the subset of 220 students
who continued to the next course and examined their course grades in
the subsequent course.
3.2. Data
3.2.1. Demographicvariables
The institution provided data on student prior achievement and a
variety of student demographics. Eight of the 238 students who com-
pleted the pre- and post-course surveys had missing data on one or two
demographic variables. Table 1 presents summary statistics on student
demographic characteristics for the 230 students. The sample was
predominantly female (79%). Students were, on average, around
18 years old. The sample was 48% Hispanic, 34% Asian/Pacific Is-
lander, 13% White, and 5% African American. More than half of the
students were first generation students. Around half of the students
were from low-income families. Students' average high school GPA and
SAT total score were 3.96 and 1619 (on a 2400 scale), respectively.
These characteristics are slightly different from the overall
Table 1
Descriptive statistics of student demographic characteristics.
Note. 230 students (97%) in the analytic sample had complete data on demo-
graphic variables."
"2020 - Using clickstream data to measure, understand, and support self-regulated learning in online courses.pdf","demographics of the university. Based on administrative data available
from the campus, in fall 2016, the campus was 53% female, 27%
Hispanic, 44% Asian/Pacific Islander, 16% White, and 3% African
American; 48% of undergraduates on the campus were first generation
college students, and 34% were low-income students. The average SAT
score of admitted students was 1725. We address how this context
might affect the generalizability of our results in the discussion section.
3.2.2. Self-reportedmeasures
Self-reported data were collected through pre- and post-course
surveys launched during the first and last week of the course, respec-
tively. Measures adapted from MSLQ were used both in the pre- and
post-course surveys to measure two sub-constructs of SRL: time man-
agement and effort regulation.
Time management was measured by two statements (α = 0.69): “I
keep/kept a record of what my assignments are/were and when they
are/were due” and “I plan/planned my work in advance so that I could
turn in my assignments on time.” Effort regulation was measured by
four statements (α = 0.67): “I often feel/felt so lazy or bored when I
study/studied that I quit before I finish what I planned/had planned to
do” (reverse coded), “I work/worked hard to do well in courses even if I
don't/didn't like what I am/was doing,” “Even when course materials
are/were dull and uninteresting, I manage/managed to keep working
until I finish/finished,” and “I am/was quick to catch up with course-
work when I start/started falling behind.” All the self-report questions
were measured in a 5-point answer format ranging from 1 (strongly
disagree) to 5 (strongly agree).
3.2.3. Clickstreammeasures
We generated three clickstream measures for time management and
one clickstream measure for effort regulation. We drew on three sources
to create these measures: the definitions of the two concepts, the key
behaviors captured by the survey measures, and previous studies on
clickstream data in learning management systems (e.g., Baker et al.,
2018; Park et al., 2017; Pintrich, Smith, Garcia, & McKeachie, 1993).
We defined three clickstream measures to capture time manage-
ment. The two survey measures of time management focus on the be-
havior of getting coursework done on time. Therefore, we created a
clickstream measure of studyingontime based on the proportion of units
accessed before the deadline. Specifically, the behavior of studying a
unit on time is defined as a student having visited unit pageiof a given
module j before the deadline of the final quiz of module j. The pro-
portion of units a student studied on time was calculated for each
module (Pj) and the average value of the proportions of units studied on
time in the four modules (
+ + +P P P P
4
1 2 3 4 ) was used in the analysis.
In addition, previous studies suggest students with higher time
management skills are more likely to study early and to space out their
study time instead of procrastinating, cramming, and completing
coursework right before the deadlines (e.g., Michinov, Brunot, Le
Bohec, Juhel, & Delaval, 2011). Therefore, we included two additional
clickstream measures—studyinginadvance and spacing—that have been
commonly used in previous studies to measure time management (e.g.,
Baker et al., 2018;Crossley et al., 2016;Park et al., 2017). The behavior
of studying in advance is defined as students studying a unit in advance
of the deadlines. It can be captured by the time difference (T
j − Ti)
between the deadline of the final quiz of a given module j(Tj) and the
timestamp of when a student visited the unit page iin module jfor the
first time (Ti). We calculated the average value of such time differences
for each module (
= T T
n
i
n j i1 ) and used the average value across the four
modules as a measure of studying in advance in the analyses
(
=
=
4
j
i
n Tj Ti
n1
4 1 ).
Spacing is defined as spacing out one's study time and it is oper-
ationalized as the standard deviation of the time differences (std
(T
j− Ti)) between the deadline of the final quiz of a given modulej(Tj)
and the timestamp of when a student visited the unit pageiin module j
for the first time (Ti). Again, we used the average value of the standard
deviations of the four modules in the analyses (
= std T T( )
4
j j i1
4 ). We ex-
pected students with higher time management skills would space out
their visits of the study unites and thus would have larger standard
deviation values for the measure of days before deadline.
The one clickstream measure generated to capture effort regulation
was based on the definition of effort regulation. Effort regulation is
defined as the extent to which students can maintain their effort level
when they encounter difficulties (Pintrich et al., 1993). Although it is
difficult to identify specific moments when students experience diffi-
culties, effort regulation could be approximately captured based on the
overall trend of student effort level in the course. In previous studies,
student effort level is usually measured by student time spent on the
system, defined as time on task (Grabe & Sigler, 2002; Munk & Drlík,
2011). Therefore, we used the change in time on task during the course
to measure effort regulation. For each individual student, the change in
time on task during the course was operationalized as the slope of a
simple linear regression that regressed time on task in a given module
on the module number.
3.2.4. Performanceoutcomes
We used student final exam scores and overall course grades in the
current course as the performance outcomes to compare the predictive
power of self-reported and clickstream measures. The final exam score
and overall course grade were measured on a 100-point scale and 4-
point scale, respectively (see Table 2). We also predicted student course
grades in the subsequent course to examine the predictive power of self-
reported and clickstream measures over longer-term outcomes.
Table 2
Descriptive statistics of self-report measures, clickstream measures, and course
performance.
M SD Min Max N
Pre-course self-report measures
Time management
Keep record of assignments_PRE 4.07 0.93 1 5 238
Plan in advance_PRE 4.11 0.83 1 5 238
Effort regulation
Quit before finishing_PRE 3.73 0.86 1 5 238
Work hard to do well_PRE 4.2 0.83 1 5 238
Keep working until finish_PRE 4 0.89 1 5 238
Catch up when falling behind_PRE 3.5 1.07 1 5 238
Post-course self-report measures
Time management
Keep record of assignments_POST 3.84 1.05 1 5 238
Plan in advance_POST 3.51 1.06 1 5 238
Effort regulation
Quit before finishing_POST 3.55 1.02 1 5 238
Work hard to do well_POST 3.77 0.95 1 5 238
Keep working until finish_POST 3.97 0.91 1 5 238
Catch up when falling behind_POST 3.64 1.05 1 5 238
Clickstream measures
Time management
Study on time_CL 0.80 0.2 0.12 1 238
Study in advance_CL 4.69 2.32 0.45 13.72 238
Space_CL 2.88 1.05 0.29 5.01 238
Effort regulation
Change in time on task_CL −0.84 0.54 −2.31 0.97 238
Course performance
Current Course final exam 64.99 17.78 2 99 238
Current course grade 3.14 0.73 1.00 4.00 238
Subsequent course grade 1.13 0.98 0.00 4.00 220
Note.238 completed both the pre- and post-course surveys and were used as the
main analytic sample. We followed a subset of students who continued to the
next course. Since 18 students did not take the subsequent course in the fol-
lowing quarter, the analytic sample for subsequent course outcome included
220 students.
Q.Li,etal. The Internet and Higher Education 45 (2020) 100727
5","demographics of the university. Based on administrative data available
from the campus, in fall 2016, the campus was 53% female, 27%
Hispanic, 44% Asian/Pacific Islander, 16% White, and 3% African
American; 48% of undergraduates on the campus were first generation
college students, and 34% were low-income students. The average SAT
score of admitted students was 1725. We address how this context
might affect the generalizability of our results in the discussion section.
3.2.2. Self-reportedmeasures
Self-reported data were collected through pre- and post-course
surveys launched during the first and last week of the course, respec-
tively. Measures adapted from MSLQ were used both in the pre- and
post-course surveys to measure two sub-constructs of SRL: time man-
agement and effort regulation.
Time management was measured by two statements (α = 0.69): “I
keep/kept a record of what my assignments are/were and when they
are/were due” and “I plan/planned my work in advance so that I could
turn in my assignments on time.” Effort regulation was measured by
four statements (α = 0.67): “I often feel/felt so lazy or bored when I
study/studied that I quit before I finish what I planned/had planned to
do” (reverse coded), “I work/worked hard to do well in courses even if I
don't/didn't like what I am/was doing,” “Even when course materials
are/were dull and uninteresting, I manage/managed to keep working
until I finish/finished,” and “I am/was quick to catch up with course-
work when I start/started falling behind.” All the self-report questions
were measured in a 5-point answer format ranging from 1 (strongly
disagree) to 5 (strongly agree).
3.2.3. Clickstreammeasures
We generated three clickstream measures for time management and
one clickstream measure for effort regulation. We drew on three sources
to create these measures: the definitions of the two concepts, the key
behaviors captured by the survey measures, and previous studies on
clickstream data in learning management systems (e.g., Baker et al.,
2018; Park et al., 2017; Pintrich, Smith, Garcia, & McKeachie, 1993).
We defined three clickstream measures to capture time manage-
ment. The two survey measures of time management focus on the be-
havior of getting coursework done on time. Therefore, we created a
clickstream measure of studyingontime based on the proportion of units
accessed before the deadline. Specifically, the behavior of studying a
unit on time is defined as a student having visited unit pageiof a given
module j before the deadline of the final quiz of module j. The pro-
portion of units a student studied on time was calculated for each
module (Pj) and the average value of the proportions of units studied on
time in the four modules (
+ + +P P P P
4
1 2 3 4 ) was used in the analysis.
In addition, previous studies suggest students with higher time
management skills are more likely to study early and to space out their
study time instead of procrastinating, cramming, and completing
coursework right before the deadlines (e.g., Michinov, Brunot, Le
Bohec, Juhel, & Delaval, 2011). Therefore, we included two additional
clickstream measures—studyinginadvance and spacing—that have been
commonly used in previous studies to measure time management (e.g.,
Baker et al., 2018;Crossley et al., 2016;Park et al., 2017). The behavior
of studying in advance is defined as students studying a unit in advance
of the deadlines. It can be captured by the time difference (T
j − Ti)
between the deadline of the final quiz of a given module j(Tj) and the
timestamp of when a student visited the unit page iin module jfor the
first time (Ti). We calculated the average value of such time differences
for each module (
= T T
n
i
n j i1 ) and used the average value across the four
modules as a measure of studying in advance in the analyses
(
=
=
4
j
i
n Tj Ti
n1
4 1 ).
Spacing is defined as spacing out one's study time and it is oper-
ationalized as the standard deviation of the time differences (std
(T
j− Ti)) between the deadline of the final quiz of a given modulej(Tj)
and the timestamp of when a student visited the unit pageiin module j
for the first time (Ti). Again, we used the average value of the standard
deviations of the four modules in the analyses (
= std T T( )
4
j j i1
4 ). We ex-
pected students with higher time management skills would space out
their visits of the study unites and thus would have larger standard
deviation values for the measure of days before deadline.
The one clickstream measure generated to capture effort regulation
was based on the definition of effort regulation. Effort regulation is
defined as the extent to which students can maintain their effort level
when they encounter difficulties (Pintrich et al., 1993). Although it is
difficult to identify specific moments when students experience diffi-
culties, effort regulation could be approximately captured based on the
overall trend of student effort level in the course. In previous studies,
student effort level is usually measured by student time spent on the
system, defined as time on task (Grabe & Sigler, 2002; Munk & Drlík,
2011). Therefore, we used the change in time on task during the course
to measure effort regulation. For each individual student, the change in
time on task during the course was operationalized as the slope of a
simple linear regression that regressed time on task in a given module
on the module number.
3.2.4. Performanceoutcomes
We used student final exam scores and overall course grades in the
current course as the performance outcomes to compare the predictive
power of self-reported and clickstream measures. The final exam score
and overall course grade were measured on a 100-point scale and 4-
point scale, respectively (see Table 2). We also predicted student course
grades in the subsequent course to examine the predictive power of self-
reported and clickstream measures over longer-term outcomes.
Table 2
Descriptive statistics of self-report measures, clickstream measures, and course
performance.
Note.238 completed both the pre- and post-course surveys and were used as the
main analytic sample. We followed a subset of students who continued to the
next course. Since 18 students did not take the subsequent course in the fol-
lowing quarter, the analytic sample for subsequent course outcome included
220 students."
"2020 - Using clickstream data to measure, understand, and support self-regulated learning in online courses.pdf","3.3. Analysis
3.3.1. Correlationanalysis
To answer the first research question, we analyzed the relationships
between self-reported and clickstream measures of time management
and effort regulation. The analyses were conducted separately for time
management and effort regulation. For each construct, we examined
the Pearson correlation coefficients between the clickstream measures
and both the pre-course survey measures and the post-course survey
measures. If the clickstream measures aligned with students' own pre-
dictions of their time management and effort regulation behaviors, one
would expect to see significantly positive correlations between the
clickstream measures and the pre-course survey measures. If click-
stream data can measure time management and effort regulation be-
haviors, and if students can accurately recall these behaviors in the
course, one would expect to see significantly positive correlations be-
tween the clickstream measures and the post-course survey measures.
3.3.2. Regressionanalysis
To examine if clickstream measures can enhance the utility of time
management and effort regulation measures, we regressed student
performance outcomes on both the self-reported and clickstream mea-
sures. For each outcome variable, we conducted multiple regression
analyses in five steps. The same regression analyses were conducted for
pre- and post-course self-reported measures separately as clickstream
measures may complement the two types of self-reported measures in
different ways. The five regression models using pre-course surveys are
written as:
= + +=y TM µi k k PRE i1
2
0 ki
(1)
= + + + += = =y TM TM TM µi k k PRE k k CLki k k CLki i1
2
1 1
3
2 1
3
3
2
ki
(2)
= + +=y ER µi k PRE i1
4
k4 ki
(3)
= + + + +=y ER ER ER µi k k PRE k CLi CLi i1
4
5 6 7
2
ki
(4)
= + +
+ +
+ + + +
= =
= =
y TM TM
TM ER
ER ER Student control µ_
i k k PRE k k CLki
k k CLki k k PRE
k CLi CLi i i
1
2
1 1
3
2
1
3
3
2
1
4
5
6 7
2
ki
ki
(5)
Model 1 regresses the outcome variable on the two measures of self-
reported time management, denoted as TMPREki. Model 2 adds the three
clickstream measures of time management, denoted asTMCLki. For each
clickstream measure, a quadratic term, denoted as
TM CLki2 , is also in-
cluded as previous research has found that the relationship between
clickstream measures and performance tend to be nonlinear (Li,
Kidzinski, Jermann, & Dillenbourg, 2015). To determine whether the
quadratic term is needed given that a linear term is already in the
model, we first regressed the outcome variable only on the linear and
quadratic terms of a clickstream measure and examined if the coeffi-
cient on the quadratic term was statistically significant. Model 3 re-
gresses the outcome variable on the four measures of self-reported ef-
fort regulation, denoted as ER
PREki. Model 4 adds the linear and
quadratic terms of the clickstream measure of effort regulation, denoted
as ER
CLi and
ERCLi2 . Finally, Model 5 regresses the outcome variable on
the self-reported and clickstream measures of both time management
and effort regulation, controlling for all the demographic variables
listed in Table 1, denoted as Student_control
i.
4. Results
4.1. Correlationsbetweenself-reportedmeasuresandclickstreammeasures
We first report the Pearson's correlation coefficients between
clickstream measures and self-reported measures. Table 3 presents the
results for time management and Table 4 presents the results for effort
regulation. There were differences in the extent to which clickstream
measures were related to the same self-reported measures from the pre-
and post-course surveys. For both time management and effort reg-
ulation, there were moderate, positive, and significant correlations
between clickstream measures and post-course survey measures.
However, the correlations between clickstream measures and pre-
course survey measures were, in general, small and insignificant.
These results for the time management are shown in Table 3. There
were significant positive correlations between the measures of time
management from the post-course survey and the clickstream measures
of studying on time, studying in advance, and spacing. However, for the
pre-course survey measures, only planning in advance was significantly
correlated with the clickstream measure of studying in advance, r
(238) = 0.17, p < .05. We found similar results for effort regulation,
shown in Table 4. All of the e effort regulation measures in the post-
course survey were positively and significantly correlated with the
change in time on task. In contrast, on the pre-course survey only the
self-reported measure of quitting before finishing was significantly
correlated with this clickstream measure, r(238) = 0.22, p < .001.
These significant correlations between clickstream measures and
post-course survey measures show the alignment between the beha-
vioral clickstream measures and students' own interpretations of their
time management and effort regulation behaviors. These significant
relationships provide evidence for the validity of using clickstream
measures to infer students' time management and effort regulation
skills. Additionally, the sizes of the correlation coefficients between
post-course survey measures and clickstream measures were relatively
small, suggesting the clickstream measures captured unique informa-
tion about students and might potentially help to improve course per-
formance prediction above survey measures alone. Finally, the lack of
Table 3
Correlations between self-report and clickstream measures of time management measures and course performance.
K_PRE P_PRE K_POST P_POST SOT_CL SA_CL SP_CL CFE CCG
Keep record of assignments_PRE 1
Plan in advance_PRE 0.53⁎⁎⁎ 1
Keep record of assignments_POST 0.31⁎⁎⁎ 0.30⁎⁎⁎ 1
Plan in advance_POST 0.31⁎⁎⁎ 0.37⁎⁎⁎ 0.56⁎⁎⁎ 1
Study on time_CL 0.08 0.07 0.22⁎⁎⁎ 0.27⁎⁎⁎ 1
Study in advance_CL 0.02 0.17⁎⁎⁎ 0.22⁎⁎⁎ 0.35⁎⁎⁎ 0.33⁎⁎⁎ 1
Space_CL 0.04 0.10 0.20⁎ 0.13⁎ 0.54⁎⁎⁎ 0.49⁎⁎⁎ 1
Current course final exam score −0.09 0.00 0.15⁎ 0.16 0.47⁎⁎⁎ 0.36⁎⁎⁎ 0.33⁎⁎⁎ 1
Current course grade −0.07 0.02 0.14⁎ 0.16⁎ 0.50⁎⁎⁎ 0.36⁎⁎⁎ 0.32⁎⁎⁎ 0.94⁎⁎⁎ 1
⁎ p < .05.
⁎⁎ p < .010.
⁎⁎⁎ p < .001.
Q.Li,etal. The Internet and Higher Education 45 (2020) 100727
6","3.3. Analysis
3.3.1. Correlationanalysis
To answer the first research question, we analyzed the relationships
between self-reported and clickstream measures of time management
and effort regulation. The analyses were conducted separately for time
management and effort regulation. For each construct, we examined
the Pearson correlation coefficients between the clickstream measures
and both the pre-course survey measures and the post-course survey
measures. If the clickstream measures aligned with students' own pre-
dictions of their time management and effort regulation behaviors, one
would expect to see significantly positive correlations between the
clickstream measures and the pre-course survey measures. If click-
stream data can measure time management and effort regulation be-
haviors, and if students can accurately recall these behaviors in the
course, one would expect to see significantly positive correlations be-
tween the clickstream measures and the post-course survey measures.
3.3.2. Regressionanalysis
To examine if clickstream measures can enhance the utility of time
management and effort regulation measures, we regressed student
performance outcomes on both the self-reported and clickstream mea-
sures. For each outcome variable, we conducted multiple regression
analyses in five steps. The same regression analyses were conducted for
pre- and post-course self-reported measures separately as clickstream
measures may complement the two types of self-reported measures in
different ways. The five regression models using pre-course surveys are
written as:
Model 1 regresses the outcome variable on the two measures of self-
reported time management, denoted as TMPREki. Model 2 adds the three
clickstream measures of time management, denoted asTMCLki. For each
clickstream measure, a quadratic term, denoted as
TM CLki2 , is also in-
cluded as previous research has found that the relationship between
clickstream measures and performance tend to be nonlinear (Li,
Kidzinski, Jermann, & Dillenbourg, 2015). To determine whether the
quadratic term is needed given that a linear term is already in the
model, we first regressed the outcome variable only on the linear and
quadratic terms of a clickstream measure and examined if the coeffi-
cient on the quadratic term was statistically significant. Model 3 re-
gresses the outcome variable on the four measures of self-reported ef-
fort regulation, denoted as ER
PREki. Model 4 adds the linear and
quadratic terms of the clickstream measure of effort regulation, denoted
as ER
CLi and
ERCLi2 . Finally, Model 5 regresses the outcome variable on
the self-reported and clickstream measures of both time management
and effort regulation, controlling for all the demographic variables
listed in Table 1, denoted as Student_control
i.
4. Results
4.1. Correlationsbetweenself-reportedmeasuresandclickstreammeasures
We first report the Pearson's correlation coefficients between
clickstream measures and self-reported measures. Table 3 presents the
results for time management and Table 4 presents the results for effort
regulation. There were differences in the extent to which clickstream
measures were related to the same self-reported measures from the pre-
and post-course surveys. For both time management and effort reg-
ulation, there were moderate, positive, and significant correlations
between clickstream measures and post-course survey measures.
However, the correlations between clickstream measures and pre-
course survey measures were, in general, small and insignificant.
These results for the time management are shown in Table 3. There
were significant positive correlations between the measures of time
management from the post-course survey and the clickstream measures
of studying on time, studying in advance, and spacing. However, for the
pre-course survey measures, only planning in advance was significantly
correlated with the clickstream measure of studying in advance, r
(238) = 0.17, p < .05. We found similar results for effort regulation,
shown in Table 4. All of the e effort regulation measures in the post-
course survey were positively and significantly correlated with the
change in time on task. In contrast, on the pre-course survey only the
self-reported measure of quitting before finishing was significantly
correlated with this clickstream measure, r(238) = 0.22, p < .001.
These significant correlations between clickstream measures and
post-course survey measures show the alignment between the beha-
vioral clickstream measures and students' own interpretations of their
time management and effort regulation behaviors. These significant
relationships provide evidence for the validity of using clickstream
measures to infer students' time management and effort regulation
skills. Additionally, the sizes of the correlation coefficients between
post-course survey measures and clickstream measures were relatively
small, suggesting the clickstream measures captured unique informa-
tion about students and might potentially help to improve course per-
formance prediction above survey measures alone. Finally, the lack of
Table 3"
"2020 - Using clickstream data to measure, understand, and support self-regulated learning in online courses.pdf","significant correlations between pre-course survey measures and
clickstream measures, which aligns with the results from previous
studies (Gilbert & Wilson, 2007), suggests that students' predictions of
their behavior made before the course may not reflect their actual be-
havior in the course.
4.2. Relationshipsbetweensurveyandclickstreammeasuresandcourse
performance
While the bivariate correlations indicate that the clickstream mea-
sures were associated with student self-reported self-regulation of time
and effort after the course, the question remains as to what extent that
these clickstream measures could provide additional information. That
is, can they be used to improve the predictions of student performance
based on self-reported data alone? We used regression analyses to ex-
amine the predictive power of both self-reported and clickstream
measures on students' course performance. Tables 5 and 6 presents
these results; Table 5 shows results from using clickstream measures
and self-reported measures from the pre-course survey to predict course
performance, and Table 6 presents results from the same regression
analyses using self-reported measures from the post-course survey.
4.2.1. Relationships between pre-course survey and clickstream measures
andstudentperformanceinthecurrentcourse
Results from Model 1 and Model 3 in Table 5 reveal that students'
self-reported time management and effort regulation from the pre-
course survey did not predict performance in the current course. The
joint F test for the overall significance of Model 1 revealed that neither
of the coefficients on the two time management measures was statis-
tically significant for course grade, F(2, 235) = 1.10, p=.35, or final
exam score, F(2, 235) = 1.24, p=.29. Similarly, the joint F test for the
four self-reported measures of effort regulation in Model 3 showed that
none of the coefficients significantly predicted course grade, F(4,
233) = 1.09, p= .36, or final exam score, F(4, 233) = 1.30, p= .27.
In contrast, we found that the clickstream measures of both time
management and effort regulation significantly improved the predic-
tion of both course grades and final exam scores in the current course.
Adding the clickstream measures of time management significantly
increased the explanatory power of the regression models for both
course grades and final exam scores, shown by the partial F tests in
Model 2 (course grade,F(5, 230) = 19.24,p <.001; final exam scores,
F(5, 230) = 17.55, p < .001). This is particularly true for the click-
stream measures of studying on time and studying in advance. For in-
stance, a one standard deviation increase in studying on time was as-
sociated with approximately a 0.4 standard deviation increase in course
grade and final exam score.
We found similar results for effort regulation. Adding linear and
quadratic measures of change in time on task significantly increased the
explanatory power of the regression models for both course grade and
final exam score, after controlling for self-reported effort regulation.
These are shown by the partial F tests in Model 4 for course grades,F(2,
231) = 41.22, p < .001, and final exam score, F(2, 231) = 32.85,
p <.001. For instance, the change in time on task had a significantly
positive linear relationship (ß = 0.449, p < .001) and a significantly
negative quadratic relationship (ß = −0.193, p < .001) with course
grade. These results suggest that an increase in time on task was asso-
ciated with better performance; however, the relationship was weaker
for students who had larger increases in their time on task.
Finally, the clickstream measures of studying on time, studying in
advance, and the change in time on task were significant predictors of
course performance even after controlling for a variety of student
background characteristics (e.g., gender, race, and prior performance)
(see Table 5 Model 5). For instance, a one standard deviation increase
in studying on time was associated with around a 0.16 standard de-
viation increase in course grade and final exam score. Again, after
controlling for student background characteristics, there was a positive
relationship between change in time on task and course grade
(ß= 0.245, p < .001), but the relationship was weaker for students
who had larger increases in time on task, as indicated by the coefficient
on the quadratic term (ß = −0.115, p < .01).
4.2.2. Relationships between post-course survey and clickstream measures
andstudentperformanceinthecurrentcourse
We then repeated the same analyses using self-reported measures
from the post-course survey and the same clickstream measures (see
Table 6). First, results from Model 1 and Model 3 suggest that, unlike
self-reported measures in the pre-course survey, the measures from the
post-course survey were predictive of student performance in the cur-
rent course. The joint F tests of the overall significance of Model 1 show
that together the two time management measures were significantly
associated with course grade, F(2, 235) = 3.58, p < .05, and final
exam score, F(2, 235) = 3.62, p < .05, although neither of the coef-
ficients on the two time management measures in Model 1 was in-
dividually significant at the 0.1 level for either course grades or final
exam scores.
For effort regulation, the joint F tests of Model 3 reveal that together
the four self-reported measures of effort regulation were significantly
associated with course grade, F(4, 233) = 8.87, p < .001, and final
exam score, F(4, 233)= 6.70,p < .001. In particular, results in Model
3 showed that the self-reported measure of keeping working until fin-
ished was predictive of course grade (β = 0.202, p < .01) and final
exam score (β = 0.224, p < .01), and the self-reported measure of
catching up when falling behind was predictive of course grade,
(ß= 0.166, p < .05), though not final exam score. These significant
relationships between course performance and student self-reported
measures from after the course may suggest that students were more
Table 4
Correlations for self-report and clickstream measures of effort regulation measures and course performance.
Q_PRE W_PRE K_PRE C_PRE Q_POST W_POST K_POST C_POST CT_CL CFE CCG
Quit before finishing_PRE 1
Work hard to do well_PRE 0.23⁎⁎⁎ 1
Keep working until finished_PRE 0.32⁎⁎⁎ 0.43⁎⁎⁎ 1
Catch up when falling behind_PRE 0.25⁎⁎⁎ 0.34⁎⁎⁎ 0.41⁎⁎⁎ 1
Quit before finishing_POST 0.35⁎⁎⁎ 0.03 0.25⁎⁎⁎ 0.08 1
Work hard to do well_POST 0.19⁎⁎ 0.2⁎⁎ 0.34⁎⁎⁎ 0.07 0.32⁎⁎⁎ 1
Keep working until finish_POST 0.22⁎⁎⁎ 0.04 0.27⁎⁎⁎ 0.12 0.42⁎⁎⁎ 0.44⁎⁎⁎ 1
Catch up when falling behind_POST 0.29⁎⁎⁎ 0.08 0.29⁎⁎⁎ 0.17⁎ 0.34⁎⁎⁎ 0.35⁎⁎⁎ 0.46⁎⁎⁎ 1
Change in time on task_CL 0.22⁎⁎⁎ 0.00 0.1 −0.05 0.21⁎⁎ 0.26⁎⁎⁎ 0.30⁎⁎⁎ 0.28⁎⁎⁎ 1
Current course final exam score 0.07 0.08 0.01 −0.07 0.17⁎⁎ 0.18⁎ 0.30⁎⁎⁎ 0.23⁎⁎⁎ 0.41⁎⁎⁎ 1
Current course grade 0.05 0.09 0.03 −0.05 0.20⁎⁎ 0.21⁎⁎ 0.32⁎⁎⁎ 0.29⁎⁎⁎ 0.42⁎⁎⁎ 0.94⁎⁎⁎ 1
⁎ p < .05.
⁎⁎ p < .010.
⁎⁎⁎ p < .001.
Q.Li,etal. The Internet and Higher Education 45 (2020) 100727
7","significant correlations between pre-course survey measures and
clickstream measures, which aligns with the results from previous
studies suggests that students' predictions of
their behavior made before the course may not reflect their actual be-
havior in the course.
4.2. Relationshipsbetweensurveyandclickstreammeasuresandcourse
performance
While the bivariate correlations indicate that the clickstream mea-
sures were associated with student self-reported self-regulation of time
and effort after the course, the question remains as to what extent that
these clickstream measures could provide additional information. That
is, can they be used to improve the predictions of student performance
based on self-reported data alone? We used regression analyses to ex-
amine the predictive power of both self-reported and clickstream
measures on students' course performance. Tables 5 and 6 presents
these results; Table 5 shows results from using clickstream measures
and self-reported measures from the pre-course survey to predict course
performance, and Table 6 presents results from the same regression
analyses using self-reported measures from the post-course survey.
4.2.1. Relationships between pre-course survey and clickstream measures
andstudentperformanceinthecurrentcourse
Results from Model 1 and Model 3 in Table 5 reveal that students'
self-reported time management and effort regulation from the pre-
course survey did not predict performance in the current course. The
joint F test for the overall significance of Model 1 revealed that neither
of the coefficients on the two time management measures was statis-
tically significant for course grade, or final
exam score. Similarly, the joint F test for the
four self-reported measures of effort regulation in Model 3 showed that
none of the coefficients significantly predicted course grade, or final exam score.
In contrast, we found that the clickstream measures of both time
management and effort regulation significantly improved the predic-
tion of both course grades and final exam scores in the current course.
Adding the clickstream measures of time management significantly
increased the explanatory power of the regression models for both
course grades and final exam scores, shown by the partial F tests in
Model 2 (course grade, final exam scores,
). This is particularly true for the click-
stream measures of studying on time and studying in advance. For in-
stance, a one standard deviation increase in studying on time was as-
sociated with approximately a 0.4 standard deviation increase in course
grade and final exam score.
We found similar results for effort regulation. Adding linear and
quadratic measures of change in time on task significantly increased the
explanatory power of the regression models for both course grade and
final exam score, after controlling for self-reported effort regulation.
These are shown by the partial F tests in Model 4 for course grades and final exam score. For instance, the change in time on task had a significantly
positive linear relationship (ß = 0.449, p < .001) and a significantly
negative quadratic relationship (ß = −0.193, p < .001) with course
grade. These results suggest that an increase in time on task was asso-
ciated with better performance; however, the relationship was weaker
for students who had larger increases in their time on task.
Finally, the clickstream measures of studying on time, studying in
advance, and the change in time on task were significant predictors of
course performance even after controlling for a variety of student
background characteristics (e.g., gender, race, and prior performance)
(see Table 5 Model 5). For instance, a one standard deviation increase
in studying on time was associated with around a 0.16 standard de-
viation increase in course grade and final exam score. Again, after
controlling for student background characteristics, there was a positive
relationship between change in time on task and course grade
(ß= 0.245, p < .001), but the relationship was weaker for students
who had larger increases in time on task, as indicated by the coefficient
on the quadratic term (ß = −0.115, p < .01).
4.2.2. Relationships between post-course survey and clickstream measures
andstudentperformanceinthecurrentcourse
We then repeated the same analyses using self-reported measures
from the post-course survey and the same clickstream measures (see
Table 6). First, results from Model 1 and Model 3 suggest that, unlike
self-reported measures in the pre-course survey, the measures from the
post-course survey were predictive of student performance in the cur-
rent course. The joint F tests of the overall significance of Model 1 show
that together the two time management measures were significantly
associated with course grade and final
exam score, although neither of the coef-
ficients on the two time management measures in Model 1 was in-
dividually significant at the 0.1 level for either course grades or final
exam scores.
For effort regulation, the joint F tests of Model 3 reveal that together
the four self-reported measures of effort regulation were significantly
associated with course grade and final
exam score. In particular, results in Model
3 showed that the self-reported measure of keeping working until fin-
ished was predictive of course grade (β = 0.202, p < .01) and final
exam score (β = 0.224, p < .01), and the self-reported measure of
catching up when falling behind was predictive of course grade,
(ß= 0.166, p < .05), though not final exam score. These significant
relationships between course performance and student self-reported
measures from after the course may suggest that students were more"
"2020 - Using clickstream data to measure, understand, and support self-regulated learning in online courses.pdf","accurate at reporting their time management and effort regulation after
they had experienced online courses. However, these findings may also
suggest that, when asked to report one's use strategies after the course,
performance in the course might influence students' self-reports.
In spite of the good predictive power of self-reported measures from
the post-course survey, we found that adding clickstream measures still
improved the prediction of student performance in the current course.
The partial F tests for all the clickstream measures of time management
in Model 2 show that adding the clickstream measures of time man-
agement significantly increased the explanatory power of the regression
models for both course grade, F(5, 230) = 17.06, p <.001, and final
exam score, F(5, 230) = 15.22, p < .001. Specifically, there were
large, positive, and significant relationships between course perfor-
mance and the measures of studying on time and studying in advance.
For instance, the clickstream measure of studying on time was sig-
nificantly associated with course grade (ß= 0.439, p < .001) and final
exam score (ß = 0.391, p < .001), even after controlling for self-re-
ported time management from the post-course survey. Similarly, results
in Model 4 showed that adding the linear and quadratic terms of the
change in time on task significantly increased the prediction of course
grade, F(2, 231) = 26.50, p < .001, and final exam score, F(2,
231) = 22.02, p < .001, after controlling for self-reported effort
regulation from the post-course survey.
When including all self-reported and clickstream measures and ad-
ditionally controlling for student background characteristics in Model
5, the clickstream measures of studying in advance and studying on
time were still predictive of final exam score, though not of course
grade. Again, there were significant, positive relationships between the
measure of change in time on task and both course grade and final exam
score, however, the positive relationships were smaller for students
with larger increases in time on task, as indicated by the negative
coefficients on the quadratic terms.
4.2.3. Relationships between post-course survey and clickstream measures
andstudentperformanceinthesubsequentcourse
Finally, we examined whether clickstream measures could improve
predictions of subsequent course outcomes from models using self-re-
ported measures from the post course survey. First, to make sure that
any potential difference in observed relationships between SRL mea-
sures and course outcomes from the current and subsequent courses
was not due to the change in the student sample, we re-estimated the
relationships between student grades in the current course and
Table 5
Pre-course self-report and clickstream measures of self-regulation predicting performance.
Course Grade Final Exam Score
M1 M2 M3 M4 M5 M1 M2 M3 M4 M5
Time management
Keep record of assignments_PRE −0.111 −0.116 + −0.070 −0.121 −0.122 + −0.089
(0.08) (0.07) (0.06) (0.08) (0.07) (0.06)
Plan in advance_PRE 0.081 0.017 0.078 0.064 −0.004 0.055
(0.08) (0.07) (0.06) (0.08) (0.07) (0.06)
Study on time_CL 0.441⁎⁎⁎ 0.160⁎ 0.395⁎⁎⁎ 0.161+
(0.07) (0.08) (0.07) (0.08)
Study in advance_CL 0.238⁎⁎ 0.143⁎ 0.258⁎⁎⁎ 0.155⁎
(0.07) (0.07) (0.08) (0.07)
Study in advance_CL2 −0.019 −0.005 −0.042 −0.028
(0.04) (0.04) (0.04) (0.04)
Space_CL −0.028 0.003 0.001 0.033
(0.07) (0.07) (0.07) (0.07)
Space_CL2 0.004 0.004 0.015 0.013
(0.05) (0.04) (0.05) (0.05)
Effort regulation
Quit before finishing_PRE 0.050 −0.031 −0.048 0.075 −0.005 −0.017
(0.07) (0.06) (0.06) (0.07) (0.06) (0.06)
Work hard to do well_PRE 0.114 0.137⁎ 0.148⁎⁎ 0.109 0.131⁎ 0.146⁎
(0.07) (0.06) (0.06) (0.07) (0.07) (0.06)
Keep working until finish_PRE 0.007 −0.057 −0.066 −0.008 −0.067 −0.070
(0.08) (0.07) (0.06) (0.08) (0.07) (0.06)
Catch up when falling behind_PRE −0.103 −0.027 −0.030 −0.119 −0.049 −0.050
(0.07) (0.06) (0.06) (0.07) (0.07) (0.06)
Change in time on task_CL 0.449⁎⁎⁎ 0.245⁎⁎⁎ 0.428⁎⁎⁎ 0.206⁎⁎
(0.06) (0.07) (0.06) (0.08)
Change in time on task_CL 2 −0.193⁎⁎⁎ −0.115⁎⁎ −0.159⁎⁎⁎ −0.080⁎
(0.04) (0.04) (0.04) (0.04)
Student controls Yes Yes
Partial F test
Self-reported time management 1.10 1.24
Clickstream measures of time management 19.24⁎⁎⁎ 17.55⁎⁎⁎
Self-reported effort regulation 1.09 1.30
Clickstream measure of effort regulation 41.22⁎⁎⁎ 32.85⁎⁎⁎
N 238 238 238 238 230 238 238 238 238 230
R square 0.009 0.301 0.018 0.277 0.507 0.010 0.284 0.022 0.238 0.459
Note.Two outcomes in the current course—course grade and final exam score—were used. For each performance outcome, five regression models were tested. Model
1 regresses course performance on self-reported time management and Model 2 adds the clickstream measures (Eqs.(1) and (2)). Similarly, Model 3 regresses course
performance on self-reported effort regulation and Model 4 adds the clickstream measure (Eqs.(3) and (4)). Finally, Model 5 regresses course performance outcomes
on all self-report measures, clickstream measures, and student controls listed in Table 1 (Eq. (5)). All coefficients are standardized.
+ p <.1.
⁎ p < .05.
⁎⁎ p <.010.
⁎⁎⁎ p <.001.
Q.Li,etal. The Internet and Higher Education 45 (2020) 100727
8","accurate at reporting their time management and effort regulation after
they had experienced online courses. However, these findings may also
suggest that, when asked to report one's use strategies after the course,
performance in the course might influence students' self-reports.
In spite of the good predictive power of self-reported measures from
the post-course survey, we found that adding clickstream measures still
improved the prediction of student performance in the current course.
The partial F tests for all the clickstream measures of time management
in Model 2 show that adding the clickstream measures of time man-
agement significantly increased the explanatory power of the regression
models for both course grade and final exam score. Specifically, there were
large, positive, and significant relationships between course perfor-
mance and the measures of studying on time and studying in advance.
For instance, the clickstream measure of studying on time was sig-
nificantly associated with course grade and final
exam score, even after controlling for self-re-
ported time management from the post-course survey. Similarly, results
in Model 4 showed that adding the linear and quadratic terms of the
change in time on task significantly increased the prediction of course
grade and final exam score, after controlling for self-reported effort
regulation from the post-course survey.
When including all self-reported and clickstream measures and ad-
ditionally controlling for student background characteristics in Model
5, the clickstream measures of studying in advance and studying on
time were still predictive of final exam score, though not of course
grade. Again, there were significant, positive relationships between the
measure of change in time on task and both course grade and final exam
score, however, the positive relationships were smaller for students
with larger increases in time on task, as indicated by the negative
coefficients on the quadratic terms.
4.2.3. Relationships between post-course survey and clickstream measures
andstudentperformanceinthesubsequentcourse
Finally, we examined whether clickstream measures could improve
predictions of subsequent course outcomes from models using self-re-
ported measures from the post course survey. First, to make sure that
any potential difference in observed relationships between SRL mea-
sures and course outcomes from the current and subsequent courses
was not due to the change in the student sample, we re-estimated the
relationships between student grades in the current course and"
"2020 - Using clickstream data to measure, understand, and support self-regulated learning in online courses.pdf","clickstream and self-reported measures on the subset of students who
enrolled in the subsequent course (N= 220). The results are presented
in the first five columns in Table 7. Most of the regression coefficients
were similar in size and directions to those in Table 6, suggesting that
potential differences in the two samples were not qualitatively chan-
ging the observed relationships. We then conducted the same analyses
using student grade in the subsequent course as the outcome measure.
The results are presented in the last five columns in Table 7.
In general, we found evidence that clickstream measures of time
management and effort regulation could improve the prediction of
students' subsequent course grades using just self-reported measures
from the post-course survey. In Models 2 and 4 in the right panel of
Table 7, the partial F tests show that, while the self-reported measures
were predictive of subsequent course performance, adding the click-
stream measures of time management, F(5, 212) = 11.10, p < .001,
and effort regulation, F(2, 213) = 8.61, p < .001, significantly im-
proved the prediction of subsequent course grade. Finally, results from
Model 5 in the same panel indicate that, after further controlling for
students' background characteristics and current course grade, there
was still a significant and positive relationship between students' sub-
sequent course grade and the clickstream measure of studying in ad-
vance (ß = 0.130, p < .1).
5. Discussion
5.1. Keyfindings
In this study, we examined the extent to which clickstream data
collected from the LMS can be used to measure and understand stu-
dents' time management and effort regulation behaviors and to increase
the effectiveness of the identification of at-risk students. Specifically,
we triangulated clickstream measures with student self-reported data
from before and after the course. These analyses provide direct em-
pirical evidence on the extent to which clickstream measures align with
self-reported measures. In addition, we used regression analyses to
examine whether adding clickstream measures to models predicting
current and subsequent course outcomes could improve predictions
from models using only self-reported measures. The results provide a
useful guidance to wisely choose SRL measures to trace the student
learning process and to support students with low SRL skills.
5.1.1. Pre-course survey measures did not correspond to clickstream
measuresnordidthempredictcourseperformance
We found that self-reported measures from the pre-course survey
were not correlated with students' clickstream behaviors later in the
Table 6
Post-course self-report and clickstream measures of self-regulation predicting performance.
Course Grade Final Exam Score
M1 M2 M3 M4 M5 M1 M2 M3 M4 M5
Time management
Keep record of assignments_POST 0.075 0.031 −0.005 0.091 0.044 0.012
(0.08) (0.07) (0.06) (0.08) (0.07) (0.06)
Plan in advance_POST 0.118 −0.059 −0.066 0.104 −0.065 −0.046
(0.08) (0.07) (0.07) (0.08) (0.07) (0.07)
Study on time_CL 0.439⁎⁎⁎ 0.127 0.391⁎⁎⁎ 0.141+
(0.07) (0.08) (0.07) (0.08)
Study in advance_CL 0.260⁎⁎ 0.108 0.276⁎⁎⁎ 0.133+
(0.08) (0.07) (0.08) (0.08)
Study in advance_CL2 −0.021 0.011 −0.043 −0.013
(0.04) (0.04) (0.04) (0.04)
Space_CL −0.041 0.020 −0.015 0.033
(0.08) (0.07) (0.08) (0.07)
Space_CL2 −0.003 0.002 0.006 0.016
(0.05) (0.04) (0.05) (0.05)
Effort regulation
Quit before finishing_POST 0.047 0.040 0.056 0.029 0.020 0.037
(0.07) (0.06) (0.06) (0.07) (0.06) (0.06)
Work hard to do well_POST 0.047 0.025 0.048 0.027 0.001 0.021
(0.07) (0.06) (0.06) (0.07) (0.07) (0.06)
Keep working until finish_POST 0.202⁎⁎ 0.105 0.100 0.224⁎⁎ 0.134+ 0.117+
(0.08) (0.07) (0.06) (0.08) (0.07) (0.07)
Catch up when falling behind_POST 0.166⁎ 0.084 0.044 0.113 0.036 −0.013
(0.07) (0.07) (0.06) (0.07) (0.07) (0.07)
Change in time on task_CL 0.367⁎⁎⁎ 0.219⁎⁎ 0.367⁎⁎⁎ 0.186⁎
(0.06) (0.07) (0.06) (0.08)
Change in time on task_CL 2 −0.172⁎⁎⁎ −0.111⁎⁎ −0.140⁎⁎⁎ −0.078⁎
(0.04) (0.04) (0.04) (0.04)
Student controls Yes Yes
Partial F test
Self-reported time management 3.58⁎ 3.62⁎
Clickstream measures of time management 17.06⁎⁎⁎ 15.22⁎⁎⁎
Self-reported effort regulation 8.87⁎⁎⁎ 6.70⁎⁎⁎
Clickstream measure of effort regulation 26.50⁎⁎⁎ 22.02⁎⁎⁎
N 238 238 238 238 230 238 238 238 238 230
R square 0.030 0.292 0.132 0.294 0.509 0.030 0.271 0.103 0.247 0.450
Note.Two outcomes in the current course—course grade and final exam score—were used. For each performance outcome, five regression models were tested. Model
1 regresses course performance on self-reported time management and Model 2 adds the clickstream measures (Eqs.(1) and (2)). Similarly, Model 3 regresses course
performance on self-reported effort regulation and Model 4 adds the clickstream measure (Eqs.(3) and (4)). Finally, Model 5 regresses course performance outcomes
on all self-report measures, clickstream measures, and student controls listed in Table 1 (Eq. (5)). All coefficients are standardized.
+ p <.1.
⁎ p < .05.
⁎⁎ p <.010.
⁎⁎⁎ p <.001.
Q.Li,etal. The Internet and Higher Education 45 (2020) 100727
9","clickstream and self-reported measures on the subset of students who
enrolled in the subsequent course (N= 220). The results are presented
in the first five columns in Table 7. Most of the regression coefficients
were similar in size and directions to those in Table 6, suggesting that
potential differences in the two samples were not qualitatively chan-
ging the observed relationships. We then conducted the same analyses
using student grade in the subsequent course as the outcome measure.
The results are presented in the last five columns in Table 7.
In general, we found evidence that clickstream measures of time
management and effort regulation could improve the prediction of
students' subsequent course grades using just self-reported measures
from the post-course survey. In Models 2 and 4 in the right panel of
Table 7, the partial F tests show that, while the self-reported measures
were predictive of subsequent course performance, adding the click-
stream measures of time management, and effort regulation, significantly im-
proved the prediction of subsequent course grade. Finally, results from
Model 5 in the same panel indicate that, after further controlling for
students' background characteristics and current course grade, there
was still a significant and positive relationship between students' sub-
sequent course grade and the clickstream measure of studying in ad-
vance.

5. Discussion
5.1. Keyfindings
In this study, we examined the extent to which clickstream data
collected from the LMS can be used to measure and understand stu-
dents' time management and effort regulation behaviors and to increase
the effectiveness of the identification of at-risk students. Specifically,
we triangulated clickstream measures with student self-reported data
from before and after the course. These analyses provide direct em-
pirical evidence on the extent to which clickstream measures align with
self-reported measures. In addition, we used regression analyses to
examine whether adding clickstream measures to models predicting
current and subsequent course outcomes could improve predictions
from models using only self-reported measures. The results provide a
useful guidance to wisely choose SRL measures to trace the student
learning process and to support students with low SRL skills.
5.1.1. Pre-course survey measures did not correspond to clickstream
measuresnordidthempredictcourseperformance
We found that self-reported measures from the pre-course survey
were not correlated with students' clickstream behaviors later in the
course."
"2020 - Using clickstream data to measure, understand, and support self-regulated learning in online courses.pdf","course nor were they predictive of students' current course perfor-
mance. In contrast, students' self-reported measures of time manage-
ment and effort regulation from the post-course survey were correlated
with their clickstream behaviors and were predictive of current and
subsequent course performance outcomes.
As suggested by previous studies, one potential reason for the lack of
significant relationships of pre-course survey measures is that students
tend to be overconfident at the beginning of the course and cannot
accurately predict their behavior in the course (DiBenedetto &
Bembenutty, 2013; Gilbert & Wilson, 2007). This may be especially
problematic in our research setting. Students in our sample were in
their first year of college and had little or no prior experience with
online learning. Indeed, we found students' self-reported time man-
agement and effort regulation behaviors both decreased from the be-
ginning to the end of the course; except for the measure of catching up
when falling behind, students reported lower values on all of self-re-
ported measures in the post-course survey as compared to the pre-
course survey.
5.1.2. Clickstream measures corresponded to post-course survey measures
andimprovedcourseperformanceprediction
We found that many of our clickstream measures were significantly
correlated with self-reported measures from the post-course survey.
Specifically, we found that the clickstream measures of studying on
time, studying in advance, and spacing were significantly correlated
with students' self-reported time management skills. The clickstream
measure of the change in time on task was significantly correlated with
students' self-reports of effort regulation. Additionally, the clickstream
measures significantly improved the predictions of both current and
subsequent course performance outcomes over models using only self-
reported measures from the post-course survey. These findings show
that the clickstream measures of time management and effort regula-
tion were both related to measures of the same concepts from a well-
established instrument (MSLQ) and predictive of student academic
success in an expected way, suggesting that these clickstream measures
can be used as valid tools to trace student SRL process and to identify
at-risk students (Messick, 1995).
Table 7
Post-course report and clickstream measures of self-regulation predicting subsequent course grade.
Current Course Grade Subsequent Course Grade
M1 M2 M3 M4 M5 M1 M2 M3 M4 M5
Time management
Keep record of assignments_POST 0.002 −0.013 −0.017 −0.086 −0.101 −0.080
(0.07) (0.07) (0.07) (0.08) (0.07) (0.06)
Plan in advance_POST 0.118 −0.040 −0.048 0.283⁎⁎⁎ 0.126 0.166⁎
(0.07) (0.08) (0.07) (0.08) (0.08) (0.07)
Study on time_CL 0.373⁎⁎⁎ 0.163⁎ 0.288⁎⁎⁎ 0.125
(0.07) (0.08) (0.07) (0.08)
Study in advance_CL 0.312⁎⁎⁎ 0.163⁎ 0.298⁎⁎⁎ 0.130+
(0.08) (0.08) (0.08) (0.07)
Study in advance_CL2 −0.030 −0.000 0.005 0.008
(0.04) (0.04) (0.04) (0.04)
Space_CL −0.076 −0.013 −0.035 −0.010
(0.08) (0.07) (0.08) (0.07)
Space_CL2 −0.029 −0.004 −0.032 −0.018
(0.05) (0.05) (0.05) (0.04)
Effort regulation
Quit before finishing_POST 0.019 0.033 0.055 −0.013 −0.002 −0.059
(0.07) (0.07) (0.06) (0.07) (0.07) (0.06)
Work hard to do well_POST 0.007 −0.032 0.006 0.086 0.051 0.085
(0.07) (0.07) (0.06) (0.08) (0.07) (0.06)
Keep working until finish_POST 0.244⁎⁎ 0.159⁎ 0.139⁎ 0.130 0.057 −0.068
(0.08) (0.08) (0.07) (0.08) (0.08) (0.07)
Catch up when falling behind_POST 0.154⁎ 0.118+ 0.060 0.120 0.088 −0.049
(0.07) (0.07) (0.07) (0.08) (0.07) (0.06)
Change in time on task_CL 0.290⁎⁎⁎ 0.123 0.252⁎⁎⁎ −0.063
(0.07) (0.08) (0.07) (0.08)
Change in time on task_CL 2 −0.140⁎⁎⁎ −0.078⁎ −0.121⁎⁎ −0.017
(0.04) (0.04) (0.04) (0.04)
Student controls Yes Yes
Current course grade Yes
Partial F test
Self-reported time management 2.02 6.95⁎⁎
Clickstream measures of time management 13.50⁎⁎⁎ 11.10⁎⁎⁎
Self-reported effort regulation 7.56⁎⁎⁎ 3.74⁎⁎
Clickstream measure of effort regulation 12.65⁎⁎⁎ 8.61⁎⁎⁎
N 220 220 220 220 213 220 220 220 220 213
R square 0.018 0.252 0.123 0.175 0.460 0.060 0.254 0.065 0.104 0.549
Note. Regression analyses in the left panel regress student grades in the current course on clickstream measures, self-report measures in the post-course survey, and
student controls listed in Table 1 only for the subset of students who enrolled in the subsequent course (N = 220). Regression analyses in the right panel regress
student grades in the subsequent course on clickstream measures, self-report measures in the post-course survey, and student controls listed in Table 1 for the same
subset of students. All coefficients are standardized.
+ p < .1.
⁎ p < .05.
⁎⁎ p < .010.
⁎⁎⁎ p < .001.
Q.Li,etal. The Internet and Higher Education 45 (2020) 100727
10","course nor were they predictive of students' current course perfor-
mance. In contrast, students' self-reported measures of time manage-
ment and effort regulation from the post-course survey were correlated
with their clickstream behaviors and were predictive of current and
subsequent course performance outcomes.
As suggested by previous studies, one potential reason for the lack of
significant relationships of pre-course survey measures is that students
tend to be overconfident at the beginning of the course and cannot
accurately predict their behavior in the course. This may be especially
problematic in our research setting. Students in our sample were in
their first year of college and had little or no prior experience with
online learning. Indeed, we found students' self-reported time man-
agement and effort regulation behaviors both decreased from the be-
ginning to the end of the course; except for the measure of catching up
when falling behind, students reported lower values on all of self-re-
ported measures in the post-course survey as compared to the pre-
course survey.
5.1.2. Clickstream measures corresponded to post-course survey measures
andimprovedcourseperformanceprediction
We found that many of our clickstream measures were significantly
correlated with self-reported measures from the post-course survey.
Specifically, we found that the clickstream measures of studying on
time, studying in advance, and spacing were significantly correlated
with students' self-reported time management skills. The clickstream
measure of the change in time on task was significantly correlated with
students' self-reports of effort regulation. Additionally, the clickstream
measures significantly improved the predictions of both current and
subsequent course performance outcomes over models using only self-
reported measures from the post-course survey. These findings show
that the clickstream measures of time management and effort regula-
tion were both related to measures of the same concepts from a well-
established instrument (MSLQ) and predictive of student academic
success in an expected way, suggesting that these clickstream measures
can be used as valid tools to trace student SRL process and to identify
at-risk students.
Table 7
Post-course report and clickstream measures of self-regulation predicting subsequent course grade."
"2020 - Using clickstream data to measure, understand, and support self-regulated learning in online courses.pdf","5.2. Implications
5.2.1. Researchimplications
Collectively, these findings have important implications for future
research regarding SRL in online learning environments. First, we found
suggestive evidence that students might overestimate their time man-
agement and effort regulation skills at the beginning of the course,
which may explain why these self-reported measures did not predict
course performance. These findings are in alignment with previous
research that identified miscalibrations between students' actual and
self-reported abilities and skills: students tend to overestimate their
performance and SRL behaviors at the beginning of the course, with
low-performing students exhibiting the most biased estimates (Dang,
Chiang, Brown, & McDonald, 2018; DiBenedetto & Bembenutty, 2013;
Osterhage, Usher, Douin, & Bailey, 2019; Winne & Jamieson-Noel,
2002).
Various explanations have been proposed for the miscalibration,
such as students' low metacognitive skills, the novelty of the course or
learning environment, and the lack of external feedback on students'
performance and behavior (Dang et al., 2018; Winne & Jamieson-Noel,
2002). However, more empirical evidence is needed to understand
what factors contribute to students' misperceptions of their ability and
skills, how students correct their estimations over time, and what
supports are needed to help students better estimate their own beha-
viors. For instance, future research could examine the relationship be-
tween students' characteristics, such as metacognitive skills, and the
accuracy of their estimation. Longitudinal studies are needed to in-
vestigate if and how students' estimation improves as they gain more
experience with a certain type of learning environment (e.g., online
courses). Finally, experimental studies could test if interventions, such
as external feedback in the form of teacher or peer evaluations, could
influence students' self-evaluations.
In addition, the evidence on the validity of these fine-grained and
unobtrusive clickstream measures allow researchers to use them in fu-
ture studies to extend our understanding of the dynamics of time
management and effort regulation behaviors at a more micro-level. In
particular, along with longitudinal analysis methods, these measures
could be used to track how time management and effort regulation
behaviors gradually and dynamically unfolds in authentic learning
environments and to examine the different changing trajectories across
students. Furthermore, using these detailed clickstream measures, re-
searchers could explore how personal and environmental factors (e.g.,
students' interest in the course content and the academic and social
resources available) shape students' behavior by examining the context
under which a given behavior (e.g., students completing homework in
advance) is most likely to occur.
5.2.2. Practicalimplications
Much work has identified the ways in which self-reported ques-
tionnaires that measure SRL can be used to support students in online
classes, both in terms of identifying at-risk students and in terms of
better understanding potential challenges. Self-reported SRL surveys
have been used to inform students' own decisions regarding course
selection, to help institutions evaluate students' skills needed to succeed
in online learning, as well as to guide the provision of timely and
personalized support to prevent student failure (Bork & Rucks-Ahidiana
Bork & Rucks-Ahidiana, 2013; Chen, 2009; Lee, Choi, & Kim, 2013;
Rowe & Rafferty, 2013). However, our results suggest that self-reported
data from before a course starts may not be reliable. This raises im-
portant concerns about the usefulness of self-reported measures of SRL.
This problem may be particularly acute for students who have little
online learning experience. Practitioners need to be cautious when
using and interpreting self-reports of SRL behaviors from students who
lack online learning experience. As a potential solution for this concern,
practitioners could administer surveys during, instead of before, the
course to give students some time to develop an appropriate
understanding of their own behavior and online learning more broadly.
However, self-evaluations that are administered during a course
may be too late for students to make a choice about which classes to
take or for instructors provide appropriate supports for students. Thus,
another potential policy solution that arises as an implication of this
research is the provision of online orientation courses that students
could take before enrolling in online courses. Such modules could
prepare students with appropriate expectations of online learning and
support them in more accurately predicting their future behavior (Bork
& Rucks-Ahidiana, 2013).
In addition, while clickstream data have been used to predict stu-
dent performance and identify at-risk students, their utility have been
critiqued in past studies (e.g., Gašević, Dawson, & Siemens, 2015;
Tempelaar, Rienties, & Nguyen, 2017; Van den Bogaard & De Vries,
2017) as raw clickstream measures (e.g., number of total page views
and frequency of login) provide little, if any, insight into why students
might be at risk and thus offer no clear guidance on how to intervene.
This study, however, identified several clickstream measures of time
management and effort regulation that can provide actionable in-
formation and potential directions for interventions. Since these mea-
sures are generated from data that are commonly recorded in learning
management systems widely used by higher education institutions,
real-time reports based on these clickstream measures can be easily
automatically generated to inform education decision-making by stu-
dents, instructors, and administrators. For instance, our findings sug-
gest that instructors could use clickstream measures to identify students
who may be suffering from poor time management skills and provide
support (e.g., sending them reminders to encourage them make a study
plan ahead of time) based on updated estimates of student time man-
agement skills using real-time clickstream data.
5.3. Limitations
There are a few limitations to this study. First, we observed some
interesting differences in the ways that self-reported measures pre-
dicted course performance in the current and subsequent courses. For
instance, while the post-course survey measure of planning in advance
was not predictive of current course performance, it was significantly
associated with subsequent course performance. One potential ex-
planation for the difference is that most of the students (99.95%) in the
subsequent course analysis were enrolled in the in-person section,
which may require different types of skills. Therefore, future research is
needed to examine how student self-reported and clickstream measures
of SRL collected in online courses may differentially predict students'
performance in different types of subsequent courses.
Additionally, as we noted in the section describing our data, this
study took place on a selective college campus with a racially and
ethnically diverse student body. This context has implications for the
generalizability of the findings. By virtue of being enrolled in a selective
four-year college, many students in this study likely had had the op-
portunity to develop SRL skills and thus might be relatively capable of
accurately reporting their SRL skills. Self-report questionnaires of SRL
may be even less effective for accurately measuring students' SRL skills
in other settings in higher education such as community colleges.
Moreover, as the range of SRL skills exhibited by students in this study
might not represent the range of skills in other settings, the clickstream
measures we found to be effective at detecting these skills within this
sample might not perform similarly in other contexts. Work that ex-
amines the contextual factors that affect the effectiveness of these self-
reported and clickstream measures could inform potential applicability
to other contexts.
5.4. Conclusion
This study provides a methodological foundation and practical
guidance for the use of clickstream data to trace and understand SRL
Q.Li,etal. The Internet and Higher Education 45 (2020) 100727
11","5.2. Implications
5.2.1. Researchimplications
Collectively, these findings have important implications for future
research regarding SRL in online learning environments. First, we found
suggestive evidence that students might overestimate their time man-
agement and effort regulation skills at the beginning of the course,
which may explain why these self-reported measures did not predict
course performance. These findings are in alignment with previous
research that identified miscalibrations between students' actual and
self-reported abilities and skills: students tend to overestimate their
performance and SRL behaviors at the beginning of the course, with
low-performing students exhibiting the most biased estimates.
Various explanations have been proposed for the miscalibration,
such as students' low metacognitive skills, the novelty of the course or
learning environment, and the lack of external feedback on students'
performance and behavior. However, more empirical evidence is needed to understand
what factors contribute to students' misperceptions of their ability and
skills, how students correct their estimations over time, and what
supports are needed to help students better estimate their own beha-
viors. For instance, future research could examine the relationship be-
tween students' characteristics, such as metacognitive skills, and the
accuracy of their estimation. Longitudinal studies are needed to in-
vestigate if and how students' estimation improves as they gain more
experience with a certain type of learning environment (e.g., online
courses). Finally, experimental studies could test if interventions, such
as external feedback in the form of teacher or peer evaluations, could
influence students' self-evaluations.
In addition, the evidence on the validity of these fine-grained and
unobtrusive clickstream measures allow researchers to use them in fu-
ture studies to extend our understanding of the dynamics of time
management and effort regulation behaviors at a more micro-level. In
particular, along with longitudinal analysis methods, these measures
could be used to track how time management and effort regulation
behaviors gradually and dynamically unfolds in authentic learning
environments and to examine the different changing trajectories across
students. Furthermore, using these detailed clickstream measures, re-
searchers could explore how personal and environmental factors (e.g.,
students' interest in the course content and the academic and social
resources available) shape students' behavior by examining the context
under which a given behavior (e.g., students completing homework in
advance) is most likely to occur.
5.2.2. Practicalimplications
Much work has identified the ways in which self-reported ques-
tionnaires that measure SRL can be used to support students in online
classes, both in terms of identifying at-risk students and in terms of
better understanding potential challenges. Self-reported SRL surveys
have been used to inform students' own decisions regarding course
selection, to help institutions evaluate students' skills needed to succeed
in online learning, as well as to guide the provision of timely and
personalized support to prevent student failure. However, our results suggest that self-reported
data from before a course starts may not be reliable. This raises im-
portant concerns about the usefulness of self-reported measures of SRL.
This problem may be particularly acute for students who have little
online learning experience. Practitioners need to be cautious when
using and interpreting self-reports of SRL behaviors from students who
lack online learning experience. As a potential solution for this concern,
practitioners could administer surveys during, instead of before, the
course to give students some time to develop an appropriate
understanding of their own behavior and online learning more broadly.
However, self-evaluations that are administered during a course
may be too late for students to make a choice about which classes to
take or for instructors provide appropriate supports for students. Thus,
another potential policy solution that arises as an implication of this
research is the provision of online orientation courses that students
could take before enrolling in online courses. Such modules could
prepare students with appropriate expectations of online learning and
support them in more accurately predicting their future behavior.
In addition, while clickstream data have been used to predict stu-
dent performance and identify at-risk students, their utility have been
critiqued in past studies as raw clickstream measures (e.g., number of total page views
and frequency of login) provide little, if any, insight into why students
might be at risk and thus offer no clear guidance on how to intervene.
This study, however, identified several clickstream measures of time
management and effort regulation that can provide actionable in-
formation and potential directions for interventions. Since these mea-
sures are generated from data that are commonly recorded in learning
management systems widely used by higher education institutions,
real-time reports based on these clickstream measures can be easily
automatically generated to inform education decision-making by stu-
dents, instructors, and administrators. For instance, our findings sug-
gest that instructors could use clickstream measures to identify students
who may be suffering from poor time management skills and provide
support (e.g., sending them reminders to encourage them make a study
plan ahead of time) based on updated estimates of student time man-
agement skills using real-time clickstream data.
5.3. Limitations
There are a few limitations to this study. First, we observed some
interesting differences in the ways that self-reported measures pre-
dicted course performance in the current and subsequent courses. For
instance, while the post-course survey measure of planning in advance
was not predictive of current course performance, it was significantly
associated with subsequent course performance. One potential ex-
planation for the difference is that most of the students (99.95%) in the
subsequent course analysis were enrolled in the in-person section,
which may require different types of skills. Therefore, future research is
needed to examine how student self-reported and clickstream measures
of SRL collected in online courses may differentially predict students'
performance in different types of subsequent courses.
Additionally, as we noted in the section describing our data, this
study took place on a selective college campus with a racially and
ethnically diverse student body. This context has implications for the
generalizability of the findings. By virtue of being enrolled in a selective
four-year college, many students in this study likely had had the op-
portunity to develop SRL skills and thus might be relatively capable of
accurately reporting their SRL skills. Self-report questionnaires of SRL
may be even less effective for accurately measuring students' SRL skills
in other settings in higher education such as community colleges.
Moreover, as the range of SRL skills exhibited by students in this study
might not represent the range of skills in other settings, the clickstream
measures we found to be effective at detecting these skills within this
sample might not perform similarly in other contexts. Work that ex-
amines the contextual factors that affect the effectiveness of these self-
reported and clickstream measures could inform potential applicability
to other contexts.
5.4. Conclusion
This study provides a methodological foundation and practical
guidance for the use of clickstream data to trace and understand SRL"
"2020 - Using clickstream data to measure, understand, and support self-regulated learning in online courses.pdf","behaviors and to identify students who lack SRL skills and are at-risk of
low performance in virtual learning environments. Using the click-
stream measures that have been verified in this study, future research
can track student SRL behaviors and explore the antecedents and con-
sequences associated with SRL behaviors. Such examinations may help
with the development of comprehensive frameworks of how student
behaviors dynamically interact with personal and environmental fac-
tors. Additionally, this study raises important concerns regarding the
use of self-report questionnaires to measure SRL and identify at-risk
students. Since the memories that students use to reflect on their past
behavior or predict their future SRL behaviors are not always accurate,
relying solely on self-reported data may lead to inaccurate measures of
SRL and under- or over-identification of at-risk students. Finally, this
study highlights the unique and significant contributions of clickstream
data in the identification of at-risk students. Institutional efforts can be
made to use clickstream data to develop and provide real-time analytic
reports of online students so that students, instructors, and institutions
can make more timely and informed decisions.
Acknowledgements
The work presented in this paper was support by the Investigating
Virtual Learning Environments Grant from the National Science
Foundation (Grant # 1535300).
References
Artino, A. R., Jr., & Stephens, J. M. (2009). Academic motivation and self-regulation: A
comparative analysis of undergraduate and graduate students learning online. The
InternetandHigherEducation,12(3–4), 146–151.
Azevedo, R., Behnagh, R., Duffy, M., Harley, J., & Trevors, G. (2012). Metacognition and
self-regulated learning in student-centered leaning environments. Theoreticalfoun-
dationsofstudent-centeredlearningenvironments (pp. 171–197). .
Baker, R., Evans, B., Li, Q., & Cung, B. (2018). Does inducing students to schedule lecture
watching in online classes improve their academic performance? An experimental
analysis of a time management intervention. ResearchinHigher Education, 1–32.
Barnard, L., Lan, W. Y., To, Y. M., Paton, V. O., & Lai, S. L. (2009). Measuring self-
regulation in online and blended learning environments. TheInternetandHigher
Education,12(1), 1–6.
Bernard, R. M., Brauer, A., Abrami, P. C., & Surkes, M. (2004). The development of a
questionnaire for predicting online learning achievement. DistanceEducation,25(1),
31–47.
Bettinger, E. P., Fox, L., Loeb, S., & Taylor, E. S. (2017). Virtual classrooms: How online
college courses affect student success.AmericanEconomicReview,107(9), 2855–2875.
Biggs, J. B. (1987). Study process questionnaire manual. StudentApproachesto Learning
andStudying. Radford House, Frederick St., Hawthorn 3122, Australia: Australian
Council for Educational Research Ltd.
Boekaerts, M. (2011). Emotions, emotion regulation, and self-regulation of learning.
Handbookofself-regulationoflearningandperformance,5, 408–425.
Bork, R. H., & Rucks-Ahidiana, Z. (2013). Roleambiguityinonlinecourses: Ananalysisof
studentandinstructorexpectations.(ccRcworkingpaperno.64). New york: Co- lumbia
University, teachers college, community college Research center.
Broadbent, J., & Poon, W. L. (2015). Self-regulated learning strategies & academic
achievement in online higher education learning environments: A systematic review.
TheInternetandHigher Education,27, 1–13.
Bruso, J. L., & Stefaniak, J. E. (2016). The use of self-regulated learning measure ques-
tionnaires as a predictor of academic success. TechTrends,60(6), 577–584.
Cazan, A. M. (2014, July). Self-regulated learning and academic achievement in the
context of online learning environments. TheInternationalScientificConference
ElearningandSoftwareFor Education. Vol.3. TheInternationalScientificConference
ElearningandSoftwareForEducation (pp. 90–). “Carol I” National Defence University.
Chang, M. M. (2007). Enhancing web-based language learning through self-monitoring.
Journal ofComputerAssistedLearning,23(3), 187–196.
Chen, C. M. (2009). Personalized E-learning system with self-regulated learning assisted
mechanisms for promoting learning performance. ExpertSystemswithApplications,
36(5), 8816–8829.
Cho, M. H., & Shen, D. (2013). Self-regulation in online learning. DistanceEducation,
34(3), 290–301.
Cicchinelli, A., Veas, E., Pardo, A., Pammer-Schindler, V., Fessl, A., Barreiros, C., &
Lindstädt, S. (2018). Finding traces of self-regulated learning in activity streams.
Proceedingsofthe8thInternationalConferenceonLearningAnalyticsandKnowledge (pp.
191–200). ACM.
Crossley, S., Paquette, L., Dascalu, M., McNamara, D. S., & Baker, R. S. (2016, April).
Combining click-stream data with NLP tools to better understand MOOC completion.
Proceedings ofthesixthinternational conferenceonlearninganalytics&knowledge (pp.
6–14). ACM.
Dabbagh, N., & Kitsantas, A. (2004). Supporting self-regulation in student-centered web-
based learning environments. InternationalJournalonE-learning,3(1), 40–47.
Dang, N. V., Chiang, J. C., Brown, H. M., & McDonald, K. K. (2018). Curricular activities
that promote metacognitive skills impact lower-performing students in an in-
troductory biology course. Journal ofMicrobiology &BiologyEducation,19(1).
DiBenedetto, M. K., & Bembenutty, H. (2013). Within the pipeline: Self-regulated
learning, self-efficacy, and socialization among college students in science courses.
LearningandIndividualDifferences,23, 218–224.
Dunnigan, J. E. (2018).Therelationshipofself-regulatedlearningandacademicriskfactorsto
academicperformanceincommunitycollegeonlinemathematicscourses. Doctoral
dissertationSeattle Pacific University.
Finnegan, C., Morris, L. V., & Lee, K. (2008). Differences by course discipline on student
behavior, persistence, and achievement in online courses of undergraduate general
education. Journal ofCollegeStudentRetention: Research,Theory&Practice,10(1),
39–54.
Fritz, J. (2011). Classroom walls that talk: Using online course activity data of successful
students to raise self-awareness of underperforming peers. TheInternetandHigher
Education,14(2), 89–97.
Gašević, D., Dawson, S., & Siemens, G. (2015). Let’s not forget: Learning analytics are
about learning. TechTrends,59(1), 64–71.
Gilbert, D. T., & Wilson, T. D. (2007). Prospection: Experiencing the future. Science,
317(5843), 1351–1354.
Grabe, M., & Sigler, E. (2002). Studying online: Evaluation of an online study environ-
ment. Computers&Education,38(4), 375–383.
Greene, J. A., & Azevedo, R. (2010). The measurement of learners’ self-regulated cogni-
tive and metacognitive processes while using computer-based learning environments.
EducationalPsychologist,45(4), 203–209.
Järvelä, S., & Hadwin, A. F. (2013). New frontiers: Regulating learning in CSCL.
EducationalPsychologist,48(1), 25–39.
Kahneman, D., Fredrickson, B. L., Schreiber, C. A., & Redelmeier, D. A. (1993). When
more pain is preferred to less: Adding a better end. PsychologicalScience,4(6),
401–405.
Kazerouni, A. M., Edwards, S. H., & Shaffer, C. A. (2017, August). Quantifying incre-
mental development practices and their relationship to procrastination.Proceedingsof
the2017ACMConferenceonInternationalComputingEducationResearch (pp. 191–
199). ACM.
Kizilcec, R. F., Pérez-Sanagustín, M., & Maldonado, J. J. (2017). Self-regulated learning
strategies predict learner behavior and goal attainment in massive open online
courses. Computers&Education,104, 18–33.
Klingsieck, K. B., Fries, S., Horz, C., & Hofer, M. (2012). Procrastination in a distance
university setting. DistanceEducation,33(3), 295–310.
Kumar, A., Kumar, P., Palvia, S. C. J., & Verma, S. (2017). Online education worldwide:
Current status and emerging trends. JournalofGlobalInformationTechnology
Management,21, 233–241.
Lee, Y., Choi, J., & Kim, T. (2013). Discriminating factors between completers of and
dropouts from online learning courses. BritishJournalofEducationalTechnology,
44(2), 328–337.
Levy, Y., & Ramim, M. M. (2013). An experimental study of habit and time incentive in
online-exam procrastination. Proceedingsofthechaisconferenceoninstructionaltech-
nologiesresearch (pp. 53–61). .
Lewis, B. A., MacEntee, V. M., DeLaCruz, S., Englander, C., Jeffrey, T., Takach, E., &
Woodall, J. (2005). Learning management systems comparison. Proceedings ofthe
2005InformingScienceandITEducationJointConference (pp. 17–29). .
Li, N., Kidzinski, L., Jermann, P., & Dillenbourg, P. (2015). How do in-video interactions
reflect perceived video difficulty? ProceedingsoftheEuropeanMOOCsstakeholder
summit2015 (pp. 112–121). PAU Education. Retrieved from https://infoscience.epfl.
ch/record/207968/files/emooc2015_howdodiff.pdf.
Lim, J. M. (2016). Predicting successful completion using student delay indicators in
undergraduate self-paced online courses. DistanceEducation,37(3), 317–332.
Loewenstein, G., O'Donoghue, T., & Rabin, M. (2003). Projection bias in predicting future
utility. The QuarterlyJournalofEconomics,118(4), 1209–1248.
Loong, T. E. (2012). Predicting pre-university international students’ math performance
by learning strategies and math anxiety in Malaysia.JournalofEducationalandSocial
Research,2(2), 73–83.
Lynch, R., & Dembo, M. (2004). The relationship between self-regulation and online
learning in a blended learning context. TheInternationalReviewofResearch inOpen
andDistributedLearning, 5(2).
Macfadyen, L. P., & Dawson, S. (2010). Mining LMS data to develop an “early warning
system” for educators: A proof of concept. Computers&Education,54(2), 588–599.
Matuga, J. M. (2009). Self-regulation, goal orientation, and academic achievement of
secondary students in online university courses. Journal ofEducationalTechnology&
Society,12(3), 4.
Messick, S. (1995). Standards of validity and the validity of standards in performance
asessment. EducationalMeasurement:IssuesandPractice,14(4), 5–8.
Michinov, N., Brunot, S., Le Bohec, O., Juhel, J., & Delaval, M. (2011). Procrastination,
participation, and performance in online learning environments. Computers&
Education,56(1), 243–252.
Morewedge, C. K., Gilbert, D. T., & Wilson, T. D. (2005). The least likely of times: How
remembering the past biases forecasts of the future. PsychologicalScience,16(8),
626–630.
Munk, M., & Drlík, M. (2011). Impact of different pre-processing tasks on effective
identification of users’ behavioral patterns in web-based educational system.Procedia
ComputerScience,4, 1640–1649.
Norton, A. (2016). MappingAustralianhighereducation2016. Melbourne: Grattan
Institute.
Osterhage, J. L., Usher, E. L., Douin, T. A., & Bailey, W. M. (2019). Opportunities for self-
evaluation increase student calibration in an introductory biology course. CBE—Life
Q.Li,etal.
The Internet and Higher Education 45 (2020) 100727
12","behaviors and to identify students who lack SRL skills and are at-risk of
low performance in virtual learning environments. Using the click-
stream measures that have been verified in this study, future research
can track student SRL behaviors and explore the antecedents and con-
sequences associated with SRL behaviors. Such examinations may help
with the development of comprehensive frameworks of how student
behaviors dynamically interact with personal and environmental fac-
tors. Additionally, this study raises important concerns regarding the
use of self-report questionnaires to measure SRL and identify at-risk
students. Since the memories that students use to reflect on their past
behavior or predict their future SRL behaviors are not always accurate,
relying solely on self-reported data may lead to inaccurate measures of
SRL and under- or over-identification of at-risk students. Finally, this
study highlights the unique and significant contributions of clickstream
data in the identification of at-risk students. Institutional efforts can be
made to use clickstream data to develop and provide real-time analytic
reports of online students so that students, instructors, and institutions
can make more timely and informed decisions.
Acknowledgements
The work presented in this paper was support by the Investigating
Virtual Learning Environments Grant from the National Science
Foundation (Grant # 1535300)."
"2020 - Using clickstream data to measure, understand, and support self-regulated learning in online courses.pdf","SciencesEducation,18(2), ar16.
Pardo, A., Han, F., & Ellis, R. A. (2016). Combining university student self-regulated
learning indicators and engagement with online learning events to predict academic
performance. IEEETransactionsonLearningTechnologies,10(1), 82–92.
Park, J., Denaro, K., Rodriguez, F., Smyth, P., & Warschauer, M. (2017, March). Detecting
changes in student behavior from clickstream data. Proceedings oftheSeventh
InternationalLearningAnalytics&KnowledgeConference (pp. 21–30). ACM.
Pintrich, P. R. (2000). The role of goal orientation in self-regulated learning.Handbookof
self-regulation(pp. 451–502). Academic Press.
Pintrich, P. R. (2004). A conceptual framework for assessing motivation and self-regu-
lated learning in college students. EducationalPsychology Review,16(4), 385–407.
Pintrich, P. R., & De Groot, E. V. (1990). Motivational and self-regulated learning com-
ponents of classroom academic performance. JournalofEducationalPsychology,
82(1), 33.
Pintrich, P. R., Smith, D., Garcia, T., & McKeachie, W. (1993). Amanualfortheuseofthe
motivatedstrategiesforlearning questionnaire(MSLQ). Ann Arbor, MI: The University
of Michigan.
Puzziferro, M. (2008). Online technologies self-efficacy and self-regulated learning as
predictors of final grade and satisfaction in college-level online courses.TheAmerican
Journal ofDistanceEducation,22(2), 72–89.
Qayyum, A., & Zawacki-Richter, O. (2018). Distance education in Australia, Europe and
the Americas. OpenanddistanceeducationinAustralia,EuropeandtheAmericas (pp.
121–131). Singapore: Springer.
Roll, I., & Winne, P. H. (2015). Understanding, evaluating, and supporting self-regulated
learning using learning analytics. JournalofLearningAnalytics,2(1), 7–12.
Rowe, F. A., & Rafferty, J. A. (2013). Instructional design interventions for supporting
self-regulated learning: Enhancing academic outcomes in postsecondary e-learning
environments. JournalofOnlineLearningandTeaching,9(4), 590–601.
Schellings, G., & Van Hout-Wolters, B. (2011). Measuring strategy use with self-report
instruments: Theoretical and empirical considerations. MetacognitionandLearning,
6(2), 83–90.
Sha, L., Looi, C. K., Chen, W., & Zhang, B. H. (2012). Understanding mobile learning from
the perspective of self-regulated learning. JournalofComputerAssistedLearning,
28(4), 366–378.
Taylor, R. T. (2012). ReviewoftheMotivatedStrategiesforLearningQuestionnaire(MSLQ)
UsingReliabilityGeneralization Techniquesto AssessscaleReliability. doctoral
dissertationAlabama, USA: Auburn University.
Tempelaar, D. T., Rienties, B., & Nguyen, Q. (2017). Towards actionable learning ana-
lytics using dispositions. IEEETransactionsonLearningTechnologies,10(1), 6–16.
U.S. Department of Education, National Center for Education Statistics (2018). In U.S.
Department of Education, National Center for Education Statistics (Ed.).
Table311.15:Numberandpercentageofstudentsenrolled indegree-grantingpost-
secondaryinstitutions,bydistanceeducationparticipation,locationofstudent,levelof
enrollment,andcontrolandlevelofinstitution:Fall2015andfall2016(2018 ed.). Digest
of Education Statistics. Retrieved from https://nces.ed.gov/programs/digest/d17/
tables/dt17_311.15.asp?current=yes.
Van Den Bogaard, M. E. D., & De Vries, P. (2017). Learning analytics is about learning,
not about analytics. Paperpresentedat45thannualSEFIconference. Terceira Portugal:
ISEP Lisbon.
Wang, C. H., Shannon, D. M., & Ross, M. E. (2013). Students’ characteristics, self-regu-
lated learning, technology self-efficacy, and course outcomes in online learning.
DistanceEducation,34(3), 302–323.
Weinstein, C. E., Schulte, A. C., & Palmer, D. R. (1987).LASSI:Learningandstudystrategies
inventory.Clearwater, FL: H. & H.
Winne, P. H. (1996). A metacognitive view of individual differences in self-regulated
learning. LearningandIndividualDifferences,8(4), 327–353.
Winne, P. H. (2010). Improving measurements of self-regulated learning. Educational
Psychologist,45(4), 267–276.
Winne, P. H., & Jamieson-Noel, D. (2002). Exploring students’ calibration of self reports
about study tactics and achievement. ContemporaryEducationalPsychology,27(4),
551–572.
Winne, P. H., Jamieson-Noel, D., & Muis, K. (2002). Methodological issues and advances
in researching tactics, strategies, and self-regulated learning. Advancesinmotivation
andachievement:Newdirectionsinmeasuresandmethods,12, 121–155.
Winne, P. H., & Perry, N. E. (2000). Measuring self-regulated learning. Handbookofself-
regulation(pp. 531–566). .
Xu, D., & Jaggars, S. S. (2011). The effectiveness of distance education across Virginia’s
community colleges: Evidence from introductory college-level math and English
courses. EducationalEvaluationandPolicyAnalysis,33(3), 360–377.
Xu, D., & Jaggars, S. S. (2013). The impact of online learning on students’ course out-
comes: Evidence from a large community and technical college system. Economicsof
EducationReview,37, 46–57.
Yilmaz, M. B., & Orhan, F. (2011). The validity and reliability study of the Turkish version
of the study process questionnaire. EducationandScience,36(159), 69–83.
You, J. W. (2016). Identifying significant indicators using LMS data to predict course
achievement in online learning. TheInternetandHigherEducation,29, 23–30.
Yukselturk, E., & Bulut, S. (2007). Predictors for student success in an online course.
JournalofEducationalTechnology&Society,10(2), 71–83.
Zimmerman, B. J. (2000). Attaining self-regulation: A social cognitive perspective.
Handbookofself-regulation (pp. 13–39). Academic Press.
Q.Li,etal.
The Internet and Higher Education 45 (2020) 100727
13","Q.Li,etal.
The Internet and Higher Education 45 (2020) 100727"
