source,page_content,cleaned_page_content
"Wade - 2019 - Measuring, Manipulating, and Predicting Student Success A 10-Year Assessment of Carnegie R1 Doctora.pdf","Article
Measuring,
Manipulating, and
Predicting Student
Success: A 10-Year
Assessment of
Carnegie R1 Doctoral
Universities Between
2004 and 2013
Nathaniel L. Wade1
Abstract
Student success measurements for 4-year institutions of higher education are a topic
of importance for numerous stakeholders including prospective and current stu-
dents, parents, staff, faculty, administrators, governing boards, policymakers, and
citizens. Common measures of student success are retention rates and 4- and
6-year graduation rates. However, the standardization, accuracy, and reporting of
these rates are less than scientific due in part to the operational definition provided
by the federal government for reporting graduation rates. The current system for
reporting retention and graduation rates are flawed. As accountability continues to
increase for institutions of higher education, this analysis provides comparative,
qualitative, and quantitative research with the goal of informing and assisting univer-
sities, as they strive to increase the rates at which their students succeed. A partic-
ular emphasis will be placed on an empirical analysis over a 10-year period of time
for retention and graduation rates of 115 Carnegie R1 doctoral universities.
1School for the Future of Innovation in Society, Center for Organization Research and Design, Arizona
State University, Phoenix, AZ, USA
Corresponding Author:
Nathaniel L. Wade, School for the Future of Innovation in Society, Center for Organization Research and
Design, Arizona State University, 550 North 3rd Street, Phoenix, AZ 85004, USA.
Email: nathaniel.wade@asu.edu
Journal of College Student Retention:
Research, Theory & Practice
2019, Vol. 21(1) 119–141
! The Author(s) 2019
Article reuse guidelines:
sagepub.com/journals-permissions
DOI: 10.1177/1521025119831456
journals.sagepub.com/home/csr","Abstract
Student success measurements for 4-year institutions of higher education are a topic
of importance for numerous stakeholders including prospective and current stu-
dents, parents, staff, faculty, administrators, governing boards, policymakers, and
citizens. Common measures of student success are retention rates and 4- and
6-year graduation rates. However, the standardization, accuracy, and reporting of
these rates are less than scientific due in part to the operational definition provided
by the federal government for reporting graduation rates. The current system for
reporting retention and graduation rates are flawed. As accountability continues to
increase for institutions of higher education, this analysis provides comparative,
qualitative, and quantitative research with the goal of informing and assisting univer-
sities, as they strive to increase the rates at which their students succeed. A partic-
ular emphasis will be placed on an empirical analysis over a 10-year period of time
for retention and graduation rates of 115 Carnegie R1 doctoral universities."
"Wade - 2019 - Measuring, Manipulating, and Predicting Student Success A 10-Year Assessment of Carnegie R1 Doctora.pdf","Keywords
student success, retention rates, graduation rates, Carnegie R1 Doctoral
Universities, higher education
Introduction
The emphasis on retention and graduation rates of colleges and universities over
the past half century has increased signiﬁcantly. Accountability for institutions
of higher education has evolved over time through multiple initiatives including
performance-based funding, strategic planning of institutions, strategic planning
of governing boards, the development of university ranking systems through
media outlets, and public policies requiring increased transparency within higher
education (Alexander, 2000; O’Meara, 2007; Pusser, 2004; Shin &
Toutkoushian, 2011). Most of these initiatives track, measure, and report stu-
dent success at universities and colleges in the form of 1-year retention and
6-year graduation rates. A continued focus on institutional retention and grad-
uation rates has transformed student success into a major academic and ﬁnan-
cial business comprised of numerous scholarly articles, books, conferences,
consulting agencies, and even a journal (Tinto, 2006). To better understand
the current state as well as the future of student success, a review of the past
should be undertaken in conjunction with empirical research to formulate and
guide future recommendations and policies involving retention and graduation
rates for institutions of higher education.
Literature Review
Historical Origin of Student Retention
Berger and Lyon (2005) provide a very thorough and comprehensive review of
the history and early developments of retention and graduation rates. One of the
earliest studies of student retention and persistence focused on students failing
to thrive in institutions of higher education. The study’s focus was on student
mortality which likened student attrition to a ﬁgurative death of the student
(McNeely, 1938). In his study, McNeely (1938) collected data from 60 institu-
tions throughout the United States in an attempt to better understand student
attrition at universities by assessing various factors including student attributes
(age to part-time employment), when and why the student left the institution,
and the average time it took for a student to obtain a degree (Berger & Lyon,
2005). It took nearly 30 years after McNeely’s study for the ﬁeld of student
retention and persistence to move to its more formative stage.
120 Journal of College Student Retention: Research, Theory & Practice 21(1)","Keywords
student success, retention rates, graduation rates, Carnegie R1 Doctoral
Universities, higher education
Introduction
The emphasis on retention and graduation rates of colleges and universities over
the past half century has increased signiﬁcantly. Accountability for institutions
of higher education has evolved over time through multiple initiatives including
performance-based funding, strategic planning of institutions, strategic planning
of governing boards, the development of university ranking systems through
media outlets, and public policies requiring increased transparency within higher
education. Most of these initiatives track, measure, and report stu-
dent success at universities and colleges in the form of 1-year retention and
6-year graduation rates. A continued focus on institutional retention and grad-
uation rates has transformed student success into a major academic and ﬁnan-
cial business comprised of numerous scholarly articles, books, conferences,
consulting agencies, and even a journal. To better understand
the current state as well as the future of student success, a review of the past
should be undertaken in conjunction with empirical research to formulate and
guide future recommendations and policies involving retention and graduation
rates for institutions of higher education.
Literature Review
Historical Origin of Student Retention
Berger and Lyon (2005) provide a very thorough and comprehensive review of
the history and early developments of retention and graduation rates. One of the
earliest studies of student retention and persistence focused on students failing
to thrive in institutions of higher education. The study’s focus was on student
mortality which likened student attrition to a ﬁgurative death of the student
(McNeely, 1938). In his study, McNeely (1938) collected data from 60 institu-
tions throughout the United States in an attempt to better understand student
attrition at universities by assessing various factors including student attributes
(age to part-time employment), when and why the student left the institution,
and the average time it took for a student to obtain a degree. It took nearly 30 years after McNeely’s study for the ﬁeld of student
retention and persistence to move to its more formative stage."
"Wade - 2019 - Measuring, Manipulating, and Predicting Student Success A 10-Year Assessment of Carnegie R1 Doctora.pdf","Theory Development for Student Retention
During the 1970s, several scholars began to develop theories regarding student
dropout, student retention, and student persistence. Spady (1970) conducted a
review of empirical literature developed during the 1960s regarding dropouts.
On completing the review, he implored others to perform more research regard-
ing interactions between students and their environment (Spady, 1970). Shortly
thereafter, Tinto (1975) developed his interactionist theory of student departure
by applying Durkheim’s (1951) theory of suicide to student dropout. Astin
(1977) was also a major contributor to the foundational theories of student
retention due to the extensive databases he built to explore student retention
in order to build theory. Through his research, student involvement was deemed
to be a major component of student retention (Astin, 1977). Bean (1980) also
contributed to theory development within retention by applying worker turn-
over theory to better explain student retention and dropout. Collective theory
building from scholars regarding student dropout led to an even more extensive
analysis of retention and graduation rates through both quantitative and qual-
itative analysis (Astin, 1971; Bean, 1990; Tinto, 1987).
Understanding Student Retention and Graduation Through
Empirical Research
Once a theoretical foundation was established, empirical analyses began to pro-
liferate in order to test the developed theories, develop new theories, and explain
the effects that individual and institutional characteristics had on student reten-
tion and graduation (Astin, 1991; Goenner & Snaith, 2004a; Pascarella &
Terenzini, 1991; Tinto, 1987). Several studies demonstrated that a student’s
individual characteristics including high school grades, high school class rank,
admissions test scores, and race were important for retention and graduation
rates (Astin, 1991, 1993, 1997; Goenner & Snaith, 2004a, 2004b), while other
studies established that institutional characteristics also affected student success
and student completion rates (Goenner & Snaith, 2004a; Tinto, 1987, 1999). To
develop a robust theoretical framework on a student’s decision to depart college,
Cabrera, Nora, and Castaneda (1993) merged Tinto’s (1975, 1987) student inte-
gration model and Bean’s (1985) student attrition model by deploying a two-
step structural equation modeling strategy. In addition to the aforementioned
empirical studies, other studies have been undertaken to quantitatively evaluate
and understand factors that affect retention and graduation rates using various
methods including stepwise linear regression analysis (Astin, 2005), Bayesian
model averaging for variable selection (Goenner & Snaith, 2004b), survival of
failure analysis (Murtaugh, Burns, & Schuster, 1999), logistic regression and
probit analysis (Dey & Astin, 1993; Kroc, Howard, Hull, & Woodard, 1997),
multiple regression analysis (Astin, 1997), linear regression (Dey & Astin, 1993),
Wade 121","Theory Development for Student Retention
During the 1970s, several scholars began to develop theories regarding student
dropout, student retention, and student persistence. Spady (1970) conducted a
review of empirical literature developed during the 1960s regarding dropouts.
On completing the review, he implored others to perform more research regard-
ing interactions between students and their environment (Spady, 1970). Shortly
thereafter, Tinto (1975) developed his interactionist theory of student departure
by applying Durkheim’s (1951) theory of suicide to student dropout. Astin
(1977) was also a major contributor to the foundational theories of student
retention due to the extensive databases he built to explore student retention
in order to build theory. Through his research, student involvement was deemed
to be a major component of student retention (Astin, 1977). Bean (1980) also
contributed to theory development within retention by applying worker turn-
over theory to better explain student retention and dropout. Collective theory
building from scholars regarding student dropout led to an even more extensive
analysis of retention and graduation rates through both quantitative and qual-
itative analysis (Astin, 1971; Bean, 1990; Tinto, 1987).
Understanding Student Retention and Graduation Through
Empirical Research
Once a theoretical foundation was established, empirical analyses began to pro-
liferate in order to test the developed theories, develop new theories, and explain
the effects that individual and institutional characteristics had on student reten-
tion and graduation (Astin, 1991; Goenner & Snaith, 2004a; Pascarella &
Terenzini, 1991; Tinto, 1987). Several studies demonstrated that a student’s
individual characteristics including high school grades, high school class rank,
admissions test scores, and race were important for retention and graduation
rates (Astin, 1991, 1993, 1997; Goenner & Snaith, 2004a, 2004b), while other
studies established that institutional characteristics also affected student success
and student completion rates (Goenner & Snaith, 2004a; Tinto, 1987, 1999). To
develop a robust theoretical framework on a student’s decision to depart college,
Cabrera, Nora, and Castaneda (1993) merged Tinto’s (1975, 1987) student inte-
gration model and Bean’s (1985) student attrition model by deploying a two-
step structural equation modeling strategy. In addition to the aforementioned
empirical studies, other studies have been undertaken to quantitatively evaluate
and understand factors that affect retention and graduation rates using various
methods including stepwise linear regression analysis (Astin, 2005), Bayesian
model averaging for variable selection (Goenner & Snaith, 2004b), survival of
failure analysis (Murtaugh, Burns, & Schuster, 1999), logistic regression and
probit analysis (Dey & Astin, 1993; Kroc, Howard, Hull, & Woodard, 1997),
multiple regression analysis (Astin, 1997), linear regression (Dey & Astin, 1993),"
"Wade - 2019 - Measuring, Manipulating, and Predicting Student Success A 10-Year Assessment of Carnegie R1 Doctora.pdf","factor analysis, multivariate analysis of covariance, setwise discriminant analy-
sis, and classiﬁcation analysis (Pascarella & Terenzini, 1980). As student reten-
tion and graduation theory continued to be strengthened by scholars from the
1980s to the 2000s, other developments were slowly taking form within higher
education through enrollment management, institutional accountability, public
policy, and university ranking systems.
Institutional, Governmental, and Media Involvement in Student
Success Measures
In an effort to sustain and even increase revenues during a period of stagnant
enrollment growth during the 1980s, administrators began to focus on retaining
students while simultaneously creating a student body of quality and quantity
through a process known as enrollment management (Berger & Lyon, 2005).
Concurrently with the development of enrollment management in the 1980s,U.
S. News and World Report(USNWR) published its ﬁrstBest College Rankings
during 1983.USNWR switched its methodological ranking formula during 1988
to include retention and graduation rates which
increasingly created greater public awareness about and institutional responsive-
ness to retention rates. As a result, campuses around the country have become
increasingly concerned about retention rates as a source of prestige that can be
converted into other kinds of symbolic, material, and human resources—particu-
larly in the competition for more students. (Berger & Lyon, 2005, p. 5).
USNWR continues to use retention and graduation rates as part of its ranking
methodology formula.USNWR’s 2016 best colleges methodology has retention
set as 22.5% of the total score where 6-year graduation rates contribute to 80%
of the retention score and ﬁrst-year retention rate contributes to the ﬁnal 20% of
the retention score (Morse, Brooks, & Mason, 2015). As media outlets like
USNWR began publishing their data publically to better inform consumers of
higher education, sell magazines, and keep stakeholders in suspense year to year
(Machung, 1998), the federal government began its attempt to hold institutions
of higher education more accountable by passing legislation requiring the pub-
lication of graduation rates.
The Student Right-to-Know and Campus Security Act (1990) was a bill
passed by the 101st Congress that became public law on November 8, 1990,
in order to provide better information to potential consumers of higher educa-
tion while holding colleges and universities more accountable. The bill amended
the Higher Education Act (HEA) of 1965 to require:
. . . all institutions of higher education participating in any program under HEA
title IV (Student Assistance) to disclose the completion or graduation rate of
122 Journal of College Student Retention: Research, Theory & Practice 21(1)","factor analysis, multivariate analysis of covariance, setwise discriminant analysis, and classiﬁcation analysis. As student retention and graduation theory continued to be strengthened by scholars from the 1980s to the 2000s, other developments were slowly taking form within higher education through enrollment management, institutional accountability, public policy, and university ranking systems.
Institutional, Governmental, and Media Involvement in Student
Success Measures
In an effort to sustain and even increase revenues during a period of stagnant enrollment growth during the 1980s, administrators began to focus on retaining students while simultaneously creating a student body of quality and quantity through a process known as enrollment management.
Concurrently with the development of enrollment management in the 1980s,U. S. News and World Report(USNWR) published its ﬁrstBest College Rankings during 1983.USNWR switched its methodological ranking formula during 1988 to include retention and graduation rates which
increasingly created greater public awareness about and institutional responsive- ness to retention rates. As a result, campuses around the country have become increasingly concerned about retention rates as a source of prestige that can be converted into other kinds of symbolic, material, and human resources—particu- larly in the competition for more students.
USNWR continues to use retention and graduation rates as part of its ranking methodology formula.USNWR’s 2016 best colleges methodology has retention set as 22.5% of the total score where 6-year graduation rates contribute to 80% of the retention score and ﬁrst-year retention rate contributes to the ﬁnal 20% of the retention score. As media outlets like USNWR began publishing their data publically to better inform consumers of higher education, sell magazines, and keep stakeholders in suspense year to year, the federal government began its attempt to hold institutions of higher education more accountable by passing legislation requiring the pub- lication of graduation rates.
The Student Right-to-Know and Campus Security Act (1990) was a bill passed by the 101st Congress that became public law on November 8, 1990, in order to provide better information to potential consumers of higher educa- tion while holding colleges and universities more accountable. The bill amended the Higher Education Act (HEA) of 1965 to require:
. . . all institutions of higher education participating in any program under HEA title IV (Student Assistance) to disclose the completion or graduation rate of"
"Wade - 2019 - Measuring, Manipulating, and Predicting Student Success A 10-Year Assessment of Carnegie R1 Doctora.pdf","certiﬁcate- or degree-seeking, full-time students entering those institutions. Sets
forth formulas for determining such rates. Allows institutions to exclude from
such rates students who leave school to serve in the armed services, on ofﬁcial
church missions, or with a recognized Federal foreign aid service. (Student Right-
to-Know and Campus Security Act, 1990).
To assist institutions with reporting their graduation rate, the Graduation Rate
Survey was developed by the National Center for Education Statistics and
housed within the Integrated Postsecondary Education Data System (IPEDS)
of the U.S. Department of Education (Albright, 2010). The following are cur-
rent operational deﬁnitions for retention rates and graduation rates that can be
found within the U.S. Department of Education’s IPEDS glossary of terms:
Retention Rate: A measure of the rate at which students persist in their educational
program at an institution, expressed as a percentage. For four-year institutions,
this is the percentage of ﬁrst-time bachelors (or equivalent) degree-seeking under-
graduates from the previous fall who are again enrolled in the current fall. For all
other institutions this is the percentage of ﬁrst-time degree/certiﬁcate-seeking stu-
dents from the previous fall who either re-enrolled or successfully completed their
program by the current fall. (U.S. Department of Education, 2016a)
Graduation Rates: The rate required for disclosure or reporting purposes under
Student Right-to-Know Act. This rate is calculated as the total number of com-
pleters within 150% of normal time divided by the revised adjusted cohort. This
annual component of IPEDS was added in 1997 to help institutions satisfy the
requirements of the Student Right-to-Know legislation. Data are collected on the
number of students entering the institution as full-time, ﬁrst-time, degree/
certiﬁcate-seeking undergraduate students in a particular year (cohort), by race/
ethnicity and gender; the number completing their program within 150 percent of
normal time to completion. (U.S. Department of Education, 2016a)
Calculating Retention and Graduation Rates
To calculate retention and graduation rates for 4-year institutions, a cohort
must be developed and tracked over time according to the terms provided by
the Student Right-to-Know and Campus Security Act as well as the above
retention rate and graduation rates deﬁnitions. To track each year’s cohort of
ﬁrst-time, full-time freshmen, an institution’s response to the Institutional
Characteristics survey question regarding its predominant calendar system
determines how the cohort for reporting is formed (Albright, 2010).
Institutions with standard academic terms must annually identify a fall cohort
of ﬁrst-time, full-time freshmen who entered either the summer or fall of the year
in which they initially enrolled. Institutional cohorts are determined by
Wade 123","certiﬁcate- or degree-seeking, full-time students entering those institutions. Sets
forth formulas for determining such rates. Allows institutions to exclude from
such rates students who leave school to serve in the armed services, on ofﬁcial
church missions, or with a recognized Federal foreign aid service.
To assist institutions with reporting their graduation rate, the Graduation Rate
Survey was developed by the National Center for Education Statistics and
housed within the Integrated Postsecondary Education Data System (IPEDS)
of the U.S. Department of Education. The following are cur-
rent operational deﬁnitions for retention rates and graduation rates that can be
found within the U.S. Department of Education’s IPEDS glossary of terms:
Retention Rate: A measure of the rate at which students persist in their educational
program at an institution, expressed as a percentage. For four-year institutions,
this is the percentage of ﬁrst-time bachelors (or equivalent) degree-seeking under-
graduates from the previous fall who are again enrolled in the current fall. For all
other institutions this is the percentage of ﬁrst-time degree/certiﬁcate-seeking stu-
dents from the previous fall who either re-enrolled or successfully completed their
program by the current fall.
Graduation Rates: The rate required for disclosure or reporting purposes under
Student Right-to-Know Act. This rate is calculated as the total number of com-
pleters within 150% of normal time divided by the revised adjusted cohort. This
annual component of IPEDS was added in 1997 to help institutions satisfy the
requirements of the Student Right-to-Know legislation. Data are collected on the
number of students entering the institution as full-time, ﬁrst-time, degree/
certiﬁcate-seeking undergraduate students in a particular year (cohort), by race/
ethnicity and gender; the number completing their program within 150 percent of
normal time to completion.
Calculating Retention and Graduation Rates
To calculate retention and graduation rates for 4-year institutions, a cohort
must be developed and tracked over time according to the terms provided by
the Student Right-to-Know and Campus Security Act as well as the above
retention rate and graduation rates deﬁnitions. To track each year’s cohort of
ﬁrst-time, full-time freshmen, an institution’s response to the Institutional
Characteristics survey question regarding its predominant calendar system
determines how the cohort for reporting is formed.
Institutions with standard academic terms must annually identify a fall cohort
of ﬁrst-time, full-time freshmen who entered either the summer or fall of the year
in which they initially enrolled. Institutional cohorts are determined by"
"Wade - 2019 - Measuring, Manipulating, and Predicting Student Success A 10-Year Assessment of Carnegie R1 Doctora.pdf","institutional census dates that can range from the end of the institution’s drop-
add period until October 15 for the year in which the freshmen class entered
(Albright, 2010). The technical deﬁnitions of retention rates, graduation rates,
cohort formation, and census dates provide a springboard to discuss several
fundamental ﬂaws and loopholes that prohibit a complete or accurate measure-
ment of student success, decrease the reliability of the reported data, and pro-
vide vague or loose deﬁnitions for institutions to interpret. Through institutional
interpretation, the possibility arises for institutions to manipulate or game
the system.
Comparing colleges and their outcomes has been a contentious matter within
higher education (Anderson & Rucker, 2013). In fact, deﬁning and calculating
retention and graduation rates has been a source of confusion for many colleges
and universities (Albright, 2010; Anderson & Rucker, 2013). By excluding all
ﬁrst-time, full-time freshmen who begin in the spring semester, all part-time
students, and all students who transfer into the institution, the deﬁnition used
to measure graduation rates has excluded nearly 61% of students at 4-year
institutions according to calculations from the American Council on
Education (Cook & Hartle, 2011; Glenn, 2010).
Hagedorn (2005) notes that some institutions only admit students with the
highest admission test scores to their fall cohorts while allowing students with
lower admission test scores to only be admitted during the spring semester.
Other institutions allow students to meet admission requirements by increasing
the acceptable criteria to include a combination of Scholastic Aptitude Test
(SAT)/American College Testing (ACT) score, high school class rank percent-
age, or overall grade point average (GPA). This allows students who struggle
with standardized testing to avoid taking or reporting their standardized test
while allowing the institution to also avoid reporting a test score for that stu-
dent. This type of admissions criteria allows institutions to provide access to
students while also allowing the institution to potentially avoid lowering its
institutional SAT mean.
Astin (1993) argues that a simple retention rate is more indicative of who a
university admits rather than the effectiveness of the institution’s retention strat-
egy. Through the development of formulas from multiple regression analysis,
Astin conducted a longitudinal study of 39,243 students from 129 four-year
colleges and institutions to demonstrate that expected rates versus actual rates
of student retention can vary drastically. The comparison between expected to
actual retention rates illustrates how effective an institution can be in retaining
and graduating its students while accounting for the complexity involved in
comparing dissimilar institutions (Astin, 1993; Cook & Hartle, 2011).
Critics of the statistics used to calculate retention and graduation rates often
cite the issue of student mobility due to the inability of institutions to count
students who transfer between institutions and complete their degree elsewhere
(Carey, 2004). A report by the National Center for Education Statistics
124 Journal of College Student Retention: Research, Theory & Practice 21(1)","institutional census dates that can range from the end of the institution’s drop-
add period until October 15 for the year in which the freshmen class entered. The technical deﬁnitions of retention rates, graduation rates,
cohort formation, and census dates provide a springboard to discuss several
fundamental ﬂaws and loopholes that prohibit a complete or accurate measure-
ment of student success, decrease the reliability of the reported data, and pro-
vide vague or loose deﬁnitions for institutions to interpret. Through institutional
interpretation, the possibility arises for institutions to manipulate or game
the system.
Comparing colleges and their outcomes has been a contentious matter within
higher education. In fact, deﬁning and calculating
retention and graduation rates has been a source of confusion for many colleges
and universities. By excluding all
ﬁrst-time, full-time freshmen who begin in the spring semester, all part-time
students, and all students who transfer into the institution, the deﬁnition used
to measure graduation rates has excluded nearly 61% of students at 4-year
institutions according to calculations from the American Council on
Education.
Hagedorn (2005) notes that some institutions only admit students with the
highest admission test scores to their fall cohorts while allowing students with
lower admission test scores to only be admitted during the spring semester.
Other institutions allow students to meet admission requirements by increasing
the acceptable criteria to include a combination of Scholastic Aptitude Test
(SAT)/American College Testing (ACT) score, high school class rank percent-
age, or overall grade point average (GPA). This allows students who struggle
with standardized testing to avoid taking or reporting their standardized test
while allowing the institution to also avoid reporting a test score for that stu-
dent. This type of admissions criteria allows institutions to provide access to
students while also allowing the institution to potentially avoid lowering its
institutional SAT mean.
Astin (1993) argues that a simple retention rate is more indicative of who a
university admits rather than the effectiveness of the institution’s retention strat-
egy. Through the development of formulas from multiple regression analysis,
Astin conducted a longitudinal study of 39,243 students from 129 four-year
colleges and institutions to demonstrate that expected rates versus actual rates
of student retention can vary drastically. The comparison between expected to
actual retention rates illustrates how effective an institution can be in retaining
and graduating its students while accounting for the complexity involved in
comparing dissimilar institutions.
Critics of the statistics used to calculate retention and graduation rates often
cite the issue of student mobility due to the inability of institutions to count
students who transfer between institutions and complete their degree elsewhere. A report by the National Center for Education Statistics"
"Wade - 2019 - Measuring, Manipulating, and Predicting Student Success A 10-Year Assessment of Carnegie R1 Doctora.pdf","demonstrated a 7% increase in reported student completion when adding in
students who completed their degree at their original institution or any other
4-year institution (Berkner, He, & Cataldi, 2002).
The variability in census date per institution demonstrates a lack of national
standardization in deﬁning institutional cohorts by one deﬁned date, length of
time, or percentage of time. The lack of standardization for institutional census
dates is less than scientiﬁc and has the potential to muddle comparative studies
of similar institutions. For example, one institution may select to have its census
date very early in the semester, while another institution may wait until October
15 to set its census date. Overall, there are several fundamental ﬂaws in the
current operational deﬁnition used to report and calculate retention and grad-
uation rates of 4-year institutions.
Research on Retention and Graduation Rates
The study of retention and graduation has developed rapidly over the past 50
years with an ever increasing focus on accountability with many states linking
resources to speciﬁc measures of retention and graduation rates (Tinto, 2006,
2002). Despite the continued emphasis on accountability, the federal deﬁnitions
and methodologies used to calculate student success remain limited in scope. In
fact, taking advantage of loopholes and gaming the system has recently been
reported for Mount St. Mary’s, Claremont McKenna, Villanova University, and
the University of Illinois (Brown, 2016; Bult, 2016; Perez-Pena & Slotnik, 2012).
This study will use comparative analyses and several examples of colleges and
universities in an attempt to explain changes in retention and graduation rates
over 10 years. In addition, this study will focus on how both student character-
istics and institutional characteristics affect retention and graduation rates over
a 10-year period of time between 2004 and 2013 at Carnegie R1: doctoral uni-
versities through the use of a multiple linear models including random and
ﬁxed effects.
The review of several previous studies involving student and institutional
characteristics aided in developing the hypotheses for this study. Knott and
Payne (2004) conducted a review of previous studies that demonstrated that
autonomous private universities were superior performers as compared with
public universities. The governance of universities may affect organizational
management and strategy by forcing highly regulated systems like public insti-
tutions to focus on politically prioritized strategies (i.e., keeping tuition low,
increasing retention, and graduation rates) compared with minimally regulated
systems like private institutions that tend to focus on research productivity and
income or tuition revenues (Enders, De Boer, & Weyer, 2013). Campus size has
been positively correlated with university performance (Eykamp, 1995), while a
study of 258 Carnegie I institutions found that SAT scores affect graduation rates
in a signiﬁcant and positive manner (Goenner & Snaith, 2004a). Astin (2005)
Wade 125","The variability in census date per institution demonstrates a lack of national
standardization in deﬁning institutional cohorts by one deﬁned date, length of
time, or percentage of time. The lack of standardization for institutional census
dates is less than scientiﬁc and has the potential to muddle comparative studies
of similar institutions. For example, one institution may select to have its census
date very early in the semester, while another institution may wait until October
15 to set its census date. Overall, there are several fundamental ﬂaws in the
current operational deﬁnition used to report and calculate retention and grad-
uation rates of 4-year institutions.
Research on Retention and Graduation Rates
The study of retention and graduation has developed rapidly over the past 50
years with an ever increasing focus on accountability with many states linking
resources to speciﬁc measures of retention and graduation rates. Despite the continued emphasis on accountability, the federal deﬁnitions
and methodologies used to calculate student success remain limited in scope. In
fact, taking advantage of loopholes and gaming the system has recently been
reported for Mount St. Mary’s, Claremont McKenna, Villanova University, and
the University of Illinois.
This study will use comparative analyses and several examples of colleges and
universities in an attempt to explain changes in retention and graduation rates
over 10 years. In addition, this study will focus on how both student character-
istics and institutional characteristics affect retention and graduation rates over
a 10-year period of time between 2004 and 2013 at Carnegie R1: doctoral uni-
versities through the use of a multiple linear models including random and
ﬁxed effects.
The review of several previous studies involving student and institutional
characteristics aided in developing the hypotheses for this study. Knott and
Payne conducted a review of previous studies that demonstrated that
autonomous private universities were superior performers as compared with
public universities. The governance of universities may affect organizational
management and strategy by forcing highly regulated systems like public insti-
tutions to focus on politically prioritized strategies (i.e., keeping tuition low,
increasing retention, and graduation rates) compared with minimally regulated
systems like private institutions that tend to focus on research productivity and
income or tuition revenues. Campus size has
been positively correlated with university performance, while a
study of 258 Carnegie I institutions found that SAT scores affect graduation rates
in a signiﬁcant and positive manner."
"Wade - 2019 - Measuring, Manipulating, and Predicting Student Success A 10-Year Assessment of Carnegie R1 Doctora.pdf","found institutional selectivity to be “the most important college characteristic
affecting the student’s chances of completing the baccalaureate degree” (p. 10).
Research Hypotheses
The hypotheses for this study are shown in Figure 1. The hypothesized factors
being investigated are indicated with solid arrows with positive and negative
effects. The dotted arrows illustrate variables from past empirical research
shown to inﬂuence retention and graduation rates. As each hypothesized
factor increases, the effect on retention and graduation rate is indicated by a
(þ)o r(/C0 ). The variables with dotted arrows were mentioned in earlier sections
of this study but are not included within the hypotheses due to the College
Scorecard not having certain metrics available (high school GPA, class rank,
alumni giving, and institutional endowment) as well as changes that occurred in
the deﬁnition of race/ethnicity over time (student diversity). The hypotheses for
this study are as follows:
Hypothesis 1:The mean institutional SAT will have signiﬁcant and positive effects
on 1-year retention and 6-year graduation rates.
Figure 1. Factors influencing student success at R:1 doctoral universities. AAU¼Association
of American Universities; GPA¼grade point average.
126 Journal of College Student Retention: Research, Theory & Practice 21(1)","found institutional selectivity to be “the most important college characteristic
affecting the student’s chances of completing the baccalaureate degree” (p. 10).
Research Hypotheses
The hypotheses for this study are shown in Figure 1. The hypothesized factors
being investigated are indicated with solid arrows with positive and negative
effects. The dotted arrows illustrate variables from past empirical research
shown to inﬂuence retention and graduation rates. As each hypothesized
factor increases, the effect on retention and graduation rate is indicated by a
(þ)o r(/C0 ). The variables with dotted arrows were mentioned in earlier sections
of this study but are not included within the hypotheses due to the College
Scorecard not having certain metrics available (high school GPA, class rank,
alumni giving, and institutional endowment) as well as changes that occurred in
the deﬁnition of race/ethnicity over time (student diversity). The hypotheses for
this study are as follows:
Hypothesis 1:The mean institutional SAT will have signiﬁcant and positive effects
on 1-year retention and 6-year graduation rates.
Figure 1. Factors influencing student success at R:1 doctoral universities."
"Wade - 2019 - Measuring, Manipulating, and Predicting Student Success A 10-Year Assessment of Carnegie R1 Doctora.pdf","Hypothesis 2:The more selective an institution is (admission rate) a signiﬁcant and
positive effect on 1-year retention and 6-year graduation rates will be observed.
Hypothesis 3: Smaller institutional enrollment will have signiﬁcant and positive
effects on 1-year retention and 6-year graduation rates.
Hypothesis 4: Compared with public institutions, private institutions will have
signiﬁcantly increased 1-year retention and 6-year graduation rates.
Hypothesis 5:Membership in the Association of American Universities (AAU) will
have a signiﬁcantly positive effect on 1-year retention and 6-year graduation rates.
Data Collection
Previous studies have investigated Carnegie I research universities (Goenner &
Snaith, 2004b) as well as members of the AAU and Land Grant universities
(Kroc, Woodard, Howard, & Hull, 1995). For this study, a data set was con-
structed from raw data obtained through the College Scorecard (U.S.
Department of Education, 2016b) for a 10-year period beginning in 2004 and
ending in 2013. Using the most recent Carnegie Classiﬁcation of Institutions of
Higher Education (2016), each of the 115 R1: doctoral universities with the
highest research activity was selected out of 7,234 postsecondary title IV insti-
tutions of higher education with 4,706 of those being degree granting institu-
tions (U.S. Department of Education, 2015). The use of Carnegie R1 institutions
for this study allowed for institutional variability to be limited by using only one
type of institution from a well-established university categorization system. The
data set was constructed to have 115 subjects based on each university’s iden-
tiﬁcation number. The City University of New York was removed for each year
due to a lack of reported data. The repeated measure for this study was time (10
individual years 2004–2013) due to it being nested within each institution. Each
year contained the variables listed from the College Scorecard for each institu-
tion including 1-year retention rate, 6-year graduation rate, mean SAT, admis-
sion rate, and total enrollment. Dummy variables were made for private
institutions (0 ¼public and 1 ¼private) and AAU members (0 ¼nonmember
and 1 ¼member). In addition, to control for year effects, individual years
were added and coded as dummy variables. All 10 individual years were com-
bined to create panel data.
Methodology
Comparative analyses were performed for all 115 Carnegie R1 institutions
in order to yield the 10-year change in retention and graduation rates, the
10 highest 1-year increases in retention and graduation rates, and the 10 highest
10-year increases in retention and graduation rates. Further investigation using
the comparative analyses allowed for speciﬁc institutions to be explored.
Wade 127","Hypothesis 2:The more selective an institution is (admission rate) a signiﬁcant and
positive effect on 1-year retention and 6-year graduation rates will be observed.
Hypothesis 3: Smaller institutional enrollment will have signiﬁcant and positive
effects on 1-year retention and 6-year graduation rates.
Hypothesis 4: Compared with public institutions, private institutions will have
signiﬁcantly increased 1-year retention and 6-year graduation rates.
Hypothesis 5:Membership in the Association of American Universities (AAU) will
have a signiﬁcantly positive effect on 1-year retention and 6-year graduation rates.
Data Collection
Previous studies have investigated Carnegie I research universities as well as members of the AAU and Land Grant universities. For this study, a data set was con-
structed from raw data obtained through the College Scorecard for a 10-year period beginning in 2004 and
ending in 2013. Using the most recent Carnegie Classiﬁcation of Institutions of
Higher Education (2016), each of the 115 R1: doctoral universities with the
highest research activity was selected out of 7,234 postsecondary title IV insti-
tutions of higher education with 4,706 of those being degree granting institu-
tions. The use of Carnegie R1 institutions
for this study allowed for institutional variability to be limited by using only one
type of institution from a well-established university categorization system. The
data set was constructed to have 115 subjects based on each university’s iden-
tiﬁcation number. The City University of New York was removed for each year
due to a lack of reported data. The repeated measure for this study was time (10
individual years 2004–2013) due to it being nested within each institution. Each
year contained the variables listed from the College Scorecard for each institu-
tion including 1-year retention rate, 6-year graduation rate, mean SAT, admis-
sion rate, and total enrollment. Dummy variables were made for private
institutions (0 ¼public and 1 ¼private) and AAU members (0 ¼nonmember
and 1 ¼member). In addition, to control for year effects, individual years
were added and coded as dummy variables. All 10 individual years were com-
bined to create panel data.
Methodology
Comparative analyses were performed for all 115 Carnegie R1 institutions
in order to yield the 10-year change in retention and graduation rates, the
10 highest 1-year increases in retention and graduation rates, and the 10 highest
10-year increases in retention and graduation rates. Further investigation using
the comparative analyses allowed for speciﬁc institutions to be explored."
"Wade - 2019 - Measuring, Manipulating, and Predicting Student Success A 10-Year Assessment of Carnegie R1 Doctora.pdf","In addition to the comparative analyses, multiple linear models were performed
with one dependent variable being institutional retention rates and the other
dependent variable being graduation rates over a 10-year period of time. The
National Center for Education and Regional Assistance within the Institute of
Education Sciences of the U.S. Department of Education has developed a help-
ful primer for analyzing nested data through the use of multilevel modeling
(O’Dwyer & Parker, 2014). For this study, the plm statistical package for R
was used to perform both random and ﬁxed effects models (Croissant &
Millo, 2008).
Results
Comparative Analyses of Retention and Graduation Rates
A comparative analysis can be found in the Supplementary Material demon-
strating changes over a 10-year period of time (2004–2013) for each institution’s
retention rate (Supplementary Table A1) and graduation rate (Supplementary
Table A2).
To better understand individual institutions and the highest increases in
retention and graduation rates, a comparative analysis was conducted to iden-
tify the 10 highest increases in retention rates from 2004 to 2013 for R1 insti-
tutions (Table 1), the 10 highest increases in graduation rates from 2004 to 2013
for R1 institutions (Table 2), the 10 highest increases in retention rates for a 1-
year period of time during 2004 to 2013 for R1 institutions (Table 3), and the 10
highest increases in graduation rates for a 1-year period of time during 2004 to
2013 for R1 institutions (Table 4).
Table 1.T en Highest Increases in Retention Rate from 2004 to 2013 at R1: Doctoral
Universities.
University name 2004 (%) 2013 (%) Change (%)
The University of T exas at Dallas 80 88.11 8.11
University of South Florida—Main Campus 81 88.78 7.78
University of Houston 77 84.63 7.63
The University of T ennessee–Knoxville 78 85.63 7.63
University of Cincinnati—Main Campus 77 84.62 7.62
Virginia Commonwealth University 79 86.59 7.59
Northeastern University 88 95.53 7.53
Arizona State University–T empe 77 84.40 7.40
University of Massachusetts–Amherst 82 89.30 7.30
George Mason University 81 87.28 6.28
128 Journal of College Student Retention: Research, Theory & Practice 21(1)","In addition to the comparative analyses, multiple linear models were performed
with one dependent variable being institutional retention rates and the other
dependent variable being graduation rates over a 10-year period of time. The
National Center for Education and Regional Assistance within the Institute of
Education Sciences of the U.S. Department of Education has developed a help-
ful primer for analyzing nested data through the use of multilevel modeling. For this study, the plm statistical package for R
was used to perform both random and ﬁxed effects models.
Results
Comparative Analyses of Retention and Graduation Rates
A comparative analysis can be found in the Supplementary Material demon-
strating changes over a 10-year period of time (2004–2013) for each institution’s
retention rate (Supplementary Table A1) and graduation rate (Supplementary
Table A2).
To better understand individual institutions and the highest increases in
retention and graduation rates, a comparative analysis was conducted to iden-
tify the 10 highest increases in retention rates from 2004 to 2013 for R1 insti-
tutions (Table 1), the 10 highest increases in graduation rates from 2004 to 2013
for R1 institutions (Table 2), the 10 highest increases in retention rates for a 1-
year period of time during 2004 to 2013 for R1 institutions (Table 3), and the 10
highest increases in graduation rates for a 1-year period of time during 2004 to
2013 for R1 institutions (Table 4).
Table 1.T en Highest Increases in Retention Rate from 2004 to 2013 at R1: Doctoral
Universities.
University name 2004 (%) 2013 (%) Change (%)
The University of T exas at Dallas 80 88.11 8.11
University of South Florida—Main Campus 81 88.78 7.78
University of Houston 77 84.63 7.63
The University of T ennessee–Knoxville 78 85.63 7.63
University of Cincinnati—Main Campus 77 84.62 7.62
Virginia Commonwealth University 79 86.59 7.59
Northeastern University 88 95.53 7.53
Arizona State University–T empe 77 84.40 7.40
University of Massachusetts–Amherst 82 89.30 7.30
George Mason University 81 87.28 6.28"
"Wade - 2019 - Measuring, Manipulating, and Predicting Student Success A 10-Year Assessment of Carnegie R1 Doctora.pdf","Notable Institutions
For this study, the University of Texas at Dallas (UT-Dallas) had the greatest
positive increase in retention rates over a 10-year period (Table 1), while
Northeastern had the greatest positive increase in graduation rates over a
10-year period of time (Table 2). These two institutions will serve as examples
of institutions that signiﬁcantly increased their retention and graduation rates.
After running descriptive statistics for the data set, Arizona State University
(ASU) emerged as an outlier due to having both the highest increase and
decrease in enrollment over a 10-year period of time for all 115 institutions.
ASU also appears as one of the top highest increases in yearly retention rates
Table 2.T en Highest Increases in Graduation Rate From 2004 to 2013 at R1: Doctoral
Universities.
University name 2004 (%) 2013 (%) Change (%)
Northeastern University 59.87 82.56 22.69
Ohio State University—Main Campus 62.10 83.23 21.13
University of Louisville 33.07 53.43 20.36
University of Minnesota—T win Cities 56.43 75.40 18.97
University of Cincinnati—Main Campus 41.31 57.90 16.59
University of South Florida—Main Campus 46.69 63.21 16.52
University of Alabama at Birmingham 37.73 53.77 16.04
Virginia Commonwealth University 40.78 56.81 16.03
George Mason University 52.77 66.70 13.93
University of Pittsburgh—Pittsburgh Campus 67.38 80.44 13.06
Table 3.T en Highest Y early Increases in Retention Rate During 2004 to 2013 at R1: Doctoral
Universities.
University name
Retention
(%; year)
Retention
(%; year) Change (%)
University of South Florida—Main Campus 80.93 (2007) 88.01 (2008) 7.08
Wayne State University 69.68 (2008) 76.11 (2009) 6.43
Florida International University 78.00 (2006) 83.91 (2007) 5.91
University of T exas at Arlington 60.09 (2008) 65.11 (2009) 5.02
University of Nebraska–Lincoln 79.00 (2004) 84.00 (2005) 5.00
University of T exas at Arlington 65.11 (2009) 69.86 (2010) 4.75
University of Mississippi 80.84 (2012) 85.58 (2013) 4.74
Kansas State University 74.28 (2008) 78.99 (2009) 4.71
Arizona State University–T empe 79.95 (2012) 84.40 (2013) 4.45
University of Kentucky 76.37 (2007) 80.80 (2008) 4.43
Wade 129","Notable Institutions
For this study, the University of Texas at Dallas (UT-Dallas) had the greatest
positive increase in retention rates over a 10-year period (Table 1), while
Northeastern had the greatest positive increase in graduation rates over a
10-year period of time (Table 2). These two institutions will serve as examples
of institutions that signiﬁcantly increased their retention and graduation rates.
After running descriptive statistics for the data set, Arizona State University
(ASU) emerged as an outlier due to having both the highest increase and
decrease in enrollment over a 10-year period of time for all 115 institutions.
ASU also appears as one of the top highest increases in yearly retention rates"
"Wade - 2019 - Measuring, Manipulating, and Predicting Student Success A 10-Year Assessment of Carnegie R1 Doctora.pdf","over a 1-year period (Table 3) and 10-year period (Table 1). Finally, a very
recent example will be explored in which a retention plan developed by the
president of Mount St. Mary’s came under intense national scrutiny. Several
institutions in the past 10 years have either inﬂated their reported scores or
misreported their statistics including Claremont McKenna, Villanova
University, and the University of Illinois (Perez-Pena & Slotnik, 2012). This
study does not allege any dishonesty or make a value judgment on the institu-
tions involved in the examples. Instead, each institution within three of the four
examples (Northeastern, UT-Dallas, and ASU) has demonstrated over a 10-year
period of time that they have had some of the most signiﬁcant gains in retention
and graduation rates. The ﬁnal example of Mount St. Mary’s made national
headlines and concluded with the resignation of its president (Brown, 2016;
Svrluga, 2016). Three of these cases may serve as examples for administrators
and policy makers who are interested in increasing their retention and gradua-
tion rates. The fourth case serves as an example for institutions on how to avoid
disastrous public relations due to trying to game their retention or gradua-
tion rates.
Northeastern University
Kutner (2014) provides an extensive review of how Northeastern University
climbed the USNWR Best College rankings from 162 to 49 over 17 years. In
his very detailed examination of Northeastern University, Kutner chronologi-
cally displays the multiple methods that Joseph Aoun, the school’s 12th presi-
dent, took over time to infuse the gaming of college rankings into the
institution’s DNA. Northeastern spent a tremendous amount of time and
Table 4.T en Highest Y early Increases in Graduation Rate During 2004 to 2013 at R1:
Doctoral Universities.
University Name
Retention
(%; year)
Retention
(%; year) Change (%)
University of T exas at Arlington 41.66 (2006) 51.90 (2007) 10.24
University of Utah 46.20 (2006) 55.99 (2007) 9.79
University of South Florida—Main Campus 56.55 (2012) 63.21 (2013) 6.66
University of Utah 51.12 (2008) 57.59 (2009) 6.47
University of Delaware 75.61 (2011) 81.98 (2012) 6.37
Ohio State University—Main Campus 62.10 (2004) 68.22 (2005) 6.12
University of Illinois at Chicago 48.14 (2008) 54.13 (2009) 5.99
Georgia State University 41.44 (2006) 47.19 (2007) 5.75
Stony Brook University 61.36 (2008) 67.08 (2009) 5.72
University of Delaware 68.32 (2009) 74.02 (2010) 5.70
130 Journal of College Student Retention: Research, Theory & Practice 21(1)","over a 1-year period (Table 3) and 10-year period (Table 1). Finally, a very
recent example will be explored in which a retention plan developed by the
president of Mount St. Mary’s came under intense national scrutiny. Several
institutions in the past 10 years have either inﬂated their reported scores or
misreported their statistics including Claremont McKenna, Villanova
University, and the University of Illinois. This
study does not allege any dishonesty or make a value judgment on the institu-
tions involved in the examples. Instead, each institution within three of the four
examples (Northeastern, UT-Dallas, and ASU) has demonstrated over a 10-year
period of time that they have had some of the most signiﬁcant gains in retention
and graduation rates. The ﬁnal example of Mount St. Mary’s made national
headlines and concluded with the resignation of its president. Three of these cases may serve as examples for administrators
and policy makers who are interested in increasing their retention and gradua-
tion rates. The fourth case serves as an example for institutions on how to avoid
disastrous public relations due to trying to game their retention or gradua-
tion rates.
Northeastern University
Kutner (2014) provides an extensive review of how Northeastern University
climbed the USNWR Best College rankings from 162 to 49 over 17 years. In
his very detailed examination of Northeastern University, Kutner chronologi-
cally displays the multiple methods that Joseph Aoun, the school’s 12th presi-
dent, took over time to infuse the gaming of college rankings into the
institution’s DNA. Northeastern spent a tremendous amount of time and"
"Wade - 2019 - Measuring, Manipulating, and Predicting Student Success A 10-Year Assessment of Carnegie R1 Doctora.pdf","money in their attempt to break into the top 100 ofUSNWR, and the fruits of
their labor are demonstrated in Table 2 as being the institution that has had the
greatest graduation rate increase from 2004 to 2013. Aoun was determined to
understand the ranking formula used byUSNWR in order to strategically adjust
institutional practices to increase Northeastern’s rank (Kutner, 2014).
Northeastern deployed multiple methods including allowing ﬁrst-time, full-
time freshmen with lower SAT scores or academic deﬁciencies to study
abroad during their fall semester in order to enroll in the spring semester,
which allowed the institution to not count those students in its initial cohort
(Kutner, 2014). The institution also increased its tuition, spent over $1B on
construction, reduced student to faculty ratios to 19:1, and began using the
Common Application for admissions to reject more applicants in order to
appear more selective (Kutner, 2014).
The University of Texas at Dallas
During the 1990s, the UT-Dallas began accepting its ﬁrst cohort of freshman
and sophomore students, but its governing board required it to use the same
admission standards at the University of Texas at Austin in order to not com-
pete with local community colleges (Watkins, 2016). Both UT-Dallas and the
University of Texas Board of Regents developed accountability plans as well as
strategic plans that incorporated enhancing the graduation rate (UT-Dallas,
2016). To increase graduation rates, UT-Dallas invested $1B on campus con-
struction, provided full scholarships to National Merit semiﬁnalists, and ﬁxed
their tuition rate, which incentivized students to graduate in 4 years (Cardona,
2013; Watkins, 2016). According to Watkins (2016), UT-Dallas’ 4-year gradu-
ation rates have increased from 30% to 50% since 2005.
Arizona State University
ASU is the largest public institution in the country with multiple campuses
under a single administration, and its aspiration to design and become the
New American University has led it to be considered a bastion of access, com-
munity embeddedness, and innovation within institutions of higher education
(Crow & Dabars, 2015). As a test bed for new education technologies like the
eAdvisor and adaptive learning platforms like Knewton, ASU has helped raise
its 1-year freshmen retention rate by 7 percentage points from 77% to 84%
(Selingo, 2013). Crow and Dabars (2015) also track an impressive increase in
6-year graduation rates of students at ASU by 14.9 percentage points from the
Fall 1995 cohort’s 6-year graduation rate of 49.2% to the 2007 entering cohort
whose 6-year graduation rate was 58.6%. Through descriptive statistics for this
data set, ASU was also an extreme outlier for both spectrums of student enroll-
ment. In 2008, ASU’s overall enrollment increased by 14,286 students from 2007
Wade 131","money in their attempt to break into the top 100 ofUSNWR, and the fruits of
their labor are demonstrated in Table 2 as being the institution that has had the
greatest graduation rate increase from 2004 to 2013. Aoun was determined to
understand the ranking formula used byUSNWR in order to strategically adjust
institutional practices to increase Northeastern’s rank.
Northeastern deployed multiple methods including allowing ﬁrst-time, full-
time freshmen with lower SAT scores or academic deﬁciencies to study
abroad during their fall semester in order to enroll in the spring semester,
which allowed the institution to not count those students in its initial cohort. The institution also increased its tuition, spent over $1B on
construction, reduced student to faculty ratios to 19:1, and began using the
Common Application for admissions to reject more applicants in order to
appear more selective.
The University of Texas at Dallas
During the 1990s, the UT-Dallas began accepting its ﬁrst cohort of freshman
and sophomore students, but its governing board required it to use the same
admission standards at the University of Texas at Austin in order to not com-
pete with local community colleges. Both UT-Dallas and the
University of Texas Board of Regents developed accountability plans as well as
strategic plans that incorporated enhancing the graduation rate. To increase graduation rates, UT-Dallas invested $1B on campus con-
struction, provided full scholarships to National Merit semiﬁnalists, and ﬁxed
their tuition rate, which incentivized students to graduate in 4 years. According to Watkins (2016), UT-Dallas’ 4-year gradu-
ation rates have increased from 30% to 50% since 2005.
Arizona State University
ASU is the largest public institution in the country with multiple campuses
under a single administration, and its aspiration to design and become the
New American University has led it to be considered a bastion of access, com-
munity embeddedness, and innovation within institutions of higher education. As a test bed for new education technologies like the
eAdvisor and adaptive learning platforms like Knewton, ASU has helped raise
its 1-year freshmen retention rate by 7 percentage points from 77% to 84%. Crow and Dabars (2015) also track an impressive increase in
6-year graduation rates of students at ASU by 14.9 percentage points from the
Fall 1995 cohort’s 6-year graduation rate of 49.2% to the 2007 entering cohort
whose 6-year graduation rate was 58.6%. Through descriptive statistics for this
data set, ASU was also an extreme outlier for both spectrums of student enroll-
ment. In 2008, ASU’s overall enrollment increased by 14,286 students from 2007"
"Wade - 2019 - Measuring, Manipulating, and Predicting Student Success A 10-Year Assessment of Carnegie R1 Doctora.pdf","according to the data collected from the College Scorecard. In 2013, ASU’s
reported enrollment decreased by 20,703 total students compared with 2012.
The change in enrollment was due to the inclusion of multiple campuses
reported as ASU beginning in 2008 through 2012 followed by a transition in
2013 to report the individual ASU–Tempe campus instead of the multiple cam-
puses together. Also in 2013, ASU’s retention rate showed a 1-year gain of 4.5%
(Table 3). ASU continues to strive to increase its retention and graduation rates
by infusing analytics and technology to improve student success via direct tar-
geting of individuals rather than general populations or cohorts of students.
This newly developed method is called precision advising and is deﬁned as
delivering an immediate and intentional intervention at the right time—every
time—to the right student.
Mount St. Mary’s University
Simon P. Newman, the former president of Mount St. Mary’s, came under
intense ﬁre and scrutiny when the university’s student-run newspaper published
Newman’s retention strategy to reduce the amount of ﬁrst-time, full-time fresh-
men by 20 to 25 before the fall census date (Brown, 2016). The strategy would
potentially yield a 4% to 5% gain in 1-year retention rates for the institution
(Brown, 2016). Coupled with his strategy, Newman used extreme language to
characterize how faculty members often view students as cuddly bunnies, but
Newman explained that the bunnies needed to be drowned or have Glocks put
to their heads (Bult, 2016). Newman’s attempt to game the retention rating
system forced the institution to undergo a tremendous amount of undo anguish,
turmoil, and stress.
Linear Models for Retention and Graduation Rates
Due to the study using panel data with time nested in years for R1 doctoral
universities, multiple linear models were performed with one dependent variable
being institutional retention rates from 2004 to 2013 (Table 5) and the other
dependent variable being graduation rates from 2004 to 2013 (Table 6). The
various regression models per dependent variable are as follows: ordinary least
square (OLS) using robust standard errors (Model 1), random effects using
clustered standard errors (Model 2), ﬁxed institutional effects using clustered
standard errors (Model 3), ﬁxed time effects (Model 4), and ﬁxed time effects
using clustered standard errors (Model 5). Independent variables for each model
included mean SAT, admission rate, total enrollment, private institutions
(0 ¼public and 1 ¼private), and AAU members (0 ¼nonmember and
1 ¼member). The model using ﬁxed time effects with clustered standard errors
(Model 5) is the preferred model for this study due to reducing both omitted
variable bias and error variance. The use of ﬁxed effects eliminates variable bias
132 Journal of College Student Retention: Research, Theory & Practice 21(1)","according to the data collected from the College Scorecard. In 2013, ASU’s
reported enrollment decreased by 20,703 total students compared with 2012.
The change in enrollment was due to the inclusion of multiple campuses
reported as ASU beginning in 2008 through 2012 followed by a transition in
2013 to report the individual ASU–Tempe campus instead of the multiple cam-
puses together. Also in 2013, ASU’s retention rate showed a 1-year gain of 4.5%
(Table 3). ASU continues to strive to increase its retention and graduation rates
by infusing analytics and technology to improve student success via direct tar-
geting of individuals rather than general populations or cohorts of students.
This newly developed method is called precision advising and is deﬁned as
delivering an immediate and intentional intervention at the right time—every
time—to the right student.
Mount St. Mary’s University
Simon P. Newman, the former president of Mount St. Mary’s, came under
intense ﬁre and scrutiny when the university’s student-run newspaper published
Newman’s retention strategy to reduce the amount of ﬁrst-time, full-time fresh-
men by 20 to 25 before the fall census date. The strategy would
potentially yield a 4% to 5% gain in 1-year retention rates for the institution. Coupled with his strategy, Newman used extreme language to
characterize how faculty members often view students as cuddly bunnies, but
Newman explained that the bunnies needed to be drowned or have Glocks put
to their heads. Newman’s attempt to game the retention rating
system forced the institution to undergo a tremendous amount of undo anguish,
turmoil, and stress.
Linear Models for Retention and Graduation Rates
Due to the study using panel data with time nested in years for R1 doctoral
universities, multiple linear models were performed with one dependent variable
being institutional retention rates from 2004 to 2013 (Table 5) and the other
dependent variable being graduation rates from 2004 to 2013 (Table 6). The
various regression models per dependent variable are as follows: ordinary least
square (OLS) using robust standard errors (Model 1), random effects using
clustered standard errors (Model 2), ﬁxed institutional effects using clustered
standard errors (Model 3), ﬁxed time effects (Model 4), and ﬁxed time effects
using clustered standard errors (Model 5). Independent variables for each model
included mean SAT, admission rate, total enrollment, private institutions
(0 ¼public and 1 ¼private), and AAU members (0 ¼nonmember and
1 ¼member). The model using ﬁxed time effects with clustered standard errors
(Model 5) is the preferred model for this study due to reducing both omitted
variable bias and error variance. The use of ﬁxed effects eliminates variable bias"
"Wade - 2019 - Measuring, Manipulating, and Predicting Student Success A 10-Year Assessment of Carnegie R1 Doctora.pdf","from omitted variables that varied over time but not across institution (ﬁxed
time effects) or those that varied over institution but not across time (ﬁxed
institution effects). To reduce autocorrelation/serial correlation due to repeated
annual measure per institution, the use of clustered standard errors
was necessary.
Discussion
Tables 5 and 6 demonstrate that the OLS model using robust standard errors
(Model 1) yields more variables that signiﬁcantly inﬂuence retention and gradua-
tion rates compared with the regression model with ﬁxed time effects using clus-
tered standard errors (Model 5). Using Model 5, this study ﬁnds that mean SAT is
a positive and signiﬁcant inﬂuencer of retention and graduation rates. For a 1-
point increase in mean SAT for an institution, an institution’s retention rate would
be expected to increase 0.024% and its graduation rate would be expected to
increase 0.031% holding all else constant. Admission rate does not appear to
signiﬁcantly inﬂuence retention or graduation rates; therefore, Hypothesis 2 is
not supported when using Model 5. The hypothesized relationship between smaller
enrollment and increased retention and graduation rates was not supported.
Instead, an increase in undergraduate enrollment has both positive and signiﬁcant
effects on retention rates only. When an institution increases its enrollment by one
student, an institution’s retention rate would be expected to increase by0.0002%
holding all else constant. Hypothesis 5 was rejected due to AAU membership not
signiﬁcantly inﬂuencing retention or graduation rates. The private institution var-
iable was dropped from the ﬁxed effects models but did signiﬁcantly and positively
inﬂuence retention and graduation rates within the random effects model (Model
2). Serial correlation was accounted for by using clustered standard errors for the
ﬁxed time effects models (Model 5). Some variables that appeared signiﬁcant using
OLS, random effects, or ﬁxed effects without clustered standard errors were no
longer signiﬁcant within the ﬁxed effects model using clustered standard errors.
The only constant and positively signiﬁcant inﬂuencer of both retention and grad-
uation rates for all models was mean SAT (Tables 5 and 6). The only other con-
stant and signiﬁcant inﬂuencer was undergraduate enrollment on retention rates
(Table 5).
Retention rates at many institutions appear to undergo a seesaw effect due to
signiﬁcant variance in retention rates per year with some schools increasing
þ5% during 1 year but then falling/C0 4% the following year. As an example,
the University of Alabama at Birmingham (UAB) started at 77% retention in
2004 and ended at 80.16% retention in 2013. The highest retention rate was
81.56% in 2009, but then it fell/C0 2.8% points over the next 2 years. For UAB’s
graduation rate, a steady increase has occurred over 10 years from 37.73% to
53.77%. The change in overall graduation rate is one of the top 10 in R1s over
the 10 years at 16.04% (Table 2).
Wade 133","Discussion
Tables 5 and 6 demonstrate that the OLS model using robust standard errors (Model 1) yields more variables that signiﬁcantly inﬂuence retention and graduation rates compared with the regression model with ﬁxed time effects using clustered standard errors (Model 5). Using Model 5, this study ﬁnds that mean SAT is a positive and signiﬁcant inﬂuencer of retention and graduation rates. For a 1-point increase in mean SAT for an institution, an institution’s retention rate would be expected to increase 0.024% and its graduation rate would be expected to increase 0.031% holding all else constant. Admission rate does not appear to signiﬁcantly inﬂuence retention or graduation rates; therefore, Hypothesis 2 is not supported when using Model 5. The hypothesized relationship between smaller enrollment and increased retention and graduation rates was not supported. Instead, an increase in undergraduate enrollment has both positive and signiﬁcant effects on retention rates only. When an institution increases its enrollment by one student, an institution’s retention rate would be expected to increase by0.0002% holding all else constant. Hypothesis 5 was rejected due to AAU membership not signiﬁcantly inﬂuencing retention or graduation rates. The private institution variable was dropped from the ﬁxed effects models but did signiﬁcantly and positively inﬂuence retention and graduation rates within the random effects model (Model 2). Serial correlation was accounted for by using clustered standard errors for the ﬁxed time effects models (Model 5). Some variables that appeared signiﬁcant using OLS, random effects, or ﬁxed effects without clustered standard errors were no longer signiﬁcant within the ﬁxed effects model using clustered standard errors. The only constant and positively signiﬁcant inﬂuencer of both retention and graduation rates for all models was mean SAT (Tables 5 and 6). The only other constant and signiﬁcant inﬂuencer was undergraduate enrollment on retention rates (Table 5).
Retention rates at many institutions appear to undergo a seesaw effect due to signiﬁcant variance in retention rates per year with some schools increasing þ5% during 1 year but then falling/C0 4% the following year. As an example, the University of Alabama at Birmingham (UAB) started at 77% retention in 2004 and ended at 80.16% retention in 2013. The highest retention rate was 81.56% in 2009, but then it fell/C0 2.8% points over the next 2 years. For UAB’s graduation rate, a steady increase has occurred over 10 years from 37.73% to 53.77%. The change in overall graduation rate is one of the top 10 in R1s over the 10 years at 16.04% (Table 2)."
"Wade - 2019 - Measuring, Manipulating, and Predicting Student Success A 10-Year Assessment of Carnegie R1 Doctora.pdf","Table 5.Model Summaries for Linear Models Including Random and Fixed Effects for Retention Rates From 2004 to 2013 at R1: Doctoral
Universities.
Parameter Model 1 Model 2 Model 3 Model 4 Model 5
Average SAT 0.048***(0.002) 0.033***(0.004) 0.029***(0.005) 0.024***(0.003) 0.024***(0.004)
Admission rate /C0 0.047***(0.008) /C0 0.027*(0.014) /C0 0.025*(0.015) /C0 0.019**(0.008) /C0 0.019(0.015)
Undergraduate enrollment 0.0001***(0.000) 0.0001*** (0.000) 0.0002***(0.000) 0.0002***(0.000) 0.0002***(0.000)
AAU 1.34***(0.230) 1.18**(0.532) 0.317 (0.586) 0.359(0.461) 0.359(0.492)
Private /C0 2.23***(0.444) 2.68**(1.186)
(Constant) 30.13*** (3.020) 45.76*** (5.192)
Y ears 2004–2013 2004–2013 2004–2013 2004–2013 2004–2013
Robust SE Y e s N o N oN oN o
Clustered SE No Y es Y es No Y es
Fixed effects No No Y es Y es Y es
Random effects No Y es No No No
Institution effects No Y es Y es No No
Time effects No Y es No Y es Y es
Note. AAU ¼Association of American Universities;SE ¼standard error.
*p <.10. **p <.05. ***p <.01.
134","Note. AAU ¼Association of American Universities;SE ¼standard error.
*p <.10. **p <.05. ***p <.01."
"Wade - 2019 - Measuring, Manipulating, and Predicting Student Success A 10-Year Assessment of Carnegie R1 Doctora.pdf","Table 6.Model Summaries for Linear Models Including Random and Fixed Effects for Graduation Rates From 2004 to 2013 at R1: Doctoral
Universities.
Parameter Model 1 Model 2 Model 3 Model 4 Model 5
Average SAT 0.111***(0.005) 0.049***(0.009) 0.065***(0.011) 0.031***(0.004) 0.031***(0.011)
Admission rate /C0 0.011(0.018) 0.011(0.019) /C0 0.022(0.021) 0.022*(0.013) 0.022(0.018)
Undergraduate enrollment 0.0002***(0.000) 0.0002*(0.000) 0.0005***(0.000) 0.0001***(0.000) 0.0001(0.000)
AAU 4.554***(0.538) 2.843**(1.118) 0.172(0.966) 0.659(0.764) 0.659(0.425)
Private /C0 1.937*(0.000) 13.552***(2.948)
(Constant) /C0 0.678*** (6.391) 1.413 (10.099)
Y ears 2004–2013 2004–2013 2004–2013 2004–2013 2004–2013
Robust SE Ye s N o N o N o N o
Clustered SE No Y es Y es No Y es
Fixed effects No No Y es Y es Y es
Random effects No Y es No No No
Institution effects No Y es Y es No No
Time effects No Y es No Y es Y es
Note. AAU ¼Association of American Universities;SE ¼standard error.
*p <.10. **p <.05. ***p <.01.
135","Table 6.Model Summaries for Linear Models Including Random and Fixed Effects for Graduation Rates From 2004 to 2013 at R1: Doctoral
Universities."
"Wade - 2019 - Measuring, Manipulating, and Predicting Student Success A 10-Year Assessment of Carnegie R1 Doctora.pdf","Conclusions
This article sought to understand the changes in 1-year retention rates and
6-year graduation rates at Carnegie R1 doctoral universities over a 10-year
period of time from 2004 to 2013. Overall, one hypothesis was upheld, one
was partially supported, and three were rejected. The institution’s mean SAT
was signiﬁcant and predicted an increases in both 1-year retention and 6-year
graduation rates, which supports similar results from previous empirical studies
(Astin, 1997; Goenner & Snaith, 2004a, 2004b; Kroc et al., 1995; Porter, 2000).
Being a member of the AAU or increasing the selectivity of the institution by
decreasing admission rates did not signiﬁcantly predict increases in either 1-year
retention rate or 6-year graduation rate. Counter to the stated hypothesis
regarding institutional enrollment, an increase in enrollment was actually
found to have a signiﬁcant and positive effect on 1-year retention rates. The
explanation for this may be that as institutions increases their enrollment, stu-
dents are being attracted to that institution (i.e., they want to be there), more
tuition revenue is being generated, and through increased revenue more services
focused on student retention are implemented.
This study also demonstrates a systematic increase in graduation rates for R1
institutions over a period of 10 years, but the trend is not seen for retention rates
among the same institutions. In comparing 10-year retention and graduation
rates (Tables 1–4), the top 10 highest changes in retention rate over the 10 years
were between 6.28% and 8.11%. The top 10 highest changes in graduation rate
over the same 10-year period were 13.06% to 22.69%.
In reviewing Tables 1 to 4, all institutions that are undergoing signiﬁcant
increases in 1-year retention and 6-year graduation rates are all public univer-
sities with the exception of Northeastern University. This can be explained by
states emphasizing institutional accountability through the monitoring of reten-
tion and graduation rates. The accountability for retention and graduation rates
is often tied to budgets, funding, and monetary incentives for both the institu-
tion and their administrators. Also, compared with public institutions of higher
education, private universities are often more exclusive, wealthy, and elite,
which has allowed them to have very high retention and graduation rates that
are not able to be increased signiﬁcantly over time. Finally, the four notable
institutions in this study provide information that can be useful to institutions,
administrators, and policy makers looking to affect their enrollment manage-
ment, retention rate, or graduation rate strategies while simultaneously avoiding
controversy.
Study Limitations and Future Research
This research has several limitations. As previously discussed, several student
characteristics that may contribute to the model are not included—ﬁrst-
136 Journal of College Student Retention: Research, Theory & Practice 21(1)","Conclusions
This article sought to understand the changes in 1-year retention rates and
6-year graduation rates at Carnegie R1 doctoral universities over a 10-year
period of time from 2004 to 2013. Overall, one hypothesis was upheld, one
was partially supported, and three were rejected. The institution’s mean SAT
was signiﬁcant and predicted an increases in both 1-year retention and 6-year
graduation rates, which supports similar results from previous empirical studies.
Being a member of the AAU or increasing the selectivity of the institution by
decreasing admission rates did not signiﬁcantly predict increases in either 1-year
retention rate or 6-year graduation rate. Counter to the stated hypothesis
regarding institutional enrollment, an increase in enrollment was actually
found to have a signiﬁcant and positive effect on 1-year retention rates. The
explanation for this may be that as institutions increases their enrollment, stu-
dents are being attracted to that institution (i.e., they want to be there), more
tuition revenue is being generated, and through increased revenue more services
focused on student retention are implemented.
This study also demonstrates a systematic increase in graduation rates for R1
institutions over a period of 10 years, but the trend is not seen for retention rates
among the same institutions. In comparing 10-year retention and graduation
rates (Tables 1–4), the top 10 highest changes in retention rate over the 10 years
were between 6.28% and 8.11%. The top 10 highest changes in graduation rate
over the same 10-year period were 13.06% to 22.69%.
In reviewing Tables 1 to 4, all institutions that are undergoing signiﬁcant
increases in 1-year retention and 6-year graduation rates are all public univer-
sities with the exception of Northeastern University. This can be explained by
states emphasizing institutional accountability through the monitoring of reten-
tion and graduation rates. The accountability for retention and graduation rates
is often tied to budgets, funding, and monetary incentives for both the institu-
tion and their administrators. Also, compared with public institutions of higher
education, private universities are often more exclusive, wealthy, and elite,
which has allowed them to have very high retention and graduation rates that
are not able to be increased signiﬁcantly over time. Finally, the four notable
institutions in this study provide information that can be useful to institutions,
administrators, and policy makers looking to affect their enrollment manage-
ment, retention rate, or graduation rate strategies while simultaneously avoiding
controversy.
Study Limitations and Future Research
This research has several limitations. As previously discussed, several student
characteristics that may contribute to the model are not included—ﬁrst-"
"Wade - 2019 - Measuring, Manipulating, and Predicting Student Success A 10-Year Assessment of Carnegie R1 Doctora.pdf","generation status, socioeconomic status, underrepresented minority status, high
school GPA, and class rank—resulting in omitted variable bias. Another limi-
tation is that the study is limited to 115 R1 doctoral granting institutions. When
compared with over 4,000 degree granting institutions in the United States, it is
a very small segment of the higher education population. Observational meth-
ods and interpretation of national policy regarding retention and graduation
rates may vary per institution and over time. Another threat to internal validity
is the implementation of performance-based funding from individual states.
Performance-based funding varies over both institution and time and can
include retention and graduate rate metrics. For future research, the addition
of the current missing student input variables to the current model could dem-
onstrate a better model ﬁt than the current construct proposed by this study.
Finally, an analysis of private versus public institutions using the same empirical
method could expand knowledge regarding how different institutional charac-
teristics affect student success.
Acknowledgments
The author would like to thank Professor Barry Bozeman for his invaluable mentorship,
guidance, insight, support, and advice provided throughout this project. The author
would also like to thank Professor Stuart Bretschneider, Professor David Siroky, and
my colleague, Gabel Taggart, for their guidance and support in selecting the appropriate
empirical methodologies for this study. Finally, the author would like to thank my col-
league and friend, Deborah Littleton, for her support and encouragement throughout
our journey to better understand and improve student success.
Declaration of Conflicting Interests
The author(s) declared no potential conﬂicts of interest with respect to the research,
authorship, and/or publication of this article.
Funding
The author(s) received no ﬁnancial support for the research, authorship, and/or publi-
cation of this article.
Supplemental Material
Supplemental material for this article is available online.
References
Albright, B. (2010, July 9).Suggestions for improving the IPEDS graduation rate survey
data collection and reporting (NPEC 2010-832). Retrieved from National
Postsecondary Education Cooperative: http://nces.ed.gov/pubs2010/2010832.pdf
Wade 137","generation status, socioeconomic status, underrepresented minority status, high
school GPA, and class rank—resulting in omitted variable bias. Another limi-
tation is that the study is limited to 115 R1 doctoral granting institutions. When
compared with over 4,000 degree granting institutions in the United States, it is
a very small segment of the higher education population. Observational meth-
ods and interpretation of national policy regarding retention and graduation
rates may vary per institution and over time. Another threat to internal validity
is the implementation of performance-based funding from individual states.
Performance-based funding varies over both institution and time and can
include retention and graduate rate metrics. For future research, the addition
of the current missing student input variables to the current model could dem-
onstrate a better model ﬁt than the current construct proposed by this study.
Finally, an analysis of private versus public institutions using the same empirical
method could expand knowledge regarding how different institutional charac-
teristics affect student success.
Acknowledgments
The author would like to thank Professor Barry Bozeman for his invaluable mentorship,
guidance, insight, support, and advice provided throughout this project. The author
would also like to thank Professor Stuart Bretschneider, Professor David Siroky, and
my colleague, Gabel Taggart, for their guidance and support in selecting the appropriate
empirical methodologies for this study. Finally, the author would like to thank my col-
league and friend, Deborah Littleton, for her support and encouragement throughout
our journey to better understand and improve student success.
Declaration of Conflicting Interests
The author(s) declared no potential conﬂicts of interest with respect to the research,
authorship, and/or publication of this article.
Funding
The author(s) received no ﬁnancial support for the research, authorship, and/or publi-
cation of this article.
Supplemental Material
Supplemental material for this article is available online."
"Wade - 2019 - Measuring, Manipulating, and Predicting Student Success A 10-Year Assessment of Carnegie R1 Doctora.pdf","Alexander, F. (2000). The changing face of accountability: Monitoring and assessing
institutional performance in higher education. The Journal of Higher Education,
71(4), 411–431. doi:10.2307/2649146
Anderson, N., & Rucker, P. (2013, August 22). Obama proposes college-rating
system in bid to Increase affordability. The Washington Post. Retrieved from
https://www.washingtonpost.com/politics/obama-to-propose-college-ranking-system-
that-could-increase-affordability/2013/08/22/73e674c0-0b17-11e3-b87c-476db8ac34
cd_story.html
Astin, A. W. (1971).Predicting academic performance in college: Selectivity data for 2300
American colleges. New York, NY: The Free Press.
Astin, A. W. (1977).Four critical years: Effects of college on beliefs, attitudes, and knowl-
edge. San Francisco, CA: Jossey-Bass.
Astin, A. W. (1991).Assessment for excellence: The philosophy and practice of assessment
and evaluation in higher education. New York, NY: American Council on Education
and Macmillan Publishing Company.
Astin, A. (1993, September 22) College retention rates are often misleading.Chronicle of
Higher Education, 22, A48. Retrieved from http://www.chronicle.com/article/College-
Retention-Rates-Are/92037/
Astin, A. W. (1997). How “good” is your institution’s retention rate?Research in Higher
Education, 38(6), 647–658. doi:10.1023/A:1024903702810
Astin, A. W. (2005). Making sense out of degree completion rates.Journal of College
Student Retention: Research, Theory & Practice, 7(1-2), 5–17. doi:10.2190/7PV9-
KHR7-C2F6-UPK5
Bean, J. P. (1980). Dropouts and turnover: The synthesis and test of a causal model of
student attrition.Research in Higher Education, 12(2), 155–187. doi:10.1007/BF00976194
Bean, J. P. (1985). Interaction effects based on class level in an explanatory model of
college student dropout syndrome. American Educational Research Journal, 22(1),
35–64. doi:10.3102/00028312022001035
Bean, J. P. (1990). Using retention research in enrollment management. In D. Hossler
(Ed.), The strategic management of college enrollments(pp. 170–185). San Francisco,
CA: Jossey-Bass.
Berger, J. B., & Lyon, S. C. (2005). Past to present: A historical look at retention. In A.
Seidman (Ed.), College student retention: Formula for student success (pp. 1–30).
Westport, CT: American Council on Education.
Berkner, L., He, S., & Cataldi, E. F. (2002, December 16).Descriptive summary of 1995-
96 beginning postsecondary students: Six years later . Statistical analysis report.
Retrieved from http://nces.ed.gov/pubs2003/2003151.pdf
Brown, S. (2016, February 1). How a freshman-retention plan turned into a PR disaster
for one campus.The Chronicle of Higher Education. Retrieved from http://chronicle.
com/article/How-a-Freshman-Retention-Plan/235122/?key¼ckJbRBItQjq5Bn-dcp_
pmyb23Pu9LKLaUibREXJDwj5hRkJUY1I5WkhOeVE5ZGYyWGZLY0l1SlpRQ
VlNNXdEZUtpQm80X3BmQkpZ
Bult, L. (2016, January 20). Maryland’s Mount St. Mary’s President allegedly likened
struggling students to ‘bunnies’ you have to ‘drown,’ faculty say. Daily News.
Retrieved from http://www.nydailynews.com/news/national/college-president-drown-
failing-students-article-1.2503194
138 Journal of College Student Retention: Research, Theory & Practice 21(1)",
"Wade - 2019 - Measuring, Manipulating, and Predicting Student Success A 10-Year Assessment of Carnegie R1 Doctora.pdf","Cabrera, A. F., Nora, A., & Castaneda, M. B. (1993). College persistence: Structural
equations modeling test of an integrated model of student retention.Journal of Higher
Education, 64, 123–139. doi:10.2307/2960026
Cardona, C. (2013, May 19). Texas colleges making gradual improvement in 4-year
graduation rates. The Dallas Morning News. Retrieved from http://www.dallasnews.
com/news/politics/headlines/20130519-texas-colleges-making-gradual-improvement-
in-four-year-graduation-rates.ece
Carey, K. (2004, May 1). A matter of degrees: Improving graduation rates at four-year
colleges and universities. Retrieved from https://edtrust.org/resource/a-matter-of-degrees/
Carnegie Classiﬁcation of Institutions of Higher Education. (2016).Basic classiﬁcation
description. Retrieved from http://carnegieclassiﬁcations.iu.edu/classiﬁcation_descrip
tions/basic.php
Cook, B., & Hartle, T. W. (2011). Why graduation rates matter–and why they don’t.
American Council on Education. Retrieved from http://www.acenet.edu/the-presiden
cy/columns-and-features/Pages/Why-Graduation-Rates-Matter%E2%80%94and-
Why-They-Don%E2%80%99t.aspx
Croissant, Y., & Millo, G. (2008). Panel data econometrics in R: The plm package.
Journal of Statistical Software, 27(2), 1–43. Retrieved from http://www.jstatsoft.org/
v27/i02/
Crow, M. M., & Dabars, W. B. (2015).Designing the new American university. Baltimore,
MD: JHU Press.
Dey, E. L., & Astin, A. W. (1993). Statistical alternatives for studying college student
retention: A comparative analysis of logit, probit, and linear regression.Research in
Higher Education, 34(5), 569–581. doi:10.1007/BF00991920
Durkheim, E. (1951).Suicide (J. A. Spaulding & G. Simpson, Trans.). Glencoe, IL: Free
Press. (Original work published 1897)
Enders, J., De Boer, H., & Weyer, E. (2013). Regulatory autonomy and performance:
The reform of higher education re-visited.Higher Education, 65(1), 5–23. doi:10.1007/
s10734-012-9578-4
Eykamp, P. W. (1995).Political control of state research universities: The effect of the
structure of political control on university quality and budget(Unpublished doctoral
dissertation). University of California, San Diego.
Glenn, D. (2010, December 6). 6-Year graduation rates: A 6-minute primer. The
Chronicle of Higher Education. Retrieved from http://www.chronicle.com/blogs/mea
suring/6-year-graduation-rates-a-6-minute-primer/27573
Goenner, C. F., & Snaith, S. M. (2004a). Predicting graduation rates: An analysis of
student and institutional factors at doctoral universities.Journal of College Student
Retention: Research, Theory & Practice, 5(4), 409–420. doi:10.2190/LKJX-CL3H-
1AJ5-WVPE
Goenner, C. F., & Snaith, S. M. (2004b). Accounting for model uncertainty in the pre-
diction of university graduation rates.Research in Higher Education, 45(1), 25–41.
doi:10.1023/B:RIHE.0000010045.13366.a6
Hagedorn, L. S. (2005). How to deﬁne retention: A new look at an old problem. In A.
Seidman (Ed.),College student retention: Formula for success(pp. 89–105). Westport,
CT: American Council on Education.
Wade 139",Wade
"Wade - 2019 - Measuring, Manipulating, and Predicting Student Success A 10-Year Assessment of Carnegie R1 Doctora.pdf","Knott, J. H., & Payne, A. A. (2004). The impact of state governance structures
on management and performance of public organizations: A study of higher
education institutions. Journal of Policy Analysis and Management, 23(1), 13–30.
doi:10.1002/pam.10176
Kroc, R., Howard, R., Hull, P., & Woodard, D. (1997).Graduation rates: Do students’
academic program choices make a difference?(PDF document). Retrieved from http://
ﬁles.eric.ed.gov/fulltext/ED417677.pdf
Kroc, R. D., Howard, R. H., & Hull, P. (1995). Predicting graduation rates: A study of
land grant, research I, and AAU universities. Paper presented at the Association for
Institutional Research meeting, Boston, 1995.
Kutner, M. (2014, August 26). How to game the college rankings. Boston Magazine.
Retrieved from http://www.bostonmagazine.com/news/article/2014/08/26/how-north
eastern-gamed-the-college-rankings/3/
Machung, A. (1998). Playing the ranking game. Change: The Magazine of Higher
Learning, 30(4), 12–16. doi:10.1080/00091389809602626
McNeely, J. H. (1938).College student mortality (U.S. Ofﬁce of Education, Bulletin 1937,
no. 11). Washington, DC: U.S. Government Printing Ofﬁce.
Morse, R., Brooks, E., & Mason, M. (2015, September 9). How U.S. news calculated the
2016 best colleges rankings. Retrieved from U.S. News and World Report: http://www.
usnews.com/education/best-colleges/articles/how-us-news-calculated-the-rankings
Murtaugh, P. A., Burns, L. D., & Schuster, J. (1999). Predicting the retention of univer-
sity students. Research in Higher Education , 40(3), 355–371. doi:10.1023/
A:1018755201899
O’Dwyer, L. M., & Parker, C. E. (2014, December 23).A primer for analyzing nested
data: Multilevel modeling in SPSS using an example from a REL study(REL 2015-
046). Retrieved from Regional Educational Laboratory Northeast & Islands: http://
ies.ed.gov/ncee/edlabs/regions/northeast/pdf/REL_2015046.pdf
O’Meara, K. (2007). Striving for what? Exploring the pursuit of prestige. InHigher
education: Handbook of theory and research . In J.C. Smart (ed) (pp. 121–179).
Dordrecht, the Netherlands: Springer.
Pascarella, E. T., & Terenzini, P. T. (1980). Predicting freshman persistence and volun-
tary dropout decisions from a theoretical model.The Journal of Higher Education,
51(1), 60–75. doi:10.2307/1981125
Pascarella, E. T., & Terenzini, P. T. (1991).How college affects students(Vol. 1). San
Francisco, CA: Jossey-Bass.
Perez-Pena, R., & Slotnik, D. E. (2012, February 1).Gaming the college rankings. The
New York Times, p. 31. Retrieved from http://www.nytimes.com/2012/02/01/educa
tion/gaming-the-college-rankings.html?_r¼0
Porter, S. R. (2000). The robustness of the graduation rate performance indicator used in
the U.S. News & World Reportcollege rankings.International Journal of Educational
Advancement, 1(2), 145–163.
Pusser, B. (2004). Knowledge and money: Research universities and the paradox of the
marketplace (book).Academe, 90(6), 115–116.
Selingo, J. J. (2013).College (un) bound: The future of higher education and what it means
for students. Las Vegas, NV: Amazon Publishing.
140 Journal of College Student Retention: Research, Theory & Practice 21(1)","Journal of College Student Retention: Research, Theory & Practice 21(1)"
"Wade - 2019 - Measuring, Manipulating, and Predicting Student Success A 10-Year Assessment of Carnegie R1 Doctora.pdf","Shin, J. C., & Toutkoushian, R. K. (2011). The past, present, and future of university
rankings. In University rankings (pp. 1–16). Dordrecht, the Netherlands: Springer.
doi:10.1007/978-94-007-1116-7_1
Spady, W. G. (1970). Dropouts from higher education: An interdisciplinary review and
synthesis. Interchange, 1(1), 64–85. doi:10.1007/BF02214313
Student Right-To-Know and Campus Security Act of 1990, Pub L. No, 101-542, 102-26.
Retrieved from https://www.congress.gov/bill/101st-congress/senate-bill/580
Svrluga, S. (2016, February 29). Mount St. Mary’s university president resigns. The
Washington Post. Retrieved from https://www.washingtonpost.com/news/grade-
point/wp/2016/02/29/mount-st-marys-future-direction-on-the-table-as-leaders-meet-
today/?utm_term¼.a7123dbc4a05
The University of Texas at Dallas. (2016, March 24).2014 ﬁfth-year interim report, Provost’s
Technology Group. Retrieved from https://web.archive.org/web/20150405030852/http://
sacscoc.utdallas.edu/5yrnav/
Tinto, V. (1975). Dropout from higher education: A theoretical synthesis of recent research.
Review of Educational Research, 45(1), 89–125. doi:10.3102/00346543045001089
Tinto, V. (1987). Leaving college: Rethinking the causes and cures of student attrition.
Chicago, IL: University of Chicago Press.
Tinto, V. (1999). Taking retention seriously: Rethinking the ﬁrst year of college.
NACADA Journal, 19(2), 5–9. doi:10.12930/0271-9517-19.2.5
Tinto, V. (2002, June 20).Establishing conditions for student success: Lessons learned in
the United States. Speech presented at 11th Annual Conference of European Access
Network, Prato, Italy. Retrieved from https://vtinto.expressions.syr.edu/wp-content/
uploads/2013/01/European-Access-Network-2002-Keynote.pdf
Tinto, V. (2006). Research and practice of student retention: What next?Journal of
College Student Retention: Research, Theory & Practice, 8(1), 1–19. doi:10.2190/
4YNU-4TMB-22DJ-AN4W
U.S. Department of Education. (2015, May).Digest of education statistics, 2013(NCES
2015–011). Retrieved from National Center for Education Statistics: https://nces.ed.
gov/programs/digest/d13/ch_2.asp
U.S. Department of Education. (2016a, August 24).IPEDS 2018–2019 data collection system.
Retrieved from Institute of Education Sciences, National Center for Education Statistics:
https://surveys.nces.ed.gov/ipeds/Downloads/Forms/IPEDSGlossary.pdf
U.S. Department of Education. (2016b, September 13).College scorecard data. Retrieved
from https://collegescorecard.ed.gov/data/
Watkins, M. (2016, April 9). How UT-Dallas transformed itself into a top Texas college.
The Texas Tribune.Retrieved from https://www.texastribune.org/2016/04/09/how-ut-
dallas-has-climbed-ranks-texas-top-colleges/
Author Biography
Nathaniel L. Wade is a doctoral candidate in the School for the Future of
Innovation in Society and senior director, Strategic Analysis and Performance
Improvement within the College of Health Solutions at Arizona State
University. His areas of research include student success, university rankings,
diversity and inclusion, higher education policy, and science and technology policy.
Wade 141","Author Biography
Nathaniel L. Wade is a doctoral candidate in the School for the Future of
Innovation in Society and senior director, Strategic Analysis and Performance
Improvement within the College of Health Solutions at Arizona State
University. His areas of research include student success, university rankings,
diversity and inclusion, higher education policy, and science and technology policy."
