source,page_content,cleaned_page_content
Copie de Mitra and Goldstein - 2015 - Designing early detection and intervention techniques via predictive statistical models—A case study.pdf,"Full Terms & Conditions of access and use can be found at
https://www.tandfonline.com/action/journalInformation?journalCode=ucas20
Communications in Statistics: Case Studies, Data
Analysis and Applications
ISSN: (Print) 2373-7484 (Online) Journal homepage: www.tandfonline.com/journals/ucas20
Designing early detection and intervention
techniques via predictive statistical models—A
case study on improving student performance in a
business statistics course
Sinjini Mitra & Zvi Goldstein
To cite this article: Sinjini Mitra & Zvi Goldstein (2015) Designing early detection and
intervention techniques via predictive statistical models—A case study on improving student
performance in a business statistics course, Communications in Statistics: Case Studies, Data
Analysis and Applications, 1:1, 9-21, DOI: 10.1080/23737484.2015.1063409
To link to this article:  https://doi.org/10.1080/23737484.2015.1063409
Published online: 18 Dec 2015.
Submit your article to this journal 
Article views: 181
View related articles 
View Crossmark data
Citing articles: 3 View citing articles","Designing early detection and intervention
techniques via predictive statistical models—A
case study on improving student performance in a
business statistics course
Sinjini Mitra & Zvi Goldstein"
Copie de Mitra and Goldstein - 2015 - Designing early detection and intervention techniques via predictive statistical models—A case study.pdf,"COMMUNICATIONSINSTATISTICS:CASESTUDIES,DATAANALYSISANDAPPLICATIONS
,VOL.,NO.,–
http://dx.doi.org/./..
CASESTUDY
Designing early detection and intervention techniques via predictive statistical
models—A case study on improving student performance in a business statistics
course
SinjiniMitraandZviGoldstein
InformationSystemsandDecisionSciencesDepartment,CaliforniaStateUniversity,Fullerton,California,USA
ARTICLE HISTORY
ReceivedFebruary
AcceptedJune
KEYWORDS
College-levelcourses;
detection;education;factors;
intervention;prediction
ABSTRACT
This article presents a comprehensive study of factors that potentially impact student performance
and success in a “bottleneck” college-level course in Business Statistics, with the goal of devising
effective intervention methods to provide additional support to students who are at risk of failing.
Thelatterarebasedonstatisticalmodelsthatpredicttheprobabilityoffailurebasedonrelevantfac-
torsidentifiedearlier.Thesemodelsreporthighaccuracyindetectingat-riskstudentsasassessedby
cross-validationtechniques.Moreover,implementationofourtechniquesyieldedpositiveoutcomes,
indicating that those students who took advantage of the intervention significantly improved their
performance.
1. Introduction
Students in Business Statistics courses are struggling.
DatafromacrosstheUnitedStatesrevealmassivefail-
ure rates, high dropout rates as well as lack of degree
completion. In fact, some universities report a 6-year
graduation rate of only 50%, which is way below the
nationalaverage.Severalstateuniversitiesreceiveavast
majority of transfer students from local community
colleges.AnalysisbytheCommunityCollegeResearch
Center at Columbia University’s Teacher’s College on
groups of studies indicates that about two thirds of
community college students enter college with aca-
demicskillsweakenoughtorequireremedialacademic
interventions along with comprehensive support ser-
vices in order to progress in college-credit learning
(Bailey 2008). It is thus necessary to design effective
interventiontechniquesthatwillhelpstudentssucceed
in college and graduate in a timely manner. Toward
this, it is necessary to form an understanding of the
factorsthatcontributetostudentsuccess,aswellasthe
challengesthatstudentsfaceinsuchcoursesinorderto
helpthemachieveahigherlevelofsuccess.Inthisarti-
cle, we present a comprehensive study of factors that
arepotentiallyassociatedwithstudentperformancein
abottleneckcourseatthecollegeofBusinessinapublic
CONTACT Sinjini Mitra smitra@fullerton.edu Information Systems and Decision Sciences Department, California State University,  N. State College
Blvd.,Fullerton,CA,USA.
universityinCaliforniainordertoimplementsuccess-
ful intervention techniques.
Of all courses in the College of Business, the intro-
ductory course in Statistics is considered “bottleneck”
sinceithistoricallyhasveryhighfailurera tes.M an yof
these students do not have a background that includes
courses in quantitative topics, work full-time outside
of school, and struggle with balancing their life in and
outside school. For such students, early detection and
intervention methods have the potential of improv-
ing performance and success rate by providing them
with an opportunity to seek additional help and sup-
p o r tf r o mt h ei n s t r u c t o ra n do t h e rr e s o u r c e sa v a i l a b l e
on campus.
T h er e s to ft h ea r t i c l ei so r g a n i z e da sf o l l o w s .S e c -
tion 2 contains an overview of existing literature on
factors contributing to student success and various
retention and intervention methods being applied in
college-level courses. Section3 describes the data col-
lected for the study and states our research goals. In
Section4,weintroducethestatisticaltoolsusedtoana-
lyze the data, followed by our initial results and find-
ings in Section5.O u rp r e d i c t i o nm o d e l sa r ei n t r o -
duced in Section 6 along with our proposed inter-
vention technique. The results from practical imple-
©Taylor&Francis","Designing early detection and intervention techniques via predictive statistical
models—A case study on improving student performance in a business statistics
course
SinjiniMitraandZviGoldstein
ABSTRACT
This article presents a comprehensive study of factors that potentially impact student performance
and success in a “bottleneck” college-level course in Business Statistics, with the goal of devising
effective intervention methods to provide additional support to students who are at risk of failing.
Thelatterarebasedonstatisticalmodelsthatpredicttheprobabilityoffailurebasedonrelevantfac-
torsidentifiedearlier.Thesemodelsreporthighaccuracyindetectingat-riskstudentsasassessedby
cross-validationtechniques.Moreover,implementationofourtechniquesyieldedpositiveoutcomes,
indicating that those students who took advantage of the intervention significantly improved their
performance.
1. Introduction
Students in Business Statistics courses are struggling.
DatafromacrosstheUnitedStatesrevealmassivefail-
ure rates, high dropout rates as well as lack of degree
completion. In fact, some universities report a 6-year
graduation rate of only 50%, which is way below the
nationalaverage.Severalstateuniversitiesreceiveavast
majority of transfer students from local community
colleges.AnalysisbytheCommunityCollegeResearch
Center at Columbia University’s Teacher’s College on
groups of studies indicates that about two thirds of
community college students enter college with aca-
demicskillsweakenoughtorequireremedialacademic
interventions along with comprehensive support ser-
vices in order to progress in college-credit learning
(Bailey 2008). It is thus necessary to design effective
interventiontechniquesthatwillhelpstudentssucceed
in college and graduate in a timely manner. Toward
this, it is necessary to form an understanding of the
factorsthatcontributetostudentsuccess,aswellasthe
challengesthatstudentsfaceinsuchcoursesinorderto
helpthemachieveahigherlevelofsuccess.Inthisarti-
cle, we present a comprehensive study of factors that
arepotentiallyassociatedwithstudentperformancein
abottleneckcourseatthecollegeofBusinessinapublic
universityinCaliforniainordertoimplementsuccess-
ful intervention techniques.
Of all courses in the College of Business, the intro-
ductory course in Statistics is considered “bottleneck”
sinceithistoricallyhasveryhighfailurera tes.M an yof
these students do not have a background that includes
courses in quantitative topics, work full-time outside
of school, and struggle with balancing their life in and
outside school. For such students, early detection and
intervention methods have the potential of improv-
ing performance and success rate by providing them
with an opportunity to seek additional help and sup-
p o r tf r o mt h ei n s t r u c t o ra n do t h e rr e s o u r c e sa v a i l a b l e
on campus.
T h er e s to ft h ea r t i c l ei so r g a n i z e da sf o l l o w s .S e c -
tion 2 contains an overview of existing literature on
factors contributing to student success and various
retention and intervention methods being applied in
college-level courses. Section 3 describes the data col-
lected for the study and states our research goals. In
Section4,weintroducethestatisticaltoolsusedtoana-
lyze the data, followed by our initial results and find-
ings in Section5.O u rp r e d i c t i o nm o d e l sa r ei n t r o-
duced in Section 6 along with our proposed inter-
vention technique. The results from practical imple-
mentation are discussed in Section 7."
Copie de Mitra and Goldstein - 2015 - Designing early detection and intervention techniques via predictive statistical models—A case study.pdf,"10 S.MITRAANDZ.GOLDSTEIN
mentation of our intervention are presented in Sec-
tion 7 and we finally conclude with a discussion in
Section8.
2. Literaturereview
The level of success students achieve in their years
at college has far-reaching implications for students’
personal and professional lives by influencing their
academic self-esteem, persistence in elected majors,
and perseverance in higher education. Success in early
semesters at college and experience in introductory
college courses also ultimately impact students’ post-
collegeexperiencesandadultlife,suchascareerchoice,
personal income and level of success, and degree and
nature of participation in community life. However,
disaffectionwithlowperformanceinintroductorycol-
lege classes is a serious problem at colleges and uni-
versities nationwide (Horn and Premo 1995;H o r n
et al.2002). For more than two decades, research has
shown that student success in STEM (Science, Tech-
nology, Engineering and Mathematics) disciplines is
most negatively affected by students’ lack of success in
the gateway courses that develop essential skills and
introducestudentstodisciplinarystudies(Tobias 1990;
Seymour and Hewitt1997). The problem is especially
evident in introductory business, mathematics, and
science courses. Such courses are often required and
are integral components of an undergraduate educa-
tion, yet many students who enroll in these courses
achieve moderate or low levels of success in them.
Thisoftenresultsinsignificantattritionoftalentedstu-
d e n t si nt h e s ea r e a so fs t u d y( G a i n e n1995;C o n g r e s s
of the United States Office of Technology Assessment
1998).
An abundance of research has been performed
in the last few decades to identify factors that con-
tribute to student performance in bottleneck courses
inBusiness,Mathematics,andotherscience-baseddis-
ciplines. These range from demographic factors (such
asgender,ethnicity)toacademicfactors(suchasprior
academic history, grade point average [GPA]). Brower
and Ketterhagen (2004) and Herndon and Moore
(2002) have shown that students belonging to some
ethnicgroupssuchasAfricanAmericansandHispan-
icsaremorelikelytodropfromBusiness,Mathematics,
and science-related majors. Furthermore, female stu-
dents are also shown to be more likely to drop from
these majors than males. All these clearly indicate a
needtoaddresstheseissuesinordertobridgetheexist-
inggap.
Studies have shown different subsets of factors that
are associated with student performance in different
types of courses, thus indicating that the type of dis-
cipline plays a major role in determining factors con-
tributing to students’ success. Cognitive and academic
variables have been shown to be only adequate pre-
dictors of success in introductory business, market-
ing,andeconomicscourses.SachdevaandSterk( 1982),
Eskew and Faley (1988), Liesz and Reyes (1989), and
Doran, Boullion, and Smith (1991)r e p o r tt h a tl o c a l l y
written and administered placement exams that mea-
sure student content knowledge and reasoning skills
predict student performance in introductory finance
courses. Eckel and Johnson (1983)r e p o r tt h a tt h e
ACT score in math predicts success in introductory
accounting courses. However, some studies contradict
thisconclusionandsuggestthatstandardizedentrance
examscoresarenoteffectivepredictorsinintroductory
accountingcourses(Brown 1966;IngramandPeterson
1987).Thecognitivefactorsthathavebeenmostwidely
considered as potential predictors of college mathe-
maticsachievementareSATandACTscores.Another
nearly universal variable that predicts students’ suc-
cess in freshman business, mathematics, and science
coursesishighschoolgradepointaverage(GPA).GPA
isneitheracognitivenoranaffectivevariable;itisnei-
ther a measure of aptitude nor a state of mind. Instead
it is a holistic measure of performance. Similar to data
on mathematical skills, data on students’ GPAs are
widelyavailable.Highschoolandcollegeperformance
seemstobeamorereliablepredictorofstudentsuccess
than are entrance exam scores in introductory courses
in the business field. Brown (1966)r e p o r t st h a th i g h
school GPA adequately predicts success in accounting
courses, and other investigators (Bellico1972;C o h n
1972;I n g r a ma n dP e t e r s o n1987;B o r d e1998)r e p o r t
that college GPA is a valid predictor of success in eco-
nomicsandmarketingcourses.
In addition to the cognitive and quantitative fac-
tors, noncognitive factors or qualitative factors have
been used successfully to predict grades in many gate-
waycourses,inbusiness,mathematics,andotherareas
of study. Although such factors are often overlooked
(Glesne 1998), some studies have shown that these
variables are more useful than cognitive variables in
predicting the academic success of nontraditional stu-
dents(e.g.,Sedlacek 2002).Meeceetal.( 1982)founda","mentation of our intervention are presented in Section 7 and we finally conclude with a discussion in Section8.
2. Literaturereview
The level of success students achieve in their years at college has far-reaching implications for students’ personal and professional lives by influencing their academic self-esteem, persistence in elected majors, and perseverance in higher education. Success in early semesters at college and experience in introductory college courses also ultimately impact students’ post-collegeexperiencesandadultlife,suchascareerchoice, personal income and level of success, and degree and nature of participation in community life. However, disaffectionwithlowperformanceinintroductorycol- lege classes is a serious problem at colleges and universities nationwide. For more than two decades, research has shown that student success in STEM (Science, Technology, Engineering and Mathematics) disciplines is most negatively affected by students’ lack of success in the gateway courses that develop essential skills and introducestudentstodisciplinarystudies. The problem is especially evident in introductory business, mathematics, and science courses. Such courses are often required and are integral components of an undergraduate educa- tion, yet many students who enroll in these courses achieve moderate or low levels of success in them. Thisoftenresultsinsignificantattritionoftalentedstu- d e n t si nt h e s ea r e a so fs t u d y.
An abundance of research has been performed in the last few decades to identify factors that con- tribute to student performance in bottleneck courses inBusiness,Mathematics,andotherscience-baseddis- ciplines. These range from demographic factors (such asgender,ethnicity)toacademicfactors(suchasprior academic history, grade point average [GPA]). Brower and Ketterhagen (2004) and Herndon and Moore (2002) have shown that students belonging to some ethnicgroupssuchasAfricanAmericansandHispan- icsaremorelikelytodropfromBusiness,Mathematics, and science-related majors. Furthermore, female stu- dents are also shown to be more likely to drop from these majors than males. All these clearly indicate a needtoaddresstheseissuesinordertobridgetheexist- inggap.
Studies have shown different subsets of factors that are associated with student performance in different types of courses, thus indicating that the type of dis- cipline plays a major role in determining factors con- tributing to students’ success. Cognitive and academic variables have been shown to be only adequate pre- dictors of success in introductory business, market- ing,andeconomicscourses.
Thecognitivefactorsthathavebeenmostwidely considered as potential predictors of college mathe- maticsachievementareSATandACTscores.Another nearly universal variable that predicts students’ suc- cess in freshman business, mathematics, and science coursesishighschoolgradepointaverage(GPA).GPA isneitheracognitivenoranaffectivevariable;itisnei- ther a measure of aptitude nor a state of mind. Instead it is a holistic measure of performance. Similar to data on mathematical skills, data on students’ GPAs are widelyavailable.Highschoolandcollegeperformance seemstobeamorereliablepredictorofstudentsuccess than are entrance exam scores in introductory courses in the business field.
In addition to the cognitive and quantitative fac- tors, noncognitive factors or qualitative factors have been used successfully to predict grades in many gate- waycourses,inbusiness,mathematics,andotherareas of study. Although such factors are often overlooked (Glesne 1998), some studies have shown that these variables are more useful than cognitive variables in predicting the academic success of nontraditional stu- dents."
Copie de Mitra and Goldstein - 2015 - Designing early detection and intervention techniques via predictive statistical models—A case study.pdf,"COMMUNICATIONSINSTATISTICS:CASESTUDIES,DATAANALYSISANDAPPLICATIONS 11
relationshipbetweenstudentmotivationandacademic
self-concept (a student’s personal opinion toward his
or her academic skills) in introductory Math courses.
Academic self-concept was shown to be a strong pre-
dictor of persistence in undergraduate math programs
(House1995)andfinalgradesinmathcourses(Gerardi
1990;W ilhi t e1990;A s tin1993;H o u se1995).Interest-
ingly, House (1995) found that academic self-concept
s p e c i fi ct om a t h e m a t i c a la b i l i t yw a sas t r o n g e rp r e -
dictor of final grade than any cognitive factors mea-
sured (including ACT scores), and that this academic
self-concept was a stronger predictor of final grade for
femalesthanformales.Butalthoughpredictivemodels
are being deployed, details of implementation includ-
ingthetypesofmodelsusedandwaystoassesspredic-
tive power are difficult to find in the literature. Some
reports are using percentage accuracies of competing
models to select the optimal one (but no mention of
anyvalidationset).
Just as there have been several studies to determine
factorsthatcanpredictstudentperformanceinpartic-
ularlydifficultcourses,therehavebeenstudiesalsoon
interventiontechniquesthathavebeencarriedoutwith
the purpose of improving academic success. Morrison
and Schmit (2010)a n dM o r r i s o n(2012)t r i e dt op r e -
dict probabilities of success in a gateway Mathematics
course at North Iowa Area Community College based
on thresholds imposed on students’ ACT Math scores
and high school GPA. University of Maryland at Balti-
moreCounty(UMBC)hasbeenimplementinga“First
Year Intervention” (FYI, for short) system to alert stu-
dents who are in danger of failing a course based on
performance on a screening quiz and first midterm
(Baradwajetal. 2012).
Moreover, with the advance of business intelligence
software in the last few years, we have the emergence
of a field called “learning analytics” in which sophisti-
cated analytic tools are used to improve learning and
education(Elias 2011).Itusestoolsandmethodsfrom
businessintelligence,webanalytics,statistics,anddata
mining to analyze large repositories of data available
at colleges and universities, mostly through integra-
tion with their Learning Management Systems (LMS).
Such data may include the number of times lecture
notes are viewed, quiz grades, and number of contri-
butionstoadiscussionforum,andprovidetheinstruc-
tor with a digital view of student performance and
progress in real time (Educause2010), commonly in
t h ef o r mo f“ d a s h b o a r d s ”t h a ta r ec o m p r i s e do fd a t a
visualization tools like graphs, charts, and tables. This
helps the instructor to track and determine which stu-
dents may need help and when so that he or she may
reach out to those students via email as a way of inter-
vention. This also helps the development of personal-
ized learning environments to refine course offerings
for users. Although dashboard technology is growing
inpopularityineducationapplications,thereareasso-
ciated challenges as well, such as providing the right
informationaccuratelyandinatimelymannerinorder
tobeuseful(Baker 2007).AccordingtoMacFaydenand
Dawson(2010), predictive modelsfor monitoring stu-
dent achievement should be built at the course level,
whichisconsistentwithpriorstudiesthatfactorsaffect-
ing student success vary significantly across courses
and disciplines. Recently, an article in the Guardian
(Ferguson 2014) discussed how analytics could help
shape students’ progress that shows that this topic is
gainingpopularityeveninthemedia.
In our research study, we seek to obtain data on
a wide range of cognitive and noncognitive variables
consistentwithpriorstudiesthathavebeenhistorically
demonstratedtoinfluencestudentperformanceinvar-
ious courses. Moreover, research (Sellers et al.2007)
shows that active, collaborative learning approaches
are more inclusive of students who come from back-
groundstraditionallynotwellrepresentedamongthose
who are in STEM fields, such as Hispanic and Native
American, low-income, and/or first-generation stu-
dents.Sinceouruniversityservesminoritypopulations
(Hispanics, Asians, and Pacific Islanders) and people
with lower income status in the neighboring commu-
nities, its student population is very unique. Hence,
as previous studies have pointed out, individual fac-
tors pertinent to our student population need to be
identifiedinordertobuildeffectiveinterventionmod-
els that will be particularly beneficial to them. To the
best of our knowledge, such models have not been
previously deployed in bottleneck courses in Business,
particularly for such a diverse student population as
ours.
3. Dataandresearchgoals
In this article, we examine students’ performance in
a course on Business Statistics, one of the gateway
courses in the College of Business at a certain pub-
lic university in California during the academic year
2012–2013. The data used in the study consisted of","relationshipbetweenstudentmotivationandacademic
self-concept (a student’s personal opinion toward his
or her academic skills) in introductory Math courses.
Academic self-concept was shown to be a strong pre-
dictor of persistence in undergraduate math programs
and final grades in math courses. Interest-
ingly, House (1995) found that academic self-concept
s p e c i fi ct om a t h e m a t i c a la b i l i t yw a sas t r o n g e rp r e -
dictor of final grade than any cognitive factors mea-
sured (including ACT scores), and that this academic
self-concept was a stronger predictor of final grade for
femalesthanformales.Butalthoughpredictivemodels
are being deployed, details of implementation includ-
ingthetypesofmodelsusedandwaystoassesspredic-
tive power are difficult to find in the literature. Some
reports are using percentage accuracies of competing
models to select the optimal one (but no mention of
anyvalidationset).
Just as there have been several studies to determine
factorsthatcanpredictstudentperformanceinpartic-
ularlydifficultcourses,therehavebeenstudiesalsoon
interventiontechniquesthathavebeencarriedoutwith
the purpose of improving academic success. Morrison
and Schmit (2010)a n dM o r r i s o n(2012)t r i e dt op r e -
dict probabilities of success in a gateway Mathematics
course at North Iowa Area Community College based
on thresholds imposed on students’ ACT Math scores
and high school GPA. University of Maryland at Balti-
moreCounty(UMBC)hasbeenimplementinga“First
Year Intervention” (FYI, for short) system to alert stu-
dents who are in danger of failing a course based on
performance on a screening quiz and first midterm
(Baradwajetal. 2012).
Moreover, with the advance of business intelligence
software in the last few years, we have the emergence
of a field called “learning analytics” in which sophisti-
cated analytic tools are used to improve learning and
education(Elias 2011).Itusestoolsandmethodsfrom
businessintelligence,webanalytics,statistics,anddata
mining to analyze large repositories of data available
at colleges and universities, mostly through integra-
tion with their Learning Management Systems (LMS).
Such data may include the number of times lecture
notes are viewed, quiz grades, and number of contri-
butionstoadiscussionforum,andprovidetheinstruc-
tor with a digital view of student performance and
progress in real time (Educause2010), commonly in
t h ef o r mo f“ d a s h b o a r d s ”t h a ta r ec o m p r i s e do fd a t a
visualization tools like graphs, charts, and tables. This
helps the instructor to track and determine which stu-
dents may need help and when so that he or she may
reach out to those students via email as a way of inter-
vention. This also helps the development of personal-
ized learning environments to refine course offerings
for users. Although dashboard technology is growing
inpopularityineducationapplications,thereareasso-
ciated challenges as well, such as providing the right
informationaccuratelyandinatimelymannerinorder
tobeuseful(Baker 2007).AccordingtoMacFaydenand
Dawson(2010), predictive modelsfor monitoring stu-
dent achievement should be built at the course level,
whichisconsistentwithpriorstudiesthatfactorsaffect-
ing student success vary significantly across courses
and disciplines. Recently, an article in the Guardian
(Ferguson 2014) discussed how analytics could help
shape students’ progress that shows that this topic is
gainingpopularityeveninthemedia.
In our research study, we seek to obtain data on
a wide range of cognitive and noncognitive variables
consistentwithpriorstudiesthathavebeenhistorically
demonstratedtoinfluencestudentperformanceinvar-
ious courses. Moreover, research (Sellers et al.2007)
shows that active, collaborative learning approaches
are more inclusive of students who come from back-
groundstraditionallynotwellrepresentedamongthose
who are in STEM fields, such as Hispanic and Native
American, low-income, and/or first-generation stu-
dents.Sinceouruniversityservesminoritypopulations
(Hispanics, Asians, and Pacific Islanders) and people
with lower income status in the neighboring commu-
nities, its student population is very unique. Hence,
as previous studies have pointed out, individual fac-
tors pertinent to our student population need to be
identifiedinordertobuildeffectiveinterventionmod-
els that will be particularly beneficial to them. To the
best of our knowledge, such models have not been
previously deployed in bottleneck courses in Business,
particularly for such a diverse student population as
ours.
3. Dataandresearchgoals
In this article, we examine students’ performance in
a course on Business Statistics, one of the gateway
courses in the College of Business at a certain pub-
lic university in California during the academic year
2012–2013. The data used in the study consisted of"
Copie de Mitra and Goldstein - 2015 - Designing early detection and intervention techniques via predictive statistical models—A case study.pdf,"12 S.MITRAANDZ.GOLDSTEIN
grades (both midterm and final) and a host of exter-
nal variables collected via an online survey. Data on
academic background was obtained from the campus
office of institutional research. These variables are cat-
ego rizedin tofiveb r oadclasses,namely:
i Demographic factors:age, gender, income, eth-
nicity,etc.
ii Academic history and record-related factors :
GPAs—both high school and current college-
level, pre-requisite course grades, scores on
standardizedtestslikeSAT,ACT,etc.
iii Work-related factors: whether they work part-
time or full-time outside of school, how many
hourstheywork,etc.
iv Course-related factors:n u m b e ro fa t t e m p t so n
the course, how many hours devoted to this
courseoutsideoflectures,howoftentheyattend
lectures,etc.
v Academic self-concept factors: general motiva-
tion,interest,andself-confidenceinquantitative
courses, level of preparedness at the start of the
course,etc.
The online survey was administered to students in
class via an online link posted on the course website.
The survey was completely voluntary and no incen-
tiveswereprovidedtoencourageparticipation.Outofa
total of almost 1,300 students enrolled in the Business
Statistics course in Fall 2012, 796 completed the sur-
vey(responserate:63%).Theresponseratesaredeter-
minedbythefactthattheyhadsubmittedthesurveyin
thefinalstep.Thereweresomemissingdataasstudents
had the option of skipping questions but they were
removed from the analysis (less than 10%). But note
here that academic data were available for all students
as they were obtained directly from campus offices, as
mentionedabove.
Our primary research goals in this article are enu-
meratedbelow:
 Identifyasubsetoffactorsthatcontributessignif-
icantlytostudentsuccessinthiscourseamongall
those that are included in the study in order to
buildstatisticalmodelstopredictstudentsuccess.
 Design an effective multi-stage intervention
method based on the predictive models to imple-
ment in the course by providing additional
s u p p o r tt os t u d e n t sw h oa r ea tr i s ko ff a i l i n gt h e
course.
 Assess and evaluate the intervention techniques,
uponimplementation.
4. Researchmethods
Ourdataobtainedfromsurveyresponsesyieldcategor-
icalvariables(likeethnicity,workstatus,etc.),aswellas
numericalones(likeGPA,SATscores,numberofunits
ofclassestaken,etc.).W eusevariousdescriptivestatis-
ticsandstatisticalinferencetechniques(suchas t-tests
andanalysisofvariance,ANOVA)toidentifyvariables
thathavestatisticallysignificanteffectsonstudentper-
formance in this course. These exploratory univariate
analyseswillhelpusgainanunderstandingofourdata
so as to utilize the insight obtained into building suit-
ablepredictivemodelsforintervention.
T h ep r e d i c t i o no ft h es p e c i fi cG P Af o ras t u d e n t
at the end of the course is difficult in terms of accu-
r a c y ,a n di saw e l l - e s t a b l i s h e dfi n d i n gi nt h el i t e r a t u r e
over many years (Goldman and Slaughter1976). On
theotherhand,theestimationofprobabilityofsuccess
for any given student has been found to be more pro-
ductiveanduseful.Inouranalysis,wethususelogistic
regression(HosmerandLemeshow 2000)toassessthe
chancesofstudents’successinthiscoursebydetermin-
ing a subset of influential factors. In our binary logis-
tic regression model, the outcome or the dependent
variable (denoted byY)r e p r e s e n t sf a i l i n gt h ec o u r s e
(coded as “1”) so that the other class denotes success
(codedas“0”).Thesedefinitionsaredrivenbythegoal
oftheinterventionmodels—detectstudentswhoareat
risk of failing. Failure in the course is determined by a
letter grade below C. Classification of a new observa-
tion is performed using a suitable cut-off value on the
estimated probability of failure determined from the
Receiver Operating Characteristic (ROC) curve. Stu-
dentspredictedtofailareidentifiedasbeingatriskfor
potentialinterventionduringthecourse.Wetestedthe
models on different subgroups of students by choos-
ing a training set and a validation set. The models are
fitted and coefficients estimated using the training set
andtestedonthevalidationsetineachcase.Themod-
els’ performance is assessed using traditional metrics
like “sensitivity” and “specificity.” The final error rates
areobtainedbyaveragingoverthosefromthedifferent
repetitions.
5. Analysesandresults
First, we check whether there is any ground to moti-
v a t ee a r l yd e t e c t i o na n di n t e r v e n t i o ni nt h ec o u r s eo f
interest. The course on Business Statistics is consid-
ered “bottleneck” in our university; hence the average","grades (both midterm and final) and a host of exter-
nal variables collected via an online survey. Data on
academic background was obtained from the campus
office of institutional research. These variables are cat-
ego rizedin tofiveb r oadclasses,namely:
i Demographic factors:age, gender, income, eth-
nicity,etc.
ii Academic history and record-related factors :
GPAs—both high school and current college-
level, pre-requisite course grades, scores on
standardizedtestslikeSAT,ACT,etc.
iii Work-related factors: whether they work part-
time or full-time outside of school, how many
hourstheywork,etc.
iv Course-related factors:n u m b e ro fa t t e m p t so n
the course, how many hours devoted to this
courseoutsideoflectures,howoftentheyattend
lectures,etc.
v Academic self-concept factors: general motiva-
tion,interest,andself-confidenceinquantitative
courses, level of preparedness at the start of the
course,etc.
The online survey was administered to students in
class via an online link posted on the course website.
The survey was completely voluntary and no incen-
tiveswereprovidedtoencourageparticipation.Outofa
total of almost 1,300 students enrolled in the Business
Statistics course in Fall 2012, 796 completed the sur-
vey(responserate:63%).Theresponseratesaredeter-
minedbythefactthattheyhadsubmittedthesurveyin
thefinalstep.Thereweresomemissingdataasstudents
had the option of skipping questions but they were
removed from the analysis (less than 10%). But note
here that academic data were available for all students
as they were obtained directly from campus offices, as
mentionedabove.
Our primary research goals in this article are enu-
meratedbelow:
 Identifyasubsetoffactorsthatcontributessignif-
icantlytostudentsuccessinthiscourseamongall
those that are included in the study in order to
buildstatisticalmodelstopredictstudentsuccess.
 Design an effective multi-stage intervention
method based on the predictive models to imple-
ment in the course by providing additional
s u p p o r tt os t u d e n t sw h oa r ea tr i s ko ff a i l i n gt h e
course.
 Assess and evaluate the intervention techniques,
uponimplementation.
4. Researchmethods
Ourdataobtainedfromsurveyresponsesyieldcategor-
icalvariables(likeethnicity,workstatus,etc.),aswellas
numericalones(likeGPA,SATscores,numberofunits
ofclassestaken,etc.).W eusevariousdescriptivestatis-
ticsandstatisticalinferencetechniques(suchas t-tests
andanalysisofvariance,ANOVA)toidentifyvariables
thathavestatisticallysignificanteffectsonstudentper-
formance in this course. These exploratory univariate
analyseswillhelpusgainanunderstandingofourdata
so as to utilize the insight obtained into building suit-
ablepredictivemodelsforintervention.
T h ep r e d i c t i o no ft h es p e c i fi cG P Af o ras t u d e n t
at the end of the course is difficult in terms of accu-
r a c y ,a n di saw e l l - e s t a b l i s h e dfi n d i n gi nt h el i t e r a t u r e
over many years . On
theotherhand,theestimationofprobabilityofsuccess
for any given student has been found to be more pro-
ductiveanduseful.Inouranalysis,wethususelogistic
regressiontoassessthe
chancesofstudents’successinthiscoursebydetermin-
ing a subset of influential factors. In our binary logis-
tic regression model, the outcome or the dependent
variable (denoted byY)r e p r e s e n t sf a i l i n gt h ec o u r s e
(coded as “1”) so that the other class denotes success
(codedas“0”).Thesedefinitionsaredrivenbythegoal
oftheinterventionmodels—detectstudentswhoareat
risk of failing. Failure in the course is determined by a
letter grade below C. Classification of a new observa-
tion is performed using a suitable cut-off value on the
estimated probability of failure determined from the
Receiver Operating Characteristic (ROC) curve. Stu-
dentspredictedtofailareidentifiedasbeingatriskfor
potentialinterventionduringthecourse.Wetestedthe
models on different subgroups of students by choos-
ing a training set and a validation set. The models are
fitted and coefficients estimated using the training set
andtestedonthevalidationsetineachcase.Themod-
els’ performance is assessed using traditional metrics
like “sensitivity” and “specificity.” The final error rates
areobtainedbyaveragingoverthosefromthedifferent
repetitions.
5. Analysesandresults
First, we check whether there is any ground to moti-
v a t ee a r l yd e t e c t i o na n di n t e r v e n t i o ni nt h ec o u r s eo f
interest. The course on Business Statistics is consid-
ered “bottleneck” in our university; hence the average"
Copie de Mitra and Goldstein - 2015 - Designing early detection and intervention techniques via predictive statistical models—A case study.pdf,"COMMUNICATIONSINSTATISTICS:CASESTUDIES,DATAANALYSISANDAPPLICATIONS 13
Table .Distribution of students by ethnicity for the course (n =
).
Ethnicity Frequency
AmericanIndian/Alaskannative (.%)
Asian/PaciﬁcIslander (%)
BlackorAfricanAmerican (%)
Hispanic (%)
WhiteorCaucasian (%)
Missingresponses (.%)
f a i l u r er a t e s( g r a d e sDa n dl o w e r )a r et y p i c a l l ya r o u n d
20%–22%. This is considerably high so that efforts to
improve student success are required. Moreover, upon
analyzing midterm and final grades of students in our
dataset,wefoundthat70%ofthestudentswhoreceived
a grade of D or lower in the first midterm ultimately
failed the course. The Pearson correlation coefficient
of midterm grades with final grades is also strongly
positive(0.78,significantwith p-value< 0.0001). This
implies that students scoring low on the first midterm
typically have poor performance in the overall course
(and as a result have higher probability of failing) as
compared to those with high midterm scores. Thus, it
is possible to detect majority of the students who are
l i k e l yt of a i le a r l yo ni nt h ec o u r s ef o rt h ep u r p o s eo f
intervention.
Apartfrommidtermgrades,wenextlookatahostof
otherbackgroundvariablesthatmayalsohelpusdetect
students who are likely to have difficulty in being suc-
cessful in the course on Business Statistics, as part of
our exploratory analysis. Note that, here we only look
at the different factors individually, and the significant
factorsthatpredictstudentsuccesswillbedetermined
fromthelogisticregressionmodel.
Demographic factors:The main demographic vari-
able that had an effect on performance was ethnicity.
Table 1showstheethnicgroupcompositionofstudents
who responded to the survey. As is clearly evident,
thecourseisdominatedbyAsian/PacificIslandersfol-
lowed by Caucasians and Hispanics, a fairly accurate
representation of the composition of our student pop-
ulationintheentireuniversity.
Statistically significant differences were observed in
both midterm and final grades for students belonging
todifferentethnicgroups( p-values:0.0203and0.0405,
respectively).Inparticular,CaucasiansandAsiansper-
formed better than African Americans and Hispan-
ics. Furthermore, students who were first generation
intheirfamilytoattendcollegehadsignificantlylower
gradesthantheotherstudents( p-value< 0.0001).Note
here that the course had 27% first generation college
attendeesenrolledinthatparticularsemester.
5.1. Academic record and history
Of all the factors that reflected the students’ aca-
demic record and history, the most influential fac-
tor was college GPA. A very high positive correlation
wasobservedbetweenGPAandgrades(midterm:0.77
and final: 0.81), statistically significant as well. Other
academic variables like high school GPA, SAT scores,
number of hours devoted to the course, number of
unitsofcoursesenrolledfor,etc.,didnothaveanysig-
nificant relationship with student performance in this
course.Moreover,studentswhorepeatthiscoursetwo
to three times have significantly lower midterm and
final grades than those who are taking it for the first
time(p-values:< 0.0001).
The pre-requisite for the course on Business Statis-
tics is a course on Business Calculus. Students with
lower grades in the pre-requisite course are seen to be
at a greater risk of failing the course. Hence, students
who are already known to have performed poorly in
the Business Calculus course are expected to have dif-
ficulty in the course, thus providing us with a way to
identify at risk even before the start of the course on
Business Statistics. Thus, our conclusion is that there
is a very strong positive association of student per-
formance and success in this course with that in the
pre-requisite course. This pattern is clearly visible in
Table 2.N o t et h a tw ed i dn o th a v eB u s i n e s sC a l c u l u s
grades for many students, especially those who trans-
ferredfromanotherinstitution.
Thus, we found that many factors that constitute
a student’s academic record have significant effect on
their performance in this course, which is consistent
with expectations and prior studies described earlier.
Thisleadstotheconclusionthatstudentswithstronger
Table .Distribution of student grades in the Business Statistics
course according to letter grades obtained in the pre-requisite
courseonBusinessCalculus( n= ).
Lettergradein
BusinessCalculus Frequency
Averagemidterm
gradesin
BusinessStatistics
Averageﬁnal
gradesin
BusinessStatistics
A(>) (%) % %
B(–) (%) % %
C(–) (%) % %
D(–) (%) % %
F(<) (%) % %","Table 1shows the ethnic group composition of students who responded to the survey. As is clearly evident, the course is dominated by Asian/Pacific Islanders followed by Caucasians and Hispanics, a fairly accurate representation of the composition of our student population in the entire university.
Statistically significant differences were observed in both midterm and final grades for students belonging to different ethnic groups (p-values: 0.0203 and 0.0405, respectively). In particular, Caucasians and Asians performed better than African Americans and Hispanics. Furthermore, students who were first generation in their family to attend college had significantly lower grades than the other students (p-value< 0.0001). Note here that the course had 27% first generation college attendees enrolled in that particular semester.

5.1. Academic record and history
Of all the factors that reflected the students’ academic record and history, the most influential factor was college GPA. A very high positive correlation was observed between GPA and grades (midterm: 0.77 and final: 0.81), statistically significant as well. Other academic variables like high school GPA, SAT scores, number of hours devoted to the course, number of units of courses enrolled for, etc., did not have any significant relationship with student performance in this course. Moreover, students who repeat this course two to three times have significantly lower midterm and final grades than those who are taking it for the first time (p-values:< 0.0001).
The pre-requisite for the course on Business Statistics is a course on Business Calculus. Students with lower grades in the pre-requisite course are seen to be at a greater risk of failing the course. Hence, students who are already known to have performed poorly in the Business Calculus course are expected to have difficulty in the course, thus providing us with a way to identify at risk even before the start of the course on Business Statistics. Thus, our conclusion is that there is a very strong positive association of student performance and success in this course with that in the pre-requisite course. This pattern is clearly visible in Table 2.
Thus, we found that many factors that constitute a student’s academic record have significant effect on their performance in this course, which is consistent with expectations and prior studies described earlier."
Copie de Mitra and Goldstein - 2015 - Designing early detection and intervention techniques via predictive statistical models—A case study.pdf,"14 S.MITRAANDZ.GOLDSTEIN
Table .Distribution of students by their work status outside of
schoolandtheaveragegrades( n= ).
Workstatus Frequency
Average
midtermgrades
Averageﬁnal
grades
Full-time (%) .% .%
Part-time (%) .% .%
Noworkoutsideschool (%) .% %
Missing/Noanswer (%) — —
academic backgrounds are likely to have significantly
bettersuccessinthiscourse.
5.2. Work-related factors
Most of the students in the College of Business work
outside of school, and the goal here is to determine
how their work activities affect performance in this
course on Business Statistics.Table 3shows the dis-
tribution of students by their work status outside of
school, along with average midterm and final grades.
Aswecansee,majorityofstudentsworkparttime.Sta-
tistical tests reveal significant differences in both sets
ofgradesforthesestudentsgroupedbytheirworksta-
tus (p-values, respectively, 0.049 and 0.019). Students
who work less outside have significantly better perfor-
mancethanthosewhoworkmore.Thisseemsreason-
able since the more time students spend on their work
activities,thelesstimetheyspendonthecourseleading
topoorerperformance.
Moreover, 40% of students stated that external
responsibilities always or often affect their success at
schoolwhereasapproximately40%saidthattheyocca-
sionallydoso.Thelargestproportionofstudentsmen-
tioned work and financial situation as the most dom-
inant factor, followed by interest and motivation in
classandfamily obligations. Social/recreationalactivi-
ties,health-relatedfactors,andathleticswerenotfound
to be the most influential factor in academic success
accordingtostudents’self-perceivedbeliefs.
5.3. Academic self-concept factors
Asinalleducationalstudies,academicself-conceptfac-
tors are very important in assessing student perfor-
mance and success in major courses. They represent
students’ self-perceived notions about certain factors
thataffectlearning.Soweincludedinoursurveysome
suchfactorsthatwereaimedatunderstandingstudents’
ownperceptionaboutmotivation,interest,intellectual
abilityintopicsofaquantitativenature,andtheirself-
perceivedlevelofpreparednessatthebeginningofthe
course. Statistical tests indicated that those students
whoweremoremotivated,hadmoreinterestinMath-
ematics, had more self-confidence in their intellectual
abilityinMathematics,andbelievedthattheywerebet-
ter prepared before the course had significantly better
performance overall (p-values close to 0 in all cases).
75% of the students were motivated to some extent,
while35%wereslightlyornotinterestedinMathemat-
ical topics. Moreover, only about 6% of the students
had low self-confidence in their intellectual ability in
Mathematics and 52% believed that they were some-
what prepared for the course but were lacking some
importantskillsandknowledge.
These findings are consistent with earlier studies
andexpectations(Wilhite 1990;House 1995).Students
who have higher academic self-concept are expected
to have more success in courses than students with
relatively lower academic self-concept. Thus, efforts
are required to help improve students’ academic self-
conceptvianovelandinnovativepedagogicalmethods
to increase motivation and interest, not only for the
Business courses but even earlier for the pre-requisite
courses that prepare them for these courses. These,
along with intervention techniques, will be helpful in
enhancing the overall intellectual and cognitive abili-
ties of students, thus improving their chances of suc-
ceedinginthecourseonBusinessStatistics.
6. Predictionmodels
Although several factors were found to affect stu-
dent success in the Business Statistics course from the
e x p l o r a t o r ya n a l y s e so u t l i n e da b o v e ,t h eg o a ln o wi s
toidentifythosethatareusefulforpredictingwhether
a student will ultimately succeed in this course while
controlling for the others. After fitting several models
using different subsets of the variables included in our
study,thevariablesthatyieldedthebestmodelsofstu-
dents’ success in terms of prediction accuracy are col-
legeGPA,pre-requisitecoursegrade,andthemidterm
grade.Notethatthesedataareobtainedfromthecam-
pusandarehencereliable.Basedonthese,twomodels
are proposed:
1 “Early intervention” model—this model pro-
duces the probability of failure in the course
based on predictors generated prior to the start
ofthesemester,butafter thecoursepre-requisite","5.2. Work-related factors
Most of the students in the College of Business work
outside of school, and the goal here is to determine
how their work activities affect performance in this
course on Business Statistics.Table 3shows the dis-
tribution of students by their work status outside of
school, along with average midterm and final grades.
Aswecansee,majorityofstudentsworkparttime.Sta-
tistical tests reveal significant differences in both sets
ofgradesforthesestudentsgroupedbytheirworksta-
tus (p-values, respectively, 0.049 and 0.019). Students
who work less outside have significantly better perfor-
mancethanthosewhoworkmore.Thisseemsreason-
able since the more time students spend on their work
activities,thelesstimetheyspendonthecourseleading
topoorerperformance.
Moreover, 40% of students stated that external
responsibilities always or often affect their success at
schoolwhereasapproximately40%saidthattheyocca-
sionallydoso.Thelargestproportionofstudentsmen-
tioned work and financial situation as the most dom-
inant factor, followed by interest and motivation in
classandfamily obligations. Social/recreationalactivi-
ties,health-relatedfactors,andathleticswerenotfound
to be the most influential factor in academic success
accordingtostudents’self-perceivedbeliefs.
5.3. Academic self-concept factors
Asinalleducationalstudies,academicself-conceptfac-
tors are very important in assessing student perfor-
mance and success in major courses. They represent
students’ self-perceived notions about certain factors
thataffectlearning.Soweincludedinoursurveysome
suchfactorsthatwereaimedatunderstandingstudents’
ownperceptionaboutmotivation,interest,intellectual
abilityintopicsofaquantitativenature,andtheirself-
perceivedlevelofpreparednessatthebeginningofthe
course. Statistical tests indicated that those students
whoweremoremotivated,hadmoreinterestinMath-
ematics, had more self-confidence in their intellectual
abilityinMathematics,andbelievedthattheywerebet-
ter prepared before the course had significantly better
performance overall (p-values close to 0 in all cases).
75% of the students were motivated to some extent,
while35%wereslightlyornotinterestedinMathemat-
ical topics. Moreover, only about 6% of the students
had low self-confidence in their intellectual ability in
Mathematics and 52% believed that they were some-
what prepared for the course but were lacking some
importantskillsandknowledge.
These findings are consistent with earlier studies
andexpectations.Students
who have higher academic self-concept are expected
to have more success in courses than students with
relatively lower academic self-concept. Thus, efforts
are required to help improve students’ academic self-
conceptvianovelandinnovativepedagogicalmethods
to increase motivation and interest, not only for the
Business courses but even earlier for the pre-requisite
courses that prepare them for these courses. These,
along with intervention techniques, will be helpful in
enhancing the overall intellectual and cognitive abili-
ties of students, thus improving their chances of suc-
ceedinginthecourseonBusinessStatistics.
6. Predictionmodels
Although several factors were found to affect stu-
dent success in the Business Statistics course from the
e x p l o r a t o r ya n a l y s e so u t l i n e da b o v e ,t h eg o a ln o wi s
toidentifythosethatareusefulforpredictingwhether
a student will ultimately succeed in this course while
controlling for the others. After fitting several models
using different subsets of the variables included in our
study,thevariablesthatyieldedthebestmodelsofstu-
dents’ success in terms of prediction accuracy are col-
legeGPA,pre-requisitecoursegrade,andthemidterm
grade.Notethatthesedataareobtainedfromthecam-
pusandarehencereliable.Basedonthese,twomodels
are proposed:
1 “Early intervention” model—this model pro-
duces the probability of failure in the course
based on predictors generated prior to the start
ofthesemester,butafter thecoursepre-requisite"
Copie de Mitra and Goldstein - 2015 - Designing early detection and intervention techniques via predictive statistical models—A case study.pdf,"COMMUNICATIONSINSTATISTICS:CASESTUDIES,DATAANALYSISANDAPPLICATIONS 15
Table .Modeloutputfortheearlyinterventionmodel.
Coeﬃcient Standarderror p-Value
MATH −. . .
GPA −. . 
Intercept . . .
w a sc o m p l e t e d .W eu s et h i sm o d e lt oi d e n t i f ya
groupofstudentsat-riskatthebeginningofthe
course. Of the 647 complete records available
(recall,thatwedidnothavepre-requisitecourse
gradesformanystudents),weuse400fortrain-
ing (or, fitting the model). The rest 247 records
form the validation set for assessing predictive
accuracy.
2 “Lateintervention”model—thismodelproduces
theprobabilityoffailureinthecoursebasedona
combination of predictors generated before the
startofthecourseinquestionandafterthefirst
midtermisgiveninthatcourse.Forthismodel,
we used 751 records for training the model and
the rest 482 for validation purposes (total sam-
plesize = 1,233).
6.1 Early intervention model
The two predictors used in this model are the letter
grade in the pre-requisite course on business calculus
that we refer to as “Math” (gradesaredivided into two
categories:Bandabovevs.belowBbecauseonlyletter
gradeswereavailable)andthecumulativeGPApriorto
enrolling in the Business Statistics course. The model
is
Probability
= exp(2.3788− 0.936Math− 1.3912GPA)
1+ exp(2.3788− 0.936Math− 1.3912GPA).
The model output along with fitted coefficients,
p-valuesareshownin Table 4.
Figure 1shows that the “Math” variable expresses
the difference in performance in a quantitative course
between students with quantitative skills and those
without quantitative skills. Note that, the difference
in the probability of failing the course between stu-
dentswhoscoredhighinMath andthose whodidnot
reduces when the GPA increases. A list of other com-
peting models is considered along with the Akaike’s
Information Criterion (or AIC) values appear in the
Appendix. Our chosen model has the lowest AIC
among allof these.
Figure. TherelationshipbetweenGPAandtheprobabilityoffail-
ingthecoursefortwodiﬀerentcategoriesofthecoursegradeon
Business Calculus. The upper line belongs to students with pre-
requisitegrade < B,whilethelowerlinebelongstothosewithpre-
requisitegrade /2265B.
Table .Modeloutputforthelateinterventionmodel.
Coeﬃcient Standarderror p-Value
MATH −. . .
GPA −. . .
Intercept . . .
6.2 Late intervention model
Thetwopredictorsforthismodelweremidtermgrade
(percentage score) and GPA, chosen again using the
AICcriterion.Themodelis
Probability
= exp(5.8368− 0.0735midterm− 1.3912GPA)
1+ exp(5.8368− 0.0735midterm− 1.3912GPA).
The model output along with fitted coefficients,
p-values are shown inTable 5. Other competing mod-
els that we explored, along with the AIC values, are
includedintheAppendix.
Figure .TheroleofGPAindeterminingtheprobabilityestimate
(y-axis).Theupperlinebelongstostudentswithmidtermgrade <
B,whilethelowerlinebelongstothosewithmidtermgrade /2265B.","Of the 647 complete records available
(recall,thatwedidnothavepre-requisitecourse
gradesformanystudents),weuse400fortrain-
ing (or, fitting the model). The rest 247 records
form the validation set for assessing predictive
accuracy.
2 “Lateintervention”model—thismodelproduces
theprobabilityoffailureinthecoursebasedona
combination of predictors generated before the
startofthecourseinquestionandafterthefirst
midtermisgiveninthatcourse.Forthismodel,
we used 751 records for training the model and
the rest 482 for validation purposes (total sam-
plesize = 1,233).
6.1 Early intervention model
The two predictors used in this model are the letter
grade in the pre-requisite course on business calculus
that we refer to as “Math” (gradesaredivided into two
categories:Bandabovevs.belowBbecauseonlyletter
gradeswereavailable)andthecumulativeGPApriorto
enrolling in the Business Statistics course.
The model output along with fitted coefficients,
p-valuesareshownin Table 4.
Figure 1shows that the “Math” variable expresses
the difference in performance in a quantitative course
between students with quantitative skills and those
without quantitative skills. Note that, the difference
in the probability of failing the course between stu-
dentswhoscoredhighinMath andthose whodidnot
reduces when the GPA increases. A list of other com-
peting models is considered along with the Akaike’s
Information Criterion (or AIC) values appear in the
Appendix. Our chosen model has the lowest AIC
among allof these.
6.2 Late intervention model
Thetwopredictorsforthismodelweremidtermgrade
(percentage score) and GPA, chosen again using the
AICcriterion.
The model output along with fitted coefficients,
p-values are shown inTable 5. Other competing mod-
els that we explored, along with the AIC values, are
includedintheAppendix."
Copie de Mitra and Goldstein - 2015 - Designing early detection and intervention techniques via predictive statistical models—A case study.pdf,"16 S.MITRAANDZ.GOLDSTEIN
InFig.2,wedemonstratethebehavioroftheproba-
bilityoffailurewithrespecttoGPAfordifferentscores
inthemidterm.Notethatthemidtermscoresaremore
consequential in predicting failure in the course for
lowerlevelsofGPA,thusindicatingthatthosestudents
with lower midterm grades are at a greater risk of fail-
inginthecourseiftheyalsohavelowGPAs.
Animportantobservationfromallthemodelsisthat
none of the background information like ethnicity or
work-related factors that were found to have a signifi-
cant effect in the univariate analyses earlier was found
to have a significant effect on the target outcome in
presence of the academic predictors (GPA, midterm,
and pre-requisite grades). This does not necessarily
imply that the background factors are not relevant to
student success, but that their effects are not as signif-
icant in the presence of the stronger academic record-
basedfactors.
6.3. Assessing predictive accuracy of the models
The model accuracy or predictive power is assessed
viaperformanceonthevalidationsets(treatedas“new
d a t a ”a te a c hs t a g e )m e a s u r e db ys p e c i fi c i t ya n ds e n s i -
tivity as mentioned earlier. The data partition is done
viarandomselection,andisrepeated25timesinorder
to remove selection bias. Specificity was calculated as
the percentage of the number of students who were
predicted to pass among those who indeed passed the
course. Sensitivity was calculated as the percentage of
t h ea c t u a ln u m b e ro fs t u d e n t sw h of a i l e dt h ec o u r s e
that were predicted to fail. If the predicted probabil-
ityoffailureforaparticularstudentwasgreaterthana
pre-determinedcut-offprobability,heorshewasdeter-
minedtobe“ atriskoffailingthecourse. ”Thelatterwas
selectedbyobservingtheROCcurve(whichplots“sen-
sitivity”vs.1 − “specificity”) shown inFig.3.
The graphs demonstrate the trade-off between sen-
sitivity and specificity for different values of the cut-
off probability. For early intervention, we focus on
reaching out only to those students who are at a high
risk of failing the course (this is because, many stu-
dents get confused by a letter early on in the course
before the first exam). Thus, we consider “specificity”
a more important criterion than “sensitivity” to select
the optimal cut-off probability at this stage. This sit-
uation is reversed for late detection because at that
s t a g eo u ro b j e c t i v ei st oi n t e r v e n eu p o na sm a n ys t u -
dents as possible and not miss anybody who might
Figure. ROCcurvesfortheearlyandthelateInterventionmod-
els.
have benefitted from it. Therefore, we consider “sen-
sitivity” a more important criterion, thus resulting in
a low cut-off probability that yields a lower specificity
value. However, in both cases we need to ensure that
the other metric also does not fall below a certain
value. Such choices are further supported by the fact
that our models predict success in the course better
than failure (possibly because the data are dominated
by success, that is, more students pass than fail the
course).
The average sensitivity and specificity values for
eachmodelarecalculatedbyaveragingoverthevalida-
tion sets from 25 repetitions using the chosen cut-off
probability, along with the estimated standard errors.
This information is summarized inTable 6.T h es t a n -
dard errors help conclude that these accuracy metrics
are quite robust, that is, they are not much affected by
specifictrainingandtestsetcombinations.
T h el a t ed e t e c t i o nm o d e li sm o r ea c c u r a t et h a n
the early detection one because it incorporates the
midtermgrades(whichbeingpartofthecourseitselfis
expected to be a stronger predictor of final scores than
the pre-requisite course grade that is included in the
early intervention model). The early detection model,
despite not using any information from the course
itself, is quite effective in predicting the success rates.
This is very crucial for intervention purposes because
Table .Predictionperformanceofthemodelsinthecourse.The
entriesinthistablerepresentthe“averageaccuracyrate” ±stan-
darderrors.
Models Sensitivity Speciﬁcity
Cut-oﬀ
probability
Earlyintervention % ± .% % ± .% .
Lateintervention % ± .% % ± .% .","In Fig. 2, we demonstrate the behavior of the probability of failure with respect to GPA for different scores in the midterm. Note that the midterm scores are more consequential in predicting failure in the course for lower levels of GPA, thus indicating that those students with lower midterm grades are at a greater risk of failing in the course if they also have low GPAs.
An important observation from all the models is that none of the background information like ethnicity or work-related factors that were found to have a significant effect in the univariate analyses earlier was found to have a significant effect on the target outcome in presence of the academic predictors (GPA, midterm, and pre-requisite grades). This does not necessarily imply that the background factors are not relevant to student success, but that their effects are not as significant in the presence of the stronger academic record-based factors.
6.3. Assessing predictive accuracy of the models
The model accuracy or predictive power is assessed via performance on the validation sets (treated as “new data” at each stage) measured by specificity and sensitivity as mentioned earlier. The data partition is done via random selection, and is repeated 25 times in order to remove selection bias. Specificity was calculated as the percentage of the number of students who were predicted to pass among those who indeed passed the course. Sensitivity was calculated as the percentage of the actual number of students who failed the course that were predicted to fail. If the predicted probability of failure for a particular student was greater than a pre-determined cut-off probability, he or she was determined to be “at risk of failing the course.” The latter was selected by observing the ROC curve (which plots “sensitivity” vs. 1 − “specificity”) shown in Fig. 3.
The graphs demonstrate the trade-off between sensitivity and specificity for different values of the cut-off probability. For early intervention, we focus on reaching out only to those students who are at a high risk of failing the course (this is because, many students get confused by a letter early on in the course before the first exam). Thus, we consider “specificity” a more important criterion than “sensitivity” to select the optimal cut-off probability at this stage. This situation is reversed for late detection because at that stage our objective is to intervene upon as many students as possible and not miss anybody who might have benefitted from it. Therefore, we consider “sensitivity” a more important criterion, thus resulting in a low cut-off probability that yields a lower specificity value. However, in both cases we need to ensure that the other metric also does not fall below a certain value. Such choices are further supported by the fact that our models predict success in the course better than failure (possibly because the data are dominated by success, that is, more students pass than fail the course).
The average sensitivity and specificity values for each model are calculated by averaging over the validation sets from 25 repetitions using the chosen cut-off probability, along with the estimated standard errors. This information is summarized in Table 6. The standard errors help conclude that these accuracy metrics are quite robust, that is, they are not much affected by specific training and test set combinations.
The late detection model is more accurate than the early detection one because it incorporates the midterm grades (which being part of the course itself is expected to be a stronger predictor of final scores than the pre-requisite course grade that is included in the early intervention model). The early detection model, despite not using any information from the course itself, is quite effective in predicting the success rates. This is very crucial for intervention purposes because"
Copie de Mitra and Goldstein - 2015 - Designing early detection and intervention techniques via predictive statistical models—A case study.pdf,"COMMUNICATIONSINSTATISTICS:CASESTUDIES,DATAANALYSISANDAPPLICATIONS 17
the earlier you identify at-risk students and provide
themwithhelpthebetteraretheirchancesofsucceed-
ingeventuallyinthecourse.
Wealsocomparedthepredictiveperformanceofour
modelswithothercommonlyusedclassificationmeth-
ods, such as Classification Trees and Neural Networks
inordertoestablishtheirrelativeefficiencyforourpur-
pose. Using the same cross-validation techniques, we
found that the same subset of predictors came out to
beinfluential(i.e.,GPAandMathgradesforearlyinter-
ventionandGPAandmidtermgradesforthelateinter-
vention) and the prediction accuracies of these mod-
els were significantly poorer than that of the logistic
regression models that we employed. Both the sen-
sitivity ratio and the specificity ratio were quite low,
the range being 45%–52%. This clearly indicates that
a large proportion of students who failed the course
wouldnotreceivetheadditionalhelpearlyonthrough
interventionthattheyneeded,shouldanyofthesetwo
models were deployed in practice. Logistic regression
thus proved to be the superior method compared to
both these tools, with significantly higher predictive
power.
However, the relatively newer classification tech-
nique of Random Forests (Breiman2001), which con-
siders an ensemble of classification trees to improve
accuracy, yielded considerably better results that were
atparwith thosewe obtainedfromthe logistic regres-
sion, with sensitivity values of 62% and 72% for
early and late intervention models, respectively, and
specificity values of 75% and 76% for the two models,
respectively. Note that these values are close and not
significantlydifferentfromthoseofourmodels.Sowe
conclude that logistic regression does an overall good
jobofpredictingstudentfailureandweadoptitforour
intervention studies. We wish to explore other classi-
fication methods such as boosted trees, in our future
work to determine whether further improvement in
predictionaccuracycanbeachieved.
6.4. Devising intervention based on the predictive
models
Our overall recommendations based on these predic-
tivemodelsconsistofatwo-stageinterventionplanfor
students in the Business Statistics course. This is done
asfollows:
 Stage 1: The early detection model is used to
identify at-risk students based on their academic
record before the start of the course. Actions are
then taken by the school to approach these stu-
dents and urge them to receive support made
availablebytheschool.
 Stage 2:Thelatedetectionmodelisusedtoiden-
tifyat-riskstudentsafterthefirstmidterm.These
students are also encouraged to avail resources to
help them with the course. Note that, those stu-
dentsselectedatthisstagewhowerealreadyiden-
tified in Stage 1 need to be provided with greater
additional support in order to improve their odds
of passing.
Theimplementationoftheseinterventionmodelsis
based on the probability estimate of failure obtained
from the logistic regression model selected at each
stage, sayP(F). With the cut-off probability selected
before(say, T), we classify a student as “failing” ifP(F)
/2265Tor“passing” ifP(F)< T.
Duringeachsemester, P(F)iscomputedforeachstu-
dent based on the relevant variables included in each
ofthemodels—GPAandpre-requisitecoursegradefor
early detection, and GPA and midterm grades for late
detection. Using a threshold as described above, we
identifysubgroupsofstudentswhoareatrisk,anexam-
plebeing:
Early detection:
1 Students with a letter grade of below B in the
pre-requisitecourseandGPAlowerthan2.72.
2 StudentswithalettergradeofAorBinBusiness
CalculusbutaGPAlowerthan2.49.
Late detection:
1 Students with midterm grade below 72% and
GPAlowerthan2.67.
2 Students with midterm grade above 72% but a
GPAlowerthan2.45.
7. Implementationoftheinterventionmethods
We deployed the two-stage intervention model for the
Business Statistics course in Spring 2014, wherein stu-
dentsdetectedtobeatriskateachstagereceivedalet-
ter from the college dean asking them to seek addi-
tional help and support for the course. The particular
interventionconsistedof supplementalinstruction(SI),
which is an academic assistance program that utilizes
peer-assisted study sessions through hands-on prac-
ticeandcollaborativegroupexercises.Theseareknown
to increase retention and improve student grades in","the earlier you identify at-risk students and provide
themwithhelpthebetteraretheirchancesofsucceed-
ingeventuallyinthecourse.
Wealsocomparedthepredictiveperformanceofour
modelswithothercommonlyusedclassificationmeth-
ods, such as Classification Trees and Neural Networks
inordertoestablishtheirrelativeefficiencyforourpur-
pose. Using the same cross-validation techniques, we
found that the same subset of predictors came out to
beinfluential(i.e.,GPAandMathgradesforearlyinter-
ventionandGPAandmidtermgradesforthelateinter-
vention) and the prediction accuracies of these mod-
els were significantly poorer than that of the logistic
regression models that we employed. Both the sen-
sitivity ratio and the specificity ratio were quite low,
the range being 45%–52%. This clearly indicates that
a large proportion of students who failed the course
wouldnotreceivetheadditionalhelpearlyonthrough
interventionthattheyneeded,shouldanyofthesetwo
models were deployed in practice. Logistic regression
thus proved to be the superior method compared to
both these tools, with significantly higher predictive
power.
However, the relatively newer classification tech-
nique of Random Forests , which con-
siders an ensemble of classification trees to improve
accuracy, yielded considerably better results that were
atparwith thosewe obtainedfromthe logistic regres-
sion, with sensitivity values of 62% and 72% for
early and late intervention models, respectively, and
specificity values of 75% and 76% for the two models,
respectively. Note that these values are close and not
significantlydifferentfromthoseofourmodels.Sowe
conclude that logistic regression does an overall good
jobofpredictingstudentfailureandweadoptitforour
intervention studies. We wish to explore other classi-
fication methods such as boosted trees, in our future
work to determine whether further improvement in
predictionaccuracycanbeachieved.
6.4. Devising intervention based on the predictive
models
Our overall recommendations based on these predic-
tivemodelsconsistofatwo-stageinterventionplanfor
students in the Business Statistics course. This is done
asfollows:
 Stage 1: The early detection model is used to
identify at-risk students based on their academic
record before the start of the course. Actions are
then taken by the school to approach these stu-
dents and urge them to receive support made
availablebytheschool.
 Stage 2:Thelatedetectionmodelisusedtoiden-
tifyat-riskstudentsafterthefirstmidterm.These
students are also encouraged to avail resources to
help them with the course. Note that, those stu-
dentsselectedatthisstagewhowerealreadyiden-
tified in Stage 1 need to be provided with greater
additional support in order to improve their odds
of passing.
Theimplementationoftheseinterventionmodelsis
based on the probability estimate of failure obtained
from the logistic regression model selected at each
stage, sayP(F). With the cut-off probability selected
before(say, T), we classify a student as “failing” ifP(F)
/2265Tor“passing” ifP(F)< T.
Duringeachsemester, P(F)iscomputedforeachstu-
dent based on the relevant variables included in each
ofthemodels—GPAandpre-requisitecoursegradefor
early detection, and GPA and midterm grades for late
detection. Using a threshold as described above, we
identifysubgroupsofstudentswhoareatrisk,anexam-
plebeing:
Early detection:
1 Students with a letter grade of below B in the
pre-requisitecourseandGPAlowerthan2.72.
2 StudentswithalettergradeofAorBinBusiness
CalculusbutaGPAlowerthan2.49.
Late detection:
1 Students with midterm grade below 72% and
GPAlowerthan2.67.
2 Students with midterm grade above 72% but a
GPAlowerthan2.45.
7. Implementationoftheinterventionmethods
We deployed the two-stage intervention model for the
Business Statistics course in Spring 2014, wherein stu-
dentsdetectedtobeatriskateachstagereceivedalet-
ter from the college dean asking them to seek addi-
tional help and support for the course. The particular
interventionconsistedof supplementalinstruction(SI),
which is an academic assistance program that utilizes
peer-assisted study sessions through hands-on prac-
ticeandcollaborativegroupexercises.Theseareknown
to increase retention and improve student grades in"
Copie de Mitra and Goldstein - 2015 - Designing early detection and intervention techniques via predictive statistical models—A case study.pdf,"18 S.MITRAANDZ.GOLDSTEIN
Table .Performance of students detected for early intervention
brokendownbywhethertheyattendedSIsessionsornot.
AttendSI Failurerates
Midtermgrades
(mean)
Finalgrades
(mean)
Yes (n= ) (.%) . .
No(n= ) (.%) . .
targeted historically difficult courses (UMKC website,
http://www.umkc.edu/ASM/si/overview.shtml).
Stage 1: Early intervention
O ft h e6 2s t u d e n t si n c l u d e di nt h ee a r l yd e t e c t i o n
phase, 10 failed (16.13%).Table 7shows the failure
ratesamongthesestudents,brokendownbythosewho
attended SI sessions and those who did not. Clearly,
thereisasignificantlylowerpercentageofstudentswho
were intervened upon and took advantage of it (by
attendingSIsessions),failedcomparedtothosedidnot,
and ap-valueof0.0375wasobservedwhentestingthe
d i ff e r e n c ei nt h et w op r o p o r t i o n so ff a i l u r er a t e s .T h e
average midterm and final grades also clearly indicate
t h a tp e r f o r m a n c eo fs t u d e n t si m p r o v e ds i g n i fi c a n t l yi f
they attended SI sessions after the intervention and it
deteriorated if they did not. The average final grade of
studentswhoattendedSIissignificantlyhigheraswell
(p-value= 0.035).
Stage 2: Late intervention
Of the 364 students who received the late inter-
vention letter (after midterm), 149 failed with D/F/W
Table .Performance of students detected for late intervention
brokendownbywhethertheyattendedSIsessionsornot.
AttendSI Failurerates
Midtermgrades
(mean)
Finalgrades
(mean)
Yes (n= ) (.%) . .
No(n= ) (.%) . .
grades (40.93%) and 209 passed (57.4%). The failure
rates inTable 8indicate that a significantly lower per-
centage of students who took advantage of the inter-
vention (by attending SI sessions) failed compared
to those did not (p-value < 0.0001), just as in the
case of the early intervention. The average midterm
and final grades also demonstrate that performance
of students improved significantly if they attended SI
sessions after the intervention, and it did not oth-
erwise. There is a statistically significant difference
i nt h efi n a lg r a d e so ft h e s et w og r o u p s(p-value <
0.0001).
7.1. Both early and late interventions
Letusnowlookatthosestudentswhowereselectedin
both stages of intervention. Clearly these students are
in greater need for additional help in order to succeed
inthecourse.Therewere33studentswhowerechosen
forbothinterventions.Ofthese33,17(51.5%)attended
SIsessionsandtherest16(48.5%)didnot.Thefailure
Figure. Averagemidtermandﬁnalgradesofstudents(shownonthe y-axes)whoreceivedinterventionsatthediﬀerentstages.","Stage 1: Early intervention
O ft h e6 2s t u d e n t si n c l u d e di nt h ee a r l yd e t e c t i o n
phase, 10 failed (16.13%).Table 7shows the failure
ratesamongthesestudents,brokendownbythosewho
attended SI sessions and those who did not. Clearly,
thereisasignificantlylowerpercentageofstudentswho
were intervened upon and took advantage of it (by
attendingSIsessions),failedcomparedtothosedidnot,
and ap-valueof0.0375wasobservedwhentestingthe
d i ff e r e n c ei nt h et w op r o p o r t i o n so ff a i l u r er a t e s .T h e
average midterm and final grades also clearly indicate
t h a tp e r f o r m a n c eo fs t u d e n t si m p r o v e ds i g n i fi c a n t l yi f
they attended SI sessions after the intervention and it
deteriorated if they did not. The average final grade of
studentswhoattendedSIissignificantlyhigheraswell
(p-value= 0.035).
Stage 2: Late intervention
Of the 364 students who received the late inter-
vention letter (after midterm), 149 failed with D/F/W
grades (40.93%) and 209 passed (57.4%). The failure
rates inTable 8indicate that a significantly lower per-
centage of students who took advantage of the inter-
vention (by attending SI sessions) failed compared
to those did not (p-value < 0.0001), just as in the
case of the early intervention. The average midterm
and final grades also demonstrate that performance
of students improved significantly if they attended SI
sessions after the intervention, and it did not oth-
erwise. There is a statistically significant difference
i nt h efi n a lg r a d e so ft h e s et w og r o u p s(p-value <
0.0001).
7.1. Both early and late interventions
Letusnowlookatthosestudentswhowereselectedin
both stages of intervention. Clearly these students are
in greater need for additional help in order to succeed
inthecourse.Therewere33studentswhowerechosen
forbothinterventions.Ofthese33,17(51.5%)attended
SIsessionsandtherest16(48.5%)didnot.Thefailure"
Copie de Mitra and Goldstein - 2015 - Designing early detection and intervention techniques via predictive statistical models—A case study.pdf,"COMMUNICATIONSINSTATISTICS:CASESTUDIES,DATAANALYSISANDAPPLICATIONS 19
Table .Performanceofstudentsdetectedforbothearlyandlate
interventionsbrokendownbywhethertheyattendedSIsessions
ornot.
AttendSI Failurerates
Midtermgrades
(mean)
Finalgrades
(mean)
Yes (n= ) (.%) . .
No(n= ) (.%) . .
ratesin Table 9indicatethatasignificantlyhigherpro-
portion of students who did not avail of the interven-
tionsfailedthecourse( p-value= 0.0146).
Table 9demonstrates the performance of these stu-
d e n t si nt h ec o u r s e ,b o t hi nt e r m so fm i d t e r ma n d
final grades. ANOVA revealed significant differences
between the midterm grades (p-value = 0.039), thus
suggesting that students who received both interven-
tionshadpoorerperformanceuptothatpointthanstu-
dents who did not (as expected). On the other hand,
thereisnostatisticallysignificantdifferenceinthefinal
grades of students who received the interventions and
those who did not (p-value = 0.857). In fact, average
gradesofthestudentswhowereintervenedupontwice
improvedfromthemidtermtothefinalwhereasforthe
rest of the students, the grades deteriorated. The typi-
caltrendinthiscourseisthatperformancedeteriorates
fromthemidtermtothefinal(asdiscussedearlier).
Theresultsfromthedifferentstagesofinterventions
are summarized inFig. 4for easy comparison of the
outcomes. It is easily seen that the biggest impact is
seen on the final grades after attending a significant
numberofSIsessions,andforthosestudentswhowere
selected for the early intervention. Note that the lat-
ter students are the ones with the weakest background
as determined by their GPA and pre-requisite course
gradebeforetheytooktheBusinessStatisticscourse.
8. Conclusions
ThisstudywasthefirstofitskindintheCollegeofBusi-
nessatthisuniversitywhereinthefocuswastodevelop
anunderstandingofthefactorsthataffectstudentsuc-
cess in two bottleneck core courses with the objective
of devising effective intervention. It was a large-scale
study involving over 1,000 students; hence the results
a r ev e ryp r o m i s i n g .W ei d e n t i fi e ds e v e r a lf a c t o r sa s s o -
ciated with student performance, as well as devise two
r i g o r o u ss t a t i s t i c a lm o d e l st ob eu s e df o re a r l yd e t e c -
tion and intervention in this course. Our intervention
implementation also proved to be a major success as
our results clearly indicated that a significantly lower
numberofstudentswhoavailedsupplementalinstruc-
tionfailedthecoursethanthosewhodidnot.Thissug-
gests that timely and effective intervention techniques
h a v et h ep o t e n t i a lt oi m p r o v es t u d e n ts u c c e s sr a t e si n
difficult courses. Development of these intervention
strategies based on the predictive models is thus the
major contribution of this work. We note here that
the factors studied in this project cover a wide range
of information about the students and are quite gen-
eral across disciplines. Thus although developed for a
businesscourse,ourmethodsmaybeeasilyadaptedin
buildingsimilarinterventionforanycourseinanyfield
andatanyinstitutionofhighereducation.
Moreover, our university particularly has a large
minoritypopulationdominatedbyHispanics,manyof
who are first generation college attendees. Historical
data have shown that many of these students have dif-
ficulty in quantitative courses in the area of Business,
andhencecanbenefitgreatly from the additional sup-
port offered in the form of intervention, both before
and during the course. Steps can be taken to develop
special curriculum with preparatory courses in quan-
titative disciplines so that students graduating from
high schools could acquire the skills necessary to be
successful in college. This considerably broadens the
scope of our research. All these insights, along with
the proposed intervention tools have the potential of
improvingstudentsuccessinbottleneckcoursesinthe
Business curricula, and as a result, have far-reaching
impact of improving graduation rates at colleges and
universities, specifically for under-represented minor-
ity groups.
Another aspect is that since most of the factors
affecting student performance are usually identifiable
beforethecoursestarts,theycanaidtheadministration
in the respective departments in the universities with
logistical planning and decision-making in the form
of allocating resources for supplemental instruction
(for instance, how many sessions to offer in a partic-
ular semester?), tutoring, and other student-centered
services (tutors, space, equipment, etc.). For example,
basedonGP Aandpre-requisitecoursegrades,theycan
estimate ahead of time how many students enrolled in
the course in a particular semester are likely to need
extra help and support. In addition, making success-
ful intervention should shorten the average time till
graduation (because the course of interest is a bot-
tleneck course), and this has an impact on cost, seat","Table .Performanceofstudentsdetectedforbothearlyandlate
interventionsbrokendownbywhethertheyattendedSIsessions
ornot.
ratesin Table 9indicatesthatasignificantlyhigherpro-
portion of students who did not avail of the interven-
tionsfailedthecourse( p-value= 0.0146).
Table 9demonstrates the performance of these stu-
d e n t si nt h ec o u r s e ,b o t hi nt e r m so fm i d t e r ma n d
final grades. ANOVA revealed significant differences
between the midterm grades (p-value = 0.039), thus
suggesting that students who received both interven-
tionshadpoorerperformanceuptothatpointthanstu-
dents who did not (as expected). On the other hand,
thereisnostatisticallysignificantdifferenceinthefinal
grades of students who received the interventions and
those who did not (p-value = 0.857). In fact, average
gradesofthestudentswhowereintervenedupontwice
improvedfromthemidtermtothefinalwhereasforthe
rest of the students, the grades deteriorated. The typi-
caltrendinthiscourseisthatperformancedeteriorates
fromthemidtermtothefinal(asdiscussedearlier).
Theresultsfromthedifferentstagesofinterventions
are summarized inFig. 4for easy comparison of the
outcomes. It is easily seen that the biggest impact is
seen on the final grades after attending a significant
numberofSIsessions,andforthosestudentswhowere
selected for the early intervention. Note that the lat-
ter students are the ones with the weakest background
as determined by their GPA and pre-requisite course
gradebeforetheytooktheBusinessStatisticscourse.
8. Conclusions
ThisstudywasthefirstofitskindintheCollegeofBusi-
nessatthisuniversitywhereinthefocuswastodevelop
anunderstandingofthefactorsthataffectstudentsuc-
cess in two bottleneck core courses with the objective
of devising effective intervention. It was a large-scale
study involving over 1,000 students; hence the results
a r ev e ryp r o m i s i n g .W ei d e n t i fi e ds e v e r a lf a c t o r sa s s o -
ciated with student performance, as well as devise two
r i g o r o u ss t a t i s t i c a lm o d e l st ob eu s e df o re a r l yd e t e c -
tion and intervention in this course. Our intervention
implementation also proved to be a major success as
our results clearly indicated that a significantly lower
numberofstudentswhoavailedsupplementalinstruc-
tionfailedthecoursethanthosewhodidnot.Thissug-
gests that timely and effective intervention techniques
h a v et h ep o t e n t i a lt oi m p r o v es t u d e n ts u c c e s sr a t e si n
difficult courses. Development of these intervention
strategies based on the predictive models is thus the
major contribution of this work. We note here that
the factors studied in this project cover a wide range
of information about the students and are quite gen-
eral across disciplines. Thus although developed for a
businesscourse,ourmethodsmaybeeasilyadaptedin
buildingsimilarinterventionforanycourseinanyfield
andatanyinstitutionofhighereducation.
Moreover, our university particularly has a large
minoritypopulationdominatedbyHispanics,manyof
who are first generation college attendees. Historical
data have shown that many of these students have dif-
ficulty in quantitative courses in the area of Business,
andhencecanbenefitgreatly from the additional sup-
port offered in the form of intervention, both before
and during the course. Steps can be taken to develop
special curriculum with preparatory courses in quan-
titative disciplines so that students graduating from
high schools could acquire the skills necessary to be
successful in college. This considerably broadens the
scope of our research. All these insights, along with
the proposed intervention tools have the potential of
improvingstudentsuccessinbottleneckcoursesinthe
Business curricula, and as a result, have far-reaching
impact of improving graduation rates at colleges and
universities, specifically for under-represented minor-
ity groups.
Another aspect is that since most of the factors
affecting student performance are usually identifiable
beforethecoursestarts,theycanaidtheadministration
in the respective departments in the universities with
logistical planning and decision-making in the form
of allocating resources for supplemental instruction
(for instance, how many sessions to offer in a partic-
ular semester?), tutoring, and other student-centered
services (tutors, space, equipment, etc.). For example,
basedonGP Aandpre-requisitecoursegrades,theycan
estimate ahead of time how many students enrolled in
the course in a particular semester are likely to need
extra help and support. In addition, making success-
ful intervention should shorten the average time till
graduation (because the course of interest is a bot-
tleneck course), and this has an impact on cost, seat"
Copie de Mitra and Goldstein - 2015 - Designing early detection and intervention techniques via predictive statistical models—A case study.pdf,"20 S.MITRAANDZ.GOLDSTEIN
occupancy,facultyrecruitment,andothermeasuresof
programefficiency.Thisstudyandtheresultsobtained,
therefore,haveextensiveramificationsintermsofbud-
getaryandresourcemanagementaswell.Wealsowish
tointegrateacostanalysisintoourmodelingforassess-
ingpredictivepower,providedweareabletoobtainthe
relevant data from campus offices.
We are currently refining our models for even bet-
ter outcomes in the future semesters, as well as study-
ingthosestudentswhowereselectedforinterventions
more closely with respect to the background factors.
S i n c eo u rp r e d i c t i v em o d e l st h a ta r et h em a i ng o a l so f
the study only required academic factors, we do not
c o n d u c tt h es u r v e ya n ym o r e ,b u ti n s t e a do b t a i na l l
ourbackgrounddatafromthecampusofficeofInstitu-
tional research. This has considerably streamlined the
entire process and ensured that the data received are
t r u s t w o r t h ys ot h a tt h ea c c u r a c ya n dv a l i d i t yo fo u r
methodscanbeestablished.Inthefuture,wealsohope
toobtainsomebackgrounddatasuchastransferstatus
from aCommunity College(Yes/No), numberofunits
of courses enrolled in, etc., from the campus in order
to incorporate them into our intervention models for
potentiallygreateraccuracyisdetectingstudentsatrisk
of failing.
References
Astin, A. W.1993.AnEmpiricalTypologyofCollegeStudents.
JournalofCollegeStudentDevelopment 34:36–46.
Bailey, T.2008. “Transition Matters: Community College to
Bachelor’s Degree.” Proceedings Report of the Advisory
Committee on Student Financial Assistance. pp. 46–49.
https://protect-us.mimecast.com/s/rx4mBRUDx1VgCW
Baker, B.2007. “A Conceptual Framework for Making Knowl-
edgeActionableThroughCapitalFormation.”D.Mgt.diss.,
UniversityofMarylandUniversityCollege.
B a r a d w a j ,R . ,K . B a r o n . ,C .B i c h y ,M .D i l t o n ,J .F r i t z ,a n d
J. Joseph.2012. Using Learner Analytics to Scale Feedback
in Gateway Courses , Baltimore, MD: University of
Maryland, Baltimore County (UMBC) Accessed April 9,
2015. http://www.jngi.org/wordpress/wp-content/uploads/
2013/04/Using-Learner-Analytics-to-Scale-Feedback-in-
Gateway-Courses-Bichy8.pdf.
Bellico, R.1972. Prediction of Undergraduate Achievement in
Economics.Journal of Economic Education3(1):54–55.
Borde,S.F. 1998.PredictorsofStudentAcademicPerformance
intheIntroductoryMarketingCourse. JournalofEducation
for Business73(5):302–306.
Breiman,L. 2001.Rando mF o r ests.Machine Learning45:5–32.
Brower, A. M., and A. Ketterhagen.2004. Is There an Inherent
Mismatch Between how Black and White Students Expect
toSucceedinCollegeandWhatTheirCollegesExpectfrom
Them?J o u rna lo fSocia lI s s ues60(1):95–116.
Brown, R. O. 1966. Prediction of Accounting Grades. The
AccountingReview 41(2):340–343.
Cohn, E. 1972. Students’ Characteristics and Performance
in Economic Statistics. Journal of Economic Education
3(2):106–111.
CongressoftheUnitedStates,OfficeoftechnologyAssessment.
1988. Educating Scientists and Engineers: Grade School to
Grad School. Washington DC: US Government Printing
Office,pp.128.
D o r a n ,B .M . ,M .L . B o u l l i o n ,a n dC .G .S m i t h .1991. Determi-
nants of Student Performance in Accounting Principles I
andII. Issues in Accounting Education6(1):74–84.
Eckel, N., and W. A. Johnson.1983.AM o d e lf o rS c r e e n i n g
and Classifying Potential Accounting Majors.Journal of
AccountingEducation 1(2):57–65.
Educause 2010. “7 Things You Should Know About Ana-
lytics, EDUCAUSE 7 Things You Should Know Series.”
Accessed April , 2015. http://www.educause.edu/ir/
library/pdf/ELI7059.pdf
Elias, T. 2011. Learning Analytics: Definitions, Processes
and Potential . Edmonton, AB, Canada: Athabasca
University. Accessed April 9, 2015. http://learning
analytics.net/LearningAnalyticsDefinitionsProcessesPote-
ntial.pdf
Eskew, R. K., and R. H. Faley.1988. Some Determinants of
Student Performance in the First College-level Financial
AccountingCourse. TheAccountingReview 63(1):137–147.
Ferguson, R. 2014. Learning Analytics don’t just Measure
Students’ Progress – They Can Shape it.The Guardian,
24 March 2014. Retrieved April , 2015. http://www.the
guardian.com/education/2014/mar/26/learning-analytics-
student-progress
Gainen,J. 1995.BarrierstoSuccessinQuantitativeGatekeeper
Courses. InFostering Student Success in Quantitative Gate-
way Courses, edited by J. Gainen and E. W. Williamson, 5–
14.SanFrancisco:Jossey-Bass.
Gerardi,S. 1990.AcademicSelf-ConceptasaPredictorofSuc-
cessAmongMinorityandLowSocio-economicStatusStu-
dents.Journal of College Student Development31:402–407.
Glesne,C. 1998.BecomingQualitativeResearchers:AnIntroduc-
tion.N ewY o rk:Lo ngman.
Goldman,R.D.,andR.E.Slaughter. 1976.W h yCollegeGrade
P o i n tA v e r a g ei sD i ffi c u l tt oP r e d i c t .Journal of Educational
Psychology68(1):9–14.
Herndon, M. K., and J. L. Moore.2002. African American
Factors for Student Success: Implications for Families and
Counselors.TheFamilyJournal:CounselingandTherapyfor
CouplesandFamilies .10(3):322–327.
Horn, L., K. Peter, and K. Rooney.2002. Profile of Undergrad-
uates in U.S. Postsecondary Institutions: 1999–2000 (NCES
2002–168).W a s h i n g t o n ,D C :U . S .D e p a r t m e n to fE d u c a -
tion,NationalCenterforEducationStatistics,U.S.Govern-
mentPrintingOffice.
H o r n ,L .J . ,a n dM .D .P r e m o .1995. Profile of Undergradu-
ates in U.S. Postsecondary Education Institutions: 1992–93,","occupancy, faculty recruitment, and other measures of programefficiency. This study and the results obtained, therefore, have extensive ramifications in terms of budgetary and resource management as well. We also wish to integrate a cost analysis into our modeling for assessing predictive power, provided we are able to obtain the relevant data from campus offices.
We are currently refining our models for even better outcomes in the future semesters, as well as studying those students who were selected for interventions more closely with respect to the background factors.
Since our predictive models that are the main goals of the study only required academic factors, we do not conduct the survey anymore, but instead obtain all our background data from the campus office of Institutional research. This has considerably streamlined the entire process and ensured that the data received are trustworthy so that the accuracy and validity of our methods can be established. In the future, we also hope to obtain some background data such as transfer status from a Community College (Yes/No), number of units of courses enrolled in, etc., from the campus in order to incorporate them into our intervention models for potentially greater accuracy is detecting students at risk of failing."
Copie de Mitra and Goldstein - 2015 - Designing early detection and intervention techniques via predictive statistical models—A case study.pdf,"COMMUNICATIONSINSTATISTICS:CASESTUDIES,DATAANALYSISANDAPPLICATIONS 21
With an Essay on Undergraduates at Risk (NCES 96–237).
Washington, DC: U.S. Department of Education, National
Center for Education Statistics, U.S. Government Printing
Office.
Hosmer, D. W., and S. Lemeshow. 2000.A p p l i e dL o g i s t i c
Regression.WileySeriesinStatisticsandProbability .H o b o -
ken,NJ:Wiley.
House, J. D.1995. Non-cognitive predictors of achievement in
introductory college Mathematics.Journal of College Stu-
dentDevelopment 36(2):171–181.
Ingram,R.W .,andR.J.Peterson. 1987.AnEvaluationofAICP A
TestsforPredictingthePerformanceofAccountingMajors.
TheAccountingReview 62(1):215–223.
Liesz,T.J.,andReyes,M.G.C. 1989.TheuseofPiagetianCon-
cepts to Enhance Student Performance in the Introductory
FinanceCourse. Journal of Finance education18:8–14.
MacFayden, L. P, and S. Dawson.2010. Mining LMS Data to
DevelopanEarlyWarningSystemforEducators:AProofof
Concept.ComputersandEducation 54(2):588–599.
Meece,J.L.,J.E.Parsons,C.M.Kaczala,S.B.Goff,andR.Futter-
man.1982.SexDifferencesinMathAchievement. Journalof
CollegeScienceTeaching 28(1):307–310.
Morrison, M. 2012.“ I m p r o v i n gP r o b a b i l i t i e sf o rS u c -
cess in a Gateway Math Course, Decisions Based
on Evidence.” Accessed November 20, 2014.
http://www.decisionsonevidence.com/2012/04/improving-
probabilities-for-success-in-a-gateway-math-course/
Morrison, M. C., and S. Schmit.2010. Predicting Success in a
Gateway Mathematics Course.N o r t hI o w aA r e aC o m m u -
nityCollege.AccessedfromInstituteofEducationSciences
(IES)ERICdatabase.http://eric.ed.gov/?id =ED511033
S a c h d e v a ,K .S . ,a n dW .E .S t e r k .1982. Projecting Finance Stu-
dentFinalCourseScoresBasedonInitialExamScores. Jour-
nal of Financial Education11:55–60.
Sedlacek, W. E.2002. “Employing Non-cognitive Variables in
the Admission and Retention of Non-traditional Students.”
UnpublishedTechnicalReport,CounselingCenter,Univer-
sityofMarylandatCollegePark.
Sellers, S. L., J. Roberts., L. Giovanetto, K. Friedrich, and C.
Hammargren. 2007. Reaching All Students, a Resource for
Teaching in Science, Technology, Engineering, and Mathe-
matics.2nded.Madison:UniversityofWisconsinCenterfor
the Integration of Research, Teaching,and Learning.
Seymour, E., and N. Hewitt.1997.Talking About Leaving: Why
UndergraduatesLeavetheSciences .Boulder,CO:Westview.
Tobias, S.1990.They’renotDumb,They’reDifferent:Stalkingthe
SecondTier. Tucson, AZ: Research Corporation.
Wilhite, S. C. 1990. Self-efficacy, Locus of Control, Self-
assessment of Memory Ability, and Study Activities as Pre-
dictors of College Course Achievement.Journal of Educa-
tional Psychology82:696–700.
Appendix:Selectingthebestpredictivemodel
While looking for the best predicting model, we used
many subsets of the available variables. In the par-
tial list that follows, we summarize some of the mod-
elsattemptedwhenfindingthebestpredictivemodels.
Tables A1and A2 show some of these models for the
earlyandlateinterventionstages,respectively.
Onecanobservethe“strength”ofthevariablesGPA
and MATH for the early detection model. Once these
twovariablesareincludedintheregression,therestof
the variables become insignificant, that is, they do not
add anything to the information we already have. We
pickmodel8,whichgivesthebest p-valuesforthevari-
ables,andthelowestAICvalue.
A similar process was followed for model selection
in case of the late intervention where we considered
several variables as well as variations of the midterm
gradeandtheGP Avariables,shownin Table A2.Again,
the model with GPA and midterm grade proved to be
thebestasassessedbytheAICvalues.
Table A.The entries are thep-values, and AIC values for com-
peting models of early intervention. Model  is the selected
model.
Workhrs/
week
Transfer
Yes/No Ethnicity
Units
taken GPA Math AIC
Model . . . .
Model . . .
Model . . . .
Model . . .
Model . . .
Model . . .
Model . . .
Model
∗ . . .
Table A.The entries are thep-values, and AIC values for com-
peting models of late intervention. Model  is the selected
model.
Midterm
Midterm-
square GPA /GPA
Transfer
Yes/No Ethnicity AIC
Model∗ . . .
Model . . .
Model . . . .
Model . . . .
Model . . . .
Model . . . .","Appendix:Selectingthebestpredictivemodel
While looking for the best predicting model, we used
many subsets of the available variables. In the par-
tial list that follows, we summarize some of the mod-
elsattemptedwhenfindingthebestpredictivemodels.
Tables A1and A2 show some of these models for the
earlyandlateinterventionstages,respectively.
Onecanobservethe“strength”ofthevariablesGPA
and MATH for the early detection model. Once these
twovariablesareincludedintheregression,therestof
the variables become insignificant, that is, they do not
add anything to the information we already have. We
pickmodel8,whichgivesthebest p-valuesforthevari-
ables,andthelowestAICvalue.
A similar process was followed for model selection
in case of the late intervention where we considered
several variables as well as variations of the midterm
gradeandtheGP Avariables,shownin Table A2.Again,
the model with GPA and midterm grade proved to be
thebestasassessedbytheAICvalues.
Table A.The entries are thep-values, and AIC values for com-
peting models of early intervention. Model  is the selected
model.
Table A.The entries are thep-values, and AIC values for com-
peting models of late intervention. Model  is the selected
model."
