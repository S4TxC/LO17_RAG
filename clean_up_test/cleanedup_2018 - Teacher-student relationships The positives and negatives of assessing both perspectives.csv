source,page_content,cleaned_page_content
2018 - Teacher-student relationships The positives and negatives of assessing both perspectives.pdf,"Contents lists available atScienceDirect
Journal of Applied Developmental Psychology
journal homepage: www.elsevier.com/locate/jappdp
Teacher-student relationships: The positives and negatives of assessing both
perspectives
Maureen E. Brinkwortha, Joseph McIntyrea, Anna D. Jurascheka, Hunter Gehlbachb,⁎
a Harvard University Graduate School of Education, United States
b University of California, Santa Barbara, United States
ARTICLE INFO
Keywords:
Interest
Motivation
Secondary school
Social emotional learning
Survey design
Teacher-student relationships
ABSTRACT
Although teacher-student relationships (TSRs) lie at the heart of teaching and learning, measuring these re-
lationships presents unique challenges. These challenges implicate how school leaders understand the connec-
tions between TSRs and student outcomes. This article addresses these challenges by describing a new approach
to measuring TSRs centered around a new scale that measures the positive and negative aspects of the overall
TSR from teachers' and students' perspectives. We describe the scale development process, document the mea-
sure's psychometric properties, and then use the scale to predict student outcomes. Drawing from a sample of
middle and high school students (N= 595) and their teachers (N = 88) in four diﬀerent schools, we found that a
two-factor model bestﬁts our items. Compared to a more traditional approach, our approach explains more
variability in student outcomes and gives educators a sharper understanding of the patterning of associations
between TSRs and student outcomes.
1. Introduction
Whatever else their jobs entail, school leaders are fundamentally in
the business of improving student outcomes. To help students improve,
schools must identify the variables of interest, develop interventions,
and assess the eﬃcacy of these interventions. Schools interested in
promoting students' social emotional learning in addition to traditional
outcomes such as grades, test scores, and graduation rates face an even
greater challenge because of the number of distinct areas they are
trying to improve. Fortunately, one aspect of students' schooling ex-
perience predicts a disproportionately large number of these outcomes:
teacher-student relationships (TSRs).Pianta and Allen (2008)note that
at the secondary school level“positive relationships with adults are
perhaps the single most important ingredient in promoting positive
youth development” (p. 24). The relative health of these relationships
has the potential to impact a tremendous array of educational outcomes
including students' academic achievement, aﬀect, behavior, and moti-
vation (Juvonen, 2006).
Because TSRs are associated with such a wide array of beneﬁts for
adolescents, they hold tremendous potential as a locus for interven-
tions. So many of these associations exist that even if TSRs are causally
related to only a fraction of the student outcomes they are correlated
with, successful TSR interventions would be a tremendous boon to any
school.
However, before developing interventions, secondary school leaders
need conﬁdence that their measures that will allow them to precisely
understand how TSRs are associated with student outcomes. For ex-
ample, numerous studies document that students who report more
positive TSRs tend to get better grades than their counterparts with less
positive TSRs (Roorda, Koomen, Split, & Oort, 2011). Thisﬁnding might
occur for many reasons. Students might report greater fondness for
those teachers who grade them more favorably. Alternatively, students
might try harder and, thus, perform better for teachers whom they like.
On the other hand, this association might be driven by teachers' per-
ceptions of the relationship. Perhaps teachers evaluate their favorite
students more favorably. As another possibility, perhaps they develop
an aﬃnity towards more highly achieving students (who make them
look good). If it is the teachers' perceptions that matter, students' re-
ports of their TSRs would correlate with their grades simply because
teachers' and students' perceptions of their TSRs are correlated. The
critical point is this: if a school assesses TSRs in such a way that the
associations between these relationships and outcomes are clear, they
will have a sharper understanding from which to develop interventions.
By contrast, aﬂawed TSR measure could encourage school leaders to
develop interventions for students when they really ought to be inter-
vening with their teachers (or vice-versa).
This manuscript introduces a measure of TSRs at the secondary level
designed to sharpen school leaders' understanding of these relationships
http://dx.doi.org/10.1016/j.appdev.2017.09.002
Received 8 September 2016; Received in revised form 31 August 2017; Accepted 11 September 2017
⁎ Corresponding author at: Gevirtz Graduate School of Education #3113, University of California, Santa Barbara 93106, United States.
E-mail address: gehlbach@ucsb.edu (H. Gehlbach).
Journal of Applied Developmental Psychology 55 (2018) 24–38
Available online 29 September 2017
0193-3973/ © 2017 Elsevier Inc. All rights reserved.
T","Teacher-student relationships: The positives and negatives of assessing both
perspectives

ABSTRACT
Although teacher-student relationships (TSRs) lie at the heart of teaching and learning, measuring these re-
lationships presents unique challenges. These challenges implicate how school leaders understand the connec-
tions between TSRs and student outcomes. This article addresses these challenges by describing a new approach
to measuring TSRs centered around a new scale that measures the positive and negative aspects of the overall
TSR from teachers' and students' perspectives. We describe the scale development process, document the mea-
sure's psychometric properties, and then use the scale to predict student outcomes. Drawing from a sample of
middle and high school students (N= 595) and their teachers (N = 88) in four diﬀerent schools, we found that a
two-factor model bestﬁts our items. Compared to a more traditional approach, our approach explains more
variability in student outcomes and gives educators a sharper understanding of the patterning of associations
between TSRs and student outcomes.
1. Introduction
Whatever else their jobs entail, school leaders are fundamentally in
the business of improving student outcomes. To help students improve,
schools must identify the variables of interest, develop interventions,
and assess the eﬃcacy of these interventions. Schools interested in
promoting students' social emotional learning in addition to traditional
outcomes such as grades, test scores, and graduation rates face an even
greater challenge because of the number of distinct areas they are
trying to improve. Fortunately, one aspect of students' schooling ex-
perience predicts a disproportionately large number of these outcomes:
teacher-student relationships (TSRs).Pianta and Allen (2008)note that
at the secondary school level“positive relationships with adults are
perhaps the single most important ingredient in promoting positive
youth development” (p. 24). The relative health of these relationships
has the potential to impact a tremendous array of educational outcomes
including students' academic achievement, aﬀect, behavior, and moti-
vation (Juvonen, 2006).
Because TSRs are associated with such a wide array of beneﬁts for
adolescents, they hold tremendous potential as a locus for interven-
tions. So many of these associations exist that even if TSRs are causally
related to only a fraction of the student outcomes they are correlated
with, successful TSR interventions would be a tremendous boon to any
school.
However, before developing interventions, secondary school leaders
need conﬁdence that their measures that will allow them to precisely
understand how TSRs are associated with student outcomes. For ex-
ample, numerous studies document that students who report more
positive TSRs tend to get better grades than their counterparts with less
positive TSRs (Roorda, Koomen, Split, & Oort, 2011). Thisﬁnding might
occur for many reasons. Students might report greater fondness for
those teachers who grade them more favorably. Alternatively, students
might try harder and, thus, perform better for teachers whom they like.
On the other hand, this association might be driven by teachers' per-
ceptions of the relationship. Perhaps teachers evaluate their favorite
students more favorably. As another possibility, perhaps they develop
an aﬃnity towards more highly achieving students (who make them
look good). If it is the teachers' perceptions that matter, students' re-
ports of their TSRs would correlate with their grades simply because
teachers' and students' perceptions of their TSRs are correlated. The
critical point is this: if a school assesses TSRs in such a way that the
associations between these relationships and outcomes are clear, they
will have a sharper understanding from which to develop interventions.
By contrast, aﬂawed TSR measure could encourage school leaders to
develop interventions for students when they really ought to be inter-
vening with their teachers (or vice-versa).
This manuscript introduces a measure of TSRs at the secondary level
designed to sharpen school leaders' understanding of these relationships"
2018 - Teacher-student relationships The positives and negatives of assessing both perspectives.pdf,"and how they relate to important student outcomes. With this measure,
we hope to provide schools with a tool and an approach to measuring
TSRs that facilitates their attempts to understand, and ultimately im-
prove these critical relationships.
1.1. Conceptualizing teacher-student relationships
Within the academic literature, TSRs are conceptualized (and
therefore measured) in diverse ways. Across this variety of con-
ceptualizations, they manifest robust associations with desirable stu-
dent outcomes. The studies reviewed in the meta-analyses ofCornelius-
White (2007) and Roorda et al. (2011) show that educational re-
searchers typically operationalize TSRs as speciﬁc facets of the re-
lationship (e.g., teacher support, holding high expectations for students,
fairness, and so forth) rather than assessing the overall relationship. See
Table 1 for some of the many ways these relationships are measured.
Past approaches also usually focus on the positive aspects of the re-
lationships (rather than the positive and negative). Finally, most
scholars focus on one perspective (the teacher's or the students' view of
the relationship, but rarely both). Despite the array of approaches, these
studies consistently ﬁnd robust associations with distinct academic,
aﬀective, behavioral, and motivational outcomes for students. Thus, for
the purposes of this article, these reviews (a) raise questions about how
to conceptualize these relationships, but (b) suggest that regardless of
which aspects are emphasized, TSRs tend to be associated with positive
student outcomes.
Our conceptual framework synthesizes key ideas from attachment
theory (e.g.,Hamre & Pianta, 2001and their focus on issues like conﬂict
and closeness), parent socialization (e.g.,Wentzel, 2002, and her focus
on control, maturity, democratic socialization, and nurturance), and
self-determination theory's emphasis on autonomy support, compe-
tency development, and relatedness (e.g., Skinner, Furrer,
Marchand, & Kindermann, 2008). In particular, our conceptualization
emphasizes these themes of conﬂict, closeness/relatedness, control,
autonomy support, and competence. We also supplement these foci
with social psychological theory.
Similar to the attachment perspective, we view secondary school
TSRs as dyadic social processes (Pianta, 1999) that involve ongoing
interactions between teachers and students in classrooms. These social
and learning interactions repeat and change continually based on
feedback. Inevitably, certain patterns are reinforced over time. From
this basic foundation, we add two elements (as shown inFig. 1).
First, we view TSRs as more than just interactions. After any given
exchange, each party might leave with divergent understandings of the
interaction. Thus, we borrow from social psychological theory on re-
lationships to include each party'sperceptions of one another and of
their interactions as key components of the relationships
(Clark & Lemay, 2010). As Gable, Reis, and Downey (2003) note,
“Patterns of interaction depend on the actions and reactions of both
partners, and their actions and reactions depend on each individual's
perceptions and interpretations of the other's behavior” (p. 100).
Second, it is important to note that students' and teachers' behaviors
and perceptions are stored in their respective memories. As Loftus'
(2003) research indicates, people's memories are far from immutable.
Thus, teachers' and students' memories of their interactions may change
over time. These revised memories might aﬀect their respective per-
ceptions, in turn aﬀecting their future interactions.
In sum, we deﬁne TSRs as teachers' and students' aggregated and
ongoing perceptions of one another, aﬀect towards each other, and
interactions over time; these perceptions are stored in memory and
guide
future interactions with the other party. Although the overall
classroom climate or teachers' and students' individual personalities
may inﬂuence TSRs, these constructs are distinct from TSRs.
1.2. Operationalizing a measure of teacher-student relationships
In translating this conceptualization of TSRs into a measure that
proves useful for schools, we faced three key challenges. First, as noted
above, these relationships comprised a myriad of factors. Past studies
have operationalized TSRs in very diﬀerent ways— teacher suppor-
tiveness (Goodenow, 1993), having high expectations of students
(Wentzel, 2002), teacher disinterest/criticism (Murdock, 1999), teacher
caring (Gregory & Weinstein, 2008), and so on. How should school
leaders think about TSRs— is it some of these? All of them?
We anticipate that most school leaders will want to think about
these relationships as a whole— in other words, by assessing theoverall
relationship. While the aphorism that“the whole is greater than the
sum of its parts” may be overused, it is almost certainly true in the case
of TSRs. Because strengths in certain areas of a TSR may compensate for
weaknesses in other areas, looking at speciﬁc aspects of TSRs might be
more misleading for school leaders than assessing the overall re-
lationship. Moreover, while researchers may conduct focused, in-depth
studies asking a multitude of questions about a narrow aspect of a TSR,
few schools have that luxury. School assessment systems must cover
numerous topics. Thus, unlike many past approaches, we examine the
overall TSR by assessing a cross-section of key characteristics of TSRs
within a single scale.
A second challenge is ascertaining whose perception of TSRs is of
interest. TSRs are two-way streets; teachers and students construct
these relationships together. Thus, members of the TSR dyad make up a
‘relational unit’ that may not be fully understood by tapping the per-
spective of a single party. Simply because a student reports liking a
teacher, does not necessitate that those feelings are reciprocated. Most
past scholarship takes this view theoretically. However, when it comes
time to measure TSRs few studies account for both perspectives:
“Missing from the literature is a description of the same child-teacher
relationship from its two participants,” (Pianta, Hamre, & Stuhlman,
2003, p. 218). Thus, our measure of TSRs incorporates both teachers'
and students' perceptions.
A third challenge to assessing TSRs is that these relationships may
be positive, negative, neither, or both. Simply because a relationship is
very positive in some ways does not preclude the possibility that it may
be very negative in other ways. A teacher may simultaneously feel
strong positive and negative feelings towards a particular student.
Furthermore, a student who does not feel particularly positively to-
wards a teacher may or may not feel strong antipathy towards that
teacher. In the study of attitudes, we know that theoretical opposites
are not always neatly arrayed along a single continuum once the data
are examined (Cacioppo & Berntson, 1994). We might reasonably ex-
pect the same of teachers' and students' attitudes towards one another.
Thus, our measure allows for separate positivity and negativity di-
mensions.
In sum, we developed scale items with the goal of assessing TSRs
holistically, from both teachers' and students' perspectives, and while
accounting for the positive and negative aspects of TSRs independently.
Although other measures, such asPianta's (2001)Student-Teacher Re-
lationship Scale, examine positive and negative aspects of TSRs (e.g.,
closeness and conﬂict), they do not attempt to capture the overall re-
lationship (for example, the academic side of the relationship, respect,
and encouragement, are not addressed). Thus, although other scales
may have some of the same features as ours, we believe this scale would
be theﬁrst at the secondary school level to assess (1) the positive and
negative
sides of TSRs, (2) the overall relationship, and (3) both tea-
chers' and students' perspectives.
With these features in mind, we take three main steps to evaluate
whether this approach to measuring TSRs at the secondary level makes
a useful (rather than merely novel) contribution to science and practice.
Because our scale design process (Gehlbach & Brinkworth, 2011)i s
unique in its approach to building a case for validity from the outset, we
ﬁrst detail this process in the hopes that it contributes to the dialogue
M.E. Brinkworth et al. Journal of Applied Developmental Psychology 55 (2018) 24–38
25","and how they relate to important student outcomes. With this measure,
we hope to provide schools with a tool and an approach to measuring
TSRs that facilitates their attempts to understand, and ultimately im-
prove these critical relationships.
1.  1. Conceptualizing teacher-student relationships
Within the academic literature, TSRs are conceptualized (and
therefore measured) in diverse ways. Across this variety of con-
ceptualizations, they manifest robust associations with desirable stu-
dent outcomes. The studies reviewed in the meta-analyses ofCornelius-
White (2007) and Roorda et al. (2011) show that educational re-
searchers typically operationalize TSRs as speciﬁc facets of the re-
lationship (e.g., teacher support, holding high expectations for students,
fairness, and so forth) rather than assessing the overall relationship. See
Table 1 for some of the many ways these relationships are measured.
Past approaches also usually focus on the positive aspects of the re-
lationships (rather than the positive and negative). Finally, most
scholars focus on one perspective (the teacher's or the students' view of
the relationship, but rarely both). Despite the array of approaches, these
studies consistently ﬁnd robust associations with distinct academic,
aﬀective, behavioral, and motivational outcomes for students. Thus, for
the purposes of this article, these reviews (a) raise questions about how
to conceptualize these relationships, but (b) suggest that regardless of
which aspects are emphasized, TSRs tend to be associated with positive
student outcomes.
Our conceptual framework synthesizes key ideas from attachment
theory (e.g.,Hamre & Pianta, 2001and their focus on issues like conﬂict
and closeness), parent socialization (e.g.,Wentzel, 2002, and her focus
on control, maturity, democratic socialization, and nurturance), and
self-determination theory's emphasis on autonomy support, compe-
tency development, and relatedness (e.g., Skinner, Furrer,
Marchand, & Kindermann, 2008). In particular, our conceptualization
emphasizes these themes of conﬂict, closeness/relatedness, control,
autonomy support, and competence. We also supplement these foci
with social psychological theory.
Similar to the attachment perspective, we view secondary school
TSRs as dyadic social processes (Pianta, 1999) that involve ongoing
interactions between teachers and students in classrooms. These social
and learning interactions repeat and change continually based on
feedback. Inevitably, certain patterns are reinforced over time. From
this basic foundation, we add two elements (as shown inFig. 1).
First, we view TSRs as more than just interactions. After any given
exchange, each party might leave with divergent understandings of the
interaction. Thus, we borrow from social psychological theory on re-
lationships to include each party'sperceptions of one another and of
their interactions as key components of the relationships
(Clark & Lemay, 2010). As Gable, Reis, and Downey (2003) note,
“Patterns of interaction depend on the actions and reactions of both
partners, and their actions and reactions depend on each individual's
perceptions and interpretations of the other's behavior” (p. 100).
Second, it is important to note that students' and teachers' behaviors
and perceptions are stored in their respective memories. As Loftus'
(2003) research indicates, people's memories are far from immutable.
Thus, teachers' and students' memories of their interactions may change
over time. These revised memories might aﬀect their respective per-
ceptions, in turn aﬀecting their future interactions.
In sum, we deﬁne TSRs as teachers' and students' aggregated and
ongoing perceptions of one another, aﬀect towards each other, and
interactions over time; these perceptions are stored in memory and
guide
future interactions with the other party. Although the overall
classroom climate or teachers' and students' individual personalities
may inﬂuence TSRs, these constructs are distinct from TSRs.
1.  2. Operationalizing a measure of teacher-student relationships
In translating this conceptualization of TSRs into a measure that
proves useful for schools, we faced three key challenges. First, as noted
above, these relationships comprised a myriad of factors. Past studies
have operationalized TSRs in very diﬀerent ways— teacher suppor-
tiveness (Goodenow, 1993), having high expectations of students
(Wentzel, 2002), teacher disinterest/criticism (Murdock, 1999), teacher
caring (Gregory & Weinstein, 2008), and so on. How should school
leaders think about TSRs— is it some of these? All of them?
We anticipate that most school leaders will want to think about
these relationships as a whole— in other words, by assessing theoverall
relationship. While the aphorism that“the whole is greater than the
sum of its parts” may be overused, it is almost certainly true in the case
of TSRs. Because strengths in certain areas of a TSR may compensate for
weaknesses in other areas, looking at speciﬁc aspects of TSRs might be
more misleading for school leaders than assessing the overall re-
lationship. Moreover, while researchers may conduct focused, in-depth
studies asking a multitude of questions about a narrow aspect of a TSR,
few schools have that luxury. School assessment systems must cover
numerous topics. Thus, unlike many past approaches, we examine the
overall TSR by assessing a cross-section of key characteristics of TSRs
within a single scale.
A second challenge is ascertaining whose perception of TSRs is of
interest. TSRs are two-way streets; teachers and students construct
these relationships together. Thus, members of the TSR dyad make up a
‘relational unit’ that may not be fully understood by tapping the per-
spective of a single party. Simply because a student reports liking a
teacher, does not necessitate that those feelings are reciprocated. Most
past scholarship takes this view theoretically. However, when it comes
time to measure TSRs few studies account for both perspectives:
“Missing from the literature is a description of the same child-teacher
relationship from its two participants,” (Pianta, Hamre, & Stuhlman,
2003, p. 218). Thus, our measure of TSRs incorporates both teachers'
and students' perceptions.
A third challenge to assessing TSRs is that these relationships may
be positive, negative, neither, or both. Simply because a relationship is
very positive in some ways does not preclude the possibility that it may
be very negative in other ways. A teacher may simultaneously feel
strong positive and negative feelings towards a particular student.
Furthermore, a student who does not feel particularly positively to-
wards a teacher may or may not feel strong antipathy towards that
teacher. In the study of attitudes, we know that theoretical opposites
are not always neatly arrayed along a single continuum once the data
are examined (Cacioppo & Berntson, 1994). We might reasonably ex-
pect the same of teachers' and students' attitudes towards one another.
Thus, our measure allows for separate positivity and negativity di-
mensions.
In sum, we developed scale items with the goal of assessing TSRs
holistically, from both teachers' and students' perspectives, and while
accounting for the positive and negative aspects of TSRs independently.
Although other measures, such asPianta's (2001)Student-Teacher Re-
lationship Scale, examine positive and negative aspects of TSRs (e.g.,
closeness and conﬂict), they do not attempt to capture the overall re-
lationship (for example, the academic side of the relationship, respect,
and encouragement, are not addressed). Thus, although other scales
may have some of the same features as ours, we believe this scale would
be theﬁrst at the secondary school level to assess (1) the positive and
negative
sides of TSRs, (2) the overall relationship, and (3) both tea-
chers' and students' perspectives.
With these features in mind, we take three main steps to evaluate
whether this approach to measuring TSRs at the secondary level makes
a useful (rather than merely novel) contribution to science and practice.
Because our scale design process (Gehlbach & Brinkworth, 2011)i s
unique in its approach to building a case for validity from the outset, we
ﬁrst detail this process in the hopes that it contributes to the dialogue"
2018 - Teacher-student relationships The positives and negatives of assessing both perspectives.pdf,"Table 1
TSR indicators collected through the scale development process and illustrative preliminary TSR items.
Indicators Illustrative
From academic literature review (sample reference) From focus groups and interviews Synthesized list preliminary items
Teachers Students
Caring (Wentzel, 1997) Kindness Caring, kindness, approachability Caring, liking During class, how kind is this student/teacher when s/he talks to you?
Communication (Johnson, 2008) Being clear and direct, listening Positive and clear
communication
During class, how often does this student talk when you are talking (for
instance, when this student is supposed to be listening)?/During class, how
often do you talk when this teacher is talking (i.e., when you are supposed
to be listening)?
Conﬂict (Ang, 2005) Conﬂict Conﬂict Anger/conﬂict What percentage of the time do you feel upset when you interact with this
student?/What percentage of the time does this teacher seem to be upset
when you interact with him/her?
Criticism (Murdock, Anderman, & Hodge, 2000) Talking back Criticism Disrespect, oﬀensive, causes
discomfort
How many times do you make this student feel upset in an average week?/
How many times does this teacher make you feel upset in an average
week?
Democratic Interactions/Regard for Adolescent
Perspective (Hamre & Pianta, 2006; Wentzel, 2002)
Student engagement Interest in student opinions and
concerns, enjoying students
Engaging with student
opinions
In the past week, how many times has this student spoken with you about
something unrelated to class?
Expectations (Muller, 2001; Murdock, 1999) Reasonable expectations
for teachers
Teacher's belief in students' abilities Expectations How reasonable are this student's/teacher's expectations of you?
Fairness/Equity (Murdock, 1999) Fairness, not favoring speciﬁc students,
reasonable use of authority/power
Fairness How unfair are the grades that you give this student in this class?/How
unfair are the grades this teacher gives you in this class?
Instructional Support (Garza, 2009) Student responsiveness Patience, availability, teacher
responsiveness
Instructional support,
learning
How patient is this student/teacher when s/he listens to you?
Motivation (Martin & Dowson, 2009) Interest in subject matter Enthusiasm, encouragement Motivation, encouragement How motivating is it to work with this student/teacher in class?
Respect (Johnson, 2008; Wentzel, 2002) Respect Respect Respect During class, how respectful is this student/teacher towards you?
Trust (Roeser et al., 1996) Trust, honesty Trust, consistency Trust/admiration How trustworthy is this student/teacher?
Sense of humor Sense of humor, teasing, mocking Humor How often does this student's/teacher's humor bother you?
Warmth (Murray & Pianta, 2007) Friendliness Friendliness Friendliness How friendly is this student/teacher towards you?
M.E. Brinkworth et al. Journal of Applied Developmental Psychology 55 (2018) 24–38
26","Table 1
TSR indicators collected through the scale development process and illustrative preliminary TSR items.
Indicators Illustrative
From academic literature review From focus groups and interviews Synthesized list preliminary items
Teachers Students
Caring Kindness Caring, kindness, approachability Caring, liking During class, how kind is this student/teacher when s/he talks to you?
Communication Being clear and direct, listening Positive and clear
communication
During class, how often does this student talk when you are talking (for
instance, when this student is supposed to be listening)?/During class, how
often do you talk when this teacher is talking (i.e., when you are supposed
to be listening)?
Conﬂict Conﬂict Conﬂict Anger/conﬂict What percentage of the time do you feel upset when you interact with this
student?/What percentage of the time does this teacher seem to be upset
when you interact with him/her?
Criticism Talking back Criticism Disrespect, oﬀensive, causes
discomfort
How many times do you make this student feel upset in an average week?/
How many times does this teacher make you feel upset in an average
week?
Democratic Interactions/Regard for Adolescent
Perspective
Student engagement Interest in student opinions and
concerns, enjoying students
Engaging with student
opinions
In the past week, how many times has this student spoken with you about
something unrelated to class?
Expectations Reasonable expectations
for teachers
Teacher's belief in students' abilities Expectations How reasonable are this student's/teacher's expectations of you?
Fairness/Equity Fairness, not favoring speciﬁc students,
reasonable use of authority/power
Fairness How unfair are the grades that you give this student in this class?/How
unfair are the grades this teacher gives you in this class?
Instructional Support Student responsiveness Patience, availability, teacher
responsiveness
Instructional support,
learning
How patient is this student/teacher when s/he listens to you?
Motivation Interest in subject matter Enthusiasm, encouragement Motivation, encouragement How motivating is it to work with this student/teacher in class?
Respect Respect Respect Respect During class, how respectful is this student/teacher towards you?
Trust Trust, honesty Trust, consistency Trust/admiration How trustworthy is this student/teacher?
Sense of humor Sense of humor, teasing, mocking Humor How often does this student's/teacher's humor bother you?
Warmth Friendliness Friendliness Friendliness How friendly is this student/teacher towards you?"
2018 - Teacher-student relationships The positives and negatives of assessing both perspectives.pdf,"around how to best assess psychological constructs (DeVellis, 2003).
Second, after describing our participants, measures, and survey
administration procedures, we tackle the question of whether the scale
shows promising evidence of validity. In particular, we ask: (1) Which
factor structure bestﬁts our data? (2) how reliable are the diﬀerent sub-
scales? (3) how much evidence of measurement invariance over dif-
ferent levels of schooling do weﬁnd? and, (4) to what extent can we
replicate robustﬁndings from past research?
Third, because a new scale might show strong evidence of validity
without contributing any new insights into how TSRs functioned, we
contrasted two approaches to measuring TSRs. In one approach, we
predicted a set of student outcomes using a full model which used two
TSR subscales from teachers and two from students. We compared this
approach against a reduced model that served as a proxy for how many
studies typically approach the measurement of TSRs at the secondary
level (i.e., only assessing TSR-positivity from students' perspectives).
The comparison allowed us to ask: (5) Is students' TSR-positivity posi-
tively and signiﬁcantly associated with all 8 outcomes in the“reduced”
model? (6) does a“full” model that includes all four TSR sub-scales
explain signiﬁcantly more variability in the eight outcomes than the
reduced model?, and (7) to what extent do the patterns of associations
between students' TSR-positivity and each outcome diﬀer between the
reduced and full models?
1.3. Scale development process
In addition to addressing these challenges, we hoped to imbue our
TSR scales with other attributes as well. To optimize its utility for
school assessment systems, we wanted to keep the scale short. Length
seemed particularly critical because we assumed teachers would fre-
quently need to complete the survey for multiple students. Because we
hoped it could assess TSRs longitudinally, the scale needed to work for
middle and high school students alike. Furthermore, the language
needed to be simple enough for 6th graders without patronizing tea-
chers. To address all these constraints, and to try to enhance the mea-
sure's validity from the outset of the design process, we followed the
survey design process detailed byGehlbach and Brinkworth (2011):
 Step 1— Literature review: We reviewed relevant literature to un-
derstand the range of conceptualizations and operationalizations of
TSRs as described above. This review shaped our deﬁnition, iden-
tiﬁed the key characteristics of TSRs, and helped us amass potential
items for consideration.
 Step 2— Interviews and focus groups: Second, we conducted open-
ended interviews and focus groups with prospective respondents to
learn how they conceptualized and understood TSRs. In this way, we
obtained a critical“second opinion” on which indicators were cen-
tral to our construct.
 Step 3— Synthesizing a list of indicators: Third, we compared re-
sponses from these interviews and focus groups against our litera-
ture review to determine points of overlap, divergence, and dis-
parities in terminology. By the end of this step, we had a synthesized
list of indicators from previous literature as well as from teachers
and students that represented the key ingredients of TSRs in sec-
ondary schools (seeTable 1).
 Step 4— Developing items: Fourth, we converted our indicators into
survey items in accordance with the best practices in survey design
(Dillman, Smyth, & Christian, 2014). All too often schools end up
using measures that increase measurement error by asking state-
ments rather than questions, using reverse-scored items, and com-
mitting other“survey sins” (Gehlbach, 2015).
 Step 5— Expert review: Fifth, to ensure that the items still mirrored
our conceptualization of TSRs, to conﬁrm that we had not over-
looked any crucial indicators, and to obtain additional evidence of
construct validity (Messick, 1995), we subjected our items to an
expert review. Twenty TSR experts assessed each item of the teacher
TSR scale and twenty others focused on the student scales, de-
pending on their expertise (McKenzie, Wood, Kotecki, Clark, & Brey,
1999; Rubio, Berg-Weger, Tebb, Lee, & Rauch, 2003).
 Step 6— Cognitive pre-testing: Sixth, we employed a cognitive pre-
testing, or “think-aloud,” procedure to see whether respondents
comprehended each item as we intended and to ensure that each
item triggered appropriate recollections as participants formulated
responses.
After completion of the cognitive pre-testing phase, we conducted a
Dyadic interactions
Teacher Student
PerceptionsMemories
Teacher TeacherStudent Student
Time
Fig. 1.A model of teacher-student relationships.
M.E. Brinkworth et al. Journal of Applied Developmental Psychology 55 (2018) 24–38
27","Second, after describing our participants, measures, and survey
administration procedures, we tackle the question of whether the scale
shows promising evidence of validity. In particular, we ask: (1) Which
factor structure bestﬁts our data? (2) how reliable are the diﬀerent sub-
scales? (3) how much evidence of measurement invariance over dif-
ferent levels of schooling do weﬁnd? and, (4) to what extent can we
replicate robustﬁndings from past research?
Third, because a new scale might show strong evidence of validity
without contributing any new insights into how TSRs functioned, we
contrasted two approaches to measuring TSRs. In one approach, we
predicted a set of student outcomes using a full model which used two
TSR subscales from teachers and two from students. We compared this
approach against a reduced model that served as a proxy for how many
studies typically approach the measurement of TSRs at the secondary
level (i.e., only assessing TSR-positivity from students' perspectives).
The comparison allowed us to ask: (5) Is students' TSR-positivity posi-
tively and signiﬁcantly associated with all 8 outcomes in the“reduced”
model? (6) does a“full” model that includes all four TSR sub-scales
explain signiﬁcantly more variability in the eight outcomes than the
reduced model?, and (7) to what extent do the patterns of associations
between students' TSR-positivity and each outcome diﬀer between the
reduced and full models?
1.3. Scale development process
In addition to addressing these challenges, we hoped to imbue our
TSR scales with other attributes as well. To optimize its utility for
school assessment systems, we wanted to keep the scale short. Length
seemed particularly critical because we assumed teachers would fre-
quently need to complete the survey for multiple students. Because we
hoped it could assess TSRs longitudinally, the scale needed to work for
middle and high school students alike. Furthermore, the language
needed to be simple enough for 6th graders without patronizing tea-
chers. To address all these constraints, and to try to enhance the mea-
sure's validity from the outset of the design process, we followed the
survey design process detailed byGehlbach and Brinkworth (2011):
 Step 1— Literature review: We reviewed relevant literature to un-
derstand the range of conceptualizations and operationalizations of
TSRs as described above. This review shaped our deﬁnition, iden-
tiﬁed the key characteristics of TSRs, and helped us amass potential
items for consideration.
 Step 2— Interviews and focus groups: Second, we conducted open-
ended interviews and focus groups with prospective respondents to
learn how they conceptualized and understood TSRs. In this way, we
obtained a critical“second opinion” on which indicators were cen-
tral to our construct.
 Step 3— Synthesizing a list of indicators: Third, we compared re-
sponses from these interviews and focus groups against our litera-
ture review to determine points of overlap, divergence, and dis-
parities in terminology. By the end of this step, we had a synthesized
list of indicators from previous literature as well as from teachers
and students that represented the key ingredients of TSRs in sec-
ondary schools (seeTable 1).
 Step 4— Developing items: Fourth, we converted our indicators into
survey items in accordance with the best practices in survey design
(Dillman, Smyth, & Christian, 2014). All too often schools end up
using measures that increase measurement error by asking state-
ments rather than questions, using reverse-scored items, and com-
mitting other“survey sins” (Gehlbach, 2015).
 Step 5— Expert review: Fifth, to ensure that the items still mirrored
our conceptualization of TSRs, to conﬁrm that we had not over-
looked any crucial indicators, and to obtain additional evidence of
construct validity (Messick, 1995), we subjected our items to an
expert review. Twenty TSR experts assessed each item of the teacher
TSR scale and twenty others focused on the student scales, de-
pending on their expertise (McKenzie, Wood, Kotecki, Clark, & Brey,
1999; Rubio, Berg-Weger, Tebb, Lee, & Rauch, 2003).
 Step 6— Cognitive pre-testing: Sixth, we employed a cognitive pre-
testing, or “think-aloud,” procedure to see whether respondents
comprehended each item as we intended and to ensure that each
item triggered appropriate recollections as participants formulated
responses.
After completion of the cognitive pre-testing phase, we conducted a
Dyadic interactions"
2018 - Teacher-student relationships The positives and negatives of assessing both perspectives.pdf,"series of small-scale pilot tests of the measure in which we administered
the items to students and teachers in their classrooms. Based on these
results, we made minor additional changes.
By addressing certain aspects of content validity such as construct
relevance (e.g., Steps 1–3), representativeness (e.g., Step 5), and tech-
nical quality (e.g., Steps 4 and 6) as well as substantive validity (e.g.,
Steps 5 and 6) into the design process (Messick, 1995), we viewed our
scale as having good preliminary evidence of validity. However, as-
sessing the validity of a new measure is an ongoing process (Gehlbach,
2015; Messick, 1995); thus, we hoped to accumulate additional in-
dicators of other types of validity. For instance, a key question re-
mained around the scale's structural validity— do the positive and ne-
gative aspects of TSRs require separate sub-scales or will our positive
and negative indicators load onto one factor? Relatedly, we sought
evidence that the scale was internally consistent. Because we wanted
the measure to be useful for longitudinal research we hoped to show
aspects of measurement invariance between middle and high school
students. Finally, we hoped to replicate some basicﬁndings from pre-
vious studies to show that the measure functioned in ways that were
congruent with prior research.
2. Methods
To obtain data that would simultaneously provide evidence for our
scale's construct validity, predictive validity, and practical utility for
educators, we administered the TSR scale to students and teachers at
four secondary schools in the northeastern United States and collected
an array of student outcomes. At each site, we assigned each student to
report on one of their teachers. Except for School 3 (where all students
reported on their English teacher), we selected these teachers ran-
domly. Speciﬁcally, we identiﬁed all of the participating teachers on
each student's schedule and randomly selected one teacher for that
student to report on. Teachers subsequently reported on each student
who had reported on them. Thus, in our analyses students are nested
within only one teacher at each school.
2.1. Participants
Five-hundred and ninety-ﬁve students and 88 teachers from four
diﬀerent participating schools volunteered to participate in the study.
In the hopes of getting approximately 500 students so that we might
have suﬃcient statistical power and examine some important sub-
groups of interest, we chose a diverse array of schools for our
study— see the summary demographic characteristics of each institu-
tion and the overall sample inTable 2. Teachers in our sample re-
presented 12 subject areas, including: Art, Biblical Studies, Computer
Science, Economics, English, Math, Music, Physical Education, Science,
History/Social Studies, Foreign Language, and Technology. Many
students sampled had the same teacher. The number of students nested
within teacher varied widely (from 1 to 78,M= 6.76, SD = 10.69,
median = 4).
At each school, we computed a total participation rate
1 (Hoynoski,
Link, & Frankel, 2009). In other words, we calculated the fraction of
students who participated out of the entire student body at each school.
Participation rates were 69% (School 1), 23% (School 2), 67% (School
3), and 42% (School 4). In terms of racial composition, the students in
our sample appeared to be generally representative of their larger
student bodies. The percentages of White students in our samples versus
their respective school populations were as follows: 38% versus 34%
(School 1), 61% versus 71% (School 2), 5% versus 6% (School 3), and
9% versus 8% (School 4). In those instances where the percentages in
our sample diﬀered markedly from the larger school population (e.g., in
School 3 our sample reported as 28% Black/African American whereas
the school reports a 53% Black population), it was primarily due to our
participants choosing more speciﬁc categories (e.g., students writing in
“Haitian” in the “other” category). For teachers, we calculated parti-
cipation rates as the fraction who participated out of all the teachers at
each school. These rates were 83% (School 1), 67% (School 2), 19%
(School 3— where we worked exclusively with all the teachers in the
English department), and 74% (School 4).
2.2. Measures
In addition to having students and teachers complete our new TSRs
measure, we also collected several student outcomes of interest with the
goal of representing commonly studied variables across several im-
portant domains: academic, aﬀect, behavior, and motivation. Due to
diﬀerent time constraints and our eﬀorts to tailor results to the interests
of the schools, we collected slightly diﬀerent measures at each school
(see Appendix Bfor complete details on the exact measures used at each
school). For both teachers and students, we also collected basic de-
mographic data (gender, race, age, grade-level, primary language
spoken at home, and parents' educational level).
2.2.1. Teacher-student relationships
In each school, students and teachers completed parallel versions of
our TSR measures (seeAppendix Afor the student and teacher versions
of each subscale). Because the validity of this measure is of central
interest, we describe the psychometric properties of these scales in the
ﬁrst part of theResults section.
Table 2
Student and teacher participants for each school and for the total sample.
School 1 School 2 School 3 School 4 Total
School description Private, Christian, urban,
6th–12th grades
Public, suburban, 6th– 8th
grades
Private, Catholic, urban,
9th–12th grades
Military/vocational, urban,
9th–12th grades
Survey mode Paper and pencil Paper and pencil Web Paper and pencil
Student participants ( n = 144) ( n = 118) ( n = 198) ( n = 135) ( N = 595)
55% Female 50% Female 57% Female 53% Female 55% Female
19% Asian 1% Asian 2% Asian 0% Asian 5% Asian
17% Black 3% Black 28% Black 64% Black 29% Black
10% Hispanic 10% Hispanic 46% Hispanic 10% Hispanic 22% Hispanic
38% White 58% White 5% White 9% White 24% White
16% Other 28% Other 19% Other 17% Other 20% Other
Teacher participants ( n = 25) ( n = 31) ( n =4 ) ( n = 28) ( N = 88)
56% Female 65% Female 50% Female 61% Female 60% Female
86% White
1 We preferred total participation rate to response rate because the latter fails to ac-
count for portions of the sampling frame that were omitted (e.g., students who were
absent on the day that the consent forms were sent home).
M.E. Brinkworth et al.
Journal of Applied Developmental Psychology 55 (2018) 24–38
28","series of small-scale pilot tests of the measure in which we administered
the items to students and teachers in their classrooms. Based on these
results, we made minor additional changes.
By addressing certain aspects of content validity such as construct
relevance (e.g., Steps 1–3), representativeness (e.g., Step 5), and tech-
nical quality (e.g., Steps 4 and 6) as well as substantive validity (e.g.,
Steps 5 and 6) into the design process (Messick, 1995), we viewed our
scale as having good preliminary evidence of validity. However, as-
sessing the validity of a new measure is an ongoing process (Gehlbach,
2015; Messick, 1995); thus, we hoped to accumulate additional in-
dicators of other types of validity. For instance, a key question re-
mained around the scale's structural validity— do the positive and ne-
gative aspects of TSRs require separate sub-scales or will our positive
and negative indicators load onto one factor? Relatedly, we sought
evidence that the scale was internally consistent. Because we wanted
the measure to be useful for longitudinal research we hoped to show
aspects of measurement invariance between middle and high school
students. Finally, we hoped to replicate some basicﬁndings from pre-
vious studies to show that the measure functioned in ways that were
congruent with prior research.
2. Methods
To obtain data that would simultaneously provide evidence for our
scale's construct validity, predictive validity, and practical utility for
educators, we administered the TSR scale to students and teachers at
four secondary schools in the northeastern United States and collected
an array of student outcomes. At each site, we assigned each student to
report on one of their teachers. Except for School 3 (where all students
reported on their English teacher), we selected these teachers ran-
domly. Speciﬁcally, we identiﬁed all of the participating teachers on
each student's schedule and randomly selected one teacher for that
student to report on. Teachers subsequently reported on each student
who had reported on them. Thus, in our analyses students are nested
within only one teacher at each school.
2.1. Participants
Five-hundred and ninety-ﬁve students and 88 teachers from four
diﬀerent participating schools volunteered to participate in the study.
In the hopes of getting approximately 500 students so that we might
have suﬃcient statistical power and examine some important sub-
groups of interest, we chose a diverse array of schools for our
study— see the summary demographic characteristics of each institu-
tion and the overall sample inTable 2. Teachers in our sample re-
presented 12 subject areas, including: Art, Biblical Studies, Computer
Science, Economics, English, Math, Music, Physical Education, Science,
History/Social Studies, Foreign Language, and Technology. Many
students sampled had the same teacher. The number of students nested
within teacher varied widely (from 1 to 78,M= 6.76, SD = 10.69,
median = 4).
At each school, we computed a total participation rate
1 (Hoynoski,
Link, & Frankel, 2009). In other words, we calculated the fraction of
students who participated out of the entire student body at each school.
Participation rates were 69% (School 1), 23% (School 2), 67% (School
3), and 42% (School 4). In terms of racial composition, the students in
our sample appeared to be generally representative of their larger
student bodies. The percentages of White students in our samples versus
their respective school populations were as follows: 38% versus 34%
(School 1), 61% versus 71% (School 2), 5% versus 6% (School 3), and
9% versus 8% (School 4). In those instances where the percentages in
our sample diﬀered markedly from the larger school population (e.g., in
School 3 our sample reported as 28% Black/African American whereas
the school reports a 53% Black population), it was primarily due to our
participants choosing more speciﬁc categories (e.g., students writing in
“Haitian” in the “other” category). For teachers, we calculated parti-
cipation rates as the fraction who participated out of all the teachers at
each school. These rates were 83% (School 1), 67% (School 2), 19%
(School 3— where we worked exclusively with all the teachers in the
English department), and 74% (School 4).
2.2. Measures
In addition to having students and teachers complete our new TSRs
measure, we also collected several student outcomes of interest with the
goal of representing commonly studied variables across several im-
portant domains: academic, aﬀect, behavior, and motivation. Due to
diﬀerent time constraints and our eﬀorts to tailor results to the interests
of the schools, we collected slightly diﬀerent measures at each school
(see Appendix Bfor complete details on the exact measures used at each
school). For both teachers and students, we also collected basic de-
mographic data (gender, race, age, grade-level, primary language
spoken at home, and parents' educational level).
2.2.1. Teacher-student relationships
In each school, students and teachers completed parallel versions of
our TSR measures (seeAppendix Afor the student and teacher versions
of each subscale). Because the validity of this measure is of central
interest, we describe the psychometric properties of these scales in the
ﬁrst part of theResults section.
Table 2
Student and teacher participants for each school and for the total sample.
School 1 School 2 School 3 School 4 Total
School description Private, Christian, urban,
6th–12th grades
Public, suburban, 6th– 8th
grades
Private, Catholic, urban,
9th–12th grades
Military/vocational, urban,
9th–12th grades
Survey mode Paper and pencil Paper and pencil Web Paper and pencil
Student participants ( n = 144) ( n = 118) ( n = 198) ( n = 135) ( N = 595)
55% Female 50% Female 57% Female 53% Female 55% Female
19% Asian 1% Asian 2% Asian 0% Asian 5% Asian
17% Black 3% Black 28% Black 64% Black 29% Black
10% Hispanic 10% Hispanic 46% Hispanic 10% Hispanic 22% Hispanic
38% White 58% White 5% White 9% White 24% White
16% Other 28% Other 19% Other 17% Other 20% Other
Teacher participants ( n = 25) ( n = 31) ( n =4 ) ( n = 28) ( N = 88)
56% Female 65% Female 50% Female 61% Female 60% Female
86% White
1 We preferred total participation rate to response rate because the latter fails to ac-
count for portions of the sampling frame that were omitted (e.g., students who were
absent on the day that the consent forms were sent home)."
2018 - Teacher-student relationships The positives and negatives of assessing both perspectives.pdf,"2.2.2. Academic
We assessed academic outcomes through two measures. First, we
examined students' grade (using a 0–100 scale) in the class that they
had with the teacher of interest, i.e., their focal class. Second, after
teachers assessed students' class participation (see the “behavior”
measures below), they rated the contribution quality of those times
when the student participated.
2.2.3. Aﬀect
To measure students' overall aﬀect towards school, we assessed
their sense of belongingness at school. We borrowed the 4-item scale
used by Roeser, Midgley, and Urdan (1996)in which students' rated
statements such as“I feel like I matter in this school.” (α = 0.76). To
balance this global sense of how studentsﬁt in at their school, we also
investigated their level of interest in their subject matter (3 items,
α = 0.73) through items such as,“If you could choose to take any
classes you wanted to in high school, how many classes would you take
in this subject?” This measure was adapted from other surveys (Maehr,
1976; Midgley et al., 2000).
2.2.4. Behavior
To assess behaviors related to students' academic performance, we
collected two measures. First, teachers reported the percentage of
homework that students completed and, second, we asked for their
subjective impression of the frequency of students' class participation.
2.2.5. Motivation
As one measure of motivation in their focal classes, students re-
ported how much eﬀort they expended for class. This 5-item self-report
scale included items such as,“How much eﬀort do you put forth for this
class?” (α = 0.82). To assess students' self-eﬃcacy in the course with
their focal teacher, we adapted the scale used byGehlbach et al. (2008).
This 5-item scale assessed how conﬁdent students were with regard to
diﬀerent aspects of the course in question with items such as,“How
conﬁdent are you that you can learn all the material presented in this
class?” (α = 0.85).
2.3. Procedures
At each school, weﬁrst described the study to teachers to ensure
that most were willing to participate and obtained their consent ac-
cordingly. Next, we sent home consent forms for students and their
parents/guardians to sign, usually through students' homeroom tea-
cher. Once we conﬁrmed our participating students, we obtained stu-
dents' class schedules and then randomly selected a participating focal
teacher for each student (except at School 3). Based on the randomly
selected teacher, we then created individualized surveys for each stu-
dent (i.e., a survey that referenced the student and focal teacher by
name, as well as the speciﬁc class the student had with that teacher). A
member
of the research team administered the survey to students in
paper and pencil format or via the web; to ensure the conﬁdentiality of
student responses, no teachers were present during the administrations.
After receiving the student surveys, we sent each teacher a parallel form
of the survey to complete at their own convenience. This survey in-
cluded an individualized section for teachers to complete the TSR items
for each student who had reported on that teacher. Teachers were paid
$4 per student who they reported on and returned the surveys to us
within two weeks.
Data were collected during the fall at Schools 1 and 2 and in
January just before the end of theﬁrst semester at Schools 3 and 4. At
Schools 1 and 2, we also completed a follow-up data collection towards
the end of the school year which was used to compute test-retest re-
liability.
3. Results
We approached our analyses with two overarching goals in mind.
First, we hoped to provide additional evidence of the scale's validity
beyond what we established through our scale development process.
Second, we sought to examine whether our more intensive approach to
assessing TSRs provided useful information over and above typical (and
more straightforward) approaches to measuring this construct.
3.1. Scale validity results
In assessing additional evidence relevant to our scale's validity, we
focused on four questions: (1) Which factor structure bestﬁts our data?
(2) how reliable are the diﬀerent sub-scales? (3) how much evidence of
measurement invariance over diﬀerent levels of schooling do weﬁnd?
(4) to what extent can we replicate priorﬁndings such as the general
decline in the health of these relationships between lower and higher
grade levels (Eccles et al., 1993) or signs that teachers perceive more
positive relationships with their female students and more negative
relationships with their male students given diﬀerences in students'
behavior (Chun & Mobley, 2010).
3.1.1. Factor structureﬁndings
To examine whether a one- or two-factor model bestﬁt our data, we
employed conﬁrmatory factor analyses, using Mplus version 6— to ﬁta
model with latent TSR factors for teachers and for students simulta-
neously. Because the indicators for each latent variable (i.e., the TSR
items) were ordered-categorical variables, we employed the
CATEGORICAL option in Mplus. The conﬁrmatory factor analyses were
complicated by the fact that students were nested within teachers. To
account for the nesting in our data, we utilized theCLUSTER ISoption
to identify “teacher” as a grouping variable. Due to this complex
structure of our data, we relied on mean- and variance-adjusted
weighted least squares for complex survey data (WLSMV-complex) es-
timation and utilized the DIFF TEST function to compare the chi-
squared values of our nested models.WLSMV-complex, which uses a
variance correction procedure, accounts for the dependence between
the observations and provides corrected standard errors, conﬁdence
intervals, and coverage (Asparouhov, 2005). We used full information
maximum likelihood (FIML) to address missing data. Less than 2% of
responses were missing for any indicator, making the use of FIML ap-
propriate in this case.
In
testing a single factor model (model 1) and a TSR-positivity and
TSR-negativity model (model 2), we found that both models failed the
Chi-squared test of exact modelﬁt. However, usingﬁt indices (CFI and
RMSEA) that are better suited to larger sample sizes, we found that each
model provided a reasonableﬁt for our data (Kline, 2011). The chi-
square diﬀerence test (Δ in χ
2
(5df) = 194.22, p < 0.001), the diﬀer-
ences in CFI (0.96 versus 0.93), and the diﬀerences in RMSEA (0.044,
90% CI [0.039, 0.048] versus 0.058, 90% CI [0.053, 0.062]2) all in-
dicated that model 2 provided a betterﬁt than model 1. Furthermore,
although the estimated correlations between the latent positivity and
negativity factors (−0.75 and −0.66 for students and teachers, re-
spectively) are large, they are small enough to suggest the existence of
two distinct but related constructs. Finally, model 1 had far more re-
sidual correlations above 0.1— which may indicate problematic mis-
ﬁt— as compared to model 2. This is especially important in a factor
with many indicators where indices of overall modelﬁt, such as the
RMSEA and CFI, may hide severe local misﬁt. SeeFig. 2for the factor
loadings of ourﬁnal two-factor model.
2 We present 90% conﬁdence intervals for the RMSEA rather than 95% conﬁdence
intervals because guidelines for acceptable ranges of RMSEA values are typically given in
terms of 90% conﬁdence intervals. See, e.g.,Kline (2011), p. 206.
M.E. Brinkworth et al. Journal of Applied Developmental Psychology 55 (2018) 24–38
29","2.2.2. Academic
We assessed academic outcomes through two measures. First, we
examined students' grade (using a 0–100 scale) in the class that they
had with the teacher of interest, i.e., their focal class. Second, after
teachers assessed students' class participation (see the “behavior”
measures below), they rated the contribution quality of those times
when the student participated.
2.2.3. Aﬀect
To measure students' overall aﬀect towards school, we assessed
their sense of belongingness at school. We borrowed the 4-item scale
used by Roeser, Midgley, and Urdan (1996)in which students' rated
statements such as“I feel like I matter in this school.” (α = 0.76). To
balance this global sense of how studentsﬁt in at their school, we also
investigated their level of interest in their subject matter (3 items,
α = 0.73) through items such as,“If you could choose to take any
classes you wanted to in high school, how many classes would you take
in this subject?” This measure was adapted from other surveys (Maehr,
1976; Midgley et al., 2000).
2.2.4. Behavior
To assess behaviors related to students' academic performance, we
collected two measures. First, teachers reported the percentage of
homework that students completed and, second, we asked for their
subjective impression of the frequency of students' class participation.
2.2.5. Motivation
As one measure of motivation in their focal classes, students re-
ported how much eﬀort they expended for class. This 5-item self-report
scale included items such as,“How much eﬀort do you put forth for this
class?” (α = 0.82). To assess students' self-eﬃcacy in the course with
their focal teacher, we adapted the scale used byGehlbach et al. (2008).
This 5-item scale assessed how conﬁdent students were with regard to
diﬀerent aspects of the course in question with items such as,“How
conﬁdent are you that you can learn all the material presented in this
class?” (α = 0.85).
2.3. Procedures
At each school, weﬁrst described the study to teachers to ensure
that most were willing to participate and obtained their consent ac-
cordingly. Next, we sent home consent forms for students and their
parents/guardians to sign, usually through students' homeroom tea-
cher. Once we conﬁrmed our participating students, we obtained stu-
dents' class schedules and then randomly selected a participating focal
teacher for each student (except at School 3). Based on the randomly
selected teacher, we then created individualized surveys for each stu-
dent (i.e., a survey that referenced the student and focal teacher by
name, as well as the speciﬁc class the student had with that teacher). A
member
of the research team administered the survey to students in
paper and pencil format or via the web; to ensure the conﬁdentiality of
student responses, no teachers were present during the administrations.
After receiving the student surveys, we sent each teacher a parallel form
of the survey to complete at their own convenience. This survey in-
cluded an individualized section for teachers to complete the TSR items
for each student who had reported on that teacher. Teachers were paid
$4 per student who they reported on and returned the surveys to us
within two weeks.
Data were collected during the fall at Schools 1 and 2 and in
January just before the end of theﬁrst semester at Schools 3 and 4. At
Schools 1 and 2, we also completed a follow-up data collection towards
the end of the school year which was used to compute test-retest re-
liability.
3. Results
We approached our analyses with two overarching goals in mind.
First, we hoped to provide additional evidence of the scale's validity
beyond what we established through our scale development process.
Second, we sought to examine whether our more intensive approach to
assessing TSRs provided useful information over and above typical (and
more straightforward) approaches to measuring this construct.
3.1. Scale validity results
In assessing additional evidence relevant to our scale's validity, we
focused on four questions: (1) Which factor structure bestﬁts our data?
(2) how reliable are the diﬀerent sub-scales? (3) how much evidence of
measurement invariance over diﬀerent levels of schooling do weﬁnd?
(4) to what extent can we replicate priorﬁndings such as the general
decline in the health of these relationships between lower and higher
grade levels (Eccles et al., 1993) or signs that teachers perceive more
positive relationships with their female students and more negative
relationships with their male students given diﬀerences in students'
behavior (Chun & Mobley, 2010).
3.1.1. Factor structureﬁndings
To examine whether a one- or two-factor model bestﬁt our data, we
employed conﬁrmatory factor analyses, using Mplus version 6— to ﬁta
model with latent TSR factors for teachers and for students simulta-
neously. Because the indicators for each latent variable (i.e., the TSR
items) were ordered-categorical variables, we employed the
CATEGORICAL option in Mplus. The conﬁrmatory factor analyses were
complicated by the fact that students were nested within teachers. To
account for the nesting in our data, we utilized theCLUSTER ISoption
to identify “teacher” as a grouping variable. Due to this complex
structure of our data, we relied on mean- and variance-adjusted
weighted least squares for complex survey data (WLSMV-complex) es-
timation and utilized the DIFF TEST function to compare the chi-
squared values of our nested models.WLSMV-complex, which uses a
variance correction procedure, accounts for the dependence between
the observations and provides corrected standard errors, conﬁdence
intervals, and coverage (Asparouhov, 2005). We used full information
maximum likelihood (FIML) to address missing data. Less than 2% of
responses were missing for any indicator, making the use of FIML ap-
propriate in this case.
In
testing a single factor model (model 1) and a TSR-positivity and
TSR-negativity model (model 2), we found that both models failed the
Chi-squared test of exact modelﬁt. However, usingﬁt indices (CFI and
RMSEA) that are better suited to larger sample sizes, we found that each
model provided a reasonableﬁt for our data (Kline, 2011). SeeFig. 2for the factor
loadings of ourﬁnal two-factor model."
2018 - Teacher-student relationships The positives and negatives of assessing both perspectives.pdf,"3.1.2. Reliability estimates
With the two factor model established as more appropriate, we then
estimated each sub-scale's reliability. For teachers, the coeﬃcient alpha
of the positivity and negativity sub-scale scores wereαs = 0.90, 95% CI
[0.89, 0.91] and 0.78, 95% CI [0.75, 0.81], respectively. For students,
these αs were 0.92, 95% CI [0.91, 0.93] and 0.78, 95% CI [0.75, 0.81],
respectively.3 We also used semTools ( Pornprasertmanit, Miller,
Schoemann, & Rosseel, 2013), a package in R (R Core Team, 2013)t o
compute omega (ω), an estimate of reliability calculated as the model-
implied variability in the indicators attributable to the underlying
factors divided by the total variability in the indicators. We found
ω = 0.91 and 0.86 for teachers andω = 0.94 and 0.86 for students on
the positivity and negativity subscales, respectively. Finally, we com-
puted test-retest correlations at two schools. We expect some real shift
in the relationships between teachers and students over the course of
the year, thus we view these estimates as lower bounds to the test-retest
reliability of our scales. Among teachers, we found the test-retest cor-
relations (unadjusted for nesting) for the positivity scale score was
r
(218) = 0.61, p < 0.001, 95% CI [0.52, 0.69]; meanwhile
r(218) = 0.60,p < 0.001, 95% CI [0.51, 0.68] for the negativity scale
score. For students, these test-retest correlations were r(230) = 0.55,
p < 0.001, 95% CI [0.45, 0.63]; andr(230) = 0.57,p < 0.001, 95% CI
[0.48, 0.65], respectively. We present full descriptive statistics and
correlations for each item of both subscales inTable 3.
TSR-
Positivity
TSR-
Negativity
P1
.80
P7
.57
P8
.75
P9
.60
P6
.51
P5
.76
P4
.63
P3
.48
P2
.67
N1
.45
N5
.61
N4
.67
N3
.74
N2
.28
.70 .61 .21 .75 .79 .54 .65 .65 .53 .96 .67 .56 .47 .67
-.66
-.75
Fig. 2.The amount of variance explained by the latent construct in each indicator of the TSR scale is denoted above each indicator for teachers (in red) and inside each indicator (in blue)
for students.
Table 3
Descriptive statistics and correlations for items in the Teacher-Student Relationship Scale– positivity & negativity sub-scales.
Ms d
P1 P2 P3 P4 P5 P6 P7 P8 P9
TSR 
Pos.
Scale
N1 N2 N3 N4 N5
TSR 
Neg.
Scale Ms d
P1 3.52 1.12 -- 0.53 0.30 0.58 0.71 0.51 0.50 0.63 0.54 0.79 -0.45 -0.38 -0.26 -0.23 -0.30 -0.47 4.04 0.74
P2 4.01 0.94 0.62 -- 0.46 0.45 0.49 0.43 0.70 0.58 0.42 0.77 -0.32 -0.19 -0.10 -0.07 -0.19 -0.26 3.76 0.91
P3 3.2 1.21 0.55 0.56 -- 0.19 0.27 0.31 0.43 0.32 0.26 0.53 -0.12 -0.12 0.00 -0.07 -0.03 -0.11 3.49 0.81
P4 4.16 0.89 0.51 0.65 0.45 -- 0.66 0.47 0.49 0.56 0.48 0.73 -0.62 -0.58 -0.40 -0.26 -0.44 -0.67 4.07 0.81
P5 3.04 1.42 0.75 0.54 0.52 0.47 -- 0.55 0.49 0.67 0.51 0.81 -0.56 -0.52 -0.26 -0.23 -0.35 -0.57 3.81 1.04
P6 3.13 1.11 0.64 0.47 0.45 0.41 0.59 -- 0.48 0.47 0.62 0.73 -0.43 -0.35 -0.31 -0.27 -0.36 -0.47 3.28 0.86
P7 3.48 1.05 0.55 0.62 0.59 0.56 0.55 0.50 -- 0.61 0.48 0.79 -0.37 -0.30 -0.15 -0.13 -0.20 -0.35 3.2 0.99
P8 3.47 1.19 0.72 0.62 0.52 0.50 0.73 0.57 0.61 -- 0.40 0.79 -0.42 -0.35 -0.19 -0.14 -0.24 -0.40 3.93 0.83
P9 3.85 1.05 0.69 0.47 0.43 0.49 0.60 0.57 0.49 0.59 -- 0.69 -0.33 -0.30 -0.31 -0.21 -0.37 -0.41 3.61 0.71
TSR 
Pos.
Scale 3.54 0.87 0.86 0.78 0.73 0.70 0.84 0.74 0.77 0.84 0.76 -- -0.55 -0.47 -0.29 -0.24 -0.37 -0.56 3.69 0.63
N1 2.14 1.04 -0.43 -0.30 -0.23 -0.31 -0.41 -0.36 -0.34 -0.39 -0.43 -0.46 -- 0.73 0.34 0.29 0.38 0.85 1.93 1.01
N2 2.31 1.15 -0.29 -0.18 -0.18 -0.21 -0.30 -0.20 -0.22 -0.29 -0.28 -0.31 0.49 -- 0.33 0.25 0.38 0.85 2.09 1.1
N3 1.4 0.85 -0.35 -0.47 -0.30 -0.56 -0.32 -0.33 -0.38 -0.38 -0.37 -0.48 0.37 0.23 -- 0.47 0.61 0.65 1.32 0.56
N4 1.58 0.95 -0.45 -0.46 -0.31 -0.45 -0.40 -0.35 -0.36 -0.45 -0.42 -0.51 0.40 0.32 0.54 -- 0.45 0.54 1.17 0.41
N5 1.62 0.98 -0.43 -0.39 -0.33 -0.39 -0.46 -0.38 -0.28 -0.45 -0.40 -0.50 0.40 0.35 0.46 0.60 -- 0.69 1.34 0.57
TSR 
Neg.
Scale 1.81 0.72 -0.53 -0.48 -0.36 -0.51 -0.52 -0.44 -0.43 -0.53 -0.52 -0.61 0.74 0.69 0.68 0.77 0.76 -- 1.57 0.55
Notes: Student scores are on the left and below the diagonal; teacher scores are on the right and above the diagonal. Bolded values represent composite means and standard deviations.
Shaded cells represent correlations involving the composite scores.
3 Here and elsewhere we report statistics which treat the indicators as interval-level
data. However, all of our models treat the indicators as ordinal. We believe it is more
sensible to regard the indicators as ordinal measures of the construct in question, but
acknowledge that most schools may prefer to treat them as interval, which is why we
present statistics such asα, and means and standard deviations of items and scale scores.
M.E. Brinkworth et al.
Journal of Applied Developmental Psychology 55 (2018) 24–38
30","3.1.2. Reliability estimates
With the two factor model established as more appropriate, we then
estimated each sub-scale's reliability. For teachers, the coeﬃcient alpha
of the positivity and negativity sub-scale scores wereαs = 0.90, 95% CI
[0.89, 0.91] and 0.78, 95% CI [0.75, 0.81], respectively. For students,
these αs were 0.92, 95% CI [0.91, 0.93] and 0.78, 95% CI [0.75, 0.81],
respectively. We also used semTools ( Pornprasertmanit, Miller,
Schoemann, & Rosseel, 2013), a package in R (R Core Team, 2013)t o
compute omega (ω), an estimate of reliability calculated as the model-
implied variability in the indicators attributable to the underlying
factors divided by the total variability in the indicators. We found
ω = 0.91 and 0.86 for teachers andω = 0.94 and 0.86 for students on
the positivity and negativity subscales, respectively. Finally, we com-
puted test-retest correlations at two schools. We expect some real shift
in the relationships between teachers and students over the course of
the year, thus we view these estimates as lower bounds to the test-retest
reliability of our scales. Among teachers, we found the test-retest cor-
relations (unadjusted for nesting) for the positivity scale score was
r
(218) = 0.61, p < 0.001, 95% CI [0.52, 0.69]; meanwhile
r(218) = 0.60,p < 0.001, 95% CI [0.51, 0.68] for the negativity scale
score. For students, these test-retest correlations were r(230) = 0.55,
p < 0.001, 95% CI [0.45, 0.63]; andr(230) = 0.57,p < 0.001, 95% CI
[0.48, 0.65], respectively. We present full descriptive statistics and
correlations for each item of both subscales inTable 3.

Table 3
Descriptive statistics and correlations for items in the Teacher-Student Relationship Scale– positivity & negativity sub-scales.

Notes: Student scores are on the left and below the diagonal; teacher scores are on the right and above the diagonal. Bolded values represent composite means and standard deviations.
Shaded cells represent correlations involving the composite scores.
3 Here and elsewhere we report statistics which treat the indicators as interval-level
data. However, all of our models treat the indicators as ordinal. We believe it is more
sensible to regard the indicators as ordinal measures of the construct in question, but
acknowledge that most schools may prefer to treat them as interval, which is why we
present statistics such asα, and means and standard deviations of items and scale scores."
2018 - Teacher-student relationships The positives and negatives of assessing both perspectives.pdf,"3.1.3. Measurement invariance
Next, we investigated whether students' scores for this two factor
model varied between the middle and high school students. Using a
weighted least squares estimator and theta parameterization, weﬁta n
unconstrained model in which thresholds and factor loadings were free
across middle school and high schools groups, residual variances were
ﬁxed at one in both groups and factor means wereﬁxed at zero in both
groups. The ﬁt statistics for this model were χ2[688] = 1123.028;
CFI = 0.961; RMSEA = 0.046; 90% CI [0.041, 0.051].
To test for invariance between groups, weﬁt a model in which
thresholds and factor loadings were constrained to be equal across
middle and high school groups, residual variances wereﬁxed at one and
factor means wereﬁxed at zero in the middle school group and free in
the high school group. Theﬁt indices for this model wereχ2[789]
= 1202.98; CFI = 0.963; RMSEA = 0.042; 90% CI [0.037, 0.047].
Using the DIFFTEST command in MPlus, the results of aχ2d iﬀerence
test between the unconstrained and constrained models were Δ in
χ2 = 125.77,Δ in df = 101,p = 0.05.
Testing for measurement invariance using signiﬁcance tests can
reveal statistically signiﬁcant but practically unimportant diﬀerences in
the measurement properties of a model, especially when the sample is
large. Therefore, we followed Cheung and Rensvold's (2002) re-
commendation to examine change in the model CFI caused by imposing
additional constraints, and to take decreases in the CFI of−0.01 or
greater as evidence of problematic non-invariance (seeChen, 2007for
an extension to models with ordinal indicators). When we imposed the
constraints, the modelﬁt improved from 0.961 to 0.963, indicating no
problematic misﬁt.
Finally, we examined the factor loadings from the constrained and
unconstrained models and found them to be extremely similar sug-
gesting once more that the measurement model is essentially the same
for middle school and high school students.
3.1.4. Scale properties and descriptive statistics
In seeking additional evidence of validity beyond the content, sub-
stantive, and structural aspects already described, we explored two
aspects of external construct validity (Messick, 1995). First, we tested
whether we would see the robust decline in perceived relationships
across grade levels documented by Eccles and her colleagues (Eccles
et al., 1993). To the extent that our scale shows a decrease in TSR-
positivity and or an increase in TSR-negativity with increasing grade
levels, it provides a signal that our measure is functioning in ways that
are congruent with past investigations. In addition, based on previous
ﬁndings that girls typically outperform boys academically
(Woolley & Grogan-Kaylor, 2006), we hypothesized that teachers would
perceive more positive relationships with their female students; based
on other ﬁndings from those studies showing that boys caused more
behavioral problems (Chun & Mobley, 2010),
 we expected that teachers
would perceive more negative relationships with boys.
To assess whether certain diﬀerences in TSRs emerged across par-
ticular subgroups of students, we ran a series of multi-level structural
equation models that nested students within teachers using the
CLUSTER ISoption and controlled for school throughﬁxed-eﬀects. With
respect to ourﬁrst hypothesis— that students in earlier grades would
perceive more positive TSRs than their peers in later grades— in Fig. 3,
we show the means for each grade at each school. Schools 1, 2, and 4
illustrate trends that are largely consistent with our hypothesis. (To
preserve the anonymity of the 4 teachers at School 3, we exclude this
school in theﬁgure). For an overall test of our hypothesis on our full
data set, we used a multi-level structural equation model to regress
students' TSR-positivity and negativity on students' grade level while
controlling for school. Results indicated that older students reported
lower levels of TSR-positivity (β = −0.23; SE =0.09; 95% CI [−0.41,
−0.04]; p = 0.02) than younger students. Though not signiﬁcant, the
diﬀerences on TSR-negativity suggested a similar trend ( β = 0.08;
SE =0.04; 95% CI [−0.003, 0.16];p = 0.06).
With respect to our second hypothesis— that teachers should feel
more positively towards their female students and more negatively
towards the boys in their classes— the results showed partial support of
our conjecture. Teachers' TSR-positivity ratings were not signiﬁcantly
diﬀerent for male and female students (β = −0.20; SE =0.14; 95% CI
[−0.48, 0.08]; p = 0.16), although the trend is in the direction we
expected. However, teachers rated their relationship with their male
students as more negative on the TSR-negativity scale ( β = 1.23;
SE =0.52; 95% CI [0.21, 2.26];p = 0.02).
3.2. Teacher-student relationships and student outcomes
Having developed our TSR scale and established multiple indicators
of validity, we then wanted to know if the scale was actually useful for
researchers and practitioners. In particular, with parallel versions for
teachers and students and with TSR-positivity and negativity subscales,
our instrument requires more eﬀort than a more traditional approach
such as simply asking students to complete a scale of their perceptions
of their teacher. Thus, we wanted evidence that our scale provided
compensatory explanatory power. We focused on three additional re-
search
questions all designed to help determine whether our approach
to measuring TSRs might provide an important complement to
1.00
1.50
2.00
2.50
3.00
3.50
4.00
4.50
5.00
6th 7th 8th 9th 10th 11th 12th
School 1-Positivity
School 2-Positivity
School 4-Positivity
School 1-Negativity
School 2-Negativity
School 4-Negativity
Fig. 3. Students' mean level TSR-positivity and TSR-negativity by
grade at schools 1, 2, and 4.
M.E. Brinkworth et al. Journal of Applied Developmental Psychology 55 (2018) 24–38
31","3.1.3. Measurement invariance
Next, we investigated whether students' scores for this two factor
model varied between the middle and high school students.
To test for invariance between groups, weﬁt a model in which
thresholds and factor loadings were constrained to be equal across
middle and high school groups, residual variances wereﬁxed at one and
factor means wereﬁxed at zero in the middle school group and free in
the high school group.
Using the DIFFTEST command in MPlus, the results of aχ2d iﬀerence
test between the unconstrained and constrained models were Δ in
χ2 = 125.77,Δ in df = 101,p = 0.05.
Testing for measurement invariance using signiﬁcance tests can
reveal statistically signiﬁcant but practically unimportant diﬀerences in
the measurement properties of a model, especially when the sample is
large. Therefore, we followed Cheung and Rensvold's (2002) re-
commendation to examine change in the model CFI caused by imposing
additional constraints, and to take decreases in the CFI of−0.01 or
greater as evidence of problematic non-invariance (seeChen, 2007for
an extension to models with ordinal indicators). When we imposed the
constraints, the modelﬁt improved from 0.961 to 0.963, indicating no
problematic misﬁt.
Finally, we examined the factor loadings from the constrained and
unconstrained models and found them to be extremely similar sug-
gesting once more that the measurement model is essentially the same
for middle school and high school students.
3.1.4. Scale properties and descriptive statistics
In seeking additional evidence of validity beyond the content, sub-
stantive, and structural aspects already described, we explored two
aspects of external construct validity (Messick, 1995). First, we tested
whether we would see the robust decline in perceived relationships
across grade levels documented by Eccles and her colleagues (Eccles
et al., 1993). To the extent that our scale shows a decrease in TSR-
positivity and or an increase in TSR-negativity with increasing grade
levels, it provides a signal that our measure is functioning in ways that
are congruent with past investigations. In addition, based on previous
ﬁndings that girls typically outperform boys academically
(Woolley & Grogan-Kaylor, 2006), we hypothesized that teachers would
perceive more positive relationships with their female students; based
on other ﬁndings from those studies showing that boys caused more
behavioral problems (Chun & Mobley, 2010),
 we expected that teachers
would perceive more negative relationships with boys.
To assess whether certain diﬀerences in TSRs emerged across par-
ticular subgroups of students, we ran a series of multi-level structural
equation models that nested students within teachers using the
CLUSTER ISoption and controlled for school throughﬁxed-eﬀects. With
respect to ourﬁrst hypothesis— that students in earlier grades would
perceive more positive TSRs than their peers in later grades— in Fig. 3,
we show the means for each grade at each school. Schools 1, 2, and 4
illustrate trends that are largely consistent with our hypothesis. (To
preserve the anonymity of the 4 teachers at School 3, we exclude this
school in theﬁgure). For an overall test of our hypothesis on our full
data set, we used a multi-level structural equation model to regress
students' TSR-positivity and negativity on students' grade level while
controlling for school. Results indicated that older students reported
lower levels of TSR-positivity (β = −0.23; SE =0.09; 95% CI [−0.41,
−0.04]; p = 0.02) than younger students. Though not signiﬁcant, the
diﬀerences on TSR-negativity suggested a similar trend ( β = 0.08;
SE =0.04; 95% CI [−0.003, 0.16];p = 0.06).
With respect to our second hypothesis— that teachers should feel
more positively towards their female students and more negatively
towards the boys in their classes— the results showed partial support of
our conjecture. Teachers' TSR-positivity ratings were not signiﬁcantly
diﬀerent for male and female students (β = −0.20; SE =0.14; 95% CI
[−0.48, 0.08]; p = 0.16), although the trend is in the direction we
expected. However, teachers rated their relationship with their male
students as more negative on the TSR-negativity scale ( β = 1.23;
SE =0.52; 95% CI [0.21, 2.26];p = 0.02).
3.2. Teacher-student relationships and student outcomes
Having developed our TSR scale and established multiple indicators
of validity, we then wanted to know if the scale was actually useful for
researchers and practitioners. In particular, with parallel versions for
teachers and students and with TSR-positivity and negativity subscales,
our instrument requires more eﬀort than a more traditional approach
such as simply asking students to complete a scale of their perceptions
of their teacher. Thus, we wanted evidence that our scale provided
compensatory explanatory power. We focused on three additional re-
search
questions all designed to help determine whether our approach
to measuring TSRs might provide an important complement to
Fig. 3. Students' mean level TSR-positivity and TSR-negativity by
grade at schools 1, 2, and 4."
2018 - Teacher-student relationships The positives and negatives of assessing both perspectives.pdf,"traditional, past approaches:
5) Is students' TSR-positivity positively and signiﬁcantly associated
with all 8 outcomes in the“reduced” model?
6) Does a “full” model that includes all four TSR sub-scales explain
signiﬁcantly more variability in the eight outcomes than the reduced
model?
7) To what extent do the patterns of associations between students'
TSR-positivity and each outcome diﬀer between the reduced and full
models?
The implicit logic of these three questions is as follows. Typically,
past studies have examined TSRs and their associations with student
outcomes through a single measurement approach— at the secondary
level, this approach typically examines students' perceptions of the TSR
and often utilizes a discrete, positive aspect of these perceptions (e.g.,
Wentzel, 1997 and her study of students' perceptions of teachers'
caring). If we approximate this approach by looking only at students'
perceptions of TSR-positivity, do weﬁnd associations with all 8 out-
comes as we would expect based on previous scholarship? An aﬃr-
mative answer to this question provides a sense that our overall mea-
sure of the construct functions similarly to past measures of discrete
aspects of TSRs, suggests our sample is probably not overly idiosyn-
cratic, and can be used as a reasonable proxy of some of the past in-
vestigations of TSRs at the secondary level. The real question for our
new scale, then, is whether the additional sub-scales provide additional,
important predictive power for these outcomes when we examine all
four sub-scales simultaneously. If additional variability is explained, it
suggests that the scale provides useful information beyond more tra-
ditional approaches to measuring TSRs. If the new scale shows a dif-
ferent pattern of associations between TSRs and student outcomes than
was previously understood (e.g., if it is actually the teachers' rather than
the students' perceptions that matter for a particular outcome), then the
scale might sharpen researchers or practitioners understanding of the
exact nature of these relationships.
Conducting the analyses to investigate these three questions again
required managing complex data. Because all the key predictor vari-
ables (and four of the outcomes) are composite scales, we used struc-
tural equation models to address measurement error. Students are
nested within teachers (which is a critical aspect of our research
questions) and teachers are nested within school (which is peripheral to
our research questions). Once again we used Mplus version 6, con-
structing separate latent factors for all unobserved outcomes and pre-
dictors. We treated all ordinal indicators as categorical and used
cluster-robust standard errors at the teacher level, and used FIML to
address missing data. Because we were not interested in idiosyncratic
diﬀerences between schools, we controlled for school usingﬁxed ef-
fects. We present descriptive statistics for each TSR sub-scale and each
of our outcomes inTable 4. Across all our models we controlled for
students' race and gender, as well as teachers' gender. We did not
control for teacher race because such a large majority of teachers in our
sample were white.
To answer ourﬁrst research question, weﬁt a series of structural
equations models in which each outcome was regressed on the students'
TSR-positivity scale (our“reduced model”). Next, we added teachers'
TSR-positivity and students' and teachers' TSR-negativity to the model
as latent factors and added paths from these factors to the outcome (our
“full model”), then used MPlus to conduct a Wald test to test the null
hypothesis that these paths were simultaneously equal to 0. To answer
the third research question, we compared the regression coeﬃcient of
each outcome on students' TSR-positivity from the reduced and full
models.
3.2.1. Does the reduced model predict student outcomes?
Congruent with our expectations, we found that students' percep-
tions of TSR-positivity were positively and signiﬁcantly
associated with
each student outcome (see theﬁrst column ofTable 5). Thus, we pro-
vide a conceptual replication of past studies that investigated these
relationships by asking students about their perceptions of speciﬁc as-
pects of their relationship with their teacher and correlating their re-
sponses with student outcomes. Although our reduced model diﬀers
from this approach in that we take a holistic approach to assessing
TSRs, the results are similar to these pastﬁndings (see Roorda et al.,
2011 for examples).
3.3. Does a ""full"" model that includes all four TSR sub-scales explain
signiﬁcantly more variability in the outcomes than the reduced model?
We answered this question byﬁtting a model in Mplus with the
outcome regressed on all four latent factors. Then, using a Wald test, we
obtained a p-value associated with simultaneously constraining the
paths from teachers' TSR-positivity and students' and teachers' TSR-
negativity to the outcome to be equal to 0. Weﬁnd evidence that this
set of latent factors is associated with each outcome, even after con-
trolling for students' TSR-positivity. This analysis suggests that failing to
account for teachers' perceptions and students' TSR-negativity could
prevent researchers from fully understanding how TSRs are associated
with outcomes. In Table 6, we show that for several outcomes the
proportion of variability explained by the full model is substantially
larger than the proportion of variability explained by the reduced
Table 4
Descriptive statistics and correlations for Teacher-Student Relationship Scales and student outcomes (unadjusted for nesting).
NM S D 1 2 3 4 567891 0 1 1
1) S_TSR+ 591 3.54 0.87 –
2) S_TSR− 591 1.81 0.72 −.61⁎⁎ –
3) T_TSR+ 589 3.69 0.63 .42 ⁎⁎ −.37⁎⁎ –
4) T_TSR− 589 1.57 0.55 −.26⁎⁎ .41⁎⁎ −.56⁎⁎ –
5) Class grade 473 82.46 11.02 .21 ⁎⁎ −.26⁎⁎ .28⁎⁎ −.32⁎⁎ –
6) Contribution quality 437 3.55 0.80 .15 ⁎⁎ −.10⁎ .42⁎⁎ −.29⁎⁎ .41⁎⁎ –
7) Sense of belonging 577 3.69 0.91 .26 ⁎⁎ −.26⁎⁎ .14⁎⁎ −.13⁎⁎ .20⁎⁎ .05 –
8) Interest 248 2.76 1.05 .54 ⁎⁎ −.35⁎⁎ .27⁎⁎ −.26⁎⁎ .16 .15 ⁎ .19⁎⁎ –
9) Participation frequency 437 3.26 1.17 .16 ⁎⁎ −.06 .46 ⁎⁎ −.14⁎⁎ .22⁎⁎ .47⁎⁎ .12⁎ .22⁎⁎ –
10) Homework submission 543 84.63 16.72 .16 ⁎⁎ −.21⁎⁎ .36⁎⁎ −.38⁎⁎ .62⁎⁎ .30⁎⁎ .12⁎⁎ .14 .09 –
11) Eﬀort 437 3.70 0.77 .51 ⁎⁎ −.38⁎⁎ .35⁎⁎ −.18⁎⁎ .19⁎⁎ .15⁎⁎ .30⁎⁎ .59⁎⁎ .29⁎⁎ .24⁎⁎ –
12) Self-eﬃcacy 437 3.63 0.84 .47 ⁎⁎ −.33⁎⁎ .28⁎⁎ −.12⁎ .23⁎⁎ .24⁎⁎ .28⁎⁎ .63⁎⁎ .24⁎⁎ .16⁎⁎ .65⁎⁎
Note: S_TSR+ is students' TSR-positivity; S_TSR− is students' TSR-negativity; T_TSR+ is teachers' TSR-positivity; T_TSR− is teachers' TSR-negativity. All variables were arrayed on a 1
to 5 scale except for class grade and homework submission whose scales ranged from 0 to 100.
⁎ p < 0.05.
⁎⁎ p < 0.01.
M.E. Brinkworth et al. Journal of Applied Developmental Psychology 55 (2018) 24–38
32","traditional, past approaches:
5) Is students' TSR-positivity positively and signiﬁcantly associated
with all 8 outcomes in the“reduced” model?
6) Does a “full” model that includes all four TSR sub-scales explain
signiﬁcantly more variability in the eight outcomes than the reduced
model?
7) To what extent do the patterns of associations between students'
TSR-positivity and each outcome diﬀer between the reduced and full
models?
The implicit logic of these three questions is as follows. Typically,
past studies have examined TSRs and their associations with student
outcomes through a single measurement approach— at the secondary
level, this approach typically examines students' perceptions of the TSR
and often utilizes a discrete, positive aspect of these perceptions (e.g.,
Wentzel, 1997 and her study of students' perceptions of teachers'
caring). If we approximate this approach by looking only at students'
perceptions of TSR-positivity, do weﬁnd associations with all 8 out-
comes as we would expect based on previous scholarship? An aﬃr-
mative answer to this question provides a sense that our overall mea-
sure of the construct functions similarly to past measures of discrete
aspects of TSRs, suggests our sample is probably not overly idiosyn-
cratic, and can be used as a reasonable proxy of some of the past in-
vestigations of TSRs at the secondary level. The real question for our
new scale, then, is whether the additional sub-scales provide additional,
important predictive power for these outcomes when we examine all
four sub-scales simultaneously. If additional variability is explained, it
suggests that the scale provides useful information beyond more tra-
ditional approaches to measuring TSRs. If the new scale shows a dif-
ferent pattern of associations between TSRs and student outcomes than
was previously understood (e.g., if it is actually the teachers' rather than
the students' perceptions that matter for a particular outcome), then the
scale might sharpen researchers or practitioners understanding of the
exact nature of these relationships.
Conducting the analyses to investigate these three questions again
required managing complex data. Because all the key predictor vari-
ables (and four of the outcomes) are composite scales, we used struc-
tural equation models to address measurement error. Students are
nested within teachers (which is a critical aspect of our research
questions) and teachers are nested within school (which is peripheral to
our research questions). Once again we used Mplus version 6, con-
structing separate latent factors for all unobserved outcomes and pre-
dictors. We treated all ordinal indicators as categorical and used
cluster-robust standard errors at the teacher level, and used FIML to
address missing data. Because we were not interested in idiosyncratic
diﬀerences between schools, we controlled for school usingﬁxed ef-
fects. We present descriptive statistics for each TSR sub-scale and each
of our outcomes inTable 4. Across all our models we controlled for
students' race and gender, as well as teachers' gender. We did not
control for teacher race because such a large majority of teachers in our
sample were white.
To answer ourﬁrst research question, weﬁt a series of structural
equations models in which each outcome was regressed on the students'
TSR-positivity scale (our“reduced model”). Next, we added teachers'
TSR-positivity and students' and teachers' TSR-negativity to the model
as latent factors and added paths from these factors to the outcome (our
“full model”), then used MPlus to conduct a Wald test to test the null
hypothesis that these paths were simultaneously equal to 0. To answer
the third research question, we compared the regression coeﬃcient of
each outcome on students' TSR-positivity from the reduced and full
models.
3.2.1. Does the reduced model predict student outcomes?
Congruent with our expectations, we found that students' percep-
tions of TSR-positivity were positively and signiﬁcantly
associated with
each student outcome (see theﬁrst column ofTable 5). Thus, we pro-
vide a conceptual replication of past studies that investigated these
relationships by asking students about their perceptions of speciﬁc as-
pects of their relationship with their teacher and correlating their re-
sponses with student outcomes. Although our reduced model diﬀers
from this approach in that we take a holistic approach to assessing
TSRs, the results are similar to these pastﬁndings (see Roorda et al.,
2011 for examples).
3.3. Does a ""full"" model that includes all four TSR sub-scales explain
signiﬁcantly more variability in the outcomes than the reduced model?
We answered this question byﬁtting a model in Mplus with the
outcome regressed on all four latent factors. Then, using a Wald test, we
obtained a p-value associated with simultaneously constraining the
paths from teachers' TSR-positivity and students' and teachers' TSR-
negativity to the outcome to be equal to 0. Weﬁnd evidence that this
set of latent factors is associated with each outcome, even after con-
trolling for students' TSR-positivity. This analysis suggests that failing to
account for teachers' perceptions and students' TSR-negativity could
prevent researchers from fully understanding how TSRs are associated
with outcomes. In Table 6, we show that for several outcomes the
proportion of variability explained by the full model is substantially
larger than the proportion of variability explained by the reduced"
2018 - Teacher-student relationships The positives and negatives of assessing both perspectives.pdf,"model.
3.4. To what extent do the patterns of associations diﬀer between the
reduced and full models?
3.4.1. Academic
Contrary to what the reduced model suggests, students' TSR-posi-
tivity was not associated with their grades (seeTable 5) when also
accounting for student TSR-negativity, and teacher TSR-positivity and
-negativity. Instead, our full-model shows large, signiﬁcant associations
between both teachers' TSR-positivity and TSR-negativity and student
grades. Controlling for the other variables in the model, a one standard-
deviation diﬀerence in teachers' TSR-positivity predicted a 1.4 per-
centage-point diﬀerence in grades (on a 0 to 100 scale), while a one-
unit diﬀerence in teachers' TSR-negativity predicted a nearly−2 per-
centage-point diﬀerence in grades.
For the quality of students' classroom contributions, and again
unlike the reduced model, teachers' TSR-positivity was the only pre-
dictor to reach signiﬁcance.
3.4.2. Aﬀect
As shown inTable 5, students' TSR-positivity was associated with
their interest in the class. Surprisingly, higher values of students' TSR-
negativity also predict higher levels of interest. However, because the
conﬁdence interval for this association approaches 0, this may be a
chance ﬁnding.
Despite the reduced model showing an association between stu-
dents' TSR-positivity and students' sense of belonging, the full model
showed no such association with the outcome. However, the Wald test
suggested that at least one of the regression coeﬃcients for the TSR
variables was non-zero (t
4 = 77.8,p < 0.001), even if we could not
determine which one.
3.4.3. Behavior
In the full model, teachers' TSR-positivity had a strong association
with students' class participation. Students' and teachers' TSR-negativity
were also associated with class participation, though in an unexpected
direction (seeTable 5).
As Table 5 also shows, teachers' felt their relationships were sig-
niﬁcantly more positive and less negative with students who completed
more homework.
3.4.4. Motivation
The more that students' felt positively about their relationship with
their teachers, the harder they reported trying in class. Similarly, the
more teachers felt as though they had a positive relationship with their
students, the more eﬀort the students reported putting forth in class.
Both of these associations were moderately strong (seeTable 5).
Likewise, the more positively students and teachers felt about their
relationships, the more eﬃcacious students felt about their class. Once
again, both associations were moderately strong, though the estimated
eﬀect size of students' TSR-positivity (0.42) was twice the size of that of
teachers' TSR-positivity.
4. Discussion
The relationship between teachers and students remains one of the
most important aspects of adolescents' schooling experience
(Pianta & Allen, 2008). As a consequence, having a precise under-
standing of how TSRs function, how they relate to student outcomes of
interest, how they change over time, and how they might be improved
through interventions are of great interest to researchers and practi-
tioners (e.g., Gehlbach et al., 2016). However, developing a compre-
hensive understanding of TSRs requires measuring these relationships
in diﬀerent ways to illuminate diﬀerent features of these relationships.
At the secondary level, researchers frequently assess these relationships
by asking students for their perceptions of speciﬁc aspects of TSRs, e.g.,
teacher caring (Wentzel, 1997), supportiveness (Goodenow, 1993), etc.
This approach has produced a voluminous literature on TSRs that
Table 6
Comparison of R2 between full and reduced models for student outcomes.
Grades Contribution quality Interest Sense of belonging Class participation Homework submission E ﬀort Self-e ﬃcacy
R2 (reduced model) .11 .04 .39 .17 .14 .11 .37 .31
R2 (full model) .20 .15 .41 .18 .48 .24 .41 .33
ΔR2 .09 .11 .02 .01 .34 .13 .04 .02
p-Value⁎ < .001 < .001 .003 .03 < .001 < .001 < .001 .04
Note: AllR2 diﬀerences represent the diﬀerence between a 6-predictor,“full” model that uses all 4 TSR sub-scales and a 3 predictor,“reduced” model that uses only students' perceptions
of TSR-positivity.
⁎ p-Value associated with constraining teachers' TSR-positivity and students' and teachers' TSR-negativity to 0 in the full model.
Table 5
Comparison ofﬁtted regression coeﬃcients between full and reduced models for student
outcomes.
Reduced
model
Full model
Student
TSR
positivity
(SE)
Student
TSR
positivity
(SE)
Teacher
TSR
positivity
(SE)
Student
TSR
negativity
(SE)
Teacher
TSR
negativity
(SE)
Grades 2.01
⁎⁎⁎ −0.31 1.40 ⁎⁎ −1.39 −1.98⁎⁎
(0.44) (0.96) (0.48) (1.17) (0.64)
Contribution
quality
0.15⁎⁎⁎ 0.01 0.58 ⁎⁎⁎ 0.15 0.01
(0.05) (0.05) (0.07) (0.09) (0.07)
Interest 0.59 ⁎⁎⁎ 0.66⁎⁎⁎ 0.05 0.17 ⁎ −0.05
(0.05) (0.08) (0.06) (0.08) (0.75)
Sense of
belonging
0.30⁎⁎⁎ 0.16 0.03 −0.18 0.00
(0.04) (0.10) (0.10) (0.11) (0.13)
Class
participa-
tion
0.20⁎⁎⁎ 0.08 0.83 ⁎⁎⁎ 0.18⁎ 0.37⁎⁎⁎
(0.05) (0.08) (0.08) (0.09) (0.10)
Homework
submission
2.30⁎⁎⁎ −0.05 3.63 ⁎⁎ 0.54 −3.57⁎⁎
(0.60) (1.24) (1.23) (1.36) (1.16)
Eﬀort 0.57 ⁎⁎⁎ 0.40⁎⁎⁎ 0.31⁎⁎⁎ −0.11 0.18
(0.05) (0.07) (0.08) (0.09) (0.09)
Self-eﬃcacy 0.53 ⁎⁎⁎ 0.42⁎⁎⁎ 0.21⁎⁎ −0.10 0.17
(0.05) (0.10) (0.08) (0.12) (0.11)
Note: All regression coeﬃcients for outcomes other than grades and homework submis-
sion can be interpreted as the predicted standard deviation diﬀerence in the outcome
associated with a one standard deviation diﬀerence in the latent factor. The coeﬃcients
for grade and homework submission can be interpreted as the diﬀerence in grades or
percentage of homework returned, on a 100 point scale, associated with a one standard
deviation diﬀerence in the latent factor. All models control for student and teacher gender
and student race (White or non-White). Standard errors are reported in parentheses.
⁎ P < 0.05.
⁎⁎ P < 0.01.
⁎⁎⁎ P < 0.001.
M.E. Brinkworth et al. Journal of Applied Developmental Psychology 55 (2018) 24–38
33","3.4. To what extent do the patterns of associations diﬀer between the
reduced and full models?
3.4.1. Academic
Contrary to what the reduced model suggests, students' TSR-posi-
tivity was not associated with their grades (seeTable 5) when also
accounting for student TSR-negativity, and teacher TSR-positivity and
-negativity. Instead, our full-model shows large, signiﬁcant associations
between both teachers' TSR-positivity and TSR-negativity and student
grades. Controlling for the other variables in the model, a one standard-
deviation diﬀerence in teachers' TSR-positivity predicted a 1.4 per-
centage-point diﬀerence in grades (on a 0 to 100 scale), while a one-
unit diﬀerence in teachers' TSR-negativity predicted a nearly−2 per-
centage-point diﬀerence in grades.
For the quality of students' classroom contributions, and again
unlike the reduced model, teachers' TSR-positivity was the only pre-
dictor to reach signiﬁcance.
3.4.2. Aﬀect
As shown inTable 5, students' TSR-positivity was associated with
their interest in the class. Surprisingly, higher values of students' TSR-
negativity also predict higher levels of interest. However, because the
conﬁdence interval for this association approaches 0, this may be a
chance ﬁnding.
Despite the reduced model showing an association between stu-
dents' TSR-positivity and students' sense of belonging, the full model
showed no such association with the outcome. However, the Wald test
suggested that at least one of the regression coeﬃcients for the TSR
variables was non-zero (t
4 = 77.8,p < 0.001), even if we could not
determine which one.
3.4.3. Behavior
In the full model, teachers' TSR-positivity had a strong association
with students' class participation. Students' and teachers' TSR-negativity
were also associated with class participation, though in an unexpected
direction (seeTable 5).
As Table 5 also shows, teachers' felt their relationships were sig-
niﬁcantly more positive and less negative with students who completed
more homework.
3.4.4. Motivation
The more that students' felt positively about their relationship with
their teachers, the harder they reported trying in class. Similarly, the
more teachers felt as though they had a positive relationship with their
students, the more eﬀort the students reported putting forth in class.
Both of these associations were moderately strong (seeTable 5).
Likewise, the more positively students and teachers felt about their
relationships, the more eﬃcacious students felt about their class. Once
again, both associations were moderately strong, though the estimated
eﬀect size of students' TSR-positivity (0.42) was twice the size of that of
teachers' TSR-positivity.
4. Discussion
The relationship between teachers and students remains one of the
most important aspects of adolescents' schooling experience
As a consequence, having a precise under-
standing of how TSRs function, how they relate to student outcomes of
interest, how they change over time, and how they might be improved
through interventions are of great interest to researchers and practi-
tioners (e.g., Gehlbach et al., 2016). However, developing a compre-
hensive understanding of TSRs requires measuring these relationships
in diﬀerent ways to illuminate diﬀerent features of these relationships.
At the secondary level, researchers frequently assess these relationships
by asking students for their perceptions of speciﬁc aspects of TSRs, e.g.,
teacher caring This approach has produced a voluminous literature on TSRs that"
2018 - Teacher-student relationships The positives and negatives of assessing both perspectives.pdf,"illustrates how consistently these relationships are associated with a
host of vital student outcomes (Roorda et al., 2011).
At the same time, the approach has left important questions un-
answered: Whose perspective— teachers' or students'— of the TSR mat-
ters more for which outcomes? Are the positive and negative aspects of
TSRs two ends of the same continuum or are they diﬀerent dimensions?
Are student outcomes predicted in diﬀerent ways when one accounts
for the overall relationship as opposed to discrete aspects? These
questions (and many others) require a new, complementary approach
to measuring this important construct.
To enable investigation of these and other important questions
about TSRs, we focused on the overall relationship, emphasized the
distinct perceptions of teachers and students, and allowed the positive
and negative aspects of the relationships to be independent. Through a
six-step survey design process, we developed a new measure of TSRs
that attempted to marshal evidence of the scale's (content and sub-
stantive) validity from the outset of the scale development process.
After creating the scale, we obtained additional evidence of validity,
including: the factor structure of this measure, reliability estimates for
the scale, and measurement invariance between middle and high school
students. Finally, we showed how the scale functioned largely as would
be predicted by theory with respect to expected developmental declines
in the health of TSRs and gender diﬀerences in teachers' perceptions.
However, ultimately the test of whether this new approach to as-
sessing TSRs proves a worthy complement to traditional approaches,
depends more on how it predicts student outcomes — particularly
whether it predicts these outcomes di ﬀerently than previous ap-
proaches. We found that our approach explains more variability in
student outcomes than our proxy of a more traditional approach. Most
importantly, we ﬁnd diﬀerent patterns of associations between TSRs
and student outcomes. Identifying these diﬀerent patterns of associa-
tions sharpens our understanding of how TSRs are associated with
student outcomes by shedding light on whose perception matters (the
teachers' or the students') and whether the positivity or negativity of the
relationship appears to drive the correlation. Discussion of theseﬁnd-
ings could address a number of diﬀerent points. We focus on those that
we think are most important for researchers and practitioners who need
to assess TSRs and are deliberating over whether our new approach or a
more traditional method makes the most sense.
4.1. Validity of the scale
Perhaps the most important question facing a new scale is the extent
to which it shows evidence of construct validity. Because the estab-
lishment of validity is a process rather than an end state (Gehlbach,
2015), a new scale should oﬀer a foundation of evidence that suggests
that it measures what it purports to. However, this foundation will in-
evitably be developed further over time by other scholars conducting
other studies. Between the scale development process and the results of
the data collection, we are conﬁdent that our scale provides a solid base
of evidence to warrant continued use by researchers and practitioners.
Past work has demonstrated that TSRs can be conceptualized and
measured as discrete aspects of these relationships (e.g., Murdock,
1999; Pianta, 2001; Wentzel, Battle, Russell, & Looney, 2010). The
factor structure that bestﬁt our data suggests that measuring TSRs as an
omnibus construct can also work for secondary school teachers and
students. However, in our case the positive and negative dimensions of
the relationship emerged as separate factors. This structure accords
with recent meta-analyticﬁndings and the suggestion that,“future re-
search, and especially secondary school studies, should consider in-
cluding negative aspects of the relationship” (Roorda et al., 2011.p .
519). An important future research direction is how many factors would
emerge
if an array of discrete aspects of TSRs were measured— e.g.,
conﬂict, closeness, dependency, academic support, expectations, social
support, etc.
In addition, our data provide strong evidence of internal consistency
for these scale scores and evidence of moderate stability in TSR scores
over the course of the school year. We interpret the practical im-
portance of the measurement invariance results as evidence that the
scales function similarly enough across middle and high school to
warrant use in longitudinal studies. Finally, by largely replicating prior
ﬁndings regarding grade-level and gender diﬀerences in TSRs, weﬁnd
further evidence that the scales are functioning as anticipated.
As scholars conduct future studies using this scale, more validity
evidence will be acquired. Through this process, we will learn the range
of appropriate uses for this approach to assessing TSRs and the bounds
of those uses. For now, we are conﬁdent that this measure shows suf-
ﬁcient evidence of validity to warrant adoption by future researchers
interested in TSRs.
4.2. Utility of the new measure
Even if a scale shows compelling evidence of validity, it may not
prove particularly useful in applied settings if it does not generate new
insights about the construct when compared against existing ap-
proaches. Weﬁnd that our full models explain more variability in each
of the eight outcomes of interest and illuminate diﬀerent patterns of
associations as compared to our proxy for a more traditional approach.
Through our reduced model, we replicate (conceptually) many past
investigations of TSRs— studies that assessed TSRs by asking students
about speciﬁc, positive aspects of their relationship with their teacher
and then correlated those student perceptions with student outcomes.
For example, our reduced model mirrorsGoodenow's (1993) ﬁnding
that students who felt more support from their teachers got better
grades; Wentzel's (1998) ﬁndings that students who perceived more
teacher support were more interested in their class and got better
grades; and Murdock and Miller's (2003)results that student percep-
tions of teacher caring predicted students' self-eﬃcacy and eﬀort. These
parallels provide some assurance that our sample functioned similarly
to samples in past investigations of TSRs and student outcomes.
In comparing this reduced model to our full model, it is also im-
portant to note that including all four TSR sub-scales increases the
proportion of variability explained in ourﬁnal models by a practically
meaningful, as well as a statistically signiﬁcant, amount for multiple
outcomes. AsTable 6shows, the full models predict far more variation
than the reduced models in student grades, contribution quality, class
participation, and homework completion. Perhaps these models explain
so much additional variability because the outcomes are directly af-
fected by teachers and students to a greater degree than other out-
comes. For instance, grades typically result from the students' eﬀorts
and teachers' subject evaluations of those eﬀorts; class participation
frequently requires students to raise their hands and teachers to call on
them. By contrast, outcomes such as students' interest in the subject
matter or sense of belonging are internal psychological states that
teachers are likely to aﬀect only indirectly.
In sum, weﬁnd that our approach to measuring TSRs oﬀers greater
overall explanatory power. Correspondingly, it seems plausible that
studies
conceptualizing TSRs more narrowly may underestimate its
importance for some student outcomes. For example, if students' per-
ceptions of how much a teacher respects and encourages them are the
key elements in the association between TSRs and student eﬀort, but a
study measures TSRs using only teacher expectations, the correlation
between TSRs and student eﬀort might be underestimated (relative to
using a measure of the overall TSR).
In addition to greater explanatory power, our approach potentially
provides a more precise understanding of the nature of the associations
between TSRs and student outcomes. For only three of the eight model
comparisons did students' TSR-positivity remain a statistically sig-
niﬁcant predictor. Meanwhile, teachers' TSR-positivity was signiﬁcantly
associated with the outcomes in six out of eight cases. Both students'
and teachers' TSR-positivity were signiﬁcant in two out of the eight
cases. We view these results as compelling evidence that scholars
M.E. Brinkworth et al. Journal of Applied Developmental Psychology 55 (2018) 24–38
34","illustrates how consistently these relationships are associated with a
host of vital student outcomes.
At the same time, the approach has left important questions un-
answered: Whose perspective— teachers' or students'— of the TSR mat-
ters more for which outcomes? Are the positive and negative aspects of
TSRs two ends of the same continuum or are they diﬀerent dimensions?
Are student outcomes predicted in diﬀerent ways when one accounts
for the overall relationship as opposed to discrete aspects? These
questions (and many others) require a new, complementary approach
to measuring this important construct.
To enable investigation of these and other important questions
about TSRs, we focused on the overall relationship, emphasized the
distinct perceptions of teachers and students, and allowed the positive
and negative aspects of the relationships to be independent. Through a
six-step survey design process, we developed a new measure of TSRs
that attempted to marshal evidence of the scale's (content and sub-
stantive) validity from the outset of the scale development process.
After creating the scale, we obtained additional evidence of validity,
including: the factor structure of this measure, reliability estimates for
the scale, and measurement invariance between middle and high school
students. Finally, we showed how the scale functioned largely as would
be predicted by theory with respect to expected developmental declines
in the health of TSRs and gender diﬀerences in teachers' perceptions.
However, ultimately the test of whether this new approach to as-
sessing TSRs proves a worthy complement to traditional approaches,
depends more on how it predicts student outcomes — particularly
whether it predicts these outcomes di ﬀerently than previous ap-
proaches. We found that our approach explains more variability in
student outcomes than our proxy of a more traditional approach. Most
importantly, we ﬁnd diﬀerent patterns of associations between TSRs
and student outcomes. Identifying these diﬀerent patterns of associa-
tions sharpens our understanding of how TSRs are associated with
student outcomes by shedding light on whose perception matters (the
teachers' or the students') and whether the positivity or negativity of the
relationship appears to drive the correlation. Discussion of theseﬁnd-
ings could address a number of diﬀerent points. We focus on those that
we think are most important for researchers and practitioners who need
to assess TSRs and are deliberating over whether our new approach or a
more traditional method makes the most sense.
4.1. Validity of the scale
Perhaps the most important question facing a new scale is the extent
to which it shows evidence of construct validity. Because the estab-
lishment of validity is a process rather than an end state, a new scale should oﬀer a foundation of evidence that suggests
that it measures what it purports to. However, this foundation will in-
evitably be developed further over time by other scholars conducting
other studies. Between the scale development process and the results of
the data collection, we are conﬁdent that our scale provides a solid base
of evidence to warrant continued use by researchers and practitioners.
Past work has demonstrated that TSRs can be conceptualized and
measured as discrete aspects of these relationships. The
factor structure that bestﬁt our data suggests that measuring TSRs as an
omnibus construct can also work for secondary school teachers and
students. However, in our case the positive and negative dimensions of
the relationship emerged as separate factors. This structure accords
with recent meta-analyticﬁndings and the suggestion that,“future re-
search, and especially secondary school studies, should consider in-
cluding negative aspects of the relationship”. An important future research direction is how many factors would
emerge
if an array of discrete aspects of TSRs were measured— e.g.,
conﬂict, closeness, dependency, academic support, expectations, social
support, etc.
In addition, our data provide strong evidence of internal consistency
for these scale scores and evidence of moderate stability in TSR scores
over the course of the school year. We interpret the practical im-
portance of the measurement invariance results as evidence that the
scales function similarly enough across middle and high school to
warrant use in longitudinal studies. Finally, by largely replicating prior
ﬁndings regarding grade-level and gender diﬀerences in TSRs, weﬁnd
further evidence that the scales are functioning as anticipated.
As scholars conduct future studies using this scale, more validity
evidence will be acquired. Through this process, we will learn the range
of appropriate uses for this approach to assessing TSRs and the bounds
of those uses. For now, we are conﬁdent that this measure shows suf-
ﬁcient evidence of validity to warrant adoption by future researchers
interested in TSRs.
4.2. Utility of the new measure
Even if a scale shows compelling evidence of validity, it may not
prove particularly useful in applied settings if it does not generate new
insights about the construct when compared against existing ap-
proaches. Weﬁnd that our full models explain more variability in each
of the eight outcomes of interest and illuminate diﬀerent patterns of
associations as compared to our proxy for a more traditional approach.
Through our reduced model, we replicate (conceptually) many past
investigations of TSRs— studies that assessed TSRs by asking students
about speciﬁc, positive aspects of their relationship with their teacher
and then correlated those student perceptions with student outcomes.
For example, our reduced model mirrorsGoodenow's (1993) ﬁnding
that students who felt more support from their teachers got better
grades; Wentzel's (1998) ﬁndings that students who perceived more
teacher support were more interested in their class and got better
grades; and Murdock and Miller's (2003)results that student percep-
tions of teacher caring predicted students' self-eﬃcacy and eﬀort. These
parallels provide some assurance that our sample functioned similarly
to samples in past investigations of TSRs and student outcomes.
In comparing this reduced model to our full model, it is also im-
portant to note that including all four TSR sub-scales increases the
proportion of variability explained in ourﬁnal models by a practically
meaningful, as well as a statistically signiﬁcant, amount for multiple
outcomes. AsTable 6shows, the full models predict far more variation
than the reduced models in student grades, contribution quality, class
participation, and homework completion. Perhaps these models explain
so much additional variability because the outcomes are directly af-
fected by teachers and students to a greater degree than other out-
comes. For instance, grades typically result from the students' eﬀorts
and teachers' subject evaluations of those eﬀorts; class participation
frequently requires students to raise their hands and teachers to call on
them. By contrast, outcomes such as students' interest in the subject
matter or sense of belonging are internal psychological states that
teachers are likely to aﬀect only indirectly.
In sum, weﬁnd that our approach to measuring TSRs oﬀers greater
overall explanatory power. Correspondingly, it seems plausible that
studies
conceptualizing TSRs more narrowly may underestimate its
importance for some student outcomes. For example, if students' per-
ceptions of how much a teacher respects and encourages them are the
key elements in the association between TSRs and student eﬀort, but a
study measures TSRs using only teacher expectations, the correlation
between TSRs and student eﬀort might be underestimated (relative to
using a measure of the overall TSR).
In addition to greater explanatory power, our approach potentially
provides a more precise understanding of the nature of the associations
between TSRs and student outcomes. For only three of the eight model
comparisons did students' TSR-positivity remain a statistically sig-
niﬁcant predictor. Meanwhile, teachers' TSR-positivity was signiﬁcantly
associated with the outcomes in six out of eight cases. Both students'
and teachers' TSR-positivity were signiﬁcant in two out of the eight
cases. We view these results as compelling evidence that scholars"
2018 - Teacher-student relationships The positives and negatives of assessing both perspectives.pdf,"should account for both teacher and student perspectives in future in-
vestigations of TSRs in order to obtain a more nuanced association of
how TSRs relate to various outcomes.
We also ﬁnd evidence for Roorda et al.'s (2011) suggestion that
accounting for the positive and negative dimensions of these relation-
ships separately may be important. Teachers' TSR-negativity was a
signiﬁcant predictor of three outcomes. Students' TSR-negativity pre-
dicted two— students' participation and interest in class. Although for
participation, both students' and teachers' TSR-negativity scores showed
evidence of unexpected suppressor eﬀects (Rosenberg, 1968), thus, we
are reticent to interpret thisﬁnding until future studies can demonstrate
that it is more than idiosyncratic.
This sharper understanding of how TSRs are associated with student
outcomes can also serve to generate important hypotheses. For in-
stance, perhaps teachers' (as compared to students') perceptions of TSRs
are more predictive of classroom outcomes in general because they
(typically) hold more power within the relationship. Others might
speculate that TSR-positivity better predicts“approach” outcomes such
as eﬀort but outcomes such as class participation— where students
might raise their hands aggressively (an approach behavior) or hide
behind a classmate (an avoidance behavior)— will typically be better
predicted by TSR-positivity and negativity subscales (Elliot, 2006).
This approach to measuring and understanding TSRs may also im-
plicate the actions taken by school leaders. This consequence is perhaps
best illustrated by the associations between TSRs and grades. If a school
leader wanted to improve students' grades, prior correlational studies
(Goodenow, 1993; Wentzel, 1998) signal that an intervention which
bolsters the positivity of students' perceptions of their relationship with
their teachers might be worth testing. By contrast, ourﬁndings suggest
that students' grades are more likely to go up by intervening directly
with teachers to help them see their students in a more positive and/or
less negative light. While researchers are (rightly) quick to point out
that correlations like those between TSRs and student outcomes are not
necessarily causal, school leaders have to make educated guesses about
where and how to improve student outcomes (often based on correla-
tional evidence). As the associations between TSRs and grades indicate,
even correlational data from this approach to measuring TSRs can
provide school leaders with clues about where and how they might
want to intervene (e.g., with teachers rather than students).
4.3. Limitations and trade-oﬀs involved in our TSR scale
In the development process, we incorporated several additional
assets into our scale. The scale is short — a particularly important
quality for teachers who might have toﬁll out the scale repeatedly.
Because we demonstrate evidence of invariance between middle and
high school respondents, the scale should work well for developmental
research between 6th and 12th grade.
However, we necessarily had to make certain trade-oﬀs. One cost of
keeping our scale short, was that our 9-item and 5-item sub-scales do
not directly represent every indicator listed inTable 1. Second, taking a
holistic approach is particularly useful for answering many research
questions. For other research questions taking a thinner slice of TSRs
(e.g., a speciﬁc scale on teacher caring or perceived criticism) may be
more appropriate. Third, we found less variability in our negativity
scale than we might have liked. In particular, teachers seemed reticent
to admit that they had especially negative relationships with any of
their students (perhaps because a negative TSR could reﬂect
poorly on
their abilities to connect with students). However, items that we might
have otherwise reworded to get more variability had other merits. For
example, few teachers responded to the question of ""How unfair are you
to < student's name > in class?"" by using thesomewhat, quite,o r ex-
tremely unfair response anchors. Ultimately, we retained the item be-
cause the students' scores showed a much broader range. We felt that
examining discordance around perceptions of fairness might be espe-
cially interesting and important for future scholars to study.
Other limitations might be addressed through future studies. For
instance, including more measures from other sources (e.g., relatively
objective outcomes such as test-scores and attendance and subjective
measures from other sources like parent reports of their children's TSRs)
will be particularly useful in providing additional tests of convergent
and discriminant validity. We might also learn more about how these
relationships function by having students complete this measure on
multiple teachers. Such an approach would shed light on respective
levels of within-student, between-teacher variance as compared to be-
tween-student, within-teacher variance in these relationships. Future
studies that can document TSRs from samples who do not volunteer to
participate will help with issues of representativeness— we worried that
relying on volunteers might leave us with a sample of teachers (and
perhaps students as well) who had disproportionately positive TSRs
and/or were more interested than most teachers in working on their
TSRs.
We remain hopeful that as future researchers and school leaders use
this TSR scale, they may develop modiﬁcations that minimize the need
to make these types of compromises and trade-oﬀs. In addition, we
hope that they might explore important issues that we could not such as
whether TSRs vary by subject area, type of school, or other important
factors.
5. Conclusion
We are particularly optimistic about the coming years of research on
TSRs. Many exciting questions are still open for investigation: To what
extent can strengths in one area of a TSR compensate for weaknesses in
another area? What are the downstream consequences when students'
and teachers' perceptions of their TSR are misaligned? Perhaps the most
important question of all is, whether interventions that improve TSRs
cause improvements in other student outcomes.
Relationships between teachers and students lie at the heart of the
learning environment. Because classrooms are fundamentally social
contexts (Gehlbach, 2010), improving these crucial relationships seems
like a particularly promising approach to improving student outcomes.
However, before scholars can test di ﬀerent approaches to under-
standing and ultimately improving TSRs, they must measure these re-
lationships accurately. We hope that measures like this one can con-
tribute to these new understandings and improvements.
Acknowledgments.
This research was supported by generous funding from the Harvard
Graduate School of Education Dean's Venture Fund, a grant from the
Spencer Foundation and an Early Career Research Award by Division
15 of the American Psychological Association. The authors are parti-
cularly grateful for the generous assistance of the participating schools
and the help of Rebecca Zazove in collecting these data. We are also
indebted to the scholars who participated in our expert review. Most of
all, we are extremely appreciative of the students, teachers, and school
principals who made this study happen.
M.E. Brinkworth et al. Journal of Applied Developmental Psychology 55 (2018) 24–38
35","should account for both teacher and student perspectives in future investigations of TSRs in order to obtain a more nuanced association of how TSRs relate to various outcomes.
We also ﬁnd evidence for Roorda et al.'s (2011) suggestion that accounting for the positive and negative dimensions of these relationships separately may be important. Teachers' TSR-negativity was a signiﬁcant predictor of three outcomes. Students' TSR-negativity predicted two— students' participation and interest in class. Although for participation, both students' and teachers' TSR-negativity scores showed evidence of unexpected suppressor eﬀects (Rosenberg, 1968), thus, we are reticent to interpret thisﬁnding until future studies can demonstrate that it is more than idiosyncratic.
This sharper understanding of how TSRs are associated with student outcomes can also serve to generate important hypotheses. For instance, perhaps teachers' (as compared to students') perceptions of TSRs are more predictive of classroom outcomes in general because they (typically) hold more power within the relationship. Others might speculate that TSR-positivity better predicts“approach” outcomes such as eﬀort but outcomes such as class participation— where students might raise their hands aggressively (an approach behavior) or hide behind a classmate (an avoidance behavior)— will typically be better predicted by TSR-positivity and negativity subscales (Elliot, 2006).
This approach to measuring and understanding TSRs may also implicate the actions taken by school leaders. This consequence is perhaps best illustrated by the associations between TSRs and grades. If a school leader wanted to improve students' grades, prior correlational studies (Goodenow, 1993; Wentzel, 1998) signal that an intervention which bolsters the positivity of students' perceptions of their relationship with their teachers might be worth testing. By contrast, ourﬁndings suggest that students' grades are more likely to go up by intervening directly with teachers to help them see their students in a more positive and/or less negative light. While researchers are (rightly) quick to point out that correlations like those between TSRs and student outcomes are not necessarily causal, school leaders have to make educated guesses about where and how to improve student outcomes (often based on correlational evidence). As the associations between TSRs and grades indicate, even correlational data from this approach to measuring TSRs can provide school leaders with clues about where and how they might want to intervene (e.g., with teachers rather than students).
4.3. Limitations and trade-oﬀs involved in our TSR scale
In the development process, we incorporated several additional assets into our scale. The scale is short — a particularly important quality for teachers who might have toﬁll out the scale repeatedly. Because we demonstrate evidence of invariance between middle and high school respondents, the scale should work well for developmental research between 6th and 12th grade.
However, we necessarily had to make certain trade-oﬀs. One cost of keeping our scale short, was that our 9-item and 5-item sub-scales do not directly represent every indicator listed inTable 1. Second, taking a holistic approach is particularly useful for answering many research questions. For other research questions taking a thinner slice of TSRs (e.g., a speciﬁc scale on teacher caring or perceived criticism) may be more appropriate. Third, we found less variability in our negativity scale than we might have liked. In particular, teachers seemed reticent to admit that they had especially negative relationships with any of their students (perhaps because a negative TSR could reﬂect poorly on their abilities to connect with students). However, items that we might have otherwise reworded to get more variability had other merits. For example, few teachers responded to the question of ""How unfair are you to < student's name > in class?"" by using thesomewhat, quite,o r extremely unfair response anchors. Ultimately, we retained the item because the students' scores showed a much broader range. We felt that examining discordance around perceptions of fairness might be espe-cially interesting and important for future scholars to study.
Other limitations might be addressed through future studies. For instance, including more measures from other sources (e.g., relatively objective outcomes such as test-scores and attendance and subjective measures from other sources like parent reports of their children's TSRs) will be particularly useful in providing additional tests of convergent and discriminant validity. We might also learn more about how these relationships function by having students complete this measure on multiple teachers. Such an approach would shed light on respective levels of within-student, between-teacher variance as compared to between-student, within-teacher variance in these relationships. Future studies that can document TSRs from samples who do not volunteer to participate will help with issues of representativeness— we worried that relying on volunteers might leave us with a sample of teachers (and perhaps students as well) who had disproportionately positive TSRs and/or were more interested than most teachers in working on their TSRs.
We remain hopeful that as future researchers and school leaders use this TSR scale, they may develop modiﬁcations that minimize the need to make these types of compromises and trade-oﬀs. In addition, we hope that they might explore important issues that we could not such as whether TSRs vary by subject area, type of school, or other important factors.
5. Conclusion
We are particularly optimistic about the coming years of research on TSRs. Many exciting questions are still open for investigation: To what extent can strengths in one area of a TSR compensate for weaknesses in another area? What are the downstream consequences when students' and teachers' perceptions of their TSR are misaligned? Perhaps the most important question of all is, whether interventions that improve TSRs cause improvements in other student outcomes.
Relationships between teachers and students lie at the heart of the learning environment. Because classrooms are fundamentally social contexts (Gehlbach, 2010), improving these crucial relationships seems like a particularly promising approach to improving student outcomes.
However, before scholars can test di ﬀerent approaches to under-standing and ultimately improving TSRs, they must measure these re-lationships accurately. We hope that measures like this one can con-tribute to these new understandings and improvements.
Acknowledgments.
The authors are parti-cularly grateful for the generous assistance of the participating schools and the help of Rebecca Zazove in collecting these data. We are also indebted to the scholars who participated in our expert review. Most of all, we are extremely appreciative of the students, teachers, and school principals who made this study happen."
2018 - Teacher-student relationships The positives and negatives of assessing both perspectives.pdf,"Appendix A. Teacher-Student Relationship Scale
Student items Teacher items
Positivity sub-scale
1 How much do you enjoy learning from 〈teacher's name〉? How much do you enjoy helping 〈student's name〉 learn?
2 How friendly is 〈teacher's name〉 towards you? How friendly is 〈student's name〉 towards you?
3 How often does 〈teacher's name〉 say something
encouraging to you?
How often do you say something encouraging to
〈student's name〉?
4 How respectful is 〈teacher's name〉 towards you? How respectful is 〈student's name〉 towards you?
5 How excited would you be to have 〈teacher's name〉
again next year?
How excited would you be to have〈student's name〉
again next year?
6 How motivating are the activities that 〈teacher's name〉
plans for class?
How motivating does〈student's name〉 ﬁnd the activities
that you plan for class?
7 How caring is 〈teacher's name〉 towards you? How caring is 〈student's name〉 towards you?
8 How much do you like 〈teacher's name〉’s personality? How much do you like 〈student's name〉 personality?
9 Overall, how much do you learn from 〈teacher's name〉? Overall, how much does 〈student's name〉 learn from
you?
Negativity sub-scale
1 How often do you ignore something 〈teacher's name〉says? How often does〈student's name〉 ignore something you
say?
2
During class, how often do you talk when〈teacher's name〉is
talking (for instance, when you are supposed to be listening)?
During class, how often does〈student's name〉 talk when
you are talking (for instance, when〈student's name〉 is
supposed to be listening)?
3 How often does 〈teacher's name〉say something that oﬀends you? How often do you say something that o ﬀends 〈student's
name〉?
4 How unfair is 〈teacher's name〉 to you in class? How unfair are you to〈student's name〉 in class?
5 How angry does 〈teacher's name〉 make you feel during class? How angry do you make 〈student's name〉 feel during
class?
Note: Response anchors were arrayed alongﬁve points. For example: Not at all/Slightly/Somewhat/Quite a bit/A tremendous amount; Not at all friendly/Slightly friendly/Somewhat
friendly/Quite friendly/Extremely friendly; Almost never/Once in a while/Sometimes/Frequently/Almost all the time; or Almost nothing/A little bit/Some/Quite a bit/A great deal.
Appendix B. Student outcome measures
Academic
1) Student grades: Collected at Schools 1, 3, and 4
a. School 1– student self-report
b. School 3– teacher reported
c. School 4– teacher reported
2) Contribution quality: Teacher ratings of the quality of students' class participation: Collected at Schools 2, 3, and 4
When Student X participates in class, how would you rate the quality of his/her contributions?
Response anchor:
Far below
average
Below average Average Above average Far above
average
Aﬀect
3) Interest in subject matter: Collected at Schools 2 and 4
How interesting do youﬁnd your ______ class?
Response anchor:
Not at all
interesting
Slightly
interesting
Somewhat
interesting
Quite
interesting
Extremely
interesting
If you could choose to take any classes you wanted to in high school, how many classes would you take in this subject?
Response anchor:
M.E. Brinkworth et al. Journal of Applied Developmental Psychology 55 (2018) 24–38
36","Appendix A. Teacher-Student Relationship Scale
Student items Teacher items
Positivity sub-scale
1 How much do you enjoy learning from 〈teacher's name〉? How much do you enjoy helping 〈student's name〉 learn?
2 How friendly is 〈teacher's name〉 towards you? How friendly is 〈student's name〉 towards you?
3 How often does 〈teacher's name〉 say something
encouraging to you?
How often do you say something encouraging to
〈student's name〉?
4 How respectful is 〈teacher's name〉 towards you? How respectful is 〈student's name〉 towards you?
5 How excited would you be to have 〈teacher's name〉
again next year?
How excited would you be to have〈student's name〉
again next year?
6 How motivating are the activities that 〈teacher's name〉
plans for class?
How motivating does〈student's name〉 ﬁnd the activities
that you plan for class?
7 How caring is 〈teacher's name〉 towards you? How caring is 〈student's name〉 towards you?
8 How much do you like 〈teacher's name〉’s personality? How much do you like 〈student's name〉 personality?
9 Overall, how much do you learn from 〈teacher's name〉? Overall, how much does 〈student's name〉 learn from
you?
Negativity sub-scale
1 How often do you ignore something 〈teacher's name〉says? How often does〈student's name〉 ignore something you
say?
2
During class, how often do you talk when〈teacher's name〉is
talking (for instance, when you are supposed to be listening)?
During class, how often does〈student's name〉 talk when
you are talking (for instance, when〈student's name〉 is
supposed to be listening)?
3 How often does 〈teacher's name〉say something that oﬀends you? How often do you say something that o ﬀends 〈student's
name〉?
4 How unfair is 〈teacher's name〉 to you in class? How unfair are you to〈student's name〉 in class?
5 How angry does 〈teacher's name〉 make you feel during class? How angry do you make 〈student's name〉 feel during
class?
Note: Response anchors were arrayed alongﬁve points. For example: Not at all/Slightly/Somewhat/Quite a bit/A tremendous amount; Not at all friendly/Slightly friendly/Somewhat
friendly/Quite friendly/Extremely friendly; Almost never/Once in a while/Sometimes/Frequently/Almost all the time; or Almost nothing/A little bit/Some/Quite a bit/A great deal.
Appendix B. Student outcome measures
Academic
1) Student grades: Collected at Schools 1, 3, and 4
a. School 1– student self-report
b. School 3– teacher reported
c. School 4– teacher reported
2) Contribution quality: Teacher ratings of the quality of students' class participation: Collected at Schools 2, 3, and 4
When Student X participates in class, how would you rate the quality of his/her contributions?
Response anchor:
Far below
average
Below average Average Above average Far above
average
Aﬀect
3) Interest in subject matter: Collected at Schools 2 and 4
How interesting do youﬁnd your ______ class?
Response anchor:
Not at all
interesting
Slightly
interesting
Somewhat
interesting
Quite
interesting
Extremely
interesting
If you could choose to take any classes you wanted to in high school, how many classes would you take in this subject?
Response anchor:"
2018 - Teacher-student relationships The positives and negatives of assessing both perspectives.pdf,"No
classes
A few
classes
Some
classes
Quite a
few classes
A lot of
classes
How likely are you to go into a ________-related career?
Response anchor:
Not at all
likely
Slightly
likely
Somewhat
likely
Quite
likely
Extremely
likely
4) Sense of belonging: Collected at all 4 schools.
I feel like I belong in this school.
I feel like I am successful in this school.
I feel like I matter in this school.
I do not feel like I am important in this school. (reversed)
Response anchor:
Not at all
true of me
Slightly
true of me
Somewhat
true of me
Quite
true of me
Extremely
true of me
Note: Scale taken fromRoeser et al. (1996).
Behavior
5) Homework completion: Teacher reports of percentage of homework completed; collected at all 4 schools.
Approximately what percentage of the assigned homework doesStudent X complete fully? _____
6) Teacher ratings of frequency of class participation: Collected at Schools 2, 3, 4
How frequently doesStudent X participate in class?
Response anchor:
Almost
never
Once in
a while
Sometimes Frequently Almost all
the time
Motivation
7) Students' self report of theireﬀort: Collected at Schools 2, 3, 4
How much eﬀort do you put forth for this class?
When Teacher X is speaking, how much eﬀort do you put into trying to pay attention?
How much eﬀort do you put into getting involved in class discussions?
How much eﬀort do you put into your homework for this class?
How much eﬀort do you put into in-class activities?
Response anchor:
Almost no
eﬀort
A little bit
of eﬀort
Some
eﬀort
Quite a bit
of eﬀort
A great deal
of eﬀort
8) Students' self report of theirself-eﬃcacy: Collected at Schools 2, 3, 4.
How conﬁdent are you that you can do the hardest work that is assigned in this class?
How conﬁdent are you that you can learn all the material presented in this class?
When complicated ideas are presented in this class, how conﬁdent are you that you can understand them?
How conﬁdent are you that you will remember what you learned in this class next year?
How conﬁdent are you that you can complete all the work that is assigned in this class?
Response anchor:
Not at all
conﬁdent
Slightly
conﬁdent
Somewhat
conﬁdent
Quite
conﬁdent
Extremely
conﬁdent
Note: Scale adapted from (Gehlbach et al., 2008).
M.E. Brinkworth et al. Journal of Applied Developmental Psychology 55 (2018) 24–38
37","4) Sense of belonging: Collected at all 4 schools.
I feel like I belong in this school.
I feel like I am successful in this school.
I feel like I matter in this school.
I do not feel like I am important in this school. (reversed)
Response anchor:
Not at all
true of me
Slightly
true of me
Somewhat
true of me
Quite
true of me
Extremely
true of me
Behavior
5) Homework completion: Teacher reports of percentage of homework completed; collected at all 4 schools.
Approximately what percentage of the assigned homework doesStudent X complete fully? _____
6) Teacher ratings of frequency of class participation: Collected at Schools 2, 3, 4
How frequently doesStudent X participate in class?
Response anchor:
Almost
never
Once in
a while
Sometimes Frequently Almost all
the time
Motivation
7) Students' self report of theireﬀort: Collected at Schools 2, 3, 4
How much eﬀort do you put forth for this class?
When Teacher X is speaking, how much eﬀort do you put into trying to pay attention?
How much eﬀort do you put into getting involved in class discussions?
How much eﬀort do you put into your homework for this class?
How much eﬀort do you put into in-class activities?
Response anchor:
Almost no
eﬀort
A little bit
of eﬀort
Some
eﬀort
Quite a bit
of eﬀort
A great deal
of eﬀort
8) Students' self report of theirself-eﬃcacy: Collected at Schools 2, 3, 4.
How conﬁdent are you that you can do the hardest work that is assigned in this class?
How conﬁdent are you that you can learn all the material presented in this class?
When complicated ideas are presented in this class, how conﬁdent are you that you can understand them?
How conﬁdent are you that you will remember what you learned in this class next year?
How conﬁdent are you that you can complete all the work that is assigned in this class?
Response anchor:
Not at all
conﬁdent
Slightly
conﬁdent
Somewhat
conﬁdent
Quite
conﬁdent
Extremely
conﬁdent"
2018 - Teacher-student relationships The positives and negatives of assessing both perspectives.pdf,"References.
Ang, R. P. (2005). Development and validation of the Teacher-Student Relationship
Inventory using exploratory and conﬁrmatory factor analysis.Journal of Experimental
Education, 74(1), 55–73. http://dx.doi.org/10.3200/jexe.74.1.55-74.
Asparouhov, T. (2005). Sampling weights in latent variable modeling.Structural Equation
Modeling: A Multidisciplinary Journal, 12(3), 411–434. http://dx.doi.org/10.1207/
s15328007sem1203_4.
Gehlbach, H. (2010). The social side of school: Why teachers need social psychology.
Educational Psychology Review, 22(3), 349–362. http://dx.doi.org/10.1007/s10648-
010-9138-3.
Gehlbach, H. (2015). Seven survey sins.The Journal of Early Adolescence, 35, 883– 897.
http://dx.doi.org/10.1177/0272431615578276.
Gehlbach, H., Brown, S. W., Ioannou, A., Boyer, M. A., Hudson, N., Niv-Solomon, A., &
Janik, L. (2008). Increasing interest in social studies: Social perspective taking and
self-eﬃcacy in stimulating simulations.Contemporary Educational Psychology, 33(4),
894–914. http://dx.doi.org/10.1016/j.cedpsych.2007.11.002.
Gehlbach, H., & Brinkworth, M. E. (2011). Measure twice, cut down error: A process for
enhancing the validity of survey scales.Review of General Psychology, 15(4), 380–387.
http://dx.doi.org/10.1037/a0025704.
Gehlbach, H., Brinkworth, M. E., King, A. M., Hsu, L. M., McIntyre, J., & Rogers, T.
(2016). Creating Birds of Similar Feathers: Leveraging Similarity to Improve
Teacher–Student Relationships and Academic Achievement.Journal of Educational
Psychology, 108(3), 342–352. http://dx.doi.org/10.1037/edu0000042.
Cacioppo, J. T., & Berntson, G. G. (1994). Relationship between attitudes and evaluative
space: A critical review, with emphasis on the separability of positive and negative
substrates. Psychological Bulletin, 115(3), 401–423. http://dx.doi.org/10.1037/0033-
2909.115.3.401.
Chen, F. F. (2007). Sensitivity of goodness ofﬁt indexes to lack of measurement in-
variance. Structural Equation Modeling, 14(3), 464– 504.
Cheung, G. W., & Rensvold, R. B. (2002). Evaluating goodness-of-ﬁt indexes for testing
measurement invariance.Structural Equation Modeling, 9(2), 233–255.
Chun, H., & Mobley, M. (2010). Gender and grade-level comparisons in the structure of
problem behaviors among adolescents.Journal of Adolescence, 33(1), 197–207.
http://dx.doi.org/10.1016/j.adolescence.2009.03.010.
Clark,
M. S., & Lemay, E. P., Jr. (2010). Close relationships. In S. T. Fiske, D. T. Gilbert, &
G. Lindzey (Vol. Eds.),Handbook of social psychology(5th ed.).Vol. 2. Handbook of
social psychology (pp. 898–940). Hoboken, NJ US: John Wiley & Sons Inc.
Cornelius-White, J. (2007). Learner-centered teacher-student relationships are eﬀective:
A meta-analysis.Review of Educational Research, 77(1), 113– 143. http://dx.doi.org/
10.3102/003465430298563.
DeVellis, R. F. (2003).Scale development: Theory and applications(2nd ed.). Newbury Park,
CA: Sage.
Dillman, D. A., Smyth, J. D., & Christian, L. M. (2014).Internet, phone, mail, and mixed-
mode surveys: The tailored design method(4th ed.). Hoboken, NJ: John Wiley & Sons.
Eccles, J. S., Midgley, C., Wigﬁeld, A., Buchanan, C. M., Reuman, D., Flanagan, C., & Mac
Iver, D. J. (1993). Development during adolescence: The impact of stage-environment
ﬁt on young adolescents' experiences in schools and in families. Special issue:
Adolescence. American Psychologist, 48(2), 90–101. http://dx.doi.org/10.1037/0003-
066X.48.2.90.
Elliot, A. J. (2006). The hierarchical model of approach-avoidance motivation.Motivation
and Emotion, 30(2), 111–116.
Gable, S. L., Reis, H. T., & Downey, G. (2003). He said, she said: A quasi-signal detection
analysis of daily interactions between close relationship partners.Psychological
Science, 14(2), 100–105.
Garza, R. (2009). Latino and white high school students' perceptions of caring behaviors:
Are we culturally responsive to our students?Urban Education, 44(3), 297–321.
Goodenow, C. (1993). Classroom belonging among early adolescent students:
Relationships to motivation and achievement.The Journal of Early Adolescence, 13(1),
21–43. http://dx.doi.org/10.1177/0272431693013001002.
Gregory, A., & Weinstein, R. S. (2008). The discipline gap and African Americans:
Deﬁance or cooperation in the high school classroom.Journal of School Psychology,
46(4), 455–475. http://dx.doi.org/10.1016/j.jsp.2007.09.001.
Hamre, B. K., & Pianta, R. C. (2001). Early teacher-child relationships and the trajectory
of children's school outcomes through eighth grade.Child Development, 72(2),
625–638.
Hamre, B. K., & Pianta, R. C. (2006). Student-teacher relationships. In G. G. Bear, & K. M.
Minke (Eds.).Children's needs III: Development, prevention, and intervention(pp. 59–71).
Washington,
DC US: National Association of School Psychologists.
Hoynoski, B., Link, M., & Frankel, M. (2009).Measuring total participation: An alternative
metric to response rate. Paper presented at the 64th Annual Conference of the American
Association for Public Opinion Research, Hollywood, FL.
Johnson, B. (2008). Teacher-student relationships which promote resilience at school: a
micro-level analysis of students' views.British Journal of Guidance and Counselling,
36(4), 385–398.
Juvonen, J. (2006). Sense of belonging, social bonds, and school functioning. In P. A.
Alexander, & P. H. Winne (Eds.).Handbook of educational psychology(pp. 655–674).
Mahwah, NJ, US: Lawrence Erlbaum Associates Publishers.
Kline, R. B. (2011).Principles and practice of structural equation modeling(3rd ed.). New
York: Guilford Press.
Loftus, E. F. (2003). Make-believe memories.American Psychologist, 58(11), 867–873.
http://dx.doi.org/10.1037/0003-066x.58.11.867.
Maehr, M. L. (1976). Continuing motivation: An analysis of a seldom considered educa-
tional outcome.Review of Educational Research, 46(3), 443–462.
Martin, A. J., & Dowson, M. (2009). Interpersonal relationships, motivation, engagement,
and achievement: Yields for theory, current issues, and educational practice.Review
of Educational Research, 79(1), 327–365. http://dx.doi.org/10.3102/
0034654308325583.
McKenzie, J. F., Wood, M. L., Kotecki, J. E., Clark, J. K., & Brey, R. A. (1999). Establishing
content validity: Using qualitative and quantitative steps.American Journal of Health
Behavior, 23(4), 311–318.
Messick, S. (1995). Validity of psychological assessment: Validation of inferences from
persons' responses and performances as scientiﬁc inquiry into score meaning.
American Psychologist, 50(9), 741– 749. http://dx.doi.org/10.1037/0003-066X.50.9.
741.
Midgley, C., Maehr, M. L., Hruda, L. Z., Anderman, E., Anderman, L., Freeman, K. E., ...
Urdan, T. (2000). Patterns of adaptive learning study. Retrieved fromhttp://www.
umich.edu/~pals/PALS%202000_V13Word97.pdf.
Muller, C. (2001). The role of caring in the teacher-student relationship for at-risk stu-
dents. Sociological Inquiry, 71(2), 241–255.
Murdock, T. B. (1999). The social context of risk: Status and motivational predictors of
alienation in middle school.Journal of Educational Psychology, 91(1), 62–75. http://
dx.doi.org/10.1037/0022-0663.91.1.62.
Murdock, T. B., Anderman, L. H., & Hodge, S. A. (2000). Middle-grade predictors of
students' motivation and behavior in high school.Journal of Adolescent Research,
15(3), 327–351. http://dx.doi.org/10.1177/0743558400153002.
Murdock,
T. B., & Miller, A. (2003). Teachers as sources of middle school students' mo-
tivational identity: Variable-centered and person-centered analytic approaches.The
Elementary School Journal, 103(4), 383–399. http://dx.doi.org/10.1086/499732.
Murray, C., & Pianta, R. C. (2007). The importance of teacher-student relationships for
adolescents with high incidence disabilities.Theory Into Practice, 46(2), 105–112.
Pianta, R. C. (1999).Enhancing relationships between children and teachers.Washington
D.C.: American Psychological Association.
Pianta, R. C. (2001).Student-teacher Relationship Scale (STRS): Professional manual.Lutz,
FL: Psychological Assessment Resources.
Pianta, R. C., & Allen, J. P. (2008). Building capacity for positive youth development in
secondary school classrooms: Changing teachers' interactions with students. In M.
Shinn, & H. Yoshikawa (Eds.).Toward positive youth development: Transforming schools
and community programs(pp. 21–39). Oxford: Oxford University Press.
Pianta, R. C., Hamre, B. K., & Stuhlman, M. (2003). Relationships between teachers and
children. In W. M. Reynolds, & G. E. Miller (Vol. Eds.),Handbook of psychology:
Educational psychology. 7. Handbook of psychology: Educational psychology(pp. 199–
234). Hoboken, NJ: John Wiley & Sons, Inc.
Pornprasertmanit, S., Miller, P., Schoemann, A., & Rosseel, Y. (2013).semTools: Useful
tools for structural equation modeling: R package version 0.4-0.Retrieved fromhttp://
CRAN.R-project.org/package=semTools.
R Core Team (2013).R: A Language and Environment for Statistical Computing. R Foundation
for Statistical Computing.Retrieved fromhttp://www.R-project.org/.
Roeser, R. W., Midgley, C., & Urdan, T. C. (1996). Perceptions of the school psychological
environment and early adolescents' psychological and behavioral functioning in
school: The mediating role of goals and belonging.Journal of Educational Psychology,
88(3), 408–422.
Roorda, D., Koomen, H., Split, J. L., & Oort, F. J. (2011). The inﬂuence of aﬀective tea-
cher-student relationships on students' school engagement and achievement: A meta-
analytic approach.Review of Educational Research, 81(4), 493– 529. http://dx.doi.org/
10.3102/0034654311421793.
Rosenberg, M. (1968).The logic of survey analysis.New York: Basic Books.
Rubio, D. M., Berg-Weger, M., Tebb, S. S., Lee, E. S., & Rauch, S. (2003). Objectifying
content validity: Conducting a content validity study in social work research.Social
Work Research, 27(2), 94–104.
Skinner, E., Furrer, C., Marchand, G., & Kindermann, T. (2008). Engagement and dis-
aﬀection in the classroom: Part of a larger motivational dynamic?Journal
 of
Educational Psychology, 100(4), 765–781. http://dx.doi.org/10.1037/a0012840.
Wentzel, K. R. (1997). Student motivation in middle school: The role of perceived ped-
agogical caring.Journal of Educational Psychology, 89(3), 411-419.http://dx.doi.org/
10.1037/0022-0663.89.3.411.
Wentzel, K. R. (1998). Social relationships and motivation in middle school: The role of
parents, teachers, and peers.Journal of Educational Psychology, 90(2), 202– 209.
Wentzel, K. R. (2002). Are eﬀective teachers like good parents? Teaching styles and
student adjustment in early adolescence.Child Development, 73(1), 287–301. http://
dx.doi.org/10.1111/1467-8624.00406.
Wentzel, K. R., Battle, A., Russell, S. L., & Looney, L. B. (2010). Social supports from
teachers and peers as predictors of academic and social motivation.Contemporary
Educational Psychology, 35(3), 193–202. http://dx.doi.org/10.1016/j.cedpsych.2010.
03.002.
Woolley, M. E., & Grogan-Kaylor, A. (2006). Protective family factors in the context of
neighborhood: Promoting positive school outcomes.Family Relations, 55(1), 93–104.
http://dx.doi.org/10.1111/j.1741-3729.2006.00359.x.
M.E. Brinkworth et al. Journal of Applied Developmental Psychology 55 (2018) 24–38
38",
